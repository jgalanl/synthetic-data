{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sdv.metadata import Metadata\n",
    "from sdv.sampling import Condition\n",
    "\n",
    "from sdv.single_table import GaussianCopulaSynthesizer\n",
    "from sdv.single_table import CTGANSynthesizer\n",
    "from sdv.single_table import TVAESynthesizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_ROWS = 50\n",
    "NUM_EPOCHS = 5_000\n",
    "NUM_SYNT_DATA = 25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cargar customizaciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('distributions.json') as f:\n",
    "    distributions = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('constraints.json') as f:\n",
    "    constraints = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GaussianCopulaSynthesizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating synthetic data for set 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling conditions: : 350it [00:02, 143.87it/s]                       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating synthetic data for set 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling conditions: : 350it [00:02, 142.71it/s]                       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating synthetic data for set 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling conditions: : 350it [00:02, 141.84it/s]                       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating synthetic data for set 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling conditions: : 350it [00:02, 144.41it/s]                       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating synthetic data for set 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling conditions: : 350it [00:02, 144.58it/s]                       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating synthetic data for set 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling conditions: : 350it [00:02, 143.93it/s]                       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating synthetic data for set 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling conditions: : 350it [00:02, 141.09it/s]                       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating synthetic data for set 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling conditions: : 350it [00:02, 145.06it/s]                       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating synthetic data for set 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling conditions: : 350it [00:02, 140.02it/s]                       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating synthetic data for set 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling conditions: : 350it [00:02, 143.82it/s]                       \n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print(f'Generating synthetic data for set {i}')\n",
    "    df = pd.read_csv(f'../data/train/set_{i}.csv')\n",
    "    metadata = Metadata()\n",
    "    metadata.detect_table_from_dataframe(data=df, table_name='TLP')\n",
    "    categorical_columns = [\n",
    "        'ED_2Clases'\n",
    "    ]\n",
    "    metadata.update_columns(\n",
    "        column_names=categorical_columns,\n",
    "        sdtype='categorical',\n",
    "        table_name='TLP'\n",
    "    )\n",
    "    numerical_columns = [\n",
    "        'demo-genero',\n",
    "        'clin-reservaCognitiva_escolaridad'\n",
    "    ]\n",
    "    metadata.update_columns(\n",
    "        column_names=numerical_columns,\n",
    "        sdtype='numerical',\n",
    "        computer_representation=\"Int8\",\n",
    "        table_name='TLP'\n",
    "    )\n",
    "    metadata.validate()\n",
    "    if os.path.exists('gc_metadata.json'):\n",
    "        os.remove('gc_metadata.json')\n",
    "    metadata.save_to_json('gc_metadata.json')\n",
    "\n",
    "    num_d, num_h = df['ED_2Clases'].value_counts()\n",
    "    # num_synthetic_data = num_d - num_h\n",
    "\n",
    "    class_d = Condition(\n",
    "        num_rows=num_h,\n",
    "        column_values={'ED_2Clases': 'D'}\n",
    "    )\n",
    "\n",
    "    class_h = Condition(\n",
    "        # num_rows=num_h + num_synthetic_data,\n",
    "        num_rows=num_d,\n",
    "        column_values={'ED_2Clases': 'H'}\n",
    "    )\n",
    "\n",
    "    gc_synthesizer = GaussianCopulaSynthesizer(\n",
    "        metadata,\n",
    "        enforce_min_max_values=False,\n",
    "        enforce_rounding=True,\n",
    "        # numerical_distributions=distributions,\n",
    "        default_distribution='gaussian_kde'\n",
    "    )\n",
    "\n",
    "    gc_synthesizer.add_constraints(constraints)\n",
    "    gc_synthesizer.fit(df)\n",
    "\n",
    "    gc_synthetic_data = gc_synthesizer.sample_from_conditions(\n",
    "        conditions=[class_d, class_h],\n",
    "        batch_size = 50,\n",
    "        max_tries_per_batch = 100\n",
    "    )\n",
    "\n",
    "    # gc_synthetic_data = pd.concat([df, gc_synthetic_data], ignore_index=True)\n",
    "    gc_synthetic_data.to_csv(\n",
    "        f'../data/synthetic/gc/set_{i}.csv',\n",
    "        index=False\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CTGANSynthesizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating synthetic data for set 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Gen. (0.08) | Discrim. (-0.16): 100%|██████████| 5000/5000 [05:03<00:00, 16.48it/s] \n",
      "Sampling conditions: : 225it [00:02, 90.25it/s]                        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating synthetic data for set 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Gen. (-0.64) | Discrim. (0.02): 100%|██████████| 5000/5000 [04:54<00:00, 16.99it/s] \n",
      "Sampling conditions: : 225it [00:02, 98.62it/s]                        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating synthetic data for set 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Gen. (-1.18) | Discrim. (-0.00): 100%|██████████| 5000/5000 [04:55<00:00, 16.92it/s]\n",
      "Sampling conditions: : 225it [00:02, 97.22it/s]                        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating synthetic data for set 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Gen. (-0.84) | Discrim. (-0.09): 100%|██████████| 5000/5000 [04:51<00:00, 17.18it/s]\n",
      "Sampling conditions: : 225it [00:02, 98.54it/s]                        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating synthetic data for set 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Gen. (-1.57) | Discrim. (0.25): 100%|██████████| 5000/5000 [04:54<00:00, 16.98it/s] \n",
      "Sampling conditions: : 225it [00:02, 96.59it/s]                        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating synthetic data for set 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Gen. (-2.01) | Discrim. (-0.09): 100%|██████████| 5000/5000 [04:46<00:00, 17.42it/s]\n",
      "Sampling conditions: : 225it [00:02, 98.74it/s]                        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating synthetic data for set 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Gen. (-0.98) | Discrim. (0.08): 100%|██████████| 5000/5000 [04:54<00:00, 17.00it/s] \n",
      "Sampling conditions: : 225it [00:02, 98.32it/s]                        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating synthetic data for set 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Gen. (-1.86) | Discrim. (-0.21): 100%|██████████| 5000/5000 [04:50<00:00, 17.22it/s]\n",
      "Sampling conditions: : 225it [00:02, 95.98it/s]                        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating synthetic data for set 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Gen. (-0.88) | Discrim. (0.02): 100%|██████████| 5000/5000 [04:56<00:00, 16.85it/s] \n",
      "Sampling conditions: : 225it [00:02, 98.01it/s]                        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating synthetic data for set 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Gen. (-1.01) | Discrim. (0.12): 100%|██████████| 5000/5000 [04:54<00:00, 17.00it/s] \n",
      "Sampling conditions: : 225it [00:02, 96.46it/s]                        \n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print(f'Generating synthetic data for set {i}')\n",
    "    df = pd.read_csv(f'../data/train/set_{i}.csv')\n",
    "    metadata = Metadata()\n",
    "    metadata.detect_table_from_dataframe(data=df, table_name='TLP')\n",
    "    categorical_columns = [\n",
    "        'ED_2Clases'\n",
    "    ]\n",
    "    metadata.update_columns(\n",
    "        column_names=categorical_columns,\n",
    "        sdtype='categorical',\n",
    "        table_name='TLP'\n",
    "    )\n",
    "    numerical_columns = [\n",
    "        'demo-genero',\n",
    "        'clin-reservaCognitiva_escolaridad'\n",
    "    ]\n",
    "    metadata.update_columns(\n",
    "        column_names=numerical_columns,\n",
    "        sdtype='numerical',\n",
    "        table_name='TLP'\n",
    "    )\n",
    "    metadata.validate()\n",
    "    if os.path.exists('ctgan_metadata.json'):\n",
    "        os.remove('ctgan_metadata.json')\n",
    "    metadata.save_to_json('ctgan_metadata.json')\n",
    "\n",
    "    num_d, num_h = df['ED_2Clases'].value_counts()\n",
    "    num_synthetic_data = num_d - num_h\n",
    "\n",
    "    class_d = Condition(\n",
    "        num_rows=NUM_SYNT_DATA,\n",
    "        column_values={'ED_2Clases': 'D'}\n",
    "    )\n",
    "\n",
    "    class_h = Condition(\n",
    "        num_rows=NUM_SYNT_DATA + num_synthetic_data,\n",
    "        column_values={'ED_2Clases': 'H'}\n",
    "    )\n",
    "\n",
    "    ctgan_synthesizer = CTGANSynthesizer(\n",
    "        metadata,\n",
    "        enforce_min_max_values=False,\n",
    "        enforce_rounding=True,\n",
    "        epochs=NUM_EPOCHS,\n",
    "        verbose=True,\n",
    "        cuda=True\n",
    "    )\n",
    "\n",
    "    ctgan_synthesizer.add_constraints(constraints)\n",
    "    ctgan_synthesizer.fit(df)\n",
    "\n",
    "    ctgan_synthetic_data = ctgan_synthesizer.sample_from_conditions(\n",
    "        conditions=[class_d, class_h],\n",
    "        batch_size = 50,\n",
    "        max_tries_per_batch = 100\n",
    "    )\n",
    "    ctgan_synthetic_data = pd.concat([df, ctgan_synthetic_data], ignore_index=True)\n",
    "    ctgan_synthetic_data.to_csv(\n",
    "        f'../data/synthetic/ctgan/set_{i}.csv',\n",
    "        index=False\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TVAESynthesizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating synthetic data for set 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: -113.824: 100%|██████████| 5000/5000 [01:40<00:00, 49.79it/s]\n",
      "Sampling conditions: : 225it [00:01, 131.23it/s]                       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating synthetic data for set 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: -113.016: 100%|██████████| 5000/5000 [01:39<00:00, 50.40it/s]\n",
      "Sampling conditions: : 225it [00:02, 103.82it/s]                       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating synthetic data for set 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: -114.027: 100%|██████████| 5000/5000 [01:40<00:00, 49.63it/s]\n",
      "Sampling conditions: : 225it [00:02, 103.98it/s]                       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating synthetic data for set 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: -119.794: 100%|██████████| 5000/5000 [01:39<00:00, 50.05it/s]\n",
      "Sampling conditions: : 225it [00:02, 106.21it/s]                       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating synthetic data for set 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: -117.437: 100%|██████████| 5000/5000 [01:41<00:00, 49.13it/s]\n",
      "Sampling conditions: : 225it [00:01, 113.14it/s]                       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating synthetic data for set 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: -115.979: 100%|██████████| 5000/5000 [01:39<00:00, 50.06it/s]\n",
      "Sampling conditions: : 225it [00:02, 98.21it/s]                        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating synthetic data for set 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: -115.674: 100%|██████████| 5000/5000 [01:40<00:00, 49.80it/s]\n",
      "Sampling conditions: : 225it [00:01, 125.00it/s]                       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating synthetic data for set 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: -109.966: 100%|██████████| 5000/5000 [01:38<00:00, 50.65it/s]\n",
      "Sampling conditions: : 225it [00:01, 125.00it/s]                       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating synthetic data for set 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: -116.295: 100%|██████████| 5000/5000 [01:39<00:00, 50.28it/s]\n",
      "Sampling conditions: : 225it [00:01, 123.85it/s]                       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating synthetic data for set 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: -116.255: 100%|██████████| 5000/5000 [01:42<00:00, 48.56it/s]\n",
      "Sampling conditions: : 225it [00:01, 127.47it/s]                       \n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print(f'Generating synthetic data for set {i}')\n",
    "    df = pd.read_csv(f'../data/train/set_{i}.csv')\n",
    "    metadata = Metadata()\n",
    "    metadata.detect_table_from_dataframe(data=df, table_name='TLP')\n",
    "    categorical_columns = [\n",
    "        'ED_2Clases'\n",
    "    ]\n",
    "    metadata.update_columns(\n",
    "        column_names=categorical_columns,\n",
    "        sdtype='categorical',\n",
    "        table_name='TLP'\n",
    "    )\n",
    "    numerical_columns = [\n",
    "        'demo-genero',\n",
    "        'clin-reservaCognitiva_escolaridad'\n",
    "    ]\n",
    "    metadata.update_columns(\n",
    "        column_names=numerical_columns,\n",
    "        sdtype='numerical',\n",
    "        table_name='TLP'\n",
    "    )\n",
    "    metadata.validate()\n",
    "    if os.path.exists('tvaes_metadata.json'):\n",
    "        os.remove('tvaes_metadata.json')\n",
    "    metadata.save_to_json('tvaes_metadata.json')\n",
    "\n",
    "    num_d, num_h = df['ED_2Clases'].value_counts()\n",
    "    num_synthetic_data = num_d - num_h\n",
    "\n",
    "    class_d = Condition(\n",
    "        num_rows=NUM_SYNT_DATA,\n",
    "        column_values={'ED_2Clases': 'D'}\n",
    "    )\n",
    "\n",
    "    class_h = Condition(\n",
    "        num_rows=NUM_SYNT_DATA + num_synthetic_data,\n",
    "        column_values={'ED_2Clases': 'H'}\n",
    "    )\n",
    "\n",
    "    tvaes_synthesizer = TVAESynthesizer(\n",
    "        metadata,\n",
    "        enforce_min_max_values=False,\n",
    "        enforce_rounding=True,\n",
    "        epochs=NUM_EPOCHS,\n",
    "        verbose=True,\n",
    "        cuda=True\n",
    "    )\n",
    "\n",
    "    tvaes_synthesizer.add_constraints(constraints)\n",
    "    tvaes_synthesizer.fit(df)\n",
    "    tvaes_synthetic_data = tvaes_synthesizer.sample_from_conditions(\n",
    "        conditions=[class_d, class_h],\n",
    "        batch_size = 50,\n",
    "        max_tries_per_batch = 100\n",
    "    )\n",
    "    tvaes_synthetic_data = pd.concat([df, tvaes_synthetic_data], ignore_index=True)\n",
    "    tvaes_synthetic_data.to_csv(\n",
    "        f'../data/synthetic/tvaes/set_{i}.csv',\n",
    "        index=False\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
