{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sdv.metadata import Metadata\n",
    "from sdv.sampling import Condition\n",
    "\n",
    "from sdv.single_table import GaussianCopulaSynthesizer\n",
    "from sdv.single_table import CTGANSynthesizer\n",
    "from sdv.single_table import TVAESynthesizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_ROWS = 50\n",
    "NUM_EPOCHS = 5_000\n",
    "NUM_SYNT_DATA = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def round_to_nearest_half(x):\n",
    "    return round(x * 2) / 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cargar customizaciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('distributions.json') as f:\n",
    "    distributions = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('constraints.json') as f:\n",
    "    constraints = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GaussianCopulaSynthesizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating synthetic data for set 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling conditions: : 400it [00:02, 145.80it/s]                       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating synthetic data for set 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling conditions: : 400it [00:02, 144.56it/s]                       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating synthetic data for set 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling conditions: : 400it [00:02, 144.95it/s]                       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating synthetic data for set 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling conditions: : 400it [00:02, 144.72it/s]                       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating synthetic data for set 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling conditions: : 400it [00:02, 146.11it/s]                       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating synthetic data for set 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling conditions: : 400it [00:02, 146.73it/s]                       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating synthetic data for set 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling conditions: : 400it [00:02, 142.72it/s]                       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating synthetic data for set 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling conditions: : 400it [00:02, 144.96it/s]                       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating synthetic data for set 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling conditions: : 400it [00:02, 149.90it/s]                       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating synthetic data for set 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling conditions: : 400it [00:02, 147.55it/s]                       \n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print(f'Generating synthetic data for set {i}')\n",
    "    df = pd.read_csv(f'../data/train/set_{i}.csv')\n",
    "    metadata = Metadata()\n",
    "    metadata.detect_table_from_dataframe(data=df, table_name='TLP')\n",
    "    categorical_columns = [\n",
    "        'ED_2Clases'\n",
    "    ]\n",
    "    metadata.update_columns(\n",
    "        column_names=categorical_columns,\n",
    "        sdtype='categorical',\n",
    "        table_name='TLP'\n",
    "    )\n",
    "    numerical_columns = [\n",
    "        'demo-genero',\n",
    "        'clin-reservaCognitiva_escolaridad'\n",
    "    ]\n",
    "    metadata.update_columns(\n",
    "        column_names=numerical_columns,\n",
    "        sdtype='numerical',\n",
    "        table_name='TLP'\n",
    "    )\n",
    "    metadata.validate()\n",
    "    if os.path.exists('gc_metadata.json'):\n",
    "        os.remove('gc_metadata.json')\n",
    "    metadata.save_to_json('gc_metadata.json')\n",
    "\n",
    "    num_d, num_h = df['ED_2Clases'].value_counts()\n",
    "    num_synthetic_data = num_d - num_h\n",
    "\n",
    "    class_d = Condition(\n",
    "        num_rows=NUM_SYNT_DATA,\n",
    "        column_values={'ED_2Clases': 'D'}\n",
    "    )\n",
    "\n",
    "    class_h = Condition(\n",
    "        num_rows=NUM_SYNT_DATA + num_synthetic_data,\n",
    "        column_values={'ED_2Clases': 'H'}\n",
    "    )\n",
    "\n",
    "    gc_synthesizer = GaussianCopulaSynthesizer(\n",
    "        metadata,\n",
    "        enforce_min_max_values=False,\n",
    "        enforce_rounding=True,\n",
    "        # numerical_distributions=distributions,\n",
    "        default_distribution='gaussian_kde'\n",
    "    )\n",
    "\n",
    "    gc_synthesizer.add_constraints(constraints)\n",
    "    gc_synthesizer.fit(df)\n",
    "\n",
    "    gc_synthetic_data = gc_synthesizer.sample_from_conditions(\n",
    "        conditions=[class_d, class_h],\n",
    "        batch_size = 50,\n",
    "        max_tries_per_batch = 100\n",
    "    )\n",
    "\n",
    "    gc_synthetic_data = pd.concat([df, gc_synthetic_data], ignore_index=True)\n",
    "    gc_synthetic_data.to_csv(\n",
    "        f'../data/synthetic/gc/set_{i}.csv',\n",
    "        index=False\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CTGANSynthesizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating synthetic data for set 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Gen. (-0.55) | Discrim. (-0.14): 100%|██████████| 5000/5000 [04:51<00:00, 17.16it/s]\n",
      "Sampling conditions: : 400it [00:03, 115.37it/s]                       \n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "Cannot save file into a non-existent directory: '..\\..\\data\\synthetic\\ctgan'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mOSError\u001b[39m                                   Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[27]\u001b[39m\u001b[32m, line 59\u001b[39m\n\u001b[32m     53\u001b[39m ctgan_synthetic_data = ctgan_synthesizer.sample_from_conditions(\n\u001b[32m     54\u001b[39m     conditions=[class_d, class_h],\n\u001b[32m     55\u001b[39m     batch_size = \u001b[32m50\u001b[39m,\n\u001b[32m     56\u001b[39m     max_tries_per_batch = \u001b[32m100\u001b[39m\n\u001b[32m     57\u001b[39m )\n\u001b[32m     58\u001b[39m ctgan_synthetic_data = pd.concat([df, ctgan_synthetic_data], ignore_index=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m---> \u001b[39m\u001b[32m59\u001b[39m \u001b[43mctgan_synthetic_data\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto_csv\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     60\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m../../data/synthetic/ctgan/set_\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mi\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m.csv\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     61\u001b[39m \u001b[43m    \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[32m     62\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.conda\\Lib\\site-packages\\pandas\\util\\_decorators.py:333\u001b[39m, in \u001b[36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    327\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) > num_allow_args:\n\u001b[32m    328\u001b[39m     warnings.warn(\n\u001b[32m    329\u001b[39m         msg.format(arguments=_format_argument_list(allow_args)),\n\u001b[32m    330\u001b[39m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[32m    331\u001b[39m         stacklevel=find_stack_level(),\n\u001b[32m    332\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m333\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.conda\\Lib\\site-packages\\pandas\\core\\generic.py:3967\u001b[39m, in \u001b[36mNDFrame.to_csv\u001b[39m\u001b[34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, decimal, errors, storage_options)\u001b[39m\n\u001b[32m   3956\u001b[39m df = \u001b[38;5;28mself\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m, ABCDataFrame) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m.to_frame()\n\u001b[32m   3958\u001b[39m formatter = DataFrameFormatter(\n\u001b[32m   3959\u001b[39m     frame=df,\n\u001b[32m   3960\u001b[39m     header=header,\n\u001b[32m   (...)\u001b[39m\u001b[32m   3964\u001b[39m     decimal=decimal,\n\u001b[32m   3965\u001b[39m )\n\u001b[32m-> \u001b[39m\u001b[32m3967\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mDataFrameRenderer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mformatter\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto_csv\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   3968\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpath_or_buf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3969\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlineterminator\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlineterminator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3970\u001b[39m \u001b[43m    \u001b[49m\u001b[43msep\u001b[49m\u001b[43m=\u001b[49m\u001b[43msep\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3971\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3972\u001b[39m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3973\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3974\u001b[39m \u001b[43m    \u001b[49m\u001b[43mquoting\u001b[49m\u001b[43m=\u001b[49m\u001b[43mquoting\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3975\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3976\u001b[39m \u001b[43m    \u001b[49m\u001b[43mindex_label\u001b[49m\u001b[43m=\u001b[49m\u001b[43mindex_label\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3977\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3978\u001b[39m \u001b[43m    \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunksize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3979\u001b[39m \u001b[43m    \u001b[49m\u001b[43mquotechar\u001b[49m\u001b[43m=\u001b[49m\u001b[43mquotechar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3980\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdate_format\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdate_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3981\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdoublequote\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdoublequote\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3982\u001b[39m \u001b[43m    \u001b[49m\u001b[43mescapechar\u001b[49m\u001b[43m=\u001b[49m\u001b[43mescapechar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3983\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3984\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.conda\\Lib\\site-packages\\pandas\\io\\formats\\format.py:1014\u001b[39m, in \u001b[36mDataFrameRenderer.to_csv\u001b[39m\u001b[34m(self, path_or_buf, encoding, sep, columns, index_label, mode, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, errors, storage_options)\u001b[39m\n\u001b[32m    993\u001b[39m     created_buffer = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m    995\u001b[39m csv_formatter = CSVFormatter(\n\u001b[32m    996\u001b[39m     path_or_buf=path_or_buf,\n\u001b[32m    997\u001b[39m     lineterminator=lineterminator,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1012\u001b[39m     formatter=\u001b[38;5;28mself\u001b[39m.fmt,\n\u001b[32m   1013\u001b[39m )\n\u001b[32m-> \u001b[39m\u001b[32m1014\u001b[39m \u001b[43mcsv_formatter\u001b[49m\u001b[43m.\u001b[49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1016\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m created_buffer:\n\u001b[32m   1017\u001b[39m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path_or_buf, StringIO)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.conda\\Lib\\site-packages\\pandas\\io\\formats\\csvs.py:251\u001b[39m, in \u001b[36mCSVFormatter.save\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    247\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    248\u001b[39m \u001b[33;03mCreate the writer & save.\u001b[39;00m\n\u001b[32m    249\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    250\u001b[39m \u001b[38;5;66;03m# apply compression and byte/text conversion\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m251\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    252\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    253\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    254\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    255\u001b[39m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    256\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    257\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    258\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m handles:\n\u001b[32m    259\u001b[39m     \u001b[38;5;66;03m# Note: self.encoding is irrelevant here\u001b[39;00m\n\u001b[32m    260\u001b[39m     \u001b[38;5;28mself\u001b[39m.writer = csvlib.writer(\n\u001b[32m    261\u001b[39m         handles.handle,\n\u001b[32m    262\u001b[39m         lineterminator=\u001b[38;5;28mself\u001b[39m.lineterminator,\n\u001b[32m   (...)\u001b[39m\u001b[32m    267\u001b[39m         quotechar=\u001b[38;5;28mself\u001b[39m.quotechar,\n\u001b[32m    268\u001b[39m     )\n\u001b[32m    270\u001b[39m     \u001b[38;5;28mself\u001b[39m._save()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.conda\\Lib\\site-packages\\pandas\\io\\common.py:749\u001b[39m, in \u001b[36mget_handle\u001b[39m\u001b[34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[39m\n\u001b[32m    747\u001b[39m \u001b[38;5;66;03m# Only for write methods\u001b[39;00m\n\u001b[32m    748\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode \u001b[38;5;129;01mand\u001b[39;00m is_path:\n\u001b[32m--> \u001b[39m\u001b[32m749\u001b[39m     \u001b[43mcheck_parent_directory\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    751\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m compression:\n\u001b[32m    752\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m compression != \u001b[33m\"\u001b[39m\u001b[33mzstd\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    753\u001b[39m         \u001b[38;5;66;03m# compression libraries do not like an explicit text-mode\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.conda\\Lib\\site-packages\\pandas\\io\\common.py:616\u001b[39m, in \u001b[36mcheck_parent_directory\u001b[39m\u001b[34m(path)\u001b[39m\n\u001b[32m    614\u001b[39m parent = Path(path).parent\n\u001b[32m    615\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m parent.is_dir():\n\u001b[32m--> \u001b[39m\u001b[32m616\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\u001b[33mrf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mCannot save file into a non-existent directory: \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparent\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mOSError\u001b[39m: Cannot save file into a non-existent directory: '..\\..\\data\\synthetic\\ctgan'"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print(f'Generating synthetic data for set {i}')\n",
    "    df = pd.read_csv(f'../data/train/set_{i}.csv')\n",
    "    metadata = Metadata()\n",
    "    metadata.detect_table_from_dataframe(data=df, table_name='TLP')\n",
    "    categorical_columns = [\n",
    "        'ED_2Clases'\n",
    "    ]\n",
    "    metadata.update_columns(\n",
    "        column_names=categorical_columns,\n",
    "        sdtype='categorical',\n",
    "        table_name='TLP'\n",
    "    )\n",
    "    numerical_columns = [\n",
    "        'demo-genero',\n",
    "        'clin-reservaCognitiva_escolaridad'\n",
    "    ]\n",
    "    metadata.update_columns(\n",
    "        column_names=numerical_columns,\n",
    "        sdtype='numerical',\n",
    "        table_name='TLP'\n",
    "    )\n",
    "    metadata.validate()\n",
    "    if os.path.exists('ctgan_metadata.json'):\n",
    "        os.remove('ctgan_metadata.json')\n",
    "    metadata.save_to_json('ctgan_metadata.json')\n",
    "\n",
    "    num_d, num_h = df['ED_2Clases'].value_counts()\n",
    "    num_synthetic_data = num_d - num_h\n",
    "\n",
    "    class_d = Condition(\n",
    "        num_rows=NUM_SYNT_DATA,\n",
    "        column_values={'ED_2Clases': 'D'}\n",
    "    )\n",
    "\n",
    "    class_h = Condition(\n",
    "        num_rows=NUM_SYNT_DATA + num_synthetic_data,\n",
    "        column_values={'ED_2Clases': 'H'}\n",
    "    )\n",
    "\n",
    "    ctgan_synthesizer = CTGANSynthesizer(\n",
    "        metadata,\n",
    "        enforce_min_max_values=False,\n",
    "        enforce_rounding=True,\n",
    "        epochs=NUM_EPOCHS,\n",
    "        verbose=True,\n",
    "        cuda=True\n",
    "    )\n",
    "\n",
    "    ctgan_synthesizer.add_constraints(constraints)\n",
    "    ctgan_synthesizer.fit(df)\n",
    "\n",
    "    ctgan_synthetic_data = ctgan_synthesizer.sample_from_conditions(\n",
    "        conditions=[class_d, class_h],\n",
    "        batch_size = 50,\n",
    "        max_tries_per_batch = 100\n",
    "    )\n",
    "    ctgan_synthetic_data = pd.concat([df, ctgan_synthetic_data], ignore_index=True)\n",
    "    ctgan_synthetic_data.to_csv(\n",
    "        f'../data/synthetic/ctgan/set_{i}.csv',\n",
    "        index=False\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.3. TVAESynthesizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    print(f'Generating synthetic data for set {i}')\n",
    "    df = pd.read_csv(f'../../data/train/set_{i}.csv')\n",
    "    metadata = Metadata()\n",
    "    metadata.detect_table_from_dataframe(data=df, table_name='TLP')\n",
    "    categorical_columns = [\n",
    "        'ED_2Clases', 'clin-frecUsoEmail'\n",
    "    ]\n",
    "    metadata.update_columns(\n",
    "        column_names=categorical_columns,\n",
    "        sdtype='categorical',\n",
    "        table_name='TLP'\n",
    "    )\n",
    "    metadata.validate()\n",
    "\n",
    "    num_d, num_h = df['ED_2Clases'].value_counts()\n",
    "    num_synthetic_data = num_d - num_h\n",
    "\n",
    "    class_d = Condition(\n",
    "        num_rows=NUM_SYNT_DATA,\n",
    "        column_values={'ED_2Clases': 'D'}\n",
    "    )\n",
    "\n",
    "    class_h = Condition(\n",
    "        num_rows=NUM_SYNT_DATA + num_synthetic_data,\n",
    "        column_values={'ED_2Clases': 'H'}\n",
    "    )\n",
    "\n",
    "    tvaes_synthesizer = TVAESynthesizer(\n",
    "        metadata,\n",
    "        enforce_min_max_values=True,\n",
    "        enforce_rounding=True,\n",
    "        epochs=NUM_EPOCHS,\n",
    "        verbose=True,\n",
    "        cuda=True\n",
    "    )\n",
    "\n",
    "    tvaes_synthesizer.auto_assign_transformers(df)\n",
    "    processed_df = tvaes_synthesizer.preprocess(df)\n",
    "    tvaes_synthesizer.fit_processed_data(processed_df)\n",
    "    tvaes_synthetic_data = tvaes_synthesizer.sample_from_conditions(\n",
    "        conditions=[class_d, class_h],\n",
    "        batch_size = 50,\n",
    "        max_tries_per_batch = 100\n",
    "    )\n",
    "    tvaes_synthetic_data = pd.concat([df, tvaes_synthetic_data], ignore_index=True)\n",
    "    tvaes_synthetic_data.to_csv(\n",
    "        f'../../data/synthetic/tvaes/set_{i}.csv',\n",
    "        index=False\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.4. CopulaGANSynthesizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    print(f'Generating synthetic data for set {i}')\n",
    "    df = pd.read_csv(f'../../data/train/set_{i}.csv')\n",
    "    metadata = Metadata()\n",
    "    metadata.detect_table_from_dataframe(data=df, table_name='TLP')\n",
    "    categorical_columns = [\n",
    "        'ED_2Clases', 'clin-frecUsoEmail'\n",
    "    ]\n",
    "    metadata.update_columns(\n",
    "        column_names=categorical_columns,\n",
    "        sdtype='categorical',\n",
    "        table_name='TLP'\n",
    "    )\n",
    "    metadata.validate()\n",
    "\n",
    "    num_d, num_h = df['ED_2Clases'].value_counts()\n",
    "    num_synthetic_data = num_d - num_h\n",
    "\n",
    "    class_d = Condition(\n",
    "        num_rows=NUM_SYNT_DATA,\n",
    "        column_values={'ED_2Clases': 'D'}\n",
    "    )\n",
    "\n",
    "    class_h = Condition(\n",
    "        num_rows=NUM_SYNT_DATA + num_synthetic_data,\n",
    "        column_values={'ED_2Clases': 'H'}\n",
    "    )\n",
    "\n",
    "    cg_synthesizer = CopulaGANSynthesizer(\n",
    "        metadata,\n",
    "        enforce_min_max_values=True,\n",
    "        enforce_rounding=True,\n",
    "        epochs=NUM_EPOCHS,\n",
    "        verbose=True,\n",
    "        cuda=True\n",
    "    )\n",
    "\n",
    "    cg_synthesizer.auto_assign_transformers(df)\n",
    "    processed_df = cg_synthesizer.preprocess(df)\n",
    "    cg_synthesizer.fit_processed_data(processed_df)\n",
    "    cg_synthetic_data = cg_synthesizer.sample_from_conditions(\n",
    "        conditions=[class_d, class_h],\n",
    "        batch_size = 50,\n",
    "        max_tries_per_batch = 100\n",
    "    )\n",
    "    cg_synthetic_data = pd.concat([df, cg_synthetic_data], ignore_index=True)\n",
    "    cg_synthetic_data.to_csv(\n",
    "        f'../../data/synthetic/cg/set_{i}.csv',\n",
    "        index=False\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Evaluating Real vs. Synthetic Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sdv.evaluation.single_table import get_column_plot\n",
    "\n",
    "plot_columns = list(df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.1. GaussianCopulaSynthesizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sdv.evaluation.single_table import run_diagnostic\n",
    "\n",
    "gc_diagnostic = run_diagnostic(\n",
    "    real_data=df,\n",
    "    synthetic_data=gc_synthetic_data,\n",
    "    metadata=metadata\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sdv.evaluation.single_table import evaluate_quality\n",
    "\n",
    "gc_quality_report = evaluate_quality(\n",
    "    df,\n",
    "    gc_synthetic_data,\n",
    "    metadata\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc_details = gc_quality_report.get_details('Column Pair Trends')\n",
    "gc_details[gc_details['Real Correlation'].notnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc_quality_report.get_details('Column Shapes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in plot_columns:\n",
    "     fig = get_column_plot(\n",
    "         real_data=df,\n",
    "         synthetic_data=gc_synthetic_data,\n",
    "         column_name=column,\n",
    "         metadata=metadata\n",
    "     )\n",
    "     fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.2. CTGANSynthesizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctgan_diagnostic = run_diagnostic(\n",
    "    real_data=df,\n",
    "    synthetic_data=ctgan_synthetic_data,\n",
    "    metadata=metadata\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctgan_quality_report = evaluate_quality(\n",
    "    df,\n",
    "    ctgan_synthetic_data,\n",
    "    metadata\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctgan_details = ctgan_quality_report.get_details('Column Pair Trends')\n",
    "ctgan_details[ctgan_details['Real Correlation'].notnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctgan_quality_report.get_details('Column Shapes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in plot_columns:\n",
    "    fig = get_column_plot(\n",
    "        real_data=df,\n",
    "        synthetic_data=ctgan_synthetic_data,\n",
    "        column_name=column,\n",
    "        metadata=metadata\n",
    "    )\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.3. TVAESSynthesizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tvaes_diagnostic = run_diagnostic(\n",
    "    real_data=df,\n",
    "    synthetic_data=tvaes_synthetic_data,\n",
    "    metadata=metadata\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tvaes_quality_report = evaluate_quality(\n",
    "    df,\n",
    "    tvaes_synthetic_data,\n",
    "    metadata\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tvaes_details = tvaes_quality_report.get_details('Column Pair Trends')\n",
    "tvaes_details[tvaes_details['Real Correlation'].notnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tvaes_quality_report.get_details('Column Shapes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in plot_columns:\n",
    "    fig = get_column_plot(\n",
    "        real_data=df,\n",
    "        synthetic_data=tvaes_synthetic_data,\n",
    "        column_name=column,\n",
    "        metadata=metadata\n",
    "    )\n",
    "    fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
