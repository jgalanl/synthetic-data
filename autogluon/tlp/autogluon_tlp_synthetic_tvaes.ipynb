{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from autogluon.tabular import TabularPredictor\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../../data/tlp/synthetic-tvaes.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>demo-genero</th>\n",
       "      <th>demo-fechaEvaluacion</th>\n",
       "      <th>demo-fechaNacimiento</th>\n",
       "      <th>demo-rangoEdad</th>\n",
       "      <th>demo-edad</th>\n",
       "      <th>clin-reservaCognitiva_total</th>\n",
       "      <th>clin-reservaCognitiva_idiomas</th>\n",
       "      <th>clin-reservaCognitiva_ocupacion</th>\n",
       "      <th>clin-reservaCognitiva_escolaridad</th>\n",
       "      <th>clin-ansiedad</th>\n",
       "      <th>...</th>\n",
       "      <th>eval-TLP-Tavec-25_Discriminabilidad-PD</th>\n",
       "      <th>eval-TLP-Tavec-26_Sesgo-PD</th>\n",
       "      <th>eval-TLP-Tavec-27_RI_B_frente_RI_A1-PD</th>\n",
       "      <th>eval-TLP-Tavec-28_RL_CP_frente_RI_A5-PD</th>\n",
       "      <th>eval-TLP-Tavec-29_RCl_Cp_frente_RCl_LP-PD</th>\n",
       "      <th>eval-TLP-Tavec-30_RL_LP_frente_RL_CP-PD</th>\n",
       "      <th>eval-TLP-Tavec-31_RCl_LP_frente_RL_LP-PD</th>\n",
       "      <th>eval-TLP-Tavec-32_Recon_Ac_frente_RL_LP-PD</th>\n",
       "      <th>eval-TLP-Tavec-33_Recon_Ac_frente_RCl_LP-PD</th>\n",
       "      <th>ED_2Clases</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>2024-02-22T00:00:00</td>\n",
       "      <td>1942-05-08T00:00:00</td>\n",
       "      <td>Rango3</td>\n",
       "      <td>81</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>84.09</td>\n",
       "      <td>0.14</td>\n",
       "      <td>-20.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>33.33</td>\n",
       "      <td>37.50</td>\n",
       "      <td>-33.33</td>\n",
       "      <td>-38.46</td>\n",
       "      <td>-7.69</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2024-06-26T00:00:00</td>\n",
       "      <td>1948-10-07T00:00:00</td>\n",
       "      <td>Rango3</td>\n",
       "      <td>75</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>79.55</td>\n",
       "      <td>-0.33</td>\n",
       "      <td>-71.43</td>\n",
       "      <td>12.50</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-20.00</td>\n",
       "      <td>-20.00</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2024-05-14T00:00:00</td>\n",
       "      <td>1952-05-08T00:00:00</td>\n",
       "      <td>Rango2</td>\n",
       "      <td>72</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>88.64</td>\n",
       "      <td>-0.60</td>\n",
       "      <td>-14.29</td>\n",
       "      <td>75.00</td>\n",
       "      <td>25.00</td>\n",
       "      <td>-20.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-16.67</td>\n",
       "      <td>-16.67</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>2024-04-10T00:00:00</td>\n",
       "      <td>1964-01-27T00:00:00</td>\n",
       "      <td>Rango1</td>\n",
       "      <td>60</td>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>90.91</td>\n",
       "      <td>0.60</td>\n",
       "      <td>60.00</td>\n",
       "      <td>16.67</td>\n",
       "      <td>0.00</td>\n",
       "      <td>50.00</td>\n",
       "      <td>-20.00</td>\n",
       "      <td>-50.00</td>\n",
       "      <td>-37.50</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>2024-05-14T00:00:00</td>\n",
       "      <td>1959-09-16T00:00:00</td>\n",
       "      <td>Rango1</td>\n",
       "      <td>64</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>86.36</td>\n",
       "      <td>-0.71</td>\n",
       "      <td>0.00</td>\n",
       "      <td>66.67</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-33.33</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-10.00</td>\n",
       "      <td>-10.00</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 80 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   demo-genero demo-fechaEvaluacion demo-fechaNacimiento demo-rangoEdad  \\\n",
       "0            2  2024-02-22T00:00:00  1942-05-08T00:00:00         Rango3   \n",
       "1            2  2024-06-26T00:00:00  1948-10-07T00:00:00         Rango3   \n",
       "2            2  2024-05-14T00:00:00  1952-05-08T00:00:00         Rango2   \n",
       "3            2  2024-04-10T00:00:00  1964-01-27T00:00:00         Rango1   \n",
       "4            2  2024-05-14T00:00:00  1959-09-16T00:00:00         Rango1   \n",
       "\n",
       "   demo-edad  clin-reservaCognitiva_total  clin-reservaCognitiva_idiomas  \\\n",
       "0         81                           12                              0   \n",
       "1         75                            8                              0   \n",
       "2         72                           11                              0   \n",
       "3         60                           18                              2   \n",
       "4         64                           13                              0   \n",
       "\n",
       "   clin-reservaCognitiva_ocupacion  clin-reservaCognitiva_escolaridad  \\\n",
       "0                                1                                  3   \n",
       "1                                1                                  3   \n",
       "2                                0                                  4   \n",
       "3                                1                                  4   \n",
       "4                                1                                  4   \n",
       "\n",
       "   clin-ansiedad  ...  eval-TLP-Tavec-25_Discriminabilidad-PD  \\\n",
       "0          False  ...                                   84.09   \n",
       "1           True  ...                                   79.55   \n",
       "2          False  ...                                   88.64   \n",
       "3          False  ...                                   90.91   \n",
       "4          False  ...                                   86.36   \n",
       "\n",
       "   eval-TLP-Tavec-26_Sesgo-PD  eval-TLP-Tavec-27_RI_B_frente_RI_A1-PD  \\\n",
       "0                        0.14                                  -20.00   \n",
       "1                       -0.33                                  -71.43   \n",
       "2                       -0.60                                  -14.29   \n",
       "3                        0.60                                   60.00   \n",
       "4                       -0.71                                    0.00   \n",
       "\n",
       "   eval-TLP-Tavec-28_RL_CP_frente_RI_A5-PD  \\\n",
       "0                                     0.00   \n",
       "1                                    12.50   \n",
       "2                                    75.00   \n",
       "3                                    16.67   \n",
       "4                                    66.67   \n",
       "\n",
       "   eval-TLP-Tavec-29_RCl_Cp_frente_RCl_LP-PD  \\\n",
       "0                                      33.33   \n",
       "1                                       0.00   \n",
       "2                                      25.00   \n",
       "3                                       0.00   \n",
       "4                                       0.00   \n",
       "\n",
       "   eval-TLP-Tavec-30_RL_LP_frente_RL_CP-PD  \\\n",
       "0                                    37.50   \n",
       "1                                     0.00   \n",
       "2                                   -20.00   \n",
       "3                                    50.00   \n",
       "4                                   -33.33   \n",
       "\n",
       "   eval-TLP-Tavec-31_RCl_LP_frente_RL_LP-PD  \\\n",
       "0                                    -33.33   \n",
       "1                                      0.00   \n",
       "2                                      0.00   \n",
       "3                                    -20.00   \n",
       "4                                      0.00   \n",
       "\n",
       "   eval-TLP-Tavec-32_Recon_Ac_frente_RL_LP-PD  \\\n",
       "0                                      -38.46   \n",
       "1                                      -20.00   \n",
       "2                                      -16.67   \n",
       "3                                      -50.00   \n",
       "4                                      -10.00   \n",
       "\n",
       "   eval-TLP-Tavec-33_Recon_Ac_frente_RCl_LP-PD ED_2Clases  \n",
       "0                                        -7.69          D  \n",
       "1                                       -20.00          D  \n",
       "2                                       -16.67          D  \n",
       "3                                       -37.50          D  \n",
       "4                                       -10.00          D  \n",
       "\n",
       "[5 rows x 80 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((396, 80), (100, 80))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train, df_test = train_test_split(df, test_size=0.2, random_state=42)\n",
    "df_train.shape, df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"AutogluonModels/synthetic/tvaes/v2\"\n"
     ]
    }
   ],
   "source": [
    "predictor= TabularPredictor(\n",
    "    label='ED_2Clases',\n",
    "    problem_type='binary',\n",
    "    eval_metric='roc_auc',\n",
    "    sample_weight='balance_weight',\n",
    "    path='AutogluonModels/synthetic/tvaes/v2'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.2\n",
      "Python Version:     3.10.2\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.26100\n",
      "CPU Count:          12\n",
      "Memory Avail:       10.70 GB / 15.94 GB (67.2%)\n",
      "Disk Space Avail:   105.27 GB / 446.36 GB (23.6%)\n",
      "===================================================\n",
      "Presets specified: ['high_quality']\n",
      "Setting dynamic_stacking from 'auto' to True. Reason: Enable dynamic_stacking when use_bag_holdout is disabled. (use_bag_holdout=False)\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=1\n",
      "Note: `save_bag_folds=False`! This will greatly reduce peak disk usage during fit (by ~8x), but runs the risk of an out-of-memory error during model refit if memory is small relative to the data size.\n",
      "\tYou can avoid this risk by setting `save_bag_folds=True`.\n",
      "DyStack is enabled (dynamic_stacking=True). AutoGluon will try to determine whether the input data is affected by stacked overfitting and enable or disable stacking as a consequence.\n",
      "\tThis is used to identify the optimal `num_stack_levels` value. Copies of AutoGluon will be fit on subsets of the data. Then holdout validation data is used to detect stacked overfitting.\n",
      "\tRunning DyStack for up to 900s of the 3600s of remaining time (25%).\n",
      "\tRunning DyStack sub-fit in a ray process to avoid memory leakage. Enabling ray logging (enable_ray_logging=True). Specify `ds_args={'enable_ray_logging': False}` if you experience logging issues.\n",
      "2025-01-31 00:15:09,396\tINFO worker.py:1743 -- Started a local Ray instance. View the dashboard at \u001b[1m\u001b[32m127.0.0.1:8265 \u001b[39m\u001b[22m\n",
      "\t\tContext path: \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\autogluon\\tlp\\AutogluonModels\\synthetic\\tvaes\\v2\\ds_sub_fit\\sub_fit_ho\"\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m Running DyStack sub-fit ...\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m Using predefined sample weighting strategy: balance_weight. Evaluation metrics will ignore sample weights, specify weight_evaluation=True to instead report weighted metrics.\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m Beginning AutoGluon training ... Time limit = 894s\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m AutoGluon will save models to \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\autogluon\\tlp\\AutogluonModels\\synthetic\\tvaes\\v2\\ds_sub_fit\\sub_fit_ho\"\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m Train Data Rows:    352\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m Train Data Columns: 79\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m Label Column:       ED_2Clases\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m Problem Type:       binary\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m Preprocessing data ...\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m Selected class <--> label mapping:  class 1 = H, class 0 = D\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m \tNote: For your binary classification, AutoGluon arbitrarily selected which label-value represents positive (H) vs negative (D) class.\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m \tTo explicitly set the positive_class, either rename classes to 1 and 0, or specify positive_class in Predictor init.\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m Assigning sample weights to balance differences in frequency of classes.\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m Using Feature Generators to preprocess the data ...\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m Fitting AutoMLPipelineFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m \tAvailable Memory:                    10395.81 MB\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m \tTrain Data (Original)  Memory Usage: 0.27 MB (0.0% of available memory)\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m \tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m \tStage 1 Generators:\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m \t\tFitting AsTypeFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m \t\t\tNote: Converting 10 features to boolean dtype as they only contain 2 unique values.\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m \tStage 2 Generators:\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m \t\tFitting FillNaFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m \tStage 3 Generators:\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m \t\tFitting IdentityFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m \t\tFitting CategoryFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m \t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m \t\tFitting DatetimeFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m \t\tFitting TextSpecialFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m \t\t\tFitting BinnedFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m \t\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m \t\tFitting TextNgramFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m \t\t\tFitting CountVectorizer for text features: ['clin-tipoAlcohol']\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m \t\t\tRemoving text_ngram feature due to error: '__nlp__'\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m \tStage 4 Generators:\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m \t\tFitting DropUniqueFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m \tStage 5 Generators:\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m \t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m \tUseless Original Features (Count: 1): ['clin-Covid_sintomaSarpullido']\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m \t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m \t\tThis is typically a feature which has the same value for all rows.\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m \t\tThese features do not need to be present at inference time.\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m \tTypes of features in original data (raw dtype, special dtypes):\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m \t\t('bool', [])                       :  8 | ['clin-ansiedad', 'clin-depresion', 'clin-cardiopatiaIsquemica', 'clin-diabetes', 'clin-Hipercolesterolemia', ...]\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m \t\t('float', [])                      : 17 | ['clin-numCigarros', 'clin-aÃ±osSinFumar', 'ques-Sus-total-PD', 'eval-TLP-FigRey-totalCopia-PD', 'eval-TLP-FigRey-totalMemoria-PD', ...]\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m \t\t('int', [])                        : 49 | ['demo-genero', 'demo-edad', 'clin-reservaCognitiva_total', 'clin-reservaCognitiva_idiomas', 'clin-reservaCognitiva_ocupacion', ...]\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m \t\t('object', [])                     :  1 | ['demo-rangoEdad']\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m \t\t('object', ['datetime_as_object']) :  2 | ['demo-fechaEvaluacion', 'demo-fechaNacimiento']\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m \t\t('object', ['text'])               :  1 | ['clin-tipoAlcohol']\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m \tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m \t\t('category', [])                    :  1 | ['demo-rangoEdad']\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m \t\t('category', ['text_as_category'])  :  1 | ['clin-tipoAlcohol']\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m \t\t('float', [])                       : 17 | ['clin-numCigarros', 'clin-aÃ±osSinFumar', 'ques-Sus-total-PD', 'eval-TLP-FigRey-totalCopia-PD', 'eval-TLP-FigRey-totalMemoria-PD', ...]\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m \t\t('int', [])                         : 47 | ['demo-edad', 'clin-reservaCognitiva_total', 'clin-reservaCognitiva_idiomas', 'clin-reservaCognitiva_ocupacion', 'clin-reservaCognitiva_escolaridad', ...]\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m \t\t('int', ['binned', 'text_special']) :  8 | ['clin-tipoAlcohol.char_count', 'clin-tipoAlcohol.word_count', 'clin-tipoAlcohol.capital_ratio', 'clin-tipoAlcohol.lower_ratio', 'clin-tipoAlcohol.digit_ratio', ...]\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m \t\t('int', ['bool'])                   : 10 | ['demo-genero', 'clin-ansiedad', 'clin-depresion', 'clin-cardiopatiaIsquemica', 'clin-diabetes', ...]\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m \t\t('int', ['datetime_as_int'])        :  9 | ['demo-fechaEvaluacion', 'demo-fechaEvaluacion.month', 'demo-fechaEvaluacion.day', 'demo-fechaEvaluacion.dayofweek', 'demo-fechaNacimiento', ...]\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m \t0.2s = Fit runtime\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m \t78 features in original data used to generate 93 features in processed data.\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m \tTrain Data (Processed) Memory Usage: 0.20 MB (0.0% of available memory)\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m Data preprocessing and feature engineering runtime = 0.2s ...\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m AutoGluon will gauge predictive performance using evaluation metric: 'roc_auc'\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m \tThis metric expects predicted probabilities rather than predicted class labels, so you'll need to use predict_proba() instead of predict()\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m \tTo change this, specify the eval_metric parameter of Predictor()\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m Large model count detected (112 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m User-specified model hyperparameters to be fit:\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m {\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m \t'NN_TORCH': [{}, {'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2}}, {'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7}}],\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m \t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m \t'CAT': [{}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5}}],\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m \t'XGB': [{}, {'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'name_suffix': '_r33', 'priority': -8}}, {'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'name_suffix': '_r89', 'priority': -16}}],\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m \t'FASTAI': [{}, {'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4}}, {'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11}}],\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m \t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m \t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m \t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m }\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m Excluded models: ['KNN', 'XT', 'RF'] (Specified by `excluded_model_types`)\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m Fitting 90 L1 models, fit_strategy=\"sequential\" ...\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 595.64s of the 893.66s of remaining time.\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.18%)\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m \t0.9713\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m \t1.43s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m \t0.03s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m Fitting model: LightGBM_BAG_L1 ... Training model for up to 584.07s of the 882.10s of remaining time.\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.21%)\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m \t0.9667\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m \t1.11s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m \t0.04s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m Fitting model: CatBoost_BAG_L1 ... Training model for up to 579.23s of the 877.25s of remaining time.\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.41%)\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m \t0.9725\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m \t164.09s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m \t0.06s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 411.55s of the 709.58s of remaining time.\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.02%)\n",
      "\u001b[36m(_ray_fit pid=13924)\u001b[0m No improvement since epoch 2: early stopping\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m \t0.8832\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m \t5.88s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m \t0.08s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m Fitting model: XGBoost_BAG_L1 ... Training model for up to 402.49s of the 700.51s of remaining time.\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.52%)\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m \t0.9595\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m \t2.24s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m \t0.08s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m Fitting model: NeuralNetTorch_BAG_L1 ... Training model for up to 396.45s of the 694.48s of remaining time.\n",
      "\u001b[36m(_ray_fit pid=2080)\u001b[0m No improvement since epoch 9: early stopping\u001b[32m [repeated 4x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/ray-logging.html#log-deduplication for more options.)\u001b[0m\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.01%)\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m \tWarning: Exception caused NeuralNetTorch_BAG_L1 to fail during training... Skipping this model.\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m \t\t\u001b[36mray::_ray_fit()\u001b[39m (pid=14872, ip=127.0.0.1)\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m   File \"python\\ray\\_raylet.pyx\", line 1889, in ray._raylet.execute_task\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m     fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m     out = self._fit(**kwargs)\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 201, in _fit\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m     train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m     dataset = self._process_train_data(\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m     self.processor = create_preprocessor(\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\utils\\data_preprocessor.py\", line 40, in create_preprocessor\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m     return ColumnTransformer(\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m Detailed Traceback:\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 2106, in _train_and_save\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m     model = self._train_single(**model_fit_kwargs)\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 1993, in _train_single\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m     model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m     out = self._fit(**kwargs)\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\stacker_ensemble_model.py\", line 270, in _fit\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m     return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\bagged_ensemble_model.py\", line 298, in _fit\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m     self._fit_folds(\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\bagged_ensemble_model.py\", line 724, in _fit_folds\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m     fold_fitting_strategy.after_all_folds_scheduled()\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 690, in after_all_folds_scheduled\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m     self._run_parallel(X, y, X_pseudo, y_pseudo, model_base_ref, time_limit_fold, head_node_id)\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 631, in _run_parallel\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m     self._process_fold_results(finished, unfinished, fold_ctx)\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 587, in _process_fold_results\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m     raise processed_exception\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 550, in _process_fold_results\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m     fold_model, pred_proba, time_start_fit, time_end_fit, predict_time, predict_1_time, predict_n_size, fit_num_cpus, fit_num_gpus = self.ray.get(finished)\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m     return fn(*args, **kwargs)\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\client_mode_hook.py\", line 103, in wrapper\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m     return func(*args, **kwargs)\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\worker.py\", line 2667, in get\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m     values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\worker.py\", line 864, in get_objects\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m     raise value.as_instanceof_cause()\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m ray.exceptions.RayTaskError(TypeError): \u001b[36mray::_ray_fit()\u001b[39m (pid=14872, ip=127.0.0.1)\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m   File \"python\\ray\\_raylet.pyx\", line 1889, in ray._raylet.execute_task\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m     fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m     out = self._fit(**kwargs)\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 201, in _fit\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m     train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m     dataset = self._process_train_data(\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m     self.processor = create_preprocessor(\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\utils\\data_preprocessor.py\", line 40, in create_preprocessor\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m     return ColumnTransformer(\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m Fitting model: LightGBMLarge_BAG_L1 ... Training model for up to 390.10s of the 688.13s of remaining time.\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.97%)\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m \t0.9498\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m \t1.91s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m \t0.04s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m Fitting model: CatBoost_r177_BAG_L1 ... Training model for up to 384.90s of the 682.92s of remaining time.\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.56%)\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m \t0.9683\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m \t34.73s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m \t0.06s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m Fitting model: NeuralNetTorch_r79_BAG_L1 ... Training model for up to 346.34s of the 644.37s of remaining time.\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.02%)\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m \tWarning: Exception caused NeuralNetTorch_r79_BAG_L1 to fail during training... Skipping this model.\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m \t\t\u001b[36mray::_ray_fit()\u001b[39m (pid=5988, ip=127.0.0.1)\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m   File \"python\\ray\\_raylet.pyx\", line 1889, in ray._raylet.execute_task\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m     fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m     out = self._fit(**kwargs)\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 201, in _fit\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m     train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m     dataset = self._process_train_data(\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m     self.processor = create_preprocessor(\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\utils\\data_preprocessor.py\", line 40, in create_preprocessor\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m     return ColumnTransformer(\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m Detailed Traceback:\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 2106, in _train_and_save\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m     model = self._train_single(**model_fit_kwargs)\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 1993, in _train_single\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m     model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m     out = self._fit(**kwargs)\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\stacker_ensemble_model.py\", line 270, in _fit\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m     return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\bagged_ensemble_model.py\", line 298, in _fit\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m     self._fit_folds(\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\bagged_ensemble_model.py\", line 724, in _fit_folds\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m     fold_fitting_strategy.after_all_folds_scheduled()\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 690, in after_all_folds_scheduled\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m     self._run_parallel(X, y, X_pseudo, y_pseudo, model_base_ref, time_limit_fold, head_node_id)\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 631, in _run_parallel\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m     self._process_fold_results(finished, unfinished, fold_ctx)\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 587, in _process_fold_results\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m     raise processed_exception\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 550, in _process_fold_results\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m     fold_model, pred_proba, time_start_fit, time_end_fit, predict_time, predict_1_time, predict_n_size, fit_num_cpus, fit_num_gpus = self.ray.get(finished)\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m     return fn(*args, **kwargs)\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\client_mode_hook.py\", line 103, in wrapper\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m     return func(*args, **kwargs)\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\worker.py\", line 2667, in get\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m     values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\worker.py\", line 864, in get_objects\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m     raise value.as_instanceof_cause()\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m ray.exceptions.RayTaskError(TypeError): \u001b[36mray::_ray_fit()\u001b[39m (pid=5988, ip=127.0.0.1)\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m   File \"python\\ray\\_raylet.pyx\", line 1889, in ray._raylet.execute_task\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m     fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m     out = self._fit(**kwargs)\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 201, in _fit\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m     train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m     dataset = self._process_train_data(\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m     self.processor = create_preprocessor(\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\utils\\data_preprocessor.py\", line 40, in create_preprocessor\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m     return ColumnTransformer(\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m Fitting model: LightGBM_r131_BAG_L1 ... Training model for up to 340.28s of the 638.31s of remaining time.\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.54%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=5332)\u001b[0m [1000]\tvalid_set's binary_logloss: 0.102873\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_dystack pid=18088)\u001b[0m \t0.9709\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m \t2.3s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m \t0.04s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m Fitting model: NeuralNetFastAI_r191_BAG_L1 ... Training model for up to 334.83s of the 632.86s of remaining time.\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.04%)\n",
      "\u001b[36m(_ray_fit pid=11128)\u001b[0m No improvement since epoch 0: early stopping\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m \t0.8937\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m \t6.22s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m \t0.09s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m Fitting model: CatBoost_r9_BAG_L1 ... Training model for up to 325.39s of the 623.41s of remaining time.\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=3.63%)\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m \t0.9688\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m \t146.46s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m \t0.07s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m Fitting model: LightGBM_r96_BAG_L1 ... Training model for up to 175.12s of the 473.15s of remaining time.\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.15%)\n",
      "\u001b[36m(_ray_fit pid=15808)\u001b[0m No improvement since epoch 14: early stopping\u001b[32m [repeated 7x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=6784)\u001b[0m [1000]\tvalid_set's binary_logloss: 0.29819\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_dystack pid=18088)\u001b[0m \t0.9653\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m \t5.44s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m \t0.06s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m Fitting model: NeuralNetTorch_r22_BAG_L1 ... Training model for up to 166.55s of the 464.57s of remaining time.\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.02%)\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m \tWarning: Exception caused NeuralNetTorch_r22_BAG_L1 to fail during training... Skipping this model.\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m \t\t\u001b[36mray::_ray_fit()\u001b[39m (pid=19808, ip=127.0.0.1)\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m   File \"python\\ray\\_raylet.pyx\", line 1889, in ray._raylet.execute_task\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m     fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m     out = self._fit(**kwargs)\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 201, in _fit\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m     train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m     dataset = self._process_train_data(\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m     self.processor = create_preprocessor(\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\utils\\data_preprocessor.py\", line 40, in create_preprocessor\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m     return ColumnTransformer(\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m Detailed Traceback:\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 2106, in _train_and_save\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m     model = self._train_single(**model_fit_kwargs)\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 1993, in _train_single\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m     model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m     out = self._fit(**kwargs)\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\stacker_ensemble_model.py\", line 270, in _fit\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m     return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\bagged_ensemble_model.py\", line 298, in _fit\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m     self._fit_folds(\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\bagged_ensemble_model.py\", line 724, in _fit_folds\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m     fold_fitting_strategy.after_all_folds_scheduled()\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 690, in after_all_folds_scheduled\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m     self._run_parallel(X, y, X_pseudo, y_pseudo, model_base_ref, time_limit_fold, head_node_id)\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 631, in _run_parallel\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m     self._process_fold_results(finished, unfinished, fold_ctx)\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 587, in _process_fold_results\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m     raise processed_exception\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 550, in _process_fold_results\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m     fold_model, pred_proba, time_start_fit, time_end_fit, predict_time, predict_1_time, predict_n_size, fit_num_cpus, fit_num_gpus = self.ray.get(finished)\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m     return fn(*args, **kwargs)\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\client_mode_hook.py\", line 103, in wrapper\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m     return func(*args, **kwargs)\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\worker.py\", line 2667, in get\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m     values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\worker.py\", line 864, in get_objects\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m     raise value.as_instanceof_cause()\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m ray.exceptions.RayTaskError(TypeError): \u001b[36mray::_ray_fit()\u001b[39m (pid=19808, ip=127.0.0.1)\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m   File \"python\\ray\\_raylet.pyx\", line 1889, in ray._raylet.execute_task\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m     fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m     out = self._fit(**kwargs)\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 201, in _fit\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m     train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m     dataset = self._process_train_data(\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m     self.processor = create_preprocessor(\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\utils\\data_preprocessor.py\", line 40, in create_preprocessor\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m     return ColumnTransformer(\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m Fitting model: XGBoost_r33_BAG_L1 ... Training model for up to 160.48s of the 458.50s of remaining time.\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=6.11%)\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m \t0.9645\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m \t7.99s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m \t0.06s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m Fitting model: CatBoost_r137_BAG_L1 ... Training model for up to 149.33s of the 447.35s of remaining time.\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.20%)\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m \t0.9704\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m \t66.66s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m \t0.05s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m Fitting model: NeuralNetFastAI_r102_BAG_L1 ... Training model for up to 79.54s of the 377.57s of remaining time.\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.05%)\n",
      "\u001b[36m(_ray_fit pid=20144)\u001b[0m No improvement since epoch 0: early stopping\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m \t0.8746\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m \t7.44s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m \t0.13s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m Fitting model: CatBoost_r13_BAG_L1 ... Training model for up to 68.95s of the 366.97s of remaining time.\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=5.63%)\n",
      "\u001b[36m(_ray_fit pid=14268)\u001b[0m \tRan out of time, early stopping on iteration 635.\n",
      "\u001b[36m(_ray_fit pid=11916)\u001b[0m No improvement since epoch 3: early stopping\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m \t0.9692\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m \t55.25s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m \t0.08s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m Fitting model: LightGBM_r188_BAG_L1 ... Training model for up to 9.92s of the 307.95s of remaining time.\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=1.68%)\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m \t0.9687\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m \t1.31s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m \t0.04s\t = Validation runtime\n",
      "\u001b[36m(_ray_fit pid=17884)\u001b[0m \tRan out of time, early stopping on iteration 641.\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m Fitting model: WeightedEnsemble_L2 ... Training model for up to 360.00s of the 296.15s of remaining time.\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m \tEnsemble Weights: {'LightGBMXT_BAG_L1': 0.7, 'CatBoost_BAG_L1': 0.3}\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m \t0.9749\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m \t0.04s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m \t0.0s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m Excluded models: ['KNN', 'XT', 'RF'] (Specified by `excluded_model_types`)\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m Fitting 90 L2 models, fit_strategy=\"sequential\" ...\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m Fitting model: LightGBMXT_BAG_L2 ... Training model for up to 296.08s of the 295.98s of remaining time.\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.44%)\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m \t0.9667\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m \t0.89s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m \t0.04s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m Fitting model: LightGBM_BAG_L2 ... Training model for up to 292.03s of the 291.93s of remaining time.\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.51%)\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m \t0.9654\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m \t1.05s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m \t0.04s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m Fitting model: CatBoost_BAG_L2 ... Training model for up to 287.49s of the 287.39s of remaining time.\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=1.01%)\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m \t0.9704\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m \t24.07s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m \t0.09s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m Fitting model: NeuralNetFastAI_BAG_L2 ... Training model for up to 259.82s of the 259.73s of remaining time.\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.05%)\n",
      "\u001b[36m(_ray_fit pid=11084)\u001b[0m No improvement since epoch 0: early stopping\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m \t0.9255\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m \t8.23s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m \t0.11s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m Fitting model: XGBoost_BAG_L2 ... Training model for up to 248.26s of the 248.16s of remaining time.\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=1.90%)\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m \t0.9614\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m \t1.13s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m \t0.06s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m Fitting model: NeuralNetTorch_BAG_L2 ... Training model for up to 242.72s of the 242.63s of remaining time.\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.03%)\n",
      "\u001b[36m(_ray_fit pid=2084)\u001b[0m No improvement since epoch 9: early stopping\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m \tWarning: Exception caused NeuralNetTorch_BAG_L2 to fail during training... Skipping this model.\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m \t\t\u001b[36mray::_ray_fit()\u001b[39m (pid=17952, ip=127.0.0.1)\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m   File \"python\\ray\\_raylet.pyx\", line 1889, in ray._raylet.execute_task\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m     fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m     out = self._fit(**kwargs)\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 201, in _fit\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m     train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m     dataset = self._process_train_data(\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m     self.processor = create_preprocessor(\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\utils\\data_preprocessor.py\", line 40, in create_preprocessor\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m     return ColumnTransformer(\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m Detailed Traceback:\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 2106, in _train_and_save\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m     model = self._train_single(**model_fit_kwargs)\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 1993, in _train_single\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m     model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m     out = self._fit(**kwargs)\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\stacker_ensemble_model.py\", line 270, in _fit\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m     return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\bagged_ensemble_model.py\", line 298, in _fit\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m     self._fit_folds(\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\bagged_ensemble_model.py\", line 724, in _fit_folds\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m     fold_fitting_strategy.after_all_folds_scheduled()\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 690, in after_all_folds_scheduled\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m     self._run_parallel(X, y, X_pseudo, y_pseudo, model_base_ref, time_limit_fold, head_node_id)\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 631, in _run_parallel\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m     self._process_fold_results(finished, unfinished, fold_ctx)\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 587, in _process_fold_results\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m     raise processed_exception\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 550, in _process_fold_results\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m     fold_model, pred_proba, time_start_fit, time_end_fit, predict_time, predict_1_time, predict_n_size, fit_num_cpus, fit_num_gpus = self.ray.get(finished)\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m     return fn(*args, **kwargs)\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\client_mode_hook.py\", line 103, in wrapper\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m     return func(*args, **kwargs)\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\worker.py\", line 2667, in get\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m     values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\worker.py\", line 864, in get_objects\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m     raise value.as_instanceof_cause()\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m ray.exceptions.RayTaskError(TypeError): \u001b[36mray::_ray_fit()\u001b[39m (pid=17952, ip=127.0.0.1)\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m   File \"python\\ray\\_raylet.pyx\", line 1889, in ray._raylet.execute_task\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m     fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m     out = self._fit(**kwargs)\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 201, in _fit\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m     train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m     dataset = self._process_train_data(\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m     self.processor = create_preprocessor(\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\utils\\data_preprocessor.py\", line 40, in create_preprocessor\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m     return ColumnTransformer(\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m Fitting model: LightGBMLarge_BAG_L2 ... Training model for up to 235.86s of the 235.76s of remaining time.\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=3.08%)\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m \t0.9425\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m \t1.68s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m \t0.03s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m Fitting model: CatBoost_r177_BAG_L2 ... Training model for up to 230.72s of the 230.62s of remaining time.\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=1.70%)\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m \t0.9708\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m \t21.09s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m \t0.06s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m Fitting model: NeuralNetTorch_r79_BAG_L2 ... Training model for up to 206.04s of the 205.94s of remaining time.\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.04%)\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m \tWarning: Exception caused NeuralNetTorch_r79_BAG_L2 to fail during training... Skipping this model.\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m \t\t\u001b[36mray::_ray_fit()\u001b[39m (pid=17812, ip=127.0.0.1)\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m   File \"python\\ray\\_raylet.pyx\", line 1889, in ray._raylet.execute_task\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m     fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m     out = self._fit(**kwargs)\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 201, in _fit\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m     train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m     dataset = self._process_train_data(\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m     self.processor = create_preprocessor(\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\utils\\data_preprocessor.py\", line 40, in create_preprocessor\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m     return ColumnTransformer(\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m Detailed Traceback:\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 2106, in _train_and_save\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m     model = self._train_single(**model_fit_kwargs)\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 1993, in _train_single\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m     model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m     out = self._fit(**kwargs)\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\stacker_ensemble_model.py\", line 270, in _fit\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m     return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\bagged_ensemble_model.py\", line 298, in _fit\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m     self._fit_folds(\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\bagged_ensemble_model.py\", line 724, in _fit_folds\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m     fold_fitting_strategy.after_all_folds_scheduled()\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 690, in after_all_folds_scheduled\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m     self._run_parallel(X, y, X_pseudo, y_pseudo, model_base_ref, time_limit_fold, head_node_id)\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 631, in _run_parallel\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m     self._process_fold_results(finished, unfinished, fold_ctx)\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 587, in _process_fold_results\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m     raise processed_exception\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 550, in _process_fold_results\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m     fold_model, pred_proba, time_start_fit, time_end_fit, predict_time, predict_1_time, predict_n_size, fit_num_cpus, fit_num_gpus = self.ray.get(finished)\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m     return fn(*args, **kwargs)\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\client_mode_hook.py\", line 103, in wrapper\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m     return func(*args, **kwargs)\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\worker.py\", line 2667, in get\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m     values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\worker.py\", line 864, in get_objects\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m     raise value.as_instanceof_cause()\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m ray.exceptions.RayTaskError(TypeError): \u001b[36mray::_ray_fit()\u001b[39m (pid=17812, ip=127.0.0.1)\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m   File \"python\\ray\\_raylet.pyx\", line 1889, in ray._raylet.execute_task\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m     fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m     out = self._fit(**kwargs)\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 201, in _fit\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m     train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m     dataset = self._process_train_data(\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m     self.processor = create_preprocessor(\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\utils\\data_preprocessor.py\", line 40, in create_preprocessor\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m     return ColumnTransformer(\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): \u001b[36mray::_ray_fit()\u001b[39m (pid=6200, ip=127.0.0.1)\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m   File \"python\\ray\\_raylet.pyx\", line 1889, in ray._raylet.execute_task\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m     fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m     out = self._fit(**kwargs)\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 201, in _fit\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m     train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m     dataset = self._process_train_data(\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m     self.processor = create_preprocessor(\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\utils\\data_preprocessor.py\", line 40, in create_preprocessor\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m     return ColumnTransformer(\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m Fitting model: LightGBM_r131_BAG_L2 ... Training model for up to 199.56s of the 199.46s of remaining time.\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=2.08%)\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m \t0.9645\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m \t1.62s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m \t0.05s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m Fitting model: NeuralNetFastAI_r191_BAG_L2 ... Training model for up to 194.44s of the 194.34s of remaining time.\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.12%)\n",
      "\u001b[36m(_ray_fit pid=8388)\u001b[0m No improvement since epoch 4: early stopping\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m \t0.9352\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m \t7.31s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m \t0.18s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m Fitting model: CatBoost_r9_BAG_L2 ... Training model for up to 183.71s of the 183.61s of remaining time.\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m \tMemory not enough to fit 8 folds in parallel. Will train 4 folds in parallel instead (Estimated 14.09% memory usage per fold, 56.36%/80.00% total).\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=3, gpus=0, memory=14.09%)\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m \t0.9666\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m \t72.67s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m \t0.06s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m Fitting model: LightGBM_r96_BAG_L2 ... Training model for up to 107.93s of the 107.84s of remaining time.\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.27%)\n",
      "\u001b[36m(_ray_fit pid=15644)\u001b[0m No improvement since epoch 7: early stopping\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m \t0.969\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m \t1.12s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m \t0.04s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m Fitting model: NeuralNetTorch_r22_BAG_L2 ... Training model for up to 103.63s of the 103.53s of remaining time.\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.04%)\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m \tWarning: Exception caused NeuralNetTorch_r22_BAG_L2 to fail during training... Skipping this model.\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m \t\t\u001b[36mray::_ray_fit()\u001b[39m (pid=1956, ip=127.0.0.1)\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m   File \"python\\ray\\_raylet.pyx\", line 1889, in ray._raylet.execute_task\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m     fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m     out = self._fit(**kwargs)\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 201, in _fit\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m     train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m     dataset = self._process_train_data(\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m     self.processor = create_preprocessor(\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\utils\\data_preprocessor.py\", line 40, in create_preprocessor\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m     return ColumnTransformer(\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m Detailed Traceback:\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 2106, in _train_and_save\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m     model = self._train_single(**model_fit_kwargs)\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 1993, in _train_single\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m     model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m     out = self._fit(**kwargs)\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\stacker_ensemble_model.py\", line 270, in _fit\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m     return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\bagged_ensemble_model.py\", line 298, in _fit\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m     self._fit_folds(\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\bagged_ensemble_model.py\", line 724, in _fit_folds\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m     fold_fitting_strategy.after_all_folds_scheduled()\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 690, in after_all_folds_scheduled\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m     self._run_parallel(X, y, X_pseudo, y_pseudo, model_base_ref, time_limit_fold, head_node_id)\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 631, in _run_parallel\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m     self._process_fold_results(finished, unfinished, fold_ctx)\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 587, in _process_fold_results\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m     raise processed_exception\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 550, in _process_fold_results\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m     fold_model, pred_proba, time_start_fit, time_end_fit, predict_time, predict_1_time, predict_n_size, fit_num_cpus, fit_num_gpus = self.ray.get(finished)\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m     return fn(*args, **kwargs)\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\client_mode_hook.py\", line 103, in wrapper\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m     return func(*args, **kwargs)\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\worker.py\", line 2667, in get\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m     values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\worker.py\", line 864, in get_objects\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m     raise value.as_instanceof_cause()\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m ray.exceptions.RayTaskError(TypeError): \u001b[36mray::_ray_fit()\u001b[39m (pid=1956, ip=127.0.0.1)\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m   File \"python\\ray\\_raylet.pyx\", line 1889, in ray._raylet.execute_task\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m     fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m     out = self._fit(**kwargs)\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 201, in _fit\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m     train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m     dataset = self._process_train_data(\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m     self.processor = create_preprocessor(\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\utils\\data_preprocessor.py\", line 40, in create_preprocessor\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m     return ColumnTransformer(\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m Fitting model: XGBoost_r33_BAG_L2 ... Training model for up to 96.84s of the 96.74s of remaining time.\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m \tMemory not enough to fit 8 folds in parallel. Will train 4 folds in parallel instead (Estimated 14.32% memory usage per fold, 57.29%/80.00% total).\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=3, gpus=0, memory=14.32%)\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m \t0.9637\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m \t5.56s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m \t0.05s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m Fitting model: CatBoost_r137_BAG_L2 ... Training model for up to 88.86s of the 88.76s of remaining time.\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.53%)\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m \t0.9699\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m \t16.34s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m \t0.07s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m Fitting model: NeuralNetFastAI_r102_BAG_L2 ... Training model for up to 69.12s of the 69.02s of remaining time.\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.12%)\n",
      "\u001b[36m(_ray_fit pid=20764)\u001b[0m No improvement since epoch 0: early stopping\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m \t0.9446\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m \t15.69s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m \t0.12s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m Fitting model: CatBoost_r13_BAG_L2 ... Training model for up to 50.05s of the 49.95s of remaining time.\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m \tMemory not enough to fit 8 folds in parallel. Will train 4 folds in parallel instead (Estimated 12.89% memory usage per fold, 51.56%/80.00% total).\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=3, gpus=0, memory=12.89%)\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_ray_fit pid=16108)\u001b[0m No improvement since epoch 6: early stopping\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=14404)\u001b[0m \tRan out of time, early stopping on iteration 356.\n",
      "\u001b[36m(_ray_fit pid=19316)\u001b[0m \tRan out of time, early stopping on iteration 368.\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m \t0.9694\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m \t42.59s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m \t0.06s\t = Validation runtime\n",
      "\u001b[36m(_ray_fit pid=20548)\u001b[0m \tRan out of time, early stopping on iteration 384.\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m Fitting model: WeightedEnsemble_L3 ... Training model for up to 360.00s of the 4.23s of remaining time.\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m \tEnsemble Weights: {'LightGBMXT_BAG_L1': 0.571, 'CatBoost_BAG_L1': 0.357, 'NeuralNetFastAI_r102_BAG_L2': 0.071}\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m \t0.9751\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m \t0.03s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m \t0.0s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m AutoGluon training complete, total runtime = 889.69s ... Best model: WeightedEnsemble_L3 | Estimated inference throughput: 121.6 rows/s (44 batch size)\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m Automatically performing refit_full as a post-fit operation (due to `.fit(..., refit_full=True)`\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m Refitting models via `predictor.refit_full` using all of the data (combined train and validation)...\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m \tModels trained in this way will have the suffix \"_FULL\" and have NaN validation score.\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m \tThis process is not bound by time_limit, but should take less time than the original `predictor.fit` call.\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m \tTo learn more, refer to the `.refit_full` method docstring which explains how \"_FULL\" models differ from normal models.\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m Fitting model: LightGBMXT_BAG_L1_FULL ...\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m \t0.41s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m Fitting model: LightGBM_BAG_L1_FULL ...\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m \t0.13s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m Fitting model: CatBoost_BAG_L1_FULL ...\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m \t16.87s\t = Training   runtime\n",
      "\u001b[36m(_ray_fit pid=6208)\u001b[0m \tRan out of time, early stopping on iteration 389.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m Fitting model: NeuralNetFastAI_BAG_L1_FULL ...\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m \tStopping at the best epoch learned earlier - 9.\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m \t0.55s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m Fitting model: XGBoost_BAG_L1_FULL ...\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m \t0.19s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m Fitting model: LightGBMLarge_BAG_L1_FULL ...\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m \t0.25s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m Fitting model: CatBoost_r177_BAG_L1_FULL ...\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m \t3.98s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m Fitting model: LightGBM_r131_BAG_L1_FULL ...\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m \t0.31s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m Fitting model: NeuralNetFastAI_r191_BAG_L1_FULL ...\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m \tStopping at the best epoch learned earlier - 6.\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m \t0.31s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m Fitting model: CatBoost_r9_BAG_L1_FULL ...\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m \t17.41s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m Fitting model: LightGBM_r96_BAG_L1_FULL ...\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m \t0.4s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m Fitting model: XGBoost_r33_BAG_L1_FULL ...\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m \t0.85s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m Fitting model: CatBoost_r137_BAG_L1_FULL ...\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m \t8.91s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m Fitting model: NeuralNetFastAI_r102_BAG_L1_FULL ...\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m \tStopping at the best epoch learned earlier - 3.\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m \t0.55s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m Fitting model: CatBoost_r13_BAG_L1_FULL ...\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m \t17.86s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m Fitting model: LightGBM_r188_BAG_L1_FULL ...\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m \t0.23s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m Fitting model: WeightedEnsemble_L2_FULL | Skipping fit via cloning parent ...\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m \tEnsemble Weights: {'LightGBMXT_BAG_L1': 0.7, 'CatBoost_BAG_L1': 0.3}\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m \t0.04s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m Fitting 1 L2 models, fit_strategy=\"sequential\" ...\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m Fitting model: LightGBMXT_BAG_L2_FULL ...\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m \t0.12s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m Fitting 1 L2 models, fit_strategy=\"sequential\" ...\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m Fitting model: LightGBM_BAG_L2_FULL ...\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m \t0.12s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m Fitting 1 L2 models, fit_strategy=\"sequential\" ...\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m Fitting model: CatBoost_BAG_L2_FULL ...\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m \t1.72s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m Fitting 1 L2 models, fit_strategy=\"sequential\" ...\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m Fitting model: NeuralNetFastAI_BAG_L2_FULL ...\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m \tStopping at the best epoch learned earlier - 7.\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m \t0.28s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m Fitting 1 L2 models, fit_strategy=\"sequential\" ...\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m Fitting model: XGBoost_BAG_L2_FULL ...\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m \t0.1s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m Fitting 1 L2 models, fit_strategy=\"sequential\" ...\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m Fitting model: LightGBMLarge_BAG_L2_FULL ...\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m \t0.21s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m Fitting 1 L2 models, fit_strategy=\"sequential\" ...\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m Fitting model: CatBoost_r177_BAG_L2_FULL ...\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m \t1.43s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m Fitting 1 L2 models, fit_strategy=\"sequential\" ...\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m Fitting model: LightGBM_r131_BAG_L2_FULL ...\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m \t0.2s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m Fitting 1 L2 models, fit_strategy=\"sequential\" ...\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m Fitting model: NeuralNetFastAI_r191_BAG_L2_FULL ...\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m \tStopping at the best epoch learned earlier - 4.\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m \t0.26s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m Fitting 1 L2 models, fit_strategy=\"sequential\" ...\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m Fitting model: CatBoost_r9_BAG_L2_FULL ...\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m \t5.12s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m Fitting 1 L2 models, fit_strategy=\"sequential\" ...\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m Fitting model: LightGBM_r96_BAG_L2_FULL ...\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m \t0.14s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m Fitting 1 L2 models, fit_strategy=\"sequential\" ...\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m Fitting model: XGBoost_r33_BAG_L2_FULL ...\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m \t0.23s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m Fitting 1 L2 models, fit_strategy=\"sequential\" ...\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m Fitting model: CatBoost_r137_BAG_L2_FULL ...\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m \t1.7s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m Fitting 1 L2 models, fit_strategy=\"sequential\" ...\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m Fitting model: NeuralNetFastAI_r102_BAG_L2_FULL ...\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m \tStopping at the best epoch learned earlier - 2.\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m \t0.44s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m Fitting 1 L2 models, fit_strategy=\"sequential\" ...\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m Fitting model: CatBoost_r13_BAG_L2_FULL ...\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m \t8.17s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m Fitting model: WeightedEnsemble_L3_FULL | Skipping fit via cloning parent ...\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m \tEnsemble Weights: {'LightGBMXT_BAG_L1': 0.571, 'CatBoost_BAG_L1': 0.357, 'NeuralNetFastAI_r102_BAG_L2': 0.071}\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m \t0.03s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m Updated best model to \"WeightedEnsemble_L3_FULL\" (Previously \"WeightedEnsemble_L3\"). AutoGluon will default to using \"WeightedEnsemble_L3_FULL\" for predict() and predict_proba().\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m Refit complete, total runtime = 93.21s ... Best model: \"WeightedEnsemble_L3_FULL\"\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\autogluon\\tlp\\AutogluonModels\\synthetic\\tvaes\\v2\\ds_sub_fit\\sub_fit_ho\")\n",
      "\u001b[36m(_dystack pid=18088)\u001b[0m Deleting DyStack predictor artifacts (clean_up_fits=True) ...\n",
      "Leaderboard on holdout data (DyStack):\n",
      "                               model  score_holdout  score_val eval_metric  pred_time_test pred_time_val   fit_time  pred_time_test_marginal pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
      "0             LightGBMXT_BAG_L1_FULL       0.987578   0.971342     roc_auc        0.021090          None   0.408791                 0.021090                   None           0.408791            1       True          1\n",
      "1           WeightedEnsemble_L2_FULL       0.985507   0.974928     roc_auc        0.055256          None  17.320892                 0.010000                   None           0.042632            2       True         17\n",
      "2                XGBoost_BAG_L2_FULL       0.985507   0.961358     roc_auc        0.191087          None  18.545998                 0.032170                   None           0.103803            2       True         22\n",
      "3           WeightedEnsemble_L3_FULL       0.985507   0.975057     roc_auc        0.217443          None  18.911102                 0.011109                   None           0.029163            3       True         33\n",
      "4               LightGBM_BAG_L2_FULL       0.985507   0.965397     roc_auc        0.181135          None  18.566522                 0.022218                   None           0.124327            2       True         19\n",
      "5          LightGBM_r131_BAG_L2_FULL       0.983437   0.964492     roc_auc        0.185151          None  18.645347                 0.026235                   None           0.203152            2       True         25\n",
      "6            XGBoost_r33_BAG_L2_FULL       0.983437   0.963749     roc_auc        0.193139          None  18.673849                 0.034223                   None           0.231654            2       True         29\n",
      "7           LightGBM_r96_BAG_L1_FULL       0.981366   0.965332     roc_auc        0.042345          None   0.401330                 0.042345                   None           0.401330            1       True         11\n",
      "8             LightGBMXT_BAG_L2_FULL       0.981366   0.966722     roc_auc        0.180020          None  18.563444                 0.021103                   None           0.121249            2       True         18\n",
      "9               CatBoost_BAG_L2_FULL       0.981366   0.970405     roc_auc        0.184042          None  20.157584                 0.025125                   None           1.715389            2       True         20\n",
      "10         CatBoost_r137_BAG_L2_FULL       0.979296   0.969920     roc_auc        0.184037          None  20.143009                 0.025120                   None           1.700814            2       True         30\n",
      "11          LightGBM_r96_BAG_L2_FULL       0.977226   0.968983     roc_auc        0.182032          None  18.586376                 0.023115                   None           0.144181            2       True         28\n",
      "12              CatBoost_BAG_L1_FULL       0.977226   0.972505     roc_auc        0.024166          None  16.869469                 0.024166                   None          16.869469            1       True          3\n",
      "13           CatBoost_r9_BAG_L2_FULL       0.975155   0.966592     roc_auc        0.187132          None  23.560376                 0.028215                   None           5.118181            2       True         27\n",
      "14         LightGBMLarge_BAG_L1_FULL       0.975155   0.949759     roc_auc        0.025152          None   0.245644                 0.025152                   None           0.245644            1       True          6\n",
      "15         LightGBMLarge_BAG_L2_FULL       0.975155   0.942490     roc_auc        0.183151          None  18.653178                 0.024234                   None           0.210983            2       True         23\n",
      "16         CatBoost_r177_BAG_L2_FULL       0.971014   0.970825     roc_auc        0.184011          None  19.872238                 0.025094                   None           1.430043            2       True         24\n",
      "17          CatBoost_r13_BAG_L2_FULL       0.971014   0.969436     roc_auc        0.186027          None  26.611535                 0.027110                   None           8.169340            2       True         32\n",
      "18         CatBoost_r177_BAG_L1_FULL       0.966874   0.968272     roc_auc        0.024242          None   3.975699                 0.024242                   None           3.975699            1       True          7\n",
      "19         CatBoost_r137_BAG_L1_FULL       0.964803   0.970373     roc_auc        0.023231          None   8.906901                 0.023231                   None           8.906901            1       True         13\n",
      "20         LightGBM_r188_BAG_L1_FULL       0.964803   0.968692     roc_auc        0.026236          None   0.228207                 0.026236                   None           0.228207            1       True         16\n",
      "21           CatBoost_r9_BAG_L1_FULL       0.964803   0.968789     roc_auc        0.028109          None  17.414075                 0.028109                   None          17.414075            1       True         10\n",
      "22           XGBoost_r33_BAG_L1_FULL       0.962733   0.964525     roc_auc        0.067342          None   0.851759                 0.067342                   None           0.851759            1       True         12\n",
      "23              LightGBM_BAG_L1_FULL       0.960663   0.966722     roc_auc        0.019123          None   0.130034                 0.019123                   None           0.130034            1       True          2\n",
      "24         LightGBM_r131_BAG_L1_FULL       0.960663   0.970857     roc_auc        0.028116          None   0.308913                 0.028116                   None           0.308913            1       True          8\n",
      "25               XGBoost_BAG_L1_FULL       0.960663   0.959452     roc_auc        0.040233          None   0.188219                 0.040233                   None           0.188219            1       True          5\n",
      "26          CatBoost_r13_BAG_L1_FULL       0.954451   0.969209     roc_auc        0.026123          None  17.860609                 0.026123                   None          17.860609            1       True         15\n",
      "27       NeuralNetFastAI_BAG_L2_FULL       0.913043   0.925495     roc_auc        0.204257          None  18.717200                 0.045341                   None           0.275005            2       True         21\n",
      "28  NeuralNetFastAI_r102_BAG_L2_FULL       0.902692   0.944638     roc_auc        0.206334          None  18.881939                 0.047417                   None           0.439744            2       True         31\n",
      "29  NeuralNetFastAI_r191_BAG_L2_FULL       0.888199   0.935156     roc_auc        0.206157          None  18.706271                 0.047240                   None           0.264076            2       True         26\n",
      "30       NeuralNetFastAI_BAG_L1_FULL       0.832298   0.883202     roc_auc        0.040356          None   0.546065                 0.040356                   None           0.546065            1       True          4\n",
      "31  NeuralNetFastAI_r191_BAG_L1_FULL       0.830228   0.893703     roc_auc        0.046318          None   0.312176                 0.046318                   None           0.312176            1       True          9\n",
      "32  NeuralNetFastAI_r102_BAG_L1_FULL       0.820911   0.874560     roc_auc        0.038240          None   0.547789                 0.038240                   None           0.547789            1       True         14\n",
      "\t0\t = Optimal   num_stack_levels (Stacked Overfitting Occurred: True)\n",
      "\t993s\t = DyStack   runtime |\t2607s\t = Remaining runtime\n",
      "Starting main fit with num_stack_levels=0.\n",
      "\tFor future fit calls on this dataset, you can skip DyStack to save time: `predictor.fit(..., dynamic_stacking=False, num_stack_levels=0)`\n",
      "Using predefined sample weighting strategy: balance_weight. Evaluation metrics will ignore sample weights, specify weight_evaluation=True to instead report weighted metrics.\n",
      "Beginning AutoGluon training ... Time limit = 2607s\n",
      "AutoGluon will save models to \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\autogluon\\tlp\\AutogluonModels\\synthetic\\tvaes\\v2\"\n",
      "Train Data Rows:    396\n",
      "Train Data Columns: 79\n",
      "Label Column:       ED_2Clases\n",
      "Problem Type:       binary\n",
      "Preprocessing data ...\n",
      "Selected class <--> label mapping:  class 1 = H, class 0 = D\n",
      "\tNote: For your binary classification, AutoGluon arbitrarily selected which label-value represents positive (H) vs negative (D) class.\n",
      "\tTo explicitly set the positive_class, either rename classes to 1 and 0, or specify positive_class in Predictor init.\n",
      "Assigning sample weights to balance differences in frequency of classes.\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    5136.47 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.30 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 10 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\t\tFitting DatetimeFeatureGenerator...\n",
      "\t\tFitting TextSpecialFeatureGenerator...\n",
      "\t\t\tFitting BinnedFeatureGenerator...\n",
      "\t\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\t\tFitting TextNgramFeatureGenerator...\n",
      "\t\t\tFitting CountVectorizer for text features: ['clin-tipoAlcohol']\n",
      "\t\t\tRemoving text_ngram feature due to error: '__nlp__'\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUseless Original Features (Count: 1): ['clin-Covid_sintomaSarpullido']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('bool', [])                       :  8 | ['clin-ansiedad', 'clin-depresion', 'clin-cardiopatiaIsquemica', 'clin-diabetes', 'clin-Hipercolesterolemia', ...]\n",
      "\t\t('float', [])                      : 17 | ['clin-numCigarros', 'clin-aÃ±osSinFumar', 'ques-Sus-total-PD', 'eval-TLP-FigRey-totalCopia-PD', 'eval-TLP-FigRey-totalMemoria-PD', ...]\n",
      "\t\t('int', [])                        : 49 | ['demo-genero', 'demo-edad', 'clin-reservaCognitiva_total', 'clin-reservaCognitiva_idiomas', 'clin-reservaCognitiva_ocupacion', ...]\n",
      "\t\t('object', [])                     :  1 | ['demo-rangoEdad']\n",
      "\t\t('object', ['datetime_as_object']) :  2 | ['demo-fechaEvaluacion', 'demo-fechaNacimiento']\n",
      "\t\t('object', ['text'])               :  1 | ['clin-tipoAlcohol']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', [])                    :  1 | ['demo-rangoEdad']\n",
      "\t\t('category', ['text_as_category'])  :  1 | ['clin-tipoAlcohol']\n",
      "\t\t('float', [])                       : 17 | ['clin-numCigarros', 'clin-aÃ±osSinFumar', 'ques-Sus-total-PD', 'eval-TLP-FigRey-totalCopia-PD', 'eval-TLP-FigRey-totalMemoria-PD', ...]\n",
      "\t\t('int', [])                         : 47 | ['demo-edad', 'clin-reservaCognitiva_total', 'clin-reservaCognitiva_idiomas', 'clin-reservaCognitiva_ocupacion', 'clin-reservaCognitiva_escolaridad', ...]\n",
      "\t\t('int', ['binned', 'text_special']) : 10 | ['clin-tipoAlcohol.char_count', 'clin-tipoAlcohol.word_count', 'clin-tipoAlcohol.capital_ratio', 'clin-tipoAlcohol.lower_ratio', 'clin-tipoAlcohol.digit_ratio', ...]\n",
      "\t\t('int', ['bool'])                   : 10 | ['demo-genero', 'clin-ansiedad', 'clin-depresion', 'clin-cardiopatiaIsquemica', 'clin-diabetes', ...]\n",
      "\t\t('int', ['datetime_as_int'])        :  9 | ['demo-fechaEvaluacion', 'demo-fechaEvaluacion.month', 'demo-fechaEvaluacion.day', 'demo-fechaEvaluacion.dayofweek', 'demo-fechaNacimiento', ...]\n",
      "\t0.2s = Fit runtime\n",
      "\t78 features in original data used to generate 95 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.23 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.26s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'roc_auc'\n",
      "\tThis metric expects predicted probabilities rather than predicted class labels, so you'll need to use predict_proba() instead of predict()\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Large model count detected (112 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': [{}, {'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2}}, {'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7}}],\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\n",
      "\t'CAT': [{}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5}}],\n",
      "\t'XGB': [{}, {'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'name_suffix': '_r33', 'priority': -8}}, {'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'name_suffix': '_r89', 'priority': -16}}],\n",
      "\t'FASTAI': [{}, {'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4}}, {'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11}}],\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "Excluded models: ['KNN', 'RF', 'XT'] (Specified by `excluded_model_types`)\n",
      "Fitting 90 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 2606.37s of the 2606.36s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.38%)\n",
      "\t0.9759\t = Validation score   (roc_auc)\n",
      "\t1.25s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 2599.33s of the 2599.32s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.50%)\n",
      "\t0.9618\t = Validation score   (roc_auc)\n",
      "\t1.7s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L1 ... Training model for up to 2595.05s of the 2595.04s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.97%)\n",
      "\t0.972\t = Validation score   (roc_auc)\n",
      "\t42.07s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 2550.28s of the 2550.27s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.06%)\n",
      "\t0.8819\t = Validation score   (roc_auc)\n",
      "\t5.96s\t = Training   runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L1 ... Training model for up to 2541.99s of the 2541.98s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=1.58%)\n",
      "\t0.9649\t = Validation score   (roc_auc)\n",
      "\t2.95s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_BAG_L1 ... Training model for up to 2535.92s of the 2535.91s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.03%)\n",
      "\tWarning: Exception caused NeuralNetTorch_BAG_L1 to fail during training... Skipping this model.\n",
      "\t\t\u001b[36mray::_ray_fit()\u001b[39m (pid=13516, ip=127.0.0.1)\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1889, in ray._raylet.execute_task\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 201, in _fit\n",
      "    train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "    dataset = self._process_train_data(\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "    self.processor = create_preprocessor(\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\utils\\data_preprocessor.py\", line 40, in create_preprocessor\n",
      "    return ColumnTransformer(\n",
      "TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 2106, in _train_and_save\n",
      "    model = self._train_single(**model_fit_kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 1993, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\stacker_ensemble_model.py\", line 270, in _fit\n",
      "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\bagged_ensemble_model.py\", line 298, in _fit\n",
      "    self._fit_folds(\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\bagged_ensemble_model.py\", line 724, in _fit_folds\n",
      "    fold_fitting_strategy.after_all_folds_scheduled()\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 690, in after_all_folds_scheduled\n",
      "    self._run_parallel(X, y, X_pseudo, y_pseudo, model_base_ref, time_limit_fold, head_node_id)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 631, in _run_parallel\n",
      "    self._process_fold_results(finished, unfinished, fold_ctx)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 587, in _process_fold_results\n",
      "    raise processed_exception\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 550, in _process_fold_results\n",
      "    fold_model, pred_proba, time_start_fit, time_end_fit, predict_time, predict_1_time, predict_n_size, fit_num_cpus, fit_num_gpus = self.ray.get(finished)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\worker.py\", line 2667, in get\n",
      "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\worker.py\", line 864, in get_objects\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(TypeError): \u001b[36mray::_ray_fit()\u001b[39m (pid=13516, ip=127.0.0.1)\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1889, in ray._raylet.execute_task\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 201, in _fit\n",
      "    train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "    dataset = self._process_train_data(\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "    self.processor = create_preprocessor(\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\utils\\data_preprocessor.py\", line 40, in create_preprocessor\n",
      "    return ColumnTransformer(\n",
      "TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "Fitting model: LightGBMLarge_BAG_L1 ... Training model for up to 2530.43s of the 2530.42s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=1.62%)\n",
      "2025-01-31 00:33:00,245\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-31 00:33:00,253\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-31 00:33:00,257\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-31 00:33:00,260\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-31 00:33:00,263\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-31 00:33:00,267\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-31 00:33:00,271\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\t0.9497\t = Validation score   (roc_auc)\n",
      "\t3.05s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: CatBoost_r177_BAG_L1 ... Training model for up to 2524.81s of the 2524.80s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.95%)\n",
      "\t0.9713\t = Validation score   (roc_auc)\n",
      "\t31.53s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r79_BAG_L1 ... Training model for up to 2490.72s of the 2490.71s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.03%)\n",
      "\tWarning: Exception caused NeuralNetTorch_r79_BAG_L1 to fail during training... Skipping this model.\n",
      "\t\t\u001b[36mray::_ray_fit()\u001b[39m (pid=15416, ip=127.0.0.1)\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1889, in ray._raylet.execute_task\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 201, in _fit\n",
      "    train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "    dataset = self._process_train_data(\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "    self.processor = create_preprocessor(\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\utils\\data_preprocessor.py\", line 40, in create_preprocessor\n",
      "    return ColumnTransformer(\n",
      "TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 2106, in _train_and_save\n",
      "    model = self._train_single(**model_fit_kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 1993, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\stacker_ensemble_model.py\", line 270, in _fit\n",
      "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\bagged_ensemble_model.py\", line 298, in _fit\n",
      "    self._fit_folds(\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\bagged_ensemble_model.py\", line 724, in _fit_folds\n",
      "    fold_fitting_strategy.after_all_folds_scheduled()\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 690, in after_all_folds_scheduled\n",
      "    self._run_parallel(X, y, X_pseudo, y_pseudo, model_base_ref, time_limit_fold, head_node_id)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 631, in _run_parallel\n",
      "    self._process_fold_results(finished, unfinished, fold_ctx)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 587, in _process_fold_results\n",
      "    raise processed_exception\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 550, in _process_fold_results\n",
      "    fold_model, pred_proba, time_start_fit, time_end_fit, predict_time, predict_1_time, predict_n_size, fit_num_cpus, fit_num_gpus = self.ray.get(finished)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\worker.py\", line 2667, in get\n",
      "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\worker.py\", line 864, in get_objects\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(TypeError): \u001b[36mray::_ray_fit()\u001b[39m (pid=15416, ip=127.0.0.1)\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1889, in ray._raylet.execute_task\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 201, in _fit\n",
      "    train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "    dataset = self._process_train_data(\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "    self.processor = create_preprocessor(\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\utils\\data_preprocessor.py\", line 40, in create_preprocessor\n",
      "    return ColumnTransformer(\n",
      "TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "Fitting model: LightGBM_r131_BAG_L1 ... Training model for up to 2485.57s of the 2485.56s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.94%)\n",
      "\t0.9687\t = Validation score   (roc_auc)\n",
      "\t2.46s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r191_BAG_L1 ... Training model for up to 2480.72s of the 2480.71s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.07%)\n",
      "2025-01-31 00:33:45,774\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-31 00:33:45,790\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-31 00:33:45,793\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-31 00:33:45,795\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-31 00:33:45,799\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-31 00:33:45,802\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\t0.8753\t = Validation score   (roc_auc)\n",
      "\t6.9s\t = Training   runtime\n",
      "\t0.11s\t = Validation runtime\n",
      "Fitting model: CatBoost_r9_BAG_L1 ... Training model for up to 2471.14s of the 2471.13s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=6.40%)\n",
      "\t0.9709\t = Validation score   (roc_auc)\n",
      "\t132.07s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: LightGBM_r96_BAG_L1 ... Training model for up to 2335.78s of the 2335.77s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.15%)\n",
      "\t0.971\t = Validation score   (roc_auc)\n",
      "\t7.12s\t = Training   runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r22_BAG_L1 ... Training model for up to 2326.22s of the 2326.21s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.02%)\n",
      "\tWarning: Exception caused NeuralNetTorch_r22_BAG_L1 to fail during training... Skipping this model.\n",
      "\t\t\u001b[36mray::_ray_fit()\u001b[39m (pid=22380, ip=127.0.0.1)\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1889, in ray._raylet.execute_task\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 201, in _fit\n",
      "    train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "    dataset = self._process_train_data(\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "    self.processor = create_preprocessor(\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\utils\\data_preprocessor.py\", line 40, in create_preprocessor\n",
      "    return ColumnTransformer(\n",
      "TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 2106, in _train_and_save\n",
      "    model = self._train_single(**model_fit_kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 1993, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\stacker_ensemble_model.py\", line 270, in _fit\n",
      "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\bagged_ensemble_model.py\", line 298, in _fit\n",
      "    self._fit_folds(\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\bagged_ensemble_model.py\", line 724, in _fit_folds\n",
      "    fold_fitting_strategy.after_all_folds_scheduled()\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 690, in after_all_folds_scheduled\n",
      "    self._run_parallel(X, y, X_pseudo, y_pseudo, model_base_ref, time_limit_fold, head_node_id)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 631, in _run_parallel\n",
      "    self._process_fold_results(finished, unfinished, fold_ctx)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 587, in _process_fold_results\n",
      "    raise processed_exception\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 550, in _process_fold_results\n",
      "    fold_model, pred_proba, time_start_fit, time_end_fit, predict_time, predict_1_time, predict_n_size, fit_num_cpus, fit_num_gpus = self.ray.get(finished)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\worker.py\", line 2667, in get\n",
      "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\worker.py\", line 864, in get_objects\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(TypeError): \u001b[36mray::_ray_fit()\u001b[39m (pid=22380, ip=127.0.0.1)\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1889, in ray._raylet.execute_task\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 201, in _fit\n",
      "    train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "    dataset = self._process_train_data(\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "    self.processor = create_preprocessor(\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\utils\\data_preprocessor.py\", line 40, in create_preprocessor\n",
      "    return ColumnTransformer(\n",
      "TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "Fitting model: XGBoost_r33_BAG_L1 ... Training model for up to 2321.01s of the 2321.00s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=4.35%)\n",
      "2025-01-31 00:36:30,493\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-31 00:36:30,496\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-31 00:36:30,499\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-31 00:36:30,501\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-31 00:36:30,503\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-31 00:36:30,506\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-31 00:36:30,508\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\t0.9673\t = Validation score   (roc_auc)\n",
      "\t4.69s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: CatBoost_r137_BAG_L1 ... Training model for up to 2313.92s of the 2313.91s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.15%)\n",
      "\t0.9719\t = Validation score   (roc_auc)\n",
      "\t36.1s\t = Training   runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r102_BAG_L1 ... Training model for up to 2275.35s of the 2275.34s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.04%)\n",
      "\t0.8676\t = Validation score   (roc_auc)\n",
      "\t8.33s\t = Training   runtime\n",
      "\t0.12s\t = Validation runtime\n",
      "Fitting model: CatBoost_r13_BAG_L1 ... Training model for up to 2264.61s of the 2264.60s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=2.95%)\n",
      "2025-01-31 00:40:39,902\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\t0.9709\t = Validation score   (roc_auc)\n",
      "\t324.51s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: LightGBM_r188_BAG_L1 ... Training model for up to 1937.27s of the 1937.26s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.90%)\n",
      "\t0.9742\t = Validation score   (roc_auc)\n",
      "\t2.35s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r145_BAG_L1 ... Training model for up to 1932.47s of the 1932.46s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.04%)\n",
      "\t0.8805\t = Validation score   (roc_auc)\n",
      "\t6.54s\t = Training   runtime\n",
      "\t0.1s\t = Validation runtime\n",
      "Fitting model: XGBoost_r89_BAG_L1 ... Training model for up to 1923.16s of the 1923.15s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.66%)\n",
      "\t0.9684\t = Validation score   (roc_auc)\n",
      "\t2.88s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r30_BAG_L1 ... Training model for up to 1917.18s of the 1917.17s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.02%)\n",
      "\tWarning: Exception caused NeuralNetTorch_r30_BAG_L1 to fail during training... Skipping this model.\n",
      "\t\t\u001b[36mray::_ray_fit()\u001b[39m (pid=22300, ip=127.0.0.1)\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1889, in ray._raylet.execute_task\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 201, in _fit\n",
      "    train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "    dataset = self._process_train_data(\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "    self.processor = create_preprocessor(\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\utils\\data_preprocessor.py\", line 40, in create_preprocessor\n",
      "    return ColumnTransformer(\n",
      "TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 2106, in _train_and_save\n",
      "    model = self._train_single(**model_fit_kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 1993, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\stacker_ensemble_model.py\", line 270, in _fit\n",
      "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\bagged_ensemble_model.py\", line 298, in _fit\n",
      "    self._fit_folds(\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\bagged_ensemble_model.py\", line 724, in _fit_folds\n",
      "    fold_fitting_strategy.after_all_folds_scheduled()\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 690, in after_all_folds_scheduled\n",
      "    self._run_parallel(X, y, X_pseudo, y_pseudo, model_base_ref, time_limit_fold, head_node_id)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 631, in _run_parallel\n",
      "    self._process_fold_results(finished, unfinished, fold_ctx)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 587, in _process_fold_results\n",
      "    raise processed_exception\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 550, in _process_fold_results\n",
      "    fold_model, pred_proba, time_start_fit, time_end_fit, predict_time, predict_1_time, predict_n_size, fit_num_cpus, fit_num_gpus = self.ray.get(finished)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\worker.py\", line 2667, in get\n",
      "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\worker.py\", line 864, in get_objects\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(TypeError): \u001b[36mray::_ray_fit()\u001b[39m (pid=22300, ip=127.0.0.1)\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1889, in ray._raylet.execute_task\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 201, in _fit\n",
      "    train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "    dataset = self._process_train_data(\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "    self.processor = create_preprocessor(\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\utils\\data_preprocessor.py\", line 40, in create_preprocessor\n",
      "    return ColumnTransformer(\n",
      "TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "Fitting model: LightGBM_r130_BAG_L1 ... Training model for up to 1911.72s of the 1911.71s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.75%)\n",
      "\t0.9676\t = Validation score   (roc_auc)\n",
      "\t2.17s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r86_BAG_L1 ... Training model for up to 1906.97s of the 1906.96s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.02%)\n",
      "2025-01-31 00:43:19,108\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-31 00:43:19,112\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-31 00:43:19,115\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-31 00:43:19,119\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-31 00:43:19,122\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-31 00:43:19,127\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\tWarning: Exception caused NeuralNetTorch_r86_BAG_L1 to fail during training... Skipping this model.\n",
      "\t\t\u001b[36mray::_ray_fit()\u001b[39m (pid=21128, ip=127.0.0.1)\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1889, in ray._raylet.execute_task\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 201, in _fit\n",
      "    train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "    dataset = self._process_train_data(\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "    self.processor = create_preprocessor(\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\utils\\data_preprocessor.py\", line 40, in create_preprocessor\n",
      "    return ColumnTransformer(\n",
      "TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 2106, in _train_and_save\n",
      "    model = self._train_single(**model_fit_kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 1993, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\stacker_ensemble_model.py\", line 270, in _fit\n",
      "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\bagged_ensemble_model.py\", line 298, in _fit\n",
      "    self._fit_folds(\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\bagged_ensemble_model.py\", line 724, in _fit_folds\n",
      "    fold_fitting_strategy.after_all_folds_scheduled()\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 690, in after_all_folds_scheduled\n",
      "    self._run_parallel(X, y, X_pseudo, y_pseudo, model_base_ref, time_limit_fold, head_node_id)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 631, in _run_parallel\n",
      "    self._process_fold_results(finished, unfinished, fold_ctx)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 587, in _process_fold_results\n",
      "    raise processed_exception\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 550, in _process_fold_results\n",
      "    fold_model, pred_proba, time_start_fit, time_end_fit, predict_time, predict_1_time, predict_n_size, fit_num_cpus, fit_num_gpus = self.ray.get(finished)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\worker.py\", line 2667, in get\n",
      "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\worker.py\", line 864, in get_objects\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(TypeError): \u001b[36mray::_ray_fit()\u001b[39m (pid=21128, ip=127.0.0.1)\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1889, in ray._raylet.execute_task\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 201, in _fit\n",
      "    train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "    dataset = self._process_train_data(\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "    self.processor = create_preprocessor(\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\utils\\data_preprocessor.py\", line 40, in create_preprocessor\n",
      "    return ColumnTransformer(\n",
      "TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "Fitting model: CatBoost_r50_BAG_L1 ... Training model for up to 1901.39s of the 1901.38s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.17%)\n",
      "2025-01-31 00:43:29,233\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-31 00:43:29,237\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-31 00:43:29,240\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-31 00:43:29,244\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-31 00:43:29,246\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-31 00:43:29,250\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\t0.9724\t = Validation score   (roc_auc)\n",
      "\t18.65s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r11_BAG_L1 ... Training model for up to 1880.21s of the 1880.20s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.04%)\n",
      "\t0.8657\t = Validation score   (roc_auc)\n",
      "\t7.3s\t = Training   runtime\n",
      "\t0.11s\t = Validation runtime\n",
      "Fitting model: XGBoost_r194_BAG_L1 ... Training model for up to 1870.44s of the 1870.43s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=1.43%)\n",
      "\t0.9686\t = Validation score   (roc_auc)\n",
      "\t2.64s\t = Training   runtime\n",
      "\t0.11s\t = Validation runtime\n",
      "Fitting model: CatBoost_r69_BAG_L1 ... Training model for up to 1864.83s of the 1864.82s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.29%)\n",
      "\t0.976\t = Validation score   (roc_auc)\n",
      "\t29.56s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r103_BAG_L1 ... Training model for up to 1832.47s of the 1832.46s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.03%)\n",
      "\t0.8776\t = Validation score   (roc_auc)\n",
      "\t6.18s\t = Training   runtime\n",
      "\t0.11s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r14_BAG_L1 ... Training model for up to 1823.96s of the 1823.95s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.03%)\n",
      "\tWarning: Exception caused NeuralNetTorch_r14_BAG_L1 to fail during training... Skipping this model.\n",
      "\t\t\u001b[36mray::_ray_fit()\u001b[39m (pid=9096, ip=127.0.0.1)\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1889, in ray._raylet.execute_task\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 201, in _fit\n",
      "    train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "    dataset = self._process_train_data(\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "    self.processor = create_preprocessor(\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\utils\\data_preprocessor.py\", line 40, in create_preprocessor\n",
      "    return ColumnTransformer(\n",
      "TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 2106, in _train_and_save\n",
      "    model = self._train_single(**model_fit_kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 1993, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\stacker_ensemble_model.py\", line 270, in _fit\n",
      "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\bagged_ensemble_model.py\", line 298, in _fit\n",
      "    self._fit_folds(\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\bagged_ensemble_model.py\", line 724, in _fit_folds\n",
      "    fold_fitting_strategy.after_all_folds_scheduled()\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 690, in after_all_folds_scheduled\n",
      "    self._run_parallel(X, y, X_pseudo, y_pseudo, model_base_ref, time_limit_fold, head_node_id)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 631, in _run_parallel\n",
      "    self._process_fold_results(finished, unfinished, fold_ctx)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 587, in _process_fold_results\n",
      "    raise processed_exception\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 550, in _process_fold_results\n",
      "    fold_model, pred_proba, time_start_fit, time_end_fit, predict_time, predict_1_time, predict_n_size, fit_num_cpus, fit_num_gpus = self.ray.get(finished)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\worker.py\", line 2667, in get\n",
      "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\worker.py\", line 864, in get_objects\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(TypeError): \u001b[36mray::_ray_fit()\u001b[39m (pid=9096, ip=127.0.0.1)\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1889, in ray._raylet.execute_task\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 201, in _fit\n",
      "    train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "    dataset = self._process_train_data(\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "    self.processor = create_preprocessor(\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\utils\\data_preprocessor.py\", line 40, in create_preprocessor\n",
      "    return ColumnTransformer(\n",
      "TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "Fitting model: LightGBM_r161_BAG_L1 ... Training model for up to 1817.91s of the 1817.90s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=2.46%)\n",
      "2025-01-31 00:44:53,261\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-31 00:44:53,265\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-31 00:44:53,268\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-31 00:44:53,271\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-31 00:44:53,275\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-31 00:44:53,279\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-31 00:44:53,283\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\t0.9697\t = Validation score   (roc_auc)\n",
      "\t3.1s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r143_BAG_L1 ... Training model for up to 1812.23s of the 1812.22s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.04%)\n",
      "\t0.892\t = Validation score   (roc_auc)\n",
      "\t9.77s\t = Training   runtime\n",
      "\t0.12s\t = Validation runtime\n",
      "Fitting model: CatBoost_r70_BAG_L1 ... Training model for up to 1799.90s of the 1799.89s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.56%)\n",
      "\t0.9736\t = Validation score   (roc_auc)\n",
      "\t55.39s\t = Training   runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r156_BAG_L1 ... Training model for up to 1741.98s of the 1741.97s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.03%)\n",
      "\t0.8716\t = Validation score   (roc_auc)\n",
      "\t8.69s\t = Training   runtime\n",
      "\t0.11s\t = Validation runtime\n",
      "Fitting model: LightGBM_r196_BAG_L1 ... Training model for up to 1730.92s of the 1730.91s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=1.13%)\n",
      "\t0.9722\t = Validation score   (roc_auc)\n",
      "\t6.05s\t = Training   runtime\n",
      "\t0.1s\t = Validation runtime\n",
      "Fitting model: CatBoost_r167_BAG_L1 ... Training model for up to 1722.34s of the 1722.33s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.97%)\n",
      "\t0.9718\t = Validation score   (roc_auc)\n",
      "\t42.03s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r95_BAG_L1 ... Training model for up to 1677.97s of the 1677.96s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.03%)\n",
      "\t0.8785\t = Validation score   (roc_auc)\n",
      "\t6.23s\t = Training   runtime\n",
      "\t0.1s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r41_BAG_L1 ... Training model for up to 1669.40s of the 1669.39s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.03%)\n",
      "\tWarning: Exception caused NeuralNetTorch_r41_BAG_L1 to fail during training... Skipping this model.\n",
      "\t\t\u001b[36mray::_ray_fit()\u001b[39m (pid=11988, ip=127.0.0.1)\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1889, in ray._raylet.execute_task\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 201, in _fit\n",
      "    train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "    dataset = self._process_train_data(\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "    self.processor = create_preprocessor(\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\utils\\data_preprocessor.py\", line 40, in create_preprocessor\n",
      "    return ColumnTransformer(\n",
      "TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 2106, in _train_and_save\n",
      "    model = self._train_single(**model_fit_kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 1993, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\stacker_ensemble_model.py\", line 270, in _fit\n",
      "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\bagged_ensemble_model.py\", line 298, in _fit\n",
      "    self._fit_folds(\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\bagged_ensemble_model.py\", line 724, in _fit_folds\n",
      "    fold_fitting_strategy.after_all_folds_scheduled()\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 690, in after_all_folds_scheduled\n",
      "    self._run_parallel(X, y, X_pseudo, y_pseudo, model_base_ref, time_limit_fold, head_node_id)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 631, in _run_parallel\n",
      "    self._process_fold_results(finished, unfinished, fold_ctx)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 587, in _process_fold_results\n",
      "    raise processed_exception\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 550, in _process_fold_results\n",
      "    fold_model, pred_proba, time_start_fit, time_end_fit, predict_time, predict_1_time, predict_n_size, fit_num_cpus, fit_num_gpus = self.ray.get(finished)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\worker.py\", line 2667, in get\n",
      "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\worker.py\", line 864, in get_objects\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(TypeError): \u001b[36mray::_ray_fit()\u001b[39m (pid=11988, ip=127.0.0.1)\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1889, in ray._raylet.execute_task\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 201, in _fit\n",
      "    train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "    dataset = self._process_train_data(\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "    self.processor = create_preprocessor(\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\utils\\data_preprocessor.py\", line 40, in create_preprocessor\n",
      "    return ColumnTransformer(\n",
      "TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "Fitting model: XGBoost_r98_BAG_L1 ... Training model for up to 1663.24s of the 1663.23s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=2.30%)\n",
      "2025-01-31 00:47:28,001\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-31 00:47:28,005\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-31 00:47:28,008\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-31 00:47:28,013\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-31 00:47:28,017\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-31 00:47:28,020\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\t0.9714\t = Validation score   (roc_auc)\n",
      "\t14.87s\t = Training   runtime\n",
      "\t0.12s\t = Validation runtime\n",
      "Fitting model: LightGBM_r15_BAG_L1 ... Training model for up to 1645.81s of the 1645.80s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.19%)\n",
      "\t0.9644\t = Validation score   (roc_auc)\n",
      "\t2.16s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r158_BAG_L1 ... Training model for up to 1641.27s of the 1641.26s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.02%)\n",
      "\tWarning: Exception caused NeuralNetTorch_r158_BAG_L1 to fail during training... Skipping this model.\n",
      "\t\t\u001b[36mray::_ray_fit()\u001b[39m (pid=6972, ip=127.0.0.1)\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1889, in ray._raylet.execute_task\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 201, in _fit\n",
      "    train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "    dataset = self._process_train_data(\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "    self.processor = create_preprocessor(\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\utils\\data_preprocessor.py\", line 40, in create_preprocessor\n",
      "    return ColumnTransformer(\n",
      "TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 2106, in _train_and_save\n",
      "    model = self._train_single(**model_fit_kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 1993, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\stacker_ensemble_model.py\", line 270, in _fit\n",
      "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\bagged_ensemble_model.py\", line 298, in _fit\n",
      "    self._fit_folds(\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\bagged_ensemble_model.py\", line 724, in _fit_folds\n",
      "    fold_fitting_strategy.after_all_folds_scheduled()\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 690, in after_all_folds_scheduled\n",
      "    self._run_parallel(X, y, X_pseudo, y_pseudo, model_base_ref, time_limit_fold, head_node_id)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 631, in _run_parallel\n",
      "    self._process_fold_results(finished, unfinished, fold_ctx)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 587, in _process_fold_results\n",
      "    raise processed_exception\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 550, in _process_fold_results\n",
      "    fold_model, pred_proba, time_start_fit, time_end_fit, predict_time, predict_1_time, predict_n_size, fit_num_cpus, fit_num_gpus = self.ray.get(finished)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\worker.py\", line 2667, in get\n",
      "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\worker.py\", line 864, in get_objects\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(TypeError): \u001b[36mray::_ray_fit()\u001b[39m (pid=6972, ip=127.0.0.1)\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1889, in ray._raylet.execute_task\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 201, in _fit\n",
      "    train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "    dataset = self._process_train_data(\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "    self.processor = create_preprocessor(\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\utils\\data_preprocessor.py\", line 40, in create_preprocessor\n",
      "    return ColumnTransformer(\n",
      "TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "Fitting model: CatBoost_r86_BAG_L1 ... Training model for up to 1635.64s of the 1635.63s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=2.57%)\n",
      "2025-01-31 00:47:55,355\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-31 00:47:55,359\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-31 00:47:55,364\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-31 00:47:55,368\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-31 00:47:55,371\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-31 00:47:55,386\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\t0.9694\t = Validation score   (roc_auc)\n",
      "\t87.77s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r37_BAG_L1 ... Training model for up to 1545.27s of the 1545.27s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.05%)\n",
      "\t0.8967\t = Validation score   (roc_auc)\n",
      "\t10.91s\t = Training   runtime\n",
      "\t0.11s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r197_BAG_L1 ... Training model for up to 1531.88s of the 1531.87s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.03%)\n",
      "\tWarning: Exception caused NeuralNetTorch_r197_BAG_L1 to fail during training... Skipping this model.\n",
      "\t\t\u001b[36mray::_ray_fit()\u001b[39m (pid=18756, ip=127.0.0.1)\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1889, in ray._raylet.execute_task\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 201, in _fit\n",
      "    train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "    dataset = self._process_train_data(\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "    self.processor = create_preprocessor(\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\utils\\data_preprocessor.py\", line 40, in create_preprocessor\n",
      "    return ColumnTransformer(\n",
      "TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 2106, in _train_and_save\n",
      "    model = self._train_single(**model_fit_kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 1993, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\stacker_ensemble_model.py\", line 270, in _fit\n",
      "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\bagged_ensemble_model.py\", line 298, in _fit\n",
      "    self._fit_folds(\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\bagged_ensemble_model.py\", line 724, in _fit_folds\n",
      "    fold_fitting_strategy.after_all_folds_scheduled()\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 690, in after_all_folds_scheduled\n",
      "    self._run_parallel(X, y, X_pseudo, y_pseudo, model_base_ref, time_limit_fold, head_node_id)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 631, in _run_parallel\n",
      "    self._process_fold_results(finished, unfinished, fold_ctx)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 587, in _process_fold_results\n",
      "    raise processed_exception\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 550, in _process_fold_results\n",
      "    fold_model, pred_proba, time_start_fit, time_end_fit, predict_time, predict_1_time, predict_n_size, fit_num_cpus, fit_num_gpus = self.ray.get(finished)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\worker.py\", line 2667, in get\n",
      "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\worker.py\", line 864, in get_objects\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(TypeError): \u001b[36mray::_ray_fit()\u001b[39m (pid=18756, ip=127.0.0.1)\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1889, in ray._raylet.execute_task\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 201, in _fit\n",
      "    train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "    dataset = self._process_train_data(\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "    self.processor = create_preprocessor(\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\utils\\data_preprocessor.py\", line 40, in create_preprocessor\n",
      "    return ColumnTransformer(\n",
      "TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "Fitting model: CatBoost_r49_BAG_L1 ... Training model for up to 1525.16s of the 1525.15s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.20%)\n",
      "2025-01-31 00:49:46,309\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-31 00:49:46,312\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-31 00:49:46,315\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-31 00:49:46,319\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-31 00:49:46,341\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-31 00:49:46,345\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-31 00:49:46,350\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\t0.9697\t = Validation score   (roc_auc)\n",
      "\t25.65s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: LightGBM_r143_BAG_L1 ... Training model for up to 1494.73s of the 1494.73s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=1.75%)\n",
      "2025-01-31 00:50:13,732\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\t0.9642\t = Validation score   (roc_auc)\n",
      "\t2.63s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r134_BAG_L1 ... Training model for up to 1489.22s of the 1489.21s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.05%)\n",
      "2025-01-31 00:50:24,081\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\t0.8762\t = Validation score   (roc_auc)\n",
      "\t11.29s\t = Training   runtime\n",
      "\t0.15s\t = Validation runtime\n",
      "Fitting model: LightGBM_r94_BAG_L1 ... Training model for up to 1474.70s of the 1474.69s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.31%)\n",
      "\t0.9736\t = Validation score   (roc_auc)\n",
      "\t2.61s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r143_BAG_L1 ... Training model for up to 1468.66s of the 1468.65s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.03%)\n",
      "\tWarning: Exception caused NeuralNetTorch_r143_BAG_L1 to fail during training... Skipping this model.\n",
      "\t\t\u001b[36mray::_ray_fit()\u001b[39m (pid=23160, ip=127.0.0.1)\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1889, in ray._raylet.execute_task\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 201, in _fit\n",
      "    train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "    dataset = self._process_train_data(\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "    self.processor = create_preprocessor(\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\utils\\data_preprocessor.py\", line 40, in create_preprocessor\n",
      "    return ColumnTransformer(\n",
      "TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 2106, in _train_and_save\n",
      "    model = self._train_single(**model_fit_kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 1993, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\stacker_ensemble_model.py\", line 270, in _fit\n",
      "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\bagged_ensemble_model.py\", line 298, in _fit\n",
      "    self._fit_folds(\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\bagged_ensemble_model.py\", line 724, in _fit_folds\n",
      "    fold_fitting_strategy.after_all_folds_scheduled()\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 690, in after_all_folds_scheduled\n",
      "    self._run_parallel(X, y, X_pseudo, y_pseudo, model_base_ref, time_limit_fold, head_node_id)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 631, in _run_parallel\n",
      "    self._process_fold_results(finished, unfinished, fold_ctx)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 587, in _process_fold_results\n",
      "    raise processed_exception\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 550, in _process_fold_results\n",
      "    fold_model, pred_proba, time_start_fit, time_end_fit, predict_time, predict_1_time, predict_n_size, fit_num_cpus, fit_num_gpus = self.ray.get(finished)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\worker.py\", line 2667, in get\n",
      "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\worker.py\", line 864, in get_objects\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(TypeError): \u001b[36mray::_ray_fit()\u001b[39m (pid=23160, ip=127.0.0.1)\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1889, in ray._raylet.execute_task\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 201, in _fit\n",
      "    train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "    dataset = self._process_train_data(\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "    self.processor = create_preprocessor(\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\utils\\data_preprocessor.py\", line 40, in create_preprocessor\n",
      "    return ColumnTransformer(\n",
      "TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "Fitting model: CatBoost_r128_BAG_L1 ... Training model for up to 1462.83s of the 1462.82s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=2.88%)\n",
      "2025-01-31 00:50:47,895\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-31 00:50:47,899\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-31 00:50:47,903\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-31 00:50:47,907\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-31 00:50:47,910\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-31 00:50:47,930\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-31 00:50:47,932\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-31 00:54:22,228\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-31 00:54:49,829\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\t0.9712\t = Validation score   (roc_auc)\n",
      "\t1042.06s\t = Training   runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r111_BAG_L1 ... Training model for up to 417.93s of the 417.92s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.04%)\n",
      "\t0.8953\t = Validation score   (roc_auc)\n",
      "\t7.97s\t = Training   runtime\n",
      "\t0.13s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r31_BAG_L1 ... Training model for up to 407.56s of the 407.55s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.03%)\n",
      "\tWarning: Exception caused NeuralNetTorch_r31_BAG_L1 to fail during training... Skipping this model.\n",
      "\t\t\u001b[36mray::_ray_fit()\u001b[39m (pid=18420, ip=127.0.0.1)\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1889, in ray._raylet.execute_task\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 201, in _fit\n",
      "    train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "    dataset = self._process_train_data(\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "    self.processor = create_preprocessor(\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\utils\\data_preprocessor.py\", line 40, in create_preprocessor\n",
      "    return ColumnTransformer(\n",
      "TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 2106, in _train_and_save\n",
      "    model = self._train_single(**model_fit_kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 1993, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\stacker_ensemble_model.py\", line 270, in _fit\n",
      "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\bagged_ensemble_model.py\", line 298, in _fit\n",
      "    self._fit_folds(\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\bagged_ensemble_model.py\", line 724, in _fit_folds\n",
      "    fold_fitting_strategy.after_all_folds_scheduled()\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 690, in after_all_folds_scheduled\n",
      "    self._run_parallel(X, y, X_pseudo, y_pseudo, model_base_ref, time_limit_fold, head_node_id)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 631, in _run_parallel\n",
      "    self._process_fold_results(finished, unfinished, fold_ctx)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 587, in _process_fold_results\n",
      "    raise processed_exception\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 550, in _process_fold_results\n",
      "    fold_model, pred_proba, time_start_fit, time_end_fit, predict_time, predict_1_time, predict_n_size, fit_num_cpus, fit_num_gpus = self.ray.get(finished)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\worker.py\", line 2667, in get\n",
      "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\worker.py\", line 864, in get_objects\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(TypeError): \u001b[36mray::_ray_fit()\u001b[39m (pid=18420, ip=127.0.0.1)\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1889, in ray._raylet.execute_task\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 201, in _fit\n",
      "    train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "    dataset = self._process_train_data(\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "    self.processor = create_preprocessor(\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\utils\\data_preprocessor.py\", line 40, in create_preprocessor\n",
      "    return ColumnTransformer(\n",
      "TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "Fitting model: NeuralNetFastAI_r65_BAG_L1 ... Training model for up to 401.08s of the 401.07s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.04%)\n",
      "2025-01-31 01:08:30,114\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-31 01:08:30,114\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-31 01:08:30,121\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-31 01:08:30,121\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-31 01:08:30,126\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-31 01:08:30,132\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\t0.8711\t = Validation score   (roc_auc)\n",
      "\t9.55s\t = Training   runtime\n",
      "\t0.09s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r88_BAG_L1 ... Training model for up to 388.93s of the 388.92s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.05%)\n",
      "\t0.8819\t = Validation score   (roc_auc)\n",
      "\t8.33s\t = Training   runtime\n",
      "\t0.1s\t = Validation runtime\n",
      "Fitting model: LightGBM_r30_BAG_L1 ... Training model for up to 377.21s of the 377.20s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=1.20%)\n",
      "\t0.9742\t = Validation score   (roc_auc)\n",
      "\t3.29s\t = Training   runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: XGBoost_r49_BAG_L1 ... Training model for up to 371.06s of the 371.05s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=1.09%)\n",
      "\t0.9647\t = Validation score   (roc_auc)\n",
      "\t3.64s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: CatBoost_r5_BAG_L1 ... Training model for up to 364.80s of the 364.79s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.15%)\n",
      "\t0.9741\t = Validation score   (roc_auc)\n",
      "\t26.45s\t = Training   runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r87_BAG_L1 ... Training model for up to 335.61s of the 335.60s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.02%)\n",
      "\tWarning: Exception caused NeuralNetTorch_r87_BAG_L1 to fail during training... Skipping this model.\n",
      "\t\t\u001b[36mray::_ray_fit()\u001b[39m (pid=1744, ip=127.0.0.1)\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1889, in ray._raylet.execute_task\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 201, in _fit\n",
      "    train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "    dataset = self._process_train_data(\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "    self.processor = create_preprocessor(\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\utils\\data_preprocessor.py\", line 40, in create_preprocessor\n",
      "    return ColumnTransformer(\n",
      "TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 2106, in _train_and_save\n",
      "    model = self._train_single(**model_fit_kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 1993, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\stacker_ensemble_model.py\", line 270, in _fit\n",
      "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\bagged_ensemble_model.py\", line 298, in _fit\n",
      "    self._fit_folds(\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\bagged_ensemble_model.py\", line 724, in _fit_folds\n",
      "    fold_fitting_strategy.after_all_folds_scheduled()\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 690, in after_all_folds_scheduled\n",
      "    self._run_parallel(X, y, X_pseudo, y_pseudo, model_base_ref, time_limit_fold, head_node_id)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 631, in _run_parallel\n",
      "    self._process_fold_results(finished, unfinished, fold_ctx)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 587, in _process_fold_results\n",
      "    raise processed_exception\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 550, in _process_fold_results\n",
      "    fold_model, pred_proba, time_start_fit, time_end_fit, predict_time, predict_1_time, predict_n_size, fit_num_cpus, fit_num_gpus = self.ray.get(finished)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\worker.py\", line 2667, in get\n",
      "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\worker.py\", line 864, in get_objects\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(TypeError): \u001b[36mray::_ray_fit()\u001b[39m (pid=1744, ip=127.0.0.1)\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1889, in ray._raylet.execute_task\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 201, in _fit\n",
      "    train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "    dataset = self._process_train_data(\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "    self.processor = create_preprocessor(\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\utils\\data_preprocessor.py\", line 40, in create_preprocessor\n",
      "    return ColumnTransformer(\n",
      "TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "Fitting model: NeuralNetTorch_r71_BAG_L1 ... Training model for up to 330.39s of the 330.38s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.02%)\n",
      "\tWarning: Exception caused NeuralNetTorch_r71_BAG_L1 to fail during training... Skipping this model.\n",
      "\t\t\u001b[36mray::_ray_fit()\u001b[39m (pid=13892, ip=127.0.0.1)\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1889, in ray._raylet.execute_task\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 201, in _fit\n",
      "    train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "    dataset = self._process_train_data(\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "    self.processor = create_preprocessor(\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\utils\\data_preprocessor.py\", line 40, in create_preprocessor\n",
      "    return ColumnTransformer(\n",
      "TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 2106, in _train_and_save\n",
      "    model = self._train_single(**model_fit_kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 1993, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\stacker_ensemble_model.py\", line 270, in _fit\n",
      "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\bagged_ensemble_model.py\", line 298, in _fit\n",
      "    self._fit_folds(\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\bagged_ensemble_model.py\", line 724, in _fit_folds\n",
      "    fold_fitting_strategy.after_all_folds_scheduled()\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 690, in after_all_folds_scheduled\n",
      "    self._run_parallel(X, y, X_pseudo, y_pseudo, model_base_ref, time_limit_fold, head_node_id)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 631, in _run_parallel\n",
      "    self._process_fold_results(finished, unfinished, fold_ctx)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 587, in _process_fold_results\n",
      "    raise processed_exception\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 550, in _process_fold_results\n",
      "    fold_model, pred_proba, time_start_fit, time_end_fit, predict_time, predict_1_time, predict_n_size, fit_num_cpus, fit_num_gpus = self.ray.get(finished)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\worker.py\", line 2667, in get\n",
      "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\worker.py\", line 864, in get_objects\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(TypeError): \u001b[36mray::_ray_fit()\u001b[39m (pid=13892, ip=127.0.0.1)\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1889, in ray._raylet.execute_task\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 201, in _fit\n",
      "    train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "    dataset = self._process_train_data(\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "    self.processor = create_preprocessor(\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\utils\\data_preprocessor.py\", line 40, in create_preprocessor\n",
      "    return ColumnTransformer(\n",
      "TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "2025-01-31 01:09:40,448\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-31 01:09:40,452\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-31 01:09:40,452\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-31 01:09:40,458\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-31 01:09:40,462\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-31 01:09:40,467\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-31 01:09:40,471\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "Fitting model: CatBoost_r143_BAG_L1 ... Training model for up to 325.09s of the 325.08s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=1.15%)\n",
      "2025-01-31 01:09:45,815\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-31 01:09:45,818\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-31 01:09:45,822\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-31 01:09:45,826\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-31 01:09:45,828\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-31 01:09:45,832\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\t0.9718\t = Validation score   (roc_auc)\n",
      "\t46.78s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: XGBoost_r31_BAG_L1 ... Training model for up to 275.77s of the 275.76s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.56%)\n",
      "\t0.9681\t = Validation score   (roc_auc)\n",
      "\t4.68s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r185_BAG_L1 ... Training model for up to 268.69s of the 268.68s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.02%)\n",
      "\tWarning: Exception caused NeuralNetTorch_r185_BAG_L1 to fail during training... Skipping this model.\n",
      "\t\t\u001b[36mray::_ray_fit()\u001b[39m (pid=11612, ip=127.0.0.1)\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1889, in ray._raylet.execute_task\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 201, in _fit\n",
      "    train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "    dataset = self._process_train_data(\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "    self.processor = create_preprocessor(\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\utils\\data_preprocessor.py\", line 40, in create_preprocessor\n",
      "    return ColumnTransformer(\n",
      "TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 2106, in _train_and_save\n",
      "    model = self._train_single(**model_fit_kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 1993, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\stacker_ensemble_model.py\", line 270, in _fit\n",
      "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\bagged_ensemble_model.py\", line 298, in _fit\n",
      "    self._fit_folds(\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\bagged_ensemble_model.py\", line 724, in _fit_folds\n",
      "    fold_fitting_strategy.after_all_folds_scheduled()\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 690, in after_all_folds_scheduled\n",
      "    self._run_parallel(X, y, X_pseudo, y_pseudo, model_base_ref, time_limit_fold, head_node_id)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 631, in _run_parallel\n",
      "    self._process_fold_results(finished, unfinished, fold_ctx)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 587, in _process_fold_results\n",
      "    raise processed_exception\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 550, in _process_fold_results\n",
      "    fold_model, pred_proba, time_start_fit, time_end_fit, predict_time, predict_1_time, predict_n_size, fit_num_cpus, fit_num_gpus = self.ray.get(finished)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\worker.py\", line 2667, in get\n",
      "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\worker.py\", line 864, in get_objects\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(TypeError): \u001b[36mray::_ray_fit()\u001b[39m (pid=11612, ip=127.0.0.1)\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1889, in ray._raylet.execute_task\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 201, in _fit\n",
      "    train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "    dataset = self._process_train_data(\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "    self.processor = create_preprocessor(\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\utils\\data_preprocessor.py\", line 40, in create_preprocessor\n",
      "    return ColumnTransformer(\n",
      "TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "Fitting model: NeuralNetFastAI_r160_BAG_L1 ... Training model for up to 263.40s of the 263.39s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.04%)\n",
      "2025-01-31 01:10:47,434\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-31 01:10:47,434\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-31 01:10:47,434\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-31 01:10:47,443\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-31 01:10:47,450\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-31 01:10:47,454\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\t0.8806\t = Validation score   (roc_auc)\n",
      "\t6.5s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: CatBoost_r60_BAG_L1 ... Training model for up to 254.27s of the 254.26s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.45%)\n",
      "\t0.9732\t = Validation score   (roc_auc)\n",
      "\t66.89s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: LightGBM_r135_BAG_L1 ... Training model for up to 183.81s of the 183.80s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=1.63%)\n",
      "\t0.9688\t = Validation score   (roc_auc)\n",
      "\t2.35s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: XGBoost_r22_BAG_L1 ... Training model for up to 179.07s of the 179.06s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.55%)\n",
      "\t0.9692\t = Validation score   (roc_auc)\n",
      "\t3.12s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r69_BAG_L1 ... Training model for up to 173.51s of the 173.49s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.04%)\n",
      "\t0.8708\t = Validation score   (roc_auc)\n",
      "\t6.47s\t = Training   runtime\n",
      "\t0.09s\t = Validation runtime\n",
      "Fitting model: CatBoost_r6_BAG_L1 ... Training model for up to 164.57s of the 164.56s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.21%)\n",
      "\t0.9723\t = Validation score   (roc_auc)\n",
      "\t21.64s\t = Training   runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r138_BAG_L1 ... Training model for up to 139.72s of the 139.71s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.04%)\n",
      "\t0.8874\t = Validation score   (roc_auc)\n",
      "\t7.67s\t = Training   runtime\n",
      "\t0.09s\t = Validation runtime\n",
      "Fitting model: LightGBM_r121_BAG_L1 ... Training model for up to 129.65s of the 129.64s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=2.31%)\n",
      "\t0.9685\t = Validation score   (roc_auc)\n",
      "\t3.04s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r172_BAG_L1 ... Training model for up to 123.66s of the 123.65s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.04%)\n",
      "\t0.8677\t = Validation score   (roc_auc)\n",
      "\t8.1s\t = Training   runtime\n",
      "\t0.11s\t = Validation runtime\n",
      "Fitting model: CatBoost_r180_BAG_L1 ... Training model for up to 112.90s of the 112.89s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=1.47%)\n",
      "\t0.9703\t = Validation score   (roc_auc)\n",
      "\t91.15s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r76_BAG_L1 ... Training model for up to 18.67s of the 18.65s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.02%)\n",
      "\tWarning: Exception caused NeuralNetTorch_r76_BAG_L1 to fail during training... Skipping this model.\n",
      "\t\t\u001b[36mray::_ray_fit()\u001b[39m (pid=22000, ip=127.0.0.1)\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1889, in ray._raylet.execute_task\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 201, in _fit\n",
      "    train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "    dataset = self._process_train_data(\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "    self.processor = create_preprocessor(\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\utils\\data_preprocessor.py\", line 40, in create_preprocessor\n",
      "    return ColumnTransformer(\n",
      "TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 2106, in _train_and_save\n",
      "    model = self._train_single(**model_fit_kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 1993, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\stacker_ensemble_model.py\", line 270, in _fit\n",
      "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\bagged_ensemble_model.py\", line 298, in _fit\n",
      "    self._fit_folds(\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\bagged_ensemble_model.py\", line 724, in _fit_folds\n",
      "    fold_fitting_strategy.after_all_folds_scheduled()\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 690, in after_all_folds_scheduled\n",
      "    self._run_parallel(X, y, X_pseudo, y_pseudo, model_base_ref, time_limit_fold, head_node_id)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 631, in _run_parallel\n",
      "    self._process_fold_results(finished, unfinished, fold_ctx)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 587, in _process_fold_results\n",
      "    raise processed_exception\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 550, in _process_fold_results\n",
      "    fold_model, pred_proba, time_start_fit, time_end_fit, predict_time, predict_1_time, predict_n_size, fit_num_cpus, fit_num_gpus = self.ray.get(finished)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\worker.py\", line 2667, in get\n",
      "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\worker.py\", line 864, in get_objects\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(TypeError): \u001b[36mray::_ray_fit()\u001b[39m (pid=22000, ip=127.0.0.1)\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1889, in ray._raylet.execute_task\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 201, in _fit\n",
      "    train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "    dataset = self._process_train_data(\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "    self.processor = create_preprocessor(\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\utils\\data_preprocessor.py\", line 40, in create_preprocessor\n",
      "    return ColumnTransformer(\n",
      "TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "Fitting model: NeuralNetTorch_r121_BAG_L1 ... Training model for up to 13.28s of the 13.27s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.02%)\n",
      "2025-01-31 01:14:57,334\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-31 01:14:57,335\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-31 01:14:57,341\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-31 01:14:57,341\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-31 01:14:57,345\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-31 01:14:57,353\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\tWarning: Exception caused NeuralNetTorch_r121_BAG_L1 to fail during training... Skipping this model.\n",
      "\t\t\u001b[36mray::_ray_fit()\u001b[39m (pid=22884, ip=127.0.0.1)\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1889, in ray._raylet.execute_task\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 201, in _fit\n",
      "    train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "    dataset = self._process_train_data(\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "    self.processor = create_preprocessor(\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\utils\\data_preprocessor.py\", line 40, in create_preprocessor\n",
      "    return ColumnTransformer(\n",
      "TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 2106, in _train_and_save\n",
      "    model = self._train_single(**model_fit_kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 1993, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\stacker_ensemble_model.py\", line 270, in _fit\n",
      "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\bagged_ensemble_model.py\", line 298, in _fit\n",
      "    self._fit_folds(\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\bagged_ensemble_model.py\", line 724, in _fit_folds\n",
      "    fold_fitting_strategy.after_all_folds_scheduled()\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 690, in after_all_folds_scheduled\n",
      "    self._run_parallel(X, y, X_pseudo, y_pseudo, model_base_ref, time_limit_fold, head_node_id)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 631, in _run_parallel\n",
      "    self._process_fold_results(finished, unfinished, fold_ctx)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 587, in _process_fold_results\n",
      "    raise processed_exception\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 550, in _process_fold_results\n",
      "    fold_model, pred_proba, time_start_fit, time_end_fit, predict_time, predict_1_time, predict_n_size, fit_num_cpus, fit_num_gpus = self.ray.get(finished)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\worker.py\", line 2667, in get\n",
      "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\worker.py\", line 864, in get_objects\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(TypeError): \u001b[36mray::_ray_fit()\u001b[39m (pid=22884, ip=127.0.0.1)\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1889, in ray._raylet.execute_task\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 201, in _fit\n",
      "    train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "    dataset = self._process_train_data(\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "    self.processor = create_preprocessor(\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\utils\\data_preprocessor.py\", line 40, in create_preprocessor\n",
      "    return ColumnTransformer(\n",
      "TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 360.00s of the 7.18s of remaining time.\n",
      "\tEnsemble Weights: {'LightGBMXT_BAG_L1': 0.462, 'CatBoost_r69_BAG_L1': 0.462, 'NeuralNetFastAI_r37_BAG_L1': 0.077}\n",
      "\t0.9777\t = Validation score   (roc_auc)\n",
      "\t0.03s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 2599.53s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 242.4 rows/s (50 batch size)\n",
      "Automatically performing refit_full as a post-fit operation (due to `.fit(..., refit_full=True)`\n",
      "Refitting models via `predictor.refit_full` using all of the data (combined train and validation)...\n",
      "\tModels trained in this way will have the suffix \"_FULL\" and have NaN validation score.\n",
      "\tThis process is not bound by time_limit, but should take less time than the original `predictor.fit` call.\n",
      "\tTo learn more, refer to the `.refit_full` method docstring which explains how \"_FULL\" models differ from normal models.\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBMXT_BAG_L1_FULL ...\n",
      "2025-01-31 01:14:58,884\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-31 01:14:58,895\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-31 01:14:58,895\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-31 01:14:58,900\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-31 01:14:58,900\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\t0.41s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBM_BAG_L1_FULL ...\n",
      "\t0.14s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: CatBoost_BAG_L1_FULL ...\n",
      "\t6.36s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: NeuralNetFastAI_BAG_L1_FULL ...\n",
      "\tStopping at the best epoch learned earlier - 10.\n",
      "\t0.48s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: XGBoost_BAG_L1_FULL ...\n",
      "\t0.17s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBMLarge_BAG_L1_FULL ...\n",
      "\t0.32s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: CatBoost_r177_BAG_L1_FULL ...\n",
      "\t4.09s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBM_r131_BAG_L1_FULL ...\n",
      "\t0.32s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: NeuralNetFastAI_r191_BAG_L1_FULL ...\n",
      "\tStopping at the best epoch learned earlier - 5.\n",
      "\t0.3s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: CatBoost_r9_BAG_L1_FULL ...\n",
      "2025-01-31 01:15:24,380\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\t17.01s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBM_r96_BAG_L1_FULL ...\n",
      "\t0.47s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: XGBoost_r33_BAG_L1_FULL ...\n",
      "\t0.61s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: CatBoost_r137_BAG_L1_FULL ...\n",
      "\t5.78s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: NeuralNetFastAI_r102_BAG_L1_FULL ...\n",
      "\tStopping at the best epoch learned earlier - 5.\n",
      "\t0.86s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: CatBoost_r13_BAG_L1_FULL ...\n",
      "\t38.23s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBM_r188_BAG_L1_FULL ...\n",
      "\t0.28s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: NeuralNetFastAI_r145_BAG_L1_FULL ...\n",
      "\tStopping at the best epoch learned earlier - 6.\n",
      "\t0.5s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: XGBoost_r89_BAG_L1_FULL ...\n",
      "\t0.16s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBM_r130_BAG_L1_FULL ...\n",
      "\t0.15s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: CatBoost_r50_BAG_L1_FULL ...\n",
      "\t2.63s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: NeuralNetFastAI_r11_BAG_L1_FULL ...\n",
      "\tStopping at the best epoch learned earlier - 3.\n",
      "\t0.35s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: XGBoost_r194_BAG_L1_FULL ...\n",
      "\t0.17s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: CatBoost_r69_BAG_L1_FULL ...\n",
      "\t4.21s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: NeuralNetFastAI_r103_BAG_L1_FULL ...\n",
      "\tStopping at the best epoch learned earlier - 6.\n",
      "\t0.27s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBM_r161_BAG_L1_FULL ...\n",
      "\t0.42s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: NeuralNetFastAI_r143_BAG_L1_FULL ...\n",
      "\tStopping at the best epoch learned earlier - 10.\n",
      "\t1.63s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: CatBoost_r70_BAG_L1_FULL ...\n",
      "\t7.3s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: NeuralNetFastAI_r156_BAG_L1_FULL ...\n",
      "\tStopping at the best epoch learned earlier - 5.\n",
      "\t0.79s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBM_r196_BAG_L1_FULL ...\n",
      "\t1.24s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: CatBoost_r167_BAG_L1_FULL ...\n",
      "2025-01-31 01:16:40,347\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\t4.63s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: NeuralNetFastAI_r95_BAG_L1_FULL ...\n",
      "\tStopping at the best epoch learned earlier - 4.\n",
      "\t0.39s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: XGBoost_r98_BAG_L1_FULL ...\n",
      "\t2.18s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBM_r15_BAG_L1_FULL ...\n",
      "\t0.19s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: CatBoost_r86_BAG_L1_FULL ...\n",
      "\t10.83s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: NeuralNetFastAI_r37_BAG_L1_FULL ...\n",
      "\tStopping at the best epoch learned earlier - 10.\n",
      "\t1.84s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: CatBoost_r49_BAG_L1_FULL ...\n",
      "\t3.7s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBM_r143_BAG_L1_FULL ...\n",
      "\t0.27s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: NeuralNetFastAI_r134_BAG_L1_FULL ...\n",
      "\tStopping at the best epoch learned earlier - 1.\n",
      "\t0.47s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBM_r94_BAG_L1_FULL ...\n",
      "\t0.21s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: CatBoost_r128_BAG_L1_FULL ...\n",
      "2025-01-31 01:17:42,047\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\t79.02s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: NeuralNetFastAI_r111_BAG_L1_FULL ...\n",
      "\tStopping at the best epoch learned earlier - 7.\n",
      "\t1.21s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: NeuralNetFastAI_r65_BAG_L1_FULL ...\n",
      "\tStopping at the best epoch learned earlier - 16.\n",
      "\t2.0s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: NeuralNetFastAI_r88_BAG_L1_FULL ...\n",
      "\tStopping at the best epoch learned earlier - 2.\n",
      "\t0.48s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBM_r30_BAG_L1_FULL ...\n",
      "\t0.42s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: XGBoost_r49_BAG_L1_FULL ...\n",
      "\t0.3s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: CatBoost_r5_BAG_L1_FULL ...\n",
      "\t4.65s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: CatBoost_r143_BAG_L1_FULL ...\n",
      "\t5.09s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: XGBoost_r31_BAG_L1_FULL ...\n",
      "\t0.62s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: NeuralNetFastAI_r160_BAG_L1_FULL ...\n",
      "\tStopping at the best epoch learned earlier - 5.\n",
      "\t0.43s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: CatBoost_r60_BAG_L1_FULL ...\n",
      "\t8.04s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBM_r135_BAG_L1_FULL ...\n",
      "\t0.16s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: XGBoost_r22_BAG_L1_FULL ...\n",
      "\t0.2s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: NeuralNetFastAI_r69_BAG_L1_FULL ...\n",
      "\tStopping at the best epoch learned earlier - 6.\n",
      "\t0.46s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: CatBoost_r6_BAG_L1_FULL ...\n",
      "\t2.68s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: NeuralNetFastAI_r138_BAG_L1_FULL ...\n",
      "\tStopping at the best epoch learned earlier - 7.\n",
      "\t0.57s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBM_r121_BAG_L1_FULL ...\n",
      "\t0.41s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: NeuralNetFastAI_r172_BAG_L1_FULL ...\n",
      "\tStopping at the best epoch learned earlier - 1.\n",
      "\t0.32s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: CatBoost_r180_BAG_L1_FULL ...\n",
      "\t14.8s\t = Training   runtime\n",
      "Fitting model: WeightedEnsemble_L2_FULL | Skipping fit via cloning parent ...\n",
      "\tEnsemble Weights: {'LightGBMXT_BAG_L1': 0.462, 'CatBoost_r69_BAG_L1': 0.462, 'NeuralNetFastAI_r37_BAG_L1': 0.077}\n",
      "\t0.03s\t = Training   runtime\n",
      "Updated best model to \"WeightedEnsemble_L2_FULL\" (Previously \"WeightedEnsemble_L2\"). AutoGluon will default to using \"WeightedEnsemble_L2_FULL\" for predict() and predict_proba().\n",
      "Refit complete, total runtime = 249.37s ... Best model: \"WeightedEnsemble_L2_FULL\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\autogluon\\tlp\\AutogluonModels\\synthetic\\tvaes\\v2\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<autogluon.tabular.predictor.predictor.TabularPredictor at 0x1d0ff6472b0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.fit(\n",
    "    train_data = df_train,\n",
    "    presets = ['high_quality'],\n",
    "    time_limit = 1 * 3600,\n",
    "    auto_stack = True,\n",
    "    excluded_model_types=['KNN','RF','XT', 'LR'],\n",
    "    verbosity = 2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Summary of fit() ***\n",
      "Estimated performance of each model:\n",
      "                                model  score_val eval_metric  pred_time_val     fit_time  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
      "0                 WeightedEnsemble_L2   0.977686     roc_auc       0.207192    41.759184                0.001023           0.033920            2      False         59\n",
      "1                 CatBoost_r69_BAG_L1   0.975975     roc_auc       0.063878    29.564252                0.063878          29.564252            1      False         23\n",
      "2                   LightGBMXT_BAG_L1   0.975899     roc_auc       0.035680     1.250397                0.035680           1.250397            1      False          1\n",
      "3                 LightGBM_r30_BAG_L1   0.974239     roc_auc       0.069385     3.286644                0.069385           3.286644            1      False         44\n",
      "4                LightGBM_r188_BAG_L1   0.974188     roc_auc       0.035332     2.354293                0.035332           2.354293            1      False         16\n",
      "5                  CatBoost_r5_BAG_L1   0.974086     roc_auc       0.079475    26.453147                0.079475          26.453147            1      False         46\n",
      "6                 LightGBM_r94_BAG_L1   0.973626     roc_auc       0.050260     2.609875                0.050260           2.609875            1      False         39\n",
      "7                 CatBoost_r70_BAG_L1   0.973601     roc_auc       0.068592    55.393886                0.068592          55.393886            1      False         27\n",
      "8                 CatBoost_r60_BAG_L1   0.973192     roc_auc       0.064883    66.894295                0.064883          66.894295            1      False         50\n",
      "9                 CatBoost_r50_BAG_L1   0.972401     roc_auc       0.063652    18.648702                0.063652          18.648702            1      False         20\n",
      "10                 CatBoost_r6_BAG_L1   0.972273     roc_auc       0.069535    21.642923                0.069535          21.642923            1      False         54\n",
      "11               LightGBM_r196_BAG_L1   0.972197     roc_auc       0.102021     6.054649                0.102021           6.054649            1      False         29\n",
      "12                    CatBoost_BAG_L1   0.972018     roc_auc       0.056752    42.067768                0.056752          42.067768            1      False          3\n",
      "13               CatBoost_r137_BAG_L1   0.971865     roc_auc       0.067588    36.101757                0.067588          36.101757            1      False         13\n",
      "14               CatBoost_r167_BAG_L1   0.971788     roc_auc       0.060478    42.025530                0.060478          42.025530            1      False         30\n",
      "15               CatBoost_r143_BAG_L1   0.971763     roc_auc       0.060333    46.784242                0.060333          46.784242            1      False         47\n",
      "16                 XGBoost_r98_BAG_L1   0.971405     roc_auc       0.117538    14.869099                0.117538          14.869099            1      False         32\n",
      "17               CatBoost_r177_BAG_L1   0.971252     roc_auc       0.059254    31.531255                0.059254          31.531255            1      False          7\n",
      "18               CatBoost_r128_BAG_L1   0.971227     roc_auc       0.074856  1042.061909                0.074856        1042.061909            1      False         40\n",
      "19                LightGBM_r96_BAG_L1   0.970997     roc_auc       0.070961     7.115317                0.070961           7.115317            1      False         11\n",
      "20                 CatBoost_r9_BAG_L1   0.970869     roc_auc       0.060150   132.065515                0.060150         132.065515            1      False         10\n",
      "21                CatBoost_r13_BAG_L1   0.970869     roc_auc       0.064011   324.509041                0.064011         324.509041            1      False         15\n",
      "22               CatBoost_r180_BAG_L1   0.970307     roc_auc       0.039804    91.149207                0.039804          91.149207            1      False         58\n",
      "23                CatBoost_r49_BAG_L1   0.969695     roc_auc       0.052444    25.648056                0.052444          25.648056            1      False         36\n",
      "24               LightGBM_r161_BAG_L1   0.969695     roc_auc       0.050587     3.104968                0.050587           3.104968            1      False         25\n",
      "25                CatBoost_r86_BAG_L1   0.969439     roc_auc       0.045871    87.770524                0.045871          87.770524            1      False         34\n",
      "26                 XGBoost_r22_BAG_L1   0.969158     roc_auc       0.042232     3.116197                0.042232           3.116197            1      False         52\n",
      "27               LightGBM_r135_BAG_L1   0.968801     roc_auc       0.009461     2.346707                0.009461           2.346707            1      False         51\n",
      "28               LightGBM_r131_BAG_L1   0.968724     roc_auc       0.040092     2.460581                0.040092           2.460581            1      False          8\n",
      "29                XGBoost_r194_BAG_L1   0.968648     roc_auc       0.107840     2.640069                0.107840           2.640069            1      False         22\n",
      "30               LightGBM_r121_BAG_L1   0.968520     roc_auc       0.047321     3.035153                0.047321           3.035153            1      False         56\n",
      "31                 XGBoost_r89_BAG_L1   0.968393     roc_auc       0.046242     2.883115                0.046242           2.883115            1      False         18\n",
      "32                 XGBoost_r31_BAG_L1   0.968112     roc_auc       0.060429     4.683691                0.060429           4.683691            1      False         48\n",
      "33               LightGBM_r130_BAG_L1   0.967576     roc_auc       0.037177     2.169868                0.037177           2.169868            1      False         19\n",
      "34                 XGBoost_r33_BAG_L1   0.967269     roc_auc       0.057413     4.686511                0.057413           4.686511            1      False         12\n",
      "35                     XGBoost_BAG_L1   0.964920     roc_auc       0.044433     2.945579                0.044433           2.945579            1      False          5\n",
      "36                 XGBoost_r49_BAG_L1   0.964716     roc_auc       0.056819     3.642580                0.056819           3.642580            1      False         45\n",
      "37                LightGBM_r15_BAG_L1   0.964384     roc_auc       0.035131     2.158880                0.035131           2.158880            1      False         33\n",
      "38               LightGBM_r143_BAG_L1   0.964205     roc_auc       0.049992     2.633712                0.049992           2.633712            1      False         37\n",
      "39                    LightGBM_BAG_L1   0.961831     roc_auc       0.032267     1.697228                0.032267           1.697228            1      False          2\n",
      "40               LightGBMLarge_BAG_L1   0.949653     roc_auc       0.038600     3.049654                0.038600           3.049654            1      False          6\n",
      "41         NeuralNetFastAI_r37_BAG_L1   0.896727     roc_auc       0.106612    10.910614                0.106612          10.910614            1      False         35\n",
      "42        NeuralNetFastAI_r111_BAG_L1   0.895297     roc_auc       0.126136     7.974630                0.126136           7.974630            1      False         41\n",
      "43        NeuralNetFastAI_r143_BAG_L1   0.891978     roc_auc       0.116027     9.768576                0.116027           9.768576            1      False         26\n",
      "44        NeuralNetFastAI_r138_BAG_L1   0.887383     roc_auc       0.092263     7.667891                0.092263           7.667891            1      False         55\n",
      "45         NeuralNetFastAI_r88_BAG_L1   0.881944     roc_auc       0.099867     8.329072                0.099867           8.329072            1      False         43\n",
      "46             NeuralNetFastAI_BAG_L1   0.881919     roc_auc       0.083769     5.959590                0.083769           5.959590            1      False          4\n",
      "47        NeuralNetFastAI_r160_BAG_L1   0.880566     roc_auc       0.041399     6.497104                0.041399           6.497104            1      False         49\n",
      "48        NeuralNetFastAI_r145_BAG_L1   0.880489     roc_auc       0.101561     6.536837                0.101561           6.536837            1      False         17\n",
      "49         NeuralNetFastAI_r95_BAG_L1   0.878498     roc_auc       0.099184     6.227763                0.099184           6.227763            1      False         31\n",
      "50        NeuralNetFastAI_r103_BAG_L1   0.877630     roc_auc       0.106362     6.176912                0.106362           6.176912            1      False         24\n",
      "51        NeuralNetFastAI_r134_BAG_L1   0.876174     roc_auc       0.147117    11.286454                0.147117          11.286454            1      False         38\n",
      "52        NeuralNetFastAI_r191_BAG_L1   0.875306     roc_auc       0.110051     6.900452                0.110051           6.900452            1      False          9\n",
      "53        NeuralNetFastAI_r156_BAG_L1   0.871553     roc_auc       0.108950     8.685307                0.108950           8.685307            1      False         28\n",
      "54         NeuralNetFastAI_r65_BAG_L1   0.871068     roc_auc       0.089826     9.546723                0.089826           9.546723            1      False         42\n",
      "55         NeuralNetFastAI_r69_BAG_L1   0.870813     roc_auc       0.085629     6.473749                0.085629           6.473749            1      False         53\n",
      "56        NeuralNetFastAI_r172_BAG_L1   0.867749     roc_auc       0.113724     8.097122                0.113724           8.097122            1      False         57\n",
      "57        NeuralNetFastAI_r102_BAG_L1   0.867570     roc_auc       0.124813     8.332886                0.124813           8.332886            1      False         14\n",
      "58         NeuralNetFastAI_r11_BAG_L1   0.865681     roc_auc       0.107489     7.295688                0.107489           7.295688            1      False         21\n",
      "59            XGBoost_r98_BAG_L1_FULL        NaN     roc_auc            NaN     2.179057                     NaN           2.179057            1       True         91\n",
      "60            XGBoost_r89_BAG_L1_FULL        NaN     roc_auc            NaN     0.158450                     NaN           0.158450            1       True         77\n",
      "61            XGBoost_r49_BAG_L1_FULL        NaN     roc_auc            NaN     0.301672                     NaN           0.301672            1       True        104\n",
      "62            XGBoost_r33_BAG_L1_FULL        NaN     roc_auc            NaN     0.606104                     NaN           0.606104            1       True         71\n",
      "63            XGBoost_r31_BAG_L1_FULL        NaN     roc_auc            NaN     0.618627                     NaN           0.618627            1       True        107\n",
      "64            XGBoost_r22_BAG_L1_FULL        NaN     roc_auc            NaN     0.201853                     NaN           0.201853            1       True        111\n",
      "65           XGBoost_r194_BAG_L1_FULL        NaN     roc_auc            NaN     0.171034                     NaN           0.171034            1       True         81\n",
      "66                XGBoost_BAG_L1_FULL        NaN     roc_auc            NaN     0.165852                     NaN           0.165852            1       True         64\n",
      "67           WeightedEnsemble_L2_FULL        NaN     roc_auc            NaN     6.497350                     NaN           0.033920            2       True        118\n",
      "68    NeuralNetFastAI_r95_BAG_L1_FULL        NaN     roc_auc            NaN     0.391472                     NaN           0.391472            1       True         90\n",
      "69    NeuralNetFastAI_r88_BAG_L1_FULL        NaN     roc_auc            NaN     0.481528                     NaN           0.481528            1       True        102\n",
      "70    NeuralNetFastAI_r69_BAG_L1_FULL        NaN     roc_auc            NaN     0.460894                     NaN           0.460894            1       True        112\n",
      "71    NeuralNetFastAI_r65_BAG_L1_FULL        NaN     roc_auc            NaN     2.001647                     NaN           2.001647            1       True        101\n",
      "72    NeuralNetFastAI_r37_BAG_L1_FULL        NaN     roc_auc            NaN     1.841722                     NaN           1.841722            1       True         94\n",
      "73   NeuralNetFastAI_r191_BAG_L1_FULL        NaN     roc_auc            NaN     0.301042                     NaN           0.301042            1       True         68\n",
      "74   NeuralNetFastAI_r172_BAG_L1_FULL        NaN     roc_auc            NaN     0.324567                     NaN           0.324567            1       True        116\n",
      "75   NeuralNetFastAI_r160_BAG_L1_FULL        NaN     roc_auc            NaN     0.429720                     NaN           0.429720            1       True        108\n",
      "76   NeuralNetFastAI_r156_BAG_L1_FULL        NaN     roc_auc            NaN     0.786643                     NaN           0.786643            1       True         87\n",
      "77   NeuralNetFastAI_r145_BAG_L1_FULL        NaN     roc_auc            NaN     0.502055                     NaN           0.502055            1       True         76\n",
      "78   NeuralNetFastAI_r143_BAG_L1_FULL        NaN     roc_auc            NaN     1.631953                     NaN           1.631953            1       True         85\n",
      "79   NeuralNetFastAI_r138_BAG_L1_FULL        NaN     roc_auc            NaN     0.569783                     NaN           0.569783            1       True        114\n",
      "80   NeuralNetFastAI_r134_BAG_L1_FULL        NaN     roc_auc            NaN     0.467399                     NaN           0.467399            1       True         97\n",
      "81    NeuralNetFastAI_r11_BAG_L1_FULL        NaN     roc_auc            NaN     0.352183                     NaN           0.352183            1       True         80\n",
      "82   NeuralNetFastAI_r111_BAG_L1_FULL        NaN     roc_auc            NaN     1.207786                     NaN           1.207786            1       True        100\n",
      "83   NeuralNetFastAI_r103_BAG_L1_FULL        NaN     roc_auc            NaN     0.272323                     NaN           0.272323            1       True         83\n",
      "84   NeuralNetFastAI_r102_BAG_L1_FULL        NaN     roc_auc            NaN     0.859345                     NaN           0.859345            1       True         73\n",
      "85        NeuralNetFastAI_BAG_L1_FULL        NaN     roc_auc            NaN     0.478848                     NaN           0.478848            1       True         63\n",
      "86           LightGBM_r96_BAG_L1_FULL        NaN     roc_auc            NaN     0.465354                     NaN           0.465354            1       True         70\n",
      "87           LightGBM_r94_BAG_L1_FULL        NaN     roc_auc            NaN     0.209047                     NaN           0.209047            1       True         98\n",
      "88           LightGBM_r30_BAG_L1_FULL        NaN     roc_auc            NaN     0.415803                     NaN           0.415803            1       True        103\n",
      "89          LightGBM_r196_BAG_L1_FULL        NaN     roc_auc            NaN     1.238010                     NaN           1.238010            1       True         88\n",
      "90          LightGBM_r188_BAG_L1_FULL        NaN     roc_auc            NaN     0.284360                     NaN           0.284360            1       True         75\n",
      "91          LightGBM_r161_BAG_L1_FULL        NaN     roc_auc            NaN     0.422961                     NaN           0.422961            1       True         84\n",
      "92           LightGBM_r15_BAG_L1_FULL        NaN     roc_auc            NaN     0.191628                     NaN           0.191628            1       True         92\n",
      "93          LightGBM_r143_BAG_L1_FULL        NaN     roc_auc            NaN     0.265473                     NaN           0.265473            1       True         96\n",
      "94          LightGBM_r135_BAG_L1_FULL        NaN     roc_auc            NaN     0.162569                     NaN           0.162569            1       True        110\n",
      "95          LightGBM_r131_BAG_L1_FULL        NaN     roc_auc            NaN     0.315413                     NaN           0.315413            1       True         67\n",
      "96          LightGBM_r130_BAG_L1_FULL        NaN     roc_auc            NaN     0.150510                     NaN           0.150510            1       True         78\n",
      "97          LightGBM_r121_BAG_L1_FULL        NaN     roc_auc            NaN     0.407051                     NaN           0.407051            1       True        115\n",
      "98               LightGBM_BAG_L1_FULL        NaN     roc_auc            NaN     0.144528                     NaN           0.144528            1       True         61\n",
      "99             LightGBMXT_BAG_L1_FULL        NaN     roc_auc            NaN     0.409025                     NaN           0.409025            1       True         60\n",
      "100         LightGBMLarge_BAG_L1_FULL        NaN     roc_auc            NaN     0.319247                     NaN           0.319247            1       True         65\n",
      "101           CatBoost_r9_BAG_L1_FULL        NaN     roc_auc            NaN    17.012684                     NaN          17.012684            1       True         69\n",
      "102          CatBoost_r86_BAG_L1_FULL        NaN     roc_auc            NaN    10.833664                     NaN          10.833664            1       True         93\n",
      "103          CatBoost_r70_BAG_L1_FULL        NaN     roc_auc            NaN     7.302479                     NaN           7.302479            1       True         86\n",
      "104           CatBoost_r6_BAG_L1_FULL        NaN     roc_auc            NaN     2.675620                     NaN           2.675620            1       True        113\n",
      "105          CatBoost_r69_BAG_L1_FULL        NaN     roc_auc            NaN     4.212683                     NaN           4.212683            1       True         82\n",
      "106          CatBoost_r60_BAG_L1_FULL        NaN     roc_auc            NaN     8.043899                     NaN           8.043899            1       True        109\n",
      "107           CatBoost_r5_BAG_L1_FULL        NaN     roc_auc            NaN     4.652194                     NaN           4.652194            1       True        105\n",
      "108          CatBoost_r50_BAG_L1_FULL        NaN     roc_auc            NaN     2.630136                     NaN           2.630136            1       True         79\n",
      "109          CatBoost_r49_BAG_L1_FULL        NaN     roc_auc            NaN     3.703181                     NaN           3.703181            1       True         95\n",
      "110         CatBoost_r180_BAG_L1_FULL        NaN     roc_auc            NaN    14.796708                     NaN          14.796708            1       True        117\n",
      "111         CatBoost_r177_BAG_L1_FULL        NaN     roc_auc            NaN     4.090867                     NaN           4.090867            1       True         66\n",
      "112         CatBoost_r167_BAG_L1_FULL        NaN     roc_auc            NaN     4.632171                     NaN           4.632171            1       True         89\n",
      "113         CatBoost_r143_BAG_L1_FULL        NaN     roc_auc            NaN     5.087612                     NaN           5.087612            1       True        106\n",
      "114          CatBoost_r13_BAG_L1_FULL        NaN     roc_auc            NaN    38.225583                     NaN          38.225583            1       True         74\n",
      "115         CatBoost_r137_BAG_L1_FULL        NaN     roc_auc            NaN     5.779315                     NaN           5.779315            1       True         72\n",
      "116         CatBoost_r128_BAG_L1_FULL        NaN     roc_auc            NaN    79.017386                     NaN          79.017386            1       True         99\n",
      "117              CatBoost_BAG_L1_FULL        NaN     roc_auc            NaN     6.363546                     NaN           6.363546            1       True         62\n",
      "Number of models trained: 118\n",
      "Types of models trained:\n",
      "{'StackerEnsembleModel_LGB', 'StackerEnsembleModel_CatBoost', 'StackerEnsembleModel_XGBoost', 'WeightedEnsembleModel', 'StackerEnsembleModel_NNFastAiTabular'}\n",
      "Bagging used: True  (with 8 folds)\n",
      "Multi-layer stack-ensembling used: False \n",
      "Feature Metadata (Processed):\n",
      "(raw dtype, special dtypes):\n",
      "('category', [])                    :  1 | ['demo-rangoEdad']\n",
      "('category', ['text_as_category'])  :  1 | ['clin-tipoAlcohol']\n",
      "('float', [])                       : 17 | ['clin-numCigarros', 'clin-aÃ±osSinFumar', 'ques-Sus-total-PD', 'eval-TLP-FigRey-totalCopia-PD', 'eval-TLP-FigRey-totalMemoria-PD', ...]\n",
      "('int', [])                         : 47 | ['demo-edad', 'clin-reservaCognitiva_total', 'clin-reservaCognitiva_idiomas', 'clin-reservaCognitiva_ocupacion', 'clin-reservaCognitiva_escolaridad', ...]\n",
      "('int', ['binned', 'text_special']) : 10 | ['clin-tipoAlcohol.char_count', 'clin-tipoAlcohol.word_count', 'clin-tipoAlcohol.capital_ratio', 'clin-tipoAlcohol.lower_ratio', 'clin-tipoAlcohol.digit_ratio', ...]\n",
      "('int', ['bool'])                   : 10 | ['demo-genero', 'clin-ansiedad', 'clin-depresion', 'clin-cardiopatiaIsquemica', 'clin-diabetes', ...]\n",
      "('int', ['datetime_as_int'])        :  9 | ['demo-fechaEvaluacion', 'demo-fechaEvaluacion.month', 'demo-fechaEvaluacion.day', 'demo-fechaEvaluacion.dayofweek', 'demo-fechaNacimiento', ...]\n",
      "Plot summary of models saved to file: c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\autogluon\\tlp\\AutogluonModels\\synthetic\\tvaes\\v2SummaryOfModels.html\n",
      "*** End of fit() summary ***\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'model_types': {'LightGBMXT_BAG_L1': 'StackerEnsembleModel_LGB',\n",
       "  'LightGBM_BAG_L1': 'StackerEnsembleModel_LGB',\n",
       "  'CatBoost_BAG_L1': 'StackerEnsembleModel_CatBoost',\n",
       "  'NeuralNetFastAI_BAG_L1': 'StackerEnsembleModel_NNFastAiTabular',\n",
       "  'XGBoost_BAG_L1': 'StackerEnsembleModel_XGBoost',\n",
       "  'LightGBMLarge_BAG_L1': 'StackerEnsembleModel_LGB',\n",
       "  'CatBoost_r177_BAG_L1': 'StackerEnsembleModel_CatBoost',\n",
       "  'LightGBM_r131_BAG_L1': 'StackerEnsembleModel_LGB',\n",
       "  'NeuralNetFastAI_r191_BAG_L1': 'StackerEnsembleModel_NNFastAiTabular',\n",
       "  'CatBoost_r9_BAG_L1': 'StackerEnsembleModel_CatBoost',\n",
       "  'LightGBM_r96_BAG_L1': 'StackerEnsembleModel_LGB',\n",
       "  'XGBoost_r33_BAG_L1': 'StackerEnsembleModel_XGBoost',\n",
       "  'CatBoost_r137_BAG_L1': 'StackerEnsembleModel_CatBoost',\n",
       "  'NeuralNetFastAI_r102_BAG_L1': 'StackerEnsembleModel_NNFastAiTabular',\n",
       "  'CatBoost_r13_BAG_L1': 'StackerEnsembleModel_CatBoost',\n",
       "  'LightGBM_r188_BAG_L1': 'StackerEnsembleModel_LGB',\n",
       "  'NeuralNetFastAI_r145_BAG_L1': 'StackerEnsembleModel_NNFastAiTabular',\n",
       "  'XGBoost_r89_BAG_L1': 'StackerEnsembleModel_XGBoost',\n",
       "  'LightGBM_r130_BAG_L1': 'StackerEnsembleModel_LGB',\n",
       "  'CatBoost_r50_BAG_L1': 'StackerEnsembleModel_CatBoost',\n",
       "  'NeuralNetFastAI_r11_BAG_L1': 'StackerEnsembleModel_NNFastAiTabular',\n",
       "  'XGBoost_r194_BAG_L1': 'StackerEnsembleModel_XGBoost',\n",
       "  'CatBoost_r69_BAG_L1': 'StackerEnsembleModel_CatBoost',\n",
       "  'NeuralNetFastAI_r103_BAG_L1': 'StackerEnsembleModel_NNFastAiTabular',\n",
       "  'LightGBM_r161_BAG_L1': 'StackerEnsembleModel_LGB',\n",
       "  'NeuralNetFastAI_r143_BAG_L1': 'StackerEnsembleModel_NNFastAiTabular',\n",
       "  'CatBoost_r70_BAG_L1': 'StackerEnsembleModel_CatBoost',\n",
       "  'NeuralNetFastAI_r156_BAG_L1': 'StackerEnsembleModel_NNFastAiTabular',\n",
       "  'LightGBM_r196_BAG_L1': 'StackerEnsembleModel_LGB',\n",
       "  'CatBoost_r167_BAG_L1': 'StackerEnsembleModel_CatBoost',\n",
       "  'NeuralNetFastAI_r95_BAG_L1': 'StackerEnsembleModel_NNFastAiTabular',\n",
       "  'XGBoost_r98_BAG_L1': 'StackerEnsembleModel_XGBoost',\n",
       "  'LightGBM_r15_BAG_L1': 'StackerEnsembleModel_LGB',\n",
       "  'CatBoost_r86_BAG_L1': 'StackerEnsembleModel_CatBoost',\n",
       "  'NeuralNetFastAI_r37_BAG_L1': 'StackerEnsembleModel_NNFastAiTabular',\n",
       "  'CatBoost_r49_BAG_L1': 'StackerEnsembleModel_CatBoost',\n",
       "  'LightGBM_r143_BAG_L1': 'StackerEnsembleModel_LGB',\n",
       "  'NeuralNetFastAI_r134_BAG_L1': 'StackerEnsembleModel_NNFastAiTabular',\n",
       "  'LightGBM_r94_BAG_L1': 'StackerEnsembleModel_LGB',\n",
       "  'CatBoost_r128_BAG_L1': 'StackerEnsembleModel_CatBoost',\n",
       "  'NeuralNetFastAI_r111_BAG_L1': 'StackerEnsembleModel_NNFastAiTabular',\n",
       "  'NeuralNetFastAI_r65_BAG_L1': 'StackerEnsembleModel_NNFastAiTabular',\n",
       "  'NeuralNetFastAI_r88_BAG_L1': 'StackerEnsembleModel_NNFastAiTabular',\n",
       "  'LightGBM_r30_BAG_L1': 'StackerEnsembleModel_LGB',\n",
       "  'XGBoost_r49_BAG_L1': 'StackerEnsembleModel_XGBoost',\n",
       "  'CatBoost_r5_BAG_L1': 'StackerEnsembleModel_CatBoost',\n",
       "  'CatBoost_r143_BAG_L1': 'StackerEnsembleModel_CatBoost',\n",
       "  'XGBoost_r31_BAG_L1': 'StackerEnsembleModel_XGBoost',\n",
       "  'NeuralNetFastAI_r160_BAG_L1': 'StackerEnsembleModel_NNFastAiTabular',\n",
       "  'CatBoost_r60_BAG_L1': 'StackerEnsembleModel_CatBoost',\n",
       "  'LightGBM_r135_BAG_L1': 'StackerEnsembleModel_LGB',\n",
       "  'XGBoost_r22_BAG_L1': 'StackerEnsembleModel_XGBoost',\n",
       "  'NeuralNetFastAI_r69_BAG_L1': 'StackerEnsembleModel_NNFastAiTabular',\n",
       "  'CatBoost_r6_BAG_L1': 'StackerEnsembleModel_CatBoost',\n",
       "  'NeuralNetFastAI_r138_BAG_L1': 'StackerEnsembleModel_NNFastAiTabular',\n",
       "  'LightGBM_r121_BAG_L1': 'StackerEnsembleModel_LGB',\n",
       "  'NeuralNetFastAI_r172_BAG_L1': 'StackerEnsembleModel_NNFastAiTabular',\n",
       "  'CatBoost_r180_BAG_L1': 'StackerEnsembleModel_CatBoost',\n",
       "  'WeightedEnsemble_L2': 'WeightedEnsembleModel',\n",
       "  'LightGBMXT_BAG_L1_FULL': 'StackerEnsembleModel_LGB',\n",
       "  'LightGBM_BAG_L1_FULL': 'StackerEnsembleModel_LGB',\n",
       "  'CatBoost_BAG_L1_FULL': 'StackerEnsembleModel_CatBoost',\n",
       "  'NeuralNetFastAI_BAG_L1_FULL': 'StackerEnsembleModel_NNFastAiTabular',\n",
       "  'XGBoost_BAG_L1_FULL': 'StackerEnsembleModel_XGBoost',\n",
       "  'LightGBMLarge_BAG_L1_FULL': 'StackerEnsembleModel_LGB',\n",
       "  'CatBoost_r177_BAG_L1_FULL': 'StackerEnsembleModel_CatBoost',\n",
       "  'LightGBM_r131_BAG_L1_FULL': 'StackerEnsembleModel_LGB',\n",
       "  'NeuralNetFastAI_r191_BAG_L1_FULL': 'StackerEnsembleModel_NNFastAiTabular',\n",
       "  'CatBoost_r9_BAG_L1_FULL': 'StackerEnsembleModel_CatBoost',\n",
       "  'LightGBM_r96_BAG_L1_FULL': 'StackerEnsembleModel_LGB',\n",
       "  'XGBoost_r33_BAG_L1_FULL': 'StackerEnsembleModel_XGBoost',\n",
       "  'CatBoost_r137_BAG_L1_FULL': 'StackerEnsembleModel_CatBoost',\n",
       "  'NeuralNetFastAI_r102_BAG_L1_FULL': 'StackerEnsembleModel_NNFastAiTabular',\n",
       "  'CatBoost_r13_BAG_L1_FULL': 'StackerEnsembleModel_CatBoost',\n",
       "  'LightGBM_r188_BAG_L1_FULL': 'StackerEnsembleModel_LGB',\n",
       "  'NeuralNetFastAI_r145_BAG_L1_FULL': 'StackerEnsembleModel_NNFastAiTabular',\n",
       "  'XGBoost_r89_BAG_L1_FULL': 'StackerEnsembleModel_XGBoost',\n",
       "  'LightGBM_r130_BAG_L1_FULL': 'StackerEnsembleModel_LGB',\n",
       "  'CatBoost_r50_BAG_L1_FULL': 'StackerEnsembleModel_CatBoost',\n",
       "  'NeuralNetFastAI_r11_BAG_L1_FULL': 'StackerEnsembleModel_NNFastAiTabular',\n",
       "  'XGBoost_r194_BAG_L1_FULL': 'StackerEnsembleModel_XGBoost',\n",
       "  'CatBoost_r69_BAG_L1_FULL': 'StackerEnsembleModel_CatBoost',\n",
       "  'NeuralNetFastAI_r103_BAG_L1_FULL': 'StackerEnsembleModel_NNFastAiTabular',\n",
       "  'LightGBM_r161_BAG_L1_FULL': 'StackerEnsembleModel_LGB',\n",
       "  'NeuralNetFastAI_r143_BAG_L1_FULL': 'StackerEnsembleModel_NNFastAiTabular',\n",
       "  'CatBoost_r70_BAG_L1_FULL': 'StackerEnsembleModel_CatBoost',\n",
       "  'NeuralNetFastAI_r156_BAG_L1_FULL': 'StackerEnsembleModel_NNFastAiTabular',\n",
       "  'LightGBM_r196_BAG_L1_FULL': 'StackerEnsembleModel_LGB',\n",
       "  'CatBoost_r167_BAG_L1_FULL': 'StackerEnsembleModel_CatBoost',\n",
       "  'NeuralNetFastAI_r95_BAG_L1_FULL': 'StackerEnsembleModel_NNFastAiTabular',\n",
       "  'XGBoost_r98_BAG_L1_FULL': 'StackerEnsembleModel_XGBoost',\n",
       "  'LightGBM_r15_BAG_L1_FULL': 'StackerEnsembleModel_LGB',\n",
       "  'CatBoost_r86_BAG_L1_FULL': 'StackerEnsembleModel_CatBoost',\n",
       "  'NeuralNetFastAI_r37_BAG_L1_FULL': 'StackerEnsembleModel_NNFastAiTabular',\n",
       "  'CatBoost_r49_BAG_L1_FULL': 'StackerEnsembleModel_CatBoost',\n",
       "  'LightGBM_r143_BAG_L1_FULL': 'StackerEnsembleModel_LGB',\n",
       "  'NeuralNetFastAI_r134_BAG_L1_FULL': 'StackerEnsembleModel_NNFastAiTabular',\n",
       "  'LightGBM_r94_BAG_L1_FULL': 'StackerEnsembleModel_LGB',\n",
       "  'CatBoost_r128_BAG_L1_FULL': 'StackerEnsembleModel_CatBoost',\n",
       "  'NeuralNetFastAI_r111_BAG_L1_FULL': 'StackerEnsembleModel_NNFastAiTabular',\n",
       "  'NeuralNetFastAI_r65_BAG_L1_FULL': 'StackerEnsembleModel_NNFastAiTabular',\n",
       "  'NeuralNetFastAI_r88_BAG_L1_FULL': 'StackerEnsembleModel_NNFastAiTabular',\n",
       "  'LightGBM_r30_BAG_L1_FULL': 'StackerEnsembleModel_LGB',\n",
       "  'XGBoost_r49_BAG_L1_FULL': 'StackerEnsembleModel_XGBoost',\n",
       "  'CatBoost_r5_BAG_L1_FULL': 'StackerEnsembleModel_CatBoost',\n",
       "  'CatBoost_r143_BAG_L1_FULL': 'StackerEnsembleModel_CatBoost',\n",
       "  'XGBoost_r31_BAG_L1_FULL': 'StackerEnsembleModel_XGBoost',\n",
       "  'NeuralNetFastAI_r160_BAG_L1_FULL': 'StackerEnsembleModel_NNFastAiTabular',\n",
       "  'CatBoost_r60_BAG_L1_FULL': 'StackerEnsembleModel_CatBoost',\n",
       "  'LightGBM_r135_BAG_L1_FULL': 'StackerEnsembleModel_LGB',\n",
       "  'XGBoost_r22_BAG_L1_FULL': 'StackerEnsembleModel_XGBoost',\n",
       "  'NeuralNetFastAI_r69_BAG_L1_FULL': 'StackerEnsembleModel_NNFastAiTabular',\n",
       "  'CatBoost_r6_BAG_L1_FULL': 'StackerEnsembleModel_CatBoost',\n",
       "  'NeuralNetFastAI_r138_BAG_L1_FULL': 'StackerEnsembleModel_NNFastAiTabular',\n",
       "  'LightGBM_r121_BAG_L1_FULL': 'StackerEnsembleModel_LGB',\n",
       "  'NeuralNetFastAI_r172_BAG_L1_FULL': 'StackerEnsembleModel_NNFastAiTabular',\n",
       "  'CatBoost_r180_BAG_L1_FULL': 'StackerEnsembleModel_CatBoost',\n",
       "  'WeightedEnsemble_L2_FULL': 'WeightedEnsembleModel'},\n",
       " 'model_performance': {'LightGBMXT_BAG_L1': 0.9758986928104576,\n",
       "  'LightGBM_BAG_L1': 0.9618310866013072,\n",
       "  'CatBoost_BAG_L1': 0.9720179738562091,\n",
       "  'NeuralNetFastAI_BAG_L1': 0.8819189133986927,\n",
       "  'XGBoost_BAG_L1': 0.964920343137255,\n",
       "  'LightGBMLarge_BAG_L1': 0.9496527777777779,\n",
       "  'CatBoost_r177_BAG_L1': 0.9712520424836601,\n",
       "  'LightGBM_r131_BAG_L1': 0.9687244689542484,\n",
       "  'NeuralNetFastAI_r191_BAG_L1': 0.8753063725490196,\n",
       "  'CatBoost_r9_BAG_L1': 0.9708690767973855,\n",
       "  'LightGBM_r96_BAG_L1': 0.9709967320261439,\n",
       "  'XGBoost_r33_BAG_L1': 0.9672691993464053,\n",
       "  'CatBoost_r137_BAG_L1': 0.9718647875816994,\n",
       "  'NeuralNetFastAI_r102_BAG_L1': 0.8675704656862746,\n",
       "  'CatBoost_r13_BAG_L1': 0.9708690767973855,\n",
       "  'LightGBM_r188_BAG_L1': 0.974188112745098,\n",
       "  'NeuralNetFastAI_r145_BAG_L1': 0.8804891748366013,\n",
       "  'XGBoost_r89_BAG_L1': 0.9683925653594772,\n",
       "  'LightGBM_r130_BAG_L1': 0.9675755718954249,\n",
       "  'CatBoost_r50_BAG_L1': 0.9724009395424836,\n",
       "  'NeuralNetFastAI_r11_BAG_L1': 0.8656811683006537,\n",
       "  'XGBoost_r194_BAG_L1': 0.9686478758169935,\n",
       "  'CatBoost_r69_BAG_L1': 0.9759752859477124,\n",
       "  'NeuralNetFastAI_r103_BAG_L1': 0.8776296977124183,\n",
       "  'LightGBM_r161_BAG_L1': 0.9696946486928104,\n",
       "  'NeuralNetFastAI_r143_BAG_L1': 0.8919781454248366,\n",
       "  'CatBoost_r70_BAG_L1': 0.9736008986928104,\n",
       "  'NeuralNetFastAI_r156_BAG_L1': 0.8715533088235294,\n",
       "  'LightGBM_r196_BAG_L1': 0.9721966911764707,\n",
       "  'CatBoost_r167_BAG_L1': 0.9717881944444444,\n",
       "  'NeuralNetFastAI_r95_BAG_L1': 0.8784977532679739,\n",
       "  'XGBoost_r98_BAG_L1': 0.9714052287581699,\n",
       "  'LightGBM_r15_BAG_L1': 0.9643841911764706,\n",
       "  'CatBoost_r86_BAG_L1': 0.9694393382352942,\n",
       "  'NeuralNetFastAI_r37_BAG_L1': 0.8967269199346405,\n",
       "  'CatBoost_r49_BAG_L1': 0.9696946486928105,\n",
       "  'LightGBM_r143_BAG_L1': 0.964205473856209,\n",
       "  'NeuralNetFastAI_r134_BAG_L1': 0.8761744281045752,\n",
       "  'LightGBM_r94_BAG_L1': 0.9736264297385621,\n",
       "  'CatBoost_r128_BAG_L1': 0.9712265114379085,\n",
       "  'NeuralNetFastAI_r111_BAG_L1': 0.895297181372549,\n",
       "  'NeuralNetFastAI_r65_BAG_L1': 0.8710682189542484,\n",
       "  'NeuralNetFastAI_r88_BAG_L1': 0.8819444444444444,\n",
       "  'LightGBM_r30_BAG_L1': 0.9742391748366013,\n",
       "  'XGBoost_r49_BAG_L1': 0.9647160947712419,\n",
       "  'CatBoost_r5_BAG_L1': 0.9740859885620915,\n",
       "  'CatBoost_r143_BAG_L1': 0.9717626633986928,\n",
       "  'XGBoost_r31_BAG_L1': 0.9681117238562091,\n",
       "  'NeuralNetFastAI_r160_BAG_L1': 0.8805657679738563,\n",
       "  'CatBoost_r60_BAG_L1': 0.9731924019607843,\n",
       "  'LightGBM_r135_BAG_L1': 0.9688010620915033,\n",
       "  'XGBoost_r22_BAG_L1': 0.969158496732026,\n",
       "  'NeuralNetFastAI_r69_BAG_L1': 0.870812908496732,\n",
       "  'CatBoost_r6_BAG_L1': 0.9722732843137255,\n",
       "  'NeuralNetFastAI_r138_BAG_L1': 0.8873825571895425,\n",
       "  'LightGBM_r121_BAG_L1': 0.9685202205882353,\n",
       "  'NeuralNetFastAI_r172_BAG_L1': 0.867749183006536,\n",
       "  'CatBoost_r180_BAG_L1': 0.9703073937908497,\n",
       "  'WeightedEnsemble_L2': 0.9776858660130718,\n",
       "  'LightGBMXT_BAG_L1_FULL': None,\n",
       "  'LightGBM_BAG_L1_FULL': None,\n",
       "  'CatBoost_BAG_L1_FULL': None,\n",
       "  'NeuralNetFastAI_BAG_L1_FULL': None,\n",
       "  'XGBoost_BAG_L1_FULL': None,\n",
       "  'LightGBMLarge_BAG_L1_FULL': None,\n",
       "  'CatBoost_r177_BAG_L1_FULL': None,\n",
       "  'LightGBM_r131_BAG_L1_FULL': None,\n",
       "  'NeuralNetFastAI_r191_BAG_L1_FULL': None,\n",
       "  'CatBoost_r9_BAG_L1_FULL': None,\n",
       "  'LightGBM_r96_BAG_L1_FULL': None,\n",
       "  'XGBoost_r33_BAG_L1_FULL': None,\n",
       "  'CatBoost_r137_BAG_L1_FULL': None,\n",
       "  'NeuralNetFastAI_r102_BAG_L1_FULL': None,\n",
       "  'CatBoost_r13_BAG_L1_FULL': None,\n",
       "  'LightGBM_r188_BAG_L1_FULL': None,\n",
       "  'NeuralNetFastAI_r145_BAG_L1_FULL': None,\n",
       "  'XGBoost_r89_BAG_L1_FULL': None,\n",
       "  'LightGBM_r130_BAG_L1_FULL': None,\n",
       "  'CatBoost_r50_BAG_L1_FULL': None,\n",
       "  'NeuralNetFastAI_r11_BAG_L1_FULL': None,\n",
       "  'XGBoost_r194_BAG_L1_FULL': None,\n",
       "  'CatBoost_r69_BAG_L1_FULL': None,\n",
       "  'NeuralNetFastAI_r103_BAG_L1_FULL': None,\n",
       "  'LightGBM_r161_BAG_L1_FULL': None,\n",
       "  'NeuralNetFastAI_r143_BAG_L1_FULL': None,\n",
       "  'CatBoost_r70_BAG_L1_FULL': None,\n",
       "  'NeuralNetFastAI_r156_BAG_L1_FULL': None,\n",
       "  'LightGBM_r196_BAG_L1_FULL': None,\n",
       "  'CatBoost_r167_BAG_L1_FULL': None,\n",
       "  'NeuralNetFastAI_r95_BAG_L1_FULL': None,\n",
       "  'XGBoost_r98_BAG_L1_FULL': None,\n",
       "  'LightGBM_r15_BAG_L1_FULL': None,\n",
       "  'CatBoost_r86_BAG_L1_FULL': None,\n",
       "  'NeuralNetFastAI_r37_BAG_L1_FULL': None,\n",
       "  'CatBoost_r49_BAG_L1_FULL': None,\n",
       "  'LightGBM_r143_BAG_L1_FULL': None,\n",
       "  'NeuralNetFastAI_r134_BAG_L1_FULL': None,\n",
       "  'LightGBM_r94_BAG_L1_FULL': None,\n",
       "  'CatBoost_r128_BAG_L1_FULL': None,\n",
       "  'NeuralNetFastAI_r111_BAG_L1_FULL': None,\n",
       "  'NeuralNetFastAI_r65_BAG_L1_FULL': None,\n",
       "  'NeuralNetFastAI_r88_BAG_L1_FULL': None,\n",
       "  'LightGBM_r30_BAG_L1_FULL': None,\n",
       "  'XGBoost_r49_BAG_L1_FULL': None,\n",
       "  'CatBoost_r5_BAG_L1_FULL': None,\n",
       "  'CatBoost_r143_BAG_L1_FULL': None,\n",
       "  'XGBoost_r31_BAG_L1_FULL': None,\n",
       "  'NeuralNetFastAI_r160_BAG_L1_FULL': None,\n",
       "  'CatBoost_r60_BAG_L1_FULL': None,\n",
       "  'LightGBM_r135_BAG_L1_FULL': None,\n",
       "  'XGBoost_r22_BAG_L1_FULL': None,\n",
       "  'NeuralNetFastAI_r69_BAG_L1_FULL': None,\n",
       "  'CatBoost_r6_BAG_L1_FULL': None,\n",
       "  'NeuralNetFastAI_r138_BAG_L1_FULL': None,\n",
       "  'LightGBM_r121_BAG_L1_FULL': None,\n",
       "  'NeuralNetFastAI_r172_BAG_L1_FULL': None,\n",
       "  'CatBoost_r180_BAG_L1_FULL': None,\n",
       "  'WeightedEnsemble_L2_FULL': None},\n",
       " 'model_best': 'WeightedEnsemble_L2_FULL',\n",
       " 'model_paths': {'LightGBMXT_BAG_L1': ['LightGBMXT_BAG_L1'],\n",
       "  'LightGBM_BAG_L1': ['LightGBM_BAG_L1'],\n",
       "  'CatBoost_BAG_L1': ['CatBoost_BAG_L1'],\n",
       "  'NeuralNetFastAI_BAG_L1': ['NeuralNetFastAI_BAG_L1'],\n",
       "  'XGBoost_BAG_L1': ['XGBoost_BAG_L1'],\n",
       "  'LightGBMLarge_BAG_L1': ['LightGBMLarge_BAG_L1'],\n",
       "  'CatBoost_r177_BAG_L1': ['CatBoost_r177_BAG_L1'],\n",
       "  'LightGBM_r131_BAG_L1': ['LightGBM_r131_BAG_L1'],\n",
       "  'NeuralNetFastAI_r191_BAG_L1': ['NeuralNetFastAI_r191_BAG_L1'],\n",
       "  'CatBoost_r9_BAG_L1': ['CatBoost_r9_BAG_L1'],\n",
       "  'LightGBM_r96_BAG_L1': ['LightGBM_r96_BAG_L1'],\n",
       "  'XGBoost_r33_BAG_L1': ['XGBoost_r33_BAG_L1'],\n",
       "  'CatBoost_r137_BAG_L1': ['CatBoost_r137_BAG_L1'],\n",
       "  'NeuralNetFastAI_r102_BAG_L1': ['NeuralNetFastAI_r102_BAG_L1'],\n",
       "  'CatBoost_r13_BAG_L1': ['CatBoost_r13_BAG_L1'],\n",
       "  'LightGBM_r188_BAG_L1': ['LightGBM_r188_BAG_L1'],\n",
       "  'NeuralNetFastAI_r145_BAG_L1': ['NeuralNetFastAI_r145_BAG_L1'],\n",
       "  'XGBoost_r89_BAG_L1': ['XGBoost_r89_BAG_L1'],\n",
       "  'LightGBM_r130_BAG_L1': ['LightGBM_r130_BAG_L1'],\n",
       "  'CatBoost_r50_BAG_L1': ['CatBoost_r50_BAG_L1'],\n",
       "  'NeuralNetFastAI_r11_BAG_L1': ['NeuralNetFastAI_r11_BAG_L1'],\n",
       "  'XGBoost_r194_BAG_L1': ['XGBoost_r194_BAG_L1'],\n",
       "  'CatBoost_r69_BAG_L1': ['CatBoost_r69_BAG_L1'],\n",
       "  'NeuralNetFastAI_r103_BAG_L1': ['NeuralNetFastAI_r103_BAG_L1'],\n",
       "  'LightGBM_r161_BAG_L1': ['LightGBM_r161_BAG_L1'],\n",
       "  'NeuralNetFastAI_r143_BAG_L1': ['NeuralNetFastAI_r143_BAG_L1'],\n",
       "  'CatBoost_r70_BAG_L1': ['CatBoost_r70_BAG_L1'],\n",
       "  'NeuralNetFastAI_r156_BAG_L1': ['NeuralNetFastAI_r156_BAG_L1'],\n",
       "  'LightGBM_r196_BAG_L1': ['LightGBM_r196_BAG_L1'],\n",
       "  'CatBoost_r167_BAG_L1': ['CatBoost_r167_BAG_L1'],\n",
       "  'NeuralNetFastAI_r95_BAG_L1': ['NeuralNetFastAI_r95_BAG_L1'],\n",
       "  'XGBoost_r98_BAG_L1': ['XGBoost_r98_BAG_L1'],\n",
       "  'LightGBM_r15_BAG_L1': ['LightGBM_r15_BAG_L1'],\n",
       "  'CatBoost_r86_BAG_L1': ['CatBoost_r86_BAG_L1'],\n",
       "  'NeuralNetFastAI_r37_BAG_L1': ['NeuralNetFastAI_r37_BAG_L1'],\n",
       "  'CatBoost_r49_BAG_L1': ['CatBoost_r49_BAG_L1'],\n",
       "  'LightGBM_r143_BAG_L1': ['LightGBM_r143_BAG_L1'],\n",
       "  'NeuralNetFastAI_r134_BAG_L1': ['NeuralNetFastAI_r134_BAG_L1'],\n",
       "  'LightGBM_r94_BAG_L1': ['LightGBM_r94_BAG_L1'],\n",
       "  'CatBoost_r128_BAG_L1': ['CatBoost_r128_BAG_L1'],\n",
       "  'NeuralNetFastAI_r111_BAG_L1': ['NeuralNetFastAI_r111_BAG_L1'],\n",
       "  'NeuralNetFastAI_r65_BAG_L1': ['NeuralNetFastAI_r65_BAG_L1'],\n",
       "  'NeuralNetFastAI_r88_BAG_L1': ['NeuralNetFastAI_r88_BAG_L1'],\n",
       "  'LightGBM_r30_BAG_L1': ['LightGBM_r30_BAG_L1'],\n",
       "  'XGBoost_r49_BAG_L1': ['XGBoost_r49_BAG_L1'],\n",
       "  'CatBoost_r5_BAG_L1': ['CatBoost_r5_BAG_L1'],\n",
       "  'CatBoost_r143_BAG_L1': ['CatBoost_r143_BAG_L1'],\n",
       "  'XGBoost_r31_BAG_L1': ['XGBoost_r31_BAG_L1'],\n",
       "  'NeuralNetFastAI_r160_BAG_L1': ['NeuralNetFastAI_r160_BAG_L1'],\n",
       "  'CatBoost_r60_BAG_L1': ['CatBoost_r60_BAG_L1'],\n",
       "  'LightGBM_r135_BAG_L1': ['LightGBM_r135_BAG_L1'],\n",
       "  'XGBoost_r22_BAG_L1': ['XGBoost_r22_BAG_L1'],\n",
       "  'NeuralNetFastAI_r69_BAG_L1': ['NeuralNetFastAI_r69_BAG_L1'],\n",
       "  'CatBoost_r6_BAG_L1': ['CatBoost_r6_BAG_L1'],\n",
       "  'NeuralNetFastAI_r138_BAG_L1': ['NeuralNetFastAI_r138_BAG_L1'],\n",
       "  'LightGBM_r121_BAG_L1': ['LightGBM_r121_BAG_L1'],\n",
       "  'NeuralNetFastAI_r172_BAG_L1': ['NeuralNetFastAI_r172_BAG_L1'],\n",
       "  'CatBoost_r180_BAG_L1': ['CatBoost_r180_BAG_L1'],\n",
       "  'WeightedEnsemble_L2': ['WeightedEnsemble_L2'],\n",
       "  'LightGBMXT_BAG_L1_FULL': ['LightGBMXT_BAG_L1_FULL'],\n",
       "  'LightGBM_BAG_L1_FULL': ['LightGBM_BAG_L1_FULL'],\n",
       "  'CatBoost_BAG_L1_FULL': ['CatBoost_BAG_L1_FULL'],\n",
       "  'NeuralNetFastAI_BAG_L1_FULL': ['NeuralNetFastAI_BAG_L1_FULL'],\n",
       "  'XGBoost_BAG_L1_FULL': ['XGBoost_BAG_L1_FULL'],\n",
       "  'LightGBMLarge_BAG_L1_FULL': ['LightGBMLarge_BAG_L1_FULL'],\n",
       "  'CatBoost_r177_BAG_L1_FULL': ['CatBoost_r177_BAG_L1_FULL'],\n",
       "  'LightGBM_r131_BAG_L1_FULL': ['LightGBM_r131_BAG_L1_FULL'],\n",
       "  'NeuralNetFastAI_r191_BAG_L1_FULL': ['NeuralNetFastAI_r191_BAG_L1_FULL'],\n",
       "  'CatBoost_r9_BAG_L1_FULL': ['CatBoost_r9_BAG_L1_FULL'],\n",
       "  'LightGBM_r96_BAG_L1_FULL': ['LightGBM_r96_BAG_L1_FULL'],\n",
       "  'XGBoost_r33_BAG_L1_FULL': ['XGBoost_r33_BAG_L1_FULL'],\n",
       "  'CatBoost_r137_BAG_L1_FULL': ['CatBoost_r137_BAG_L1_FULL'],\n",
       "  'NeuralNetFastAI_r102_BAG_L1_FULL': ['NeuralNetFastAI_r102_BAG_L1_FULL'],\n",
       "  'CatBoost_r13_BAG_L1_FULL': ['CatBoost_r13_BAG_L1_FULL'],\n",
       "  'LightGBM_r188_BAG_L1_FULL': ['LightGBM_r188_BAG_L1_FULL'],\n",
       "  'NeuralNetFastAI_r145_BAG_L1_FULL': ['NeuralNetFastAI_r145_BAG_L1_FULL'],\n",
       "  'XGBoost_r89_BAG_L1_FULL': ['XGBoost_r89_BAG_L1_FULL'],\n",
       "  'LightGBM_r130_BAG_L1_FULL': ['LightGBM_r130_BAG_L1_FULL'],\n",
       "  'CatBoost_r50_BAG_L1_FULL': ['CatBoost_r50_BAG_L1_FULL'],\n",
       "  'NeuralNetFastAI_r11_BAG_L1_FULL': ['NeuralNetFastAI_r11_BAG_L1_FULL'],\n",
       "  'XGBoost_r194_BAG_L1_FULL': ['XGBoost_r194_BAG_L1_FULL'],\n",
       "  'CatBoost_r69_BAG_L1_FULL': ['CatBoost_r69_BAG_L1_FULL'],\n",
       "  'NeuralNetFastAI_r103_BAG_L1_FULL': ['NeuralNetFastAI_r103_BAG_L1_FULL'],\n",
       "  'LightGBM_r161_BAG_L1_FULL': ['LightGBM_r161_BAG_L1_FULL'],\n",
       "  'NeuralNetFastAI_r143_BAG_L1_FULL': ['NeuralNetFastAI_r143_BAG_L1_FULL'],\n",
       "  'CatBoost_r70_BAG_L1_FULL': ['CatBoost_r70_BAG_L1_FULL'],\n",
       "  'NeuralNetFastAI_r156_BAG_L1_FULL': ['NeuralNetFastAI_r156_BAG_L1_FULL'],\n",
       "  'LightGBM_r196_BAG_L1_FULL': ['LightGBM_r196_BAG_L1_FULL'],\n",
       "  'CatBoost_r167_BAG_L1_FULL': ['CatBoost_r167_BAG_L1_FULL'],\n",
       "  'NeuralNetFastAI_r95_BAG_L1_FULL': ['NeuralNetFastAI_r95_BAG_L1_FULL'],\n",
       "  'XGBoost_r98_BAG_L1_FULL': ['XGBoost_r98_BAG_L1_FULL'],\n",
       "  'LightGBM_r15_BAG_L1_FULL': ['LightGBM_r15_BAG_L1_FULL'],\n",
       "  'CatBoost_r86_BAG_L1_FULL': ['CatBoost_r86_BAG_L1_FULL'],\n",
       "  'NeuralNetFastAI_r37_BAG_L1_FULL': ['NeuralNetFastAI_r37_BAG_L1_FULL'],\n",
       "  'CatBoost_r49_BAG_L1_FULL': ['CatBoost_r49_BAG_L1_FULL'],\n",
       "  'LightGBM_r143_BAG_L1_FULL': ['LightGBM_r143_BAG_L1_FULL'],\n",
       "  'NeuralNetFastAI_r134_BAG_L1_FULL': ['NeuralNetFastAI_r134_BAG_L1_FULL'],\n",
       "  'LightGBM_r94_BAG_L1_FULL': ['LightGBM_r94_BAG_L1_FULL'],\n",
       "  'CatBoost_r128_BAG_L1_FULL': ['CatBoost_r128_BAG_L1_FULL'],\n",
       "  'NeuralNetFastAI_r111_BAG_L1_FULL': ['NeuralNetFastAI_r111_BAG_L1_FULL'],\n",
       "  'NeuralNetFastAI_r65_BAG_L1_FULL': ['NeuralNetFastAI_r65_BAG_L1_FULL'],\n",
       "  'NeuralNetFastAI_r88_BAG_L1_FULL': ['NeuralNetFastAI_r88_BAG_L1_FULL'],\n",
       "  'LightGBM_r30_BAG_L1_FULL': ['LightGBM_r30_BAG_L1_FULL'],\n",
       "  'XGBoost_r49_BAG_L1_FULL': ['XGBoost_r49_BAG_L1_FULL'],\n",
       "  'CatBoost_r5_BAG_L1_FULL': ['CatBoost_r5_BAG_L1_FULL'],\n",
       "  'CatBoost_r143_BAG_L1_FULL': ['CatBoost_r143_BAG_L1_FULL'],\n",
       "  'XGBoost_r31_BAG_L1_FULL': ['XGBoost_r31_BAG_L1_FULL'],\n",
       "  'NeuralNetFastAI_r160_BAG_L1_FULL': ['NeuralNetFastAI_r160_BAG_L1_FULL'],\n",
       "  'CatBoost_r60_BAG_L1_FULL': ['CatBoost_r60_BAG_L1_FULL'],\n",
       "  'LightGBM_r135_BAG_L1_FULL': ['LightGBM_r135_BAG_L1_FULL'],\n",
       "  'XGBoost_r22_BAG_L1_FULL': ['XGBoost_r22_BAG_L1_FULL'],\n",
       "  'NeuralNetFastAI_r69_BAG_L1_FULL': ['NeuralNetFastAI_r69_BAG_L1_FULL'],\n",
       "  'CatBoost_r6_BAG_L1_FULL': ['CatBoost_r6_BAG_L1_FULL'],\n",
       "  'NeuralNetFastAI_r138_BAG_L1_FULL': ['NeuralNetFastAI_r138_BAG_L1_FULL'],\n",
       "  'LightGBM_r121_BAG_L1_FULL': ['LightGBM_r121_BAG_L1_FULL'],\n",
       "  'NeuralNetFastAI_r172_BAG_L1_FULL': ['NeuralNetFastAI_r172_BAG_L1_FULL'],\n",
       "  'CatBoost_r180_BAG_L1_FULL': ['CatBoost_r180_BAG_L1_FULL'],\n",
       "  'WeightedEnsemble_L2_FULL': ['WeightedEnsemble_L2_FULL']},\n",
       " 'model_fit_times': {'LightGBMXT_BAG_L1': 1.2503974437713623,\n",
       "  'LightGBM_BAG_L1': 1.697228193283081,\n",
       "  'CatBoost_BAG_L1': 42.06776785850525,\n",
       "  'NeuralNetFastAI_BAG_L1': 5.959589719772339,\n",
       "  'XGBoost_BAG_L1': 2.9455790519714355,\n",
       "  'LightGBMLarge_BAG_L1': 3.0496535301208496,\n",
       "  'CatBoost_r177_BAG_L1': 31.531254768371582,\n",
       "  'LightGBM_r131_BAG_L1': 2.460580587387085,\n",
       "  'NeuralNetFastAI_r191_BAG_L1': 6.90045166015625,\n",
       "  'CatBoost_r9_BAG_L1': 132.06551480293274,\n",
       "  'LightGBM_r96_BAG_L1': 7.115317344665527,\n",
       "  'XGBoost_r33_BAG_L1': 4.686510801315308,\n",
       "  'CatBoost_r137_BAG_L1': 36.10175704956055,\n",
       "  'NeuralNetFastAI_r102_BAG_L1': 8.3328857421875,\n",
       "  'CatBoost_r13_BAG_L1': 324.50904083251953,\n",
       "  'LightGBM_r188_BAG_L1': 2.3542933464050293,\n",
       "  'NeuralNetFastAI_r145_BAG_L1': 6.536836624145508,\n",
       "  'XGBoost_r89_BAG_L1': 2.88311505317688,\n",
       "  'LightGBM_r130_BAG_L1': 2.169867515563965,\n",
       "  'CatBoost_r50_BAG_L1': 18.648702383041382,\n",
       "  'NeuralNetFastAI_r11_BAG_L1': 7.2956883907318115,\n",
       "  'XGBoost_r194_BAG_L1': 2.6400692462921143,\n",
       "  'CatBoost_r69_BAG_L1': 29.564252376556396,\n",
       "  'NeuralNetFastAI_r103_BAG_L1': 6.1769115924835205,\n",
       "  'LightGBM_r161_BAG_L1': 3.1049678325653076,\n",
       "  'NeuralNetFastAI_r143_BAG_L1': 9.76857614517212,\n",
       "  'CatBoost_r70_BAG_L1': 55.39388585090637,\n",
       "  'NeuralNetFastAI_r156_BAG_L1': 8.685307264328003,\n",
       "  'LightGBM_r196_BAG_L1': 6.0546486377716064,\n",
       "  'CatBoost_r167_BAG_L1': 42.025529861450195,\n",
       "  'NeuralNetFastAI_r95_BAG_L1': 6.227762699127197,\n",
       "  'XGBoost_r98_BAG_L1': 14.869099378585815,\n",
       "  'LightGBM_r15_BAG_L1': 2.1588804721832275,\n",
       "  'CatBoost_r86_BAG_L1': 87.77052402496338,\n",
       "  'NeuralNetFastAI_r37_BAG_L1': 10.910613775253296,\n",
       "  'CatBoost_r49_BAG_L1': 25.64805555343628,\n",
       "  'LightGBM_r143_BAG_L1': 2.633711576461792,\n",
       "  'NeuralNetFastAI_r134_BAG_L1': 11.28645396232605,\n",
       "  'LightGBM_r94_BAG_L1': 2.609875202178955,\n",
       "  'CatBoost_r128_BAG_L1': 1042.0619094371796,\n",
       "  'NeuralNetFastAI_r111_BAG_L1': 7.974629878997803,\n",
       "  'NeuralNetFastAI_r65_BAG_L1': 9.546723127365112,\n",
       "  'NeuralNetFastAI_r88_BAG_L1': 8.32907223701477,\n",
       "  'LightGBM_r30_BAG_L1': 3.2866437435150146,\n",
       "  'XGBoost_r49_BAG_L1': 3.642580270767212,\n",
       "  'CatBoost_r5_BAG_L1': 26.453147411346436,\n",
       "  'CatBoost_r143_BAG_L1': 46.784241914749146,\n",
       "  'XGBoost_r31_BAG_L1': 4.683690786361694,\n",
       "  'NeuralNetFastAI_r160_BAG_L1': 6.4971044063568115,\n",
       "  'CatBoost_r60_BAG_L1': 66.89429521560669,\n",
       "  'LightGBM_r135_BAG_L1': 2.3467071056365967,\n",
       "  'XGBoost_r22_BAG_L1': 3.116196632385254,\n",
       "  'NeuralNetFastAI_r69_BAG_L1': 6.473748683929443,\n",
       "  'CatBoost_r6_BAG_L1': 21.64292287826538,\n",
       "  'NeuralNetFastAI_r138_BAG_L1': 7.667890787124634,\n",
       "  'LightGBM_r121_BAG_L1': 3.035153388977051,\n",
       "  'NeuralNetFastAI_r172_BAG_L1': 8.097122430801392,\n",
       "  'CatBoost_r180_BAG_L1': 91.14920735359192,\n",
       "  'WeightedEnsemble_L2': 0.0339200496673584,\n",
       "  'LightGBMXT_BAG_L1_FULL': 0.409024715423584,\n",
       "  'LightGBM_BAG_L1_FULL': 0.14452815055847168,\n",
       "  'CatBoost_BAG_L1_FULL': 6.363545656204224,\n",
       "  'NeuralNetFastAI_BAG_L1_FULL': 0.4788477420806885,\n",
       "  'XGBoost_BAG_L1_FULL': 0.16585159301757812,\n",
       "  'LightGBMLarge_BAG_L1_FULL': 0.3192472457885742,\n",
       "  'CatBoost_r177_BAG_L1_FULL': 4.090866804122925,\n",
       "  'LightGBM_r131_BAG_L1_FULL': 0.315413236618042,\n",
       "  'NeuralNetFastAI_r191_BAG_L1_FULL': 0.301041841506958,\n",
       "  'CatBoost_r9_BAG_L1_FULL': 17.012684106826782,\n",
       "  'LightGBM_r96_BAG_L1_FULL': 0.46535420417785645,\n",
       "  'XGBoost_r33_BAG_L1_FULL': 0.6061038970947266,\n",
       "  'CatBoost_r137_BAG_L1_FULL': 5.77931547164917,\n",
       "  'NeuralNetFastAI_r102_BAG_L1_FULL': 0.8593447208404541,\n",
       "  'CatBoost_r13_BAG_L1_FULL': 38.22558283805847,\n",
       "  'LightGBM_r188_BAG_L1_FULL': 0.2843599319458008,\n",
       "  'NeuralNetFastAI_r145_BAG_L1_FULL': 0.5020546913146973,\n",
       "  'XGBoost_r89_BAG_L1_FULL': 0.15845036506652832,\n",
       "  'LightGBM_r130_BAG_L1_FULL': 0.15051007270812988,\n",
       "  'CatBoost_r50_BAG_L1_FULL': 2.6301357746124268,\n",
       "  'NeuralNetFastAI_r11_BAG_L1_FULL': 0.35218310356140137,\n",
       "  'XGBoost_r194_BAG_L1_FULL': 0.1710343360900879,\n",
       "  'CatBoost_r69_BAG_L1_FULL': 4.212683439254761,\n",
       "  'NeuralNetFastAI_r103_BAG_L1_FULL': 0.2723233699798584,\n",
       "  'LightGBM_r161_BAG_L1_FULL': 0.4229609966278076,\n",
       "  'NeuralNetFastAI_r143_BAG_L1_FULL': 1.631953239440918,\n",
       "  'CatBoost_r70_BAG_L1_FULL': 7.302479267120361,\n",
       "  'NeuralNetFastAI_r156_BAG_L1_FULL': 0.7866432666778564,\n",
       "  'LightGBM_r196_BAG_L1_FULL': 1.2380099296569824,\n",
       "  'CatBoost_r167_BAG_L1_FULL': 4.632170677185059,\n",
       "  'NeuralNetFastAI_r95_BAG_L1_FULL': 0.39147210121154785,\n",
       "  'XGBoost_r98_BAG_L1_FULL': 2.1790573596954346,\n",
       "  'LightGBM_r15_BAG_L1_FULL': 0.19162750244140625,\n",
       "  'CatBoost_r86_BAG_L1_FULL': 10.833664178848267,\n",
       "  'NeuralNetFastAI_r37_BAG_L1_FULL': 1.841722011566162,\n",
       "  'CatBoost_r49_BAG_L1_FULL': 3.703181266784668,\n",
       "  'LightGBM_r143_BAG_L1_FULL': 0.2654728889465332,\n",
       "  'NeuralNetFastAI_r134_BAG_L1_FULL': 0.46739912033081055,\n",
       "  'LightGBM_r94_BAG_L1_FULL': 0.2090473175048828,\n",
       "  'CatBoost_r128_BAG_L1_FULL': 79.01738619804382,\n",
       "  'NeuralNetFastAI_r111_BAG_L1_FULL': 1.2077863216400146,\n",
       "  'NeuralNetFastAI_r65_BAG_L1_FULL': 2.0016469955444336,\n",
       "  'NeuralNetFastAI_r88_BAG_L1_FULL': 0.48152804374694824,\n",
       "  'LightGBM_r30_BAG_L1_FULL': 0.4158027172088623,\n",
       "  'XGBoost_r49_BAG_L1_FULL': 0.30167245864868164,\n",
       "  'CatBoost_r5_BAG_L1_FULL': 4.652194023132324,\n",
       "  'CatBoost_r143_BAG_L1_FULL': 5.087611675262451,\n",
       "  'XGBoost_r31_BAG_L1_FULL': 0.6186270713806152,\n",
       "  'NeuralNetFastAI_r160_BAG_L1_FULL': 0.4297201633453369,\n",
       "  'CatBoost_r60_BAG_L1_FULL': 8.043899059295654,\n",
       "  'LightGBM_r135_BAG_L1_FULL': 0.16256928443908691,\n",
       "  'XGBoost_r22_BAG_L1_FULL': 0.20185303688049316,\n",
       "  'NeuralNetFastAI_r69_BAG_L1_FULL': 0.4608943462371826,\n",
       "  'CatBoost_r6_BAG_L1_FULL': 2.675619602203369,\n",
       "  'NeuralNetFastAI_r138_BAG_L1_FULL': 0.5697827339172363,\n",
       "  'LightGBM_r121_BAG_L1_FULL': 0.40705084800720215,\n",
       "  'NeuralNetFastAI_r172_BAG_L1_FULL': 0.3245673179626465,\n",
       "  'CatBoost_r180_BAG_L1_FULL': 14.796708345413208,\n",
       "  'WeightedEnsemble_L2_FULL': 0.0339200496673584},\n",
       " 'model_pred_times': {'LightGBMXT_BAG_L1': 0.03567981719970703,\n",
       "  'LightGBM_BAG_L1': 0.032267093658447266,\n",
       "  'CatBoost_BAG_L1': 0.05675196647644043,\n",
       "  'NeuralNetFastAI_BAG_L1': 0.08376884460449219,\n",
       "  'XGBoost_BAG_L1': 0.0444333553314209,\n",
       "  'LightGBMLarge_BAG_L1': 0.03859972953796387,\n",
       "  'CatBoost_r177_BAG_L1': 0.05925416946411133,\n",
       "  'LightGBM_r131_BAG_L1': 0.040091753005981445,\n",
       "  'NeuralNetFastAI_r191_BAG_L1': 0.11005091667175293,\n",
       "  'CatBoost_r9_BAG_L1': 0.0601503849029541,\n",
       "  'LightGBM_r96_BAG_L1': 0.07096123695373535,\n",
       "  'XGBoost_r33_BAG_L1': 0.057413339614868164,\n",
       "  'CatBoost_r137_BAG_L1': 0.06758785247802734,\n",
       "  'NeuralNetFastAI_r102_BAG_L1': 0.12481307983398438,\n",
       "  'CatBoost_r13_BAG_L1': 0.0640108585357666,\n",
       "  'LightGBM_r188_BAG_L1': 0.03533172607421875,\n",
       "  'NeuralNetFastAI_r145_BAG_L1': 0.10156130790710449,\n",
       "  'XGBoost_r89_BAG_L1': 0.04624199867248535,\n",
       "  'LightGBM_r130_BAG_L1': 0.03717660903930664,\n",
       "  'CatBoost_r50_BAG_L1': 0.06365180015563965,\n",
       "  'NeuralNetFastAI_r11_BAG_L1': 0.10748863220214844,\n",
       "  'XGBoost_r194_BAG_L1': 0.10784029960632324,\n",
       "  'CatBoost_r69_BAG_L1': 0.06387805938720703,\n",
       "  'NeuralNetFastAI_r103_BAG_L1': 0.10636210441589355,\n",
       "  'LightGBM_r161_BAG_L1': 0.05058741569519043,\n",
       "  'NeuralNetFastAI_r143_BAG_L1': 0.1160273551940918,\n",
       "  'CatBoost_r70_BAG_L1': 0.06859183311462402,\n",
       "  'NeuralNetFastAI_r156_BAG_L1': 0.10895013809204102,\n",
       "  'LightGBM_r196_BAG_L1': 0.10202145576477051,\n",
       "  'CatBoost_r167_BAG_L1': 0.06047821044921875,\n",
       "  'NeuralNetFastAI_r95_BAG_L1': 0.09918355941772461,\n",
       "  'XGBoost_r98_BAG_L1': 0.1175377368927002,\n",
       "  'LightGBM_r15_BAG_L1': 0.035130977630615234,\n",
       "  'CatBoost_r86_BAG_L1': 0.04587125778198242,\n",
       "  'NeuralNetFastAI_r37_BAG_L1': 0.10661172866821289,\n",
       "  'CatBoost_r49_BAG_L1': 0.0524444580078125,\n",
       "  'LightGBM_r143_BAG_L1': 0.04999232292175293,\n",
       "  'NeuralNetFastAI_r134_BAG_L1': 0.14711713790893555,\n",
       "  'LightGBM_r94_BAG_L1': 0.05025982856750488,\n",
       "  'CatBoost_r128_BAG_L1': 0.07485628128051758,\n",
       "  'NeuralNetFastAI_r111_BAG_L1': 0.12613606452941895,\n",
       "  'NeuralNetFastAI_r65_BAG_L1': 0.08982634544372559,\n",
       "  'NeuralNetFastAI_r88_BAG_L1': 0.09986734390258789,\n",
       "  'LightGBM_r30_BAG_L1': 0.06938481330871582,\n",
       "  'XGBoost_r49_BAG_L1': 0.05681920051574707,\n",
       "  'CatBoost_r5_BAG_L1': 0.07947516441345215,\n",
       "  'CatBoost_r143_BAG_L1': 0.0603334903717041,\n",
       "  'XGBoost_r31_BAG_L1': 0.06042933464050293,\n",
       "  'NeuralNetFastAI_r160_BAG_L1': 0.041399478912353516,\n",
       "  'CatBoost_r60_BAG_L1': 0.06488251686096191,\n",
       "  'LightGBM_r135_BAG_L1': 0.009461164474487305,\n",
       "  'XGBoost_r22_BAG_L1': 0.04223179817199707,\n",
       "  'NeuralNetFastAI_r69_BAG_L1': 0.08562874794006348,\n",
       "  'CatBoost_r6_BAG_L1': 0.0695350170135498,\n",
       "  'NeuralNetFastAI_r138_BAG_L1': 0.09226322174072266,\n",
       "  'LightGBM_r121_BAG_L1': 0.04732108116149902,\n",
       "  'NeuralNetFastAI_r172_BAG_L1': 0.1137242317199707,\n",
       "  'CatBoost_r180_BAG_L1': 0.03980398178100586,\n",
       "  'WeightedEnsemble_L2': 0.0010225772857666016,\n",
       "  'LightGBMXT_BAG_L1_FULL': None,\n",
       "  'LightGBM_BAG_L1_FULL': None,\n",
       "  'CatBoost_BAG_L1_FULL': None,\n",
       "  'NeuralNetFastAI_BAG_L1_FULL': None,\n",
       "  'XGBoost_BAG_L1_FULL': None,\n",
       "  'LightGBMLarge_BAG_L1_FULL': None,\n",
       "  'CatBoost_r177_BAG_L1_FULL': None,\n",
       "  'LightGBM_r131_BAG_L1_FULL': None,\n",
       "  'NeuralNetFastAI_r191_BAG_L1_FULL': None,\n",
       "  'CatBoost_r9_BAG_L1_FULL': None,\n",
       "  'LightGBM_r96_BAG_L1_FULL': None,\n",
       "  'XGBoost_r33_BAG_L1_FULL': None,\n",
       "  'CatBoost_r137_BAG_L1_FULL': None,\n",
       "  'NeuralNetFastAI_r102_BAG_L1_FULL': None,\n",
       "  'CatBoost_r13_BAG_L1_FULL': None,\n",
       "  'LightGBM_r188_BAG_L1_FULL': None,\n",
       "  'NeuralNetFastAI_r145_BAG_L1_FULL': None,\n",
       "  'XGBoost_r89_BAG_L1_FULL': None,\n",
       "  'LightGBM_r130_BAG_L1_FULL': None,\n",
       "  'CatBoost_r50_BAG_L1_FULL': None,\n",
       "  'NeuralNetFastAI_r11_BAG_L1_FULL': None,\n",
       "  'XGBoost_r194_BAG_L1_FULL': None,\n",
       "  'CatBoost_r69_BAG_L1_FULL': None,\n",
       "  'NeuralNetFastAI_r103_BAG_L1_FULL': None,\n",
       "  'LightGBM_r161_BAG_L1_FULL': None,\n",
       "  'NeuralNetFastAI_r143_BAG_L1_FULL': None,\n",
       "  'CatBoost_r70_BAG_L1_FULL': None,\n",
       "  'NeuralNetFastAI_r156_BAG_L1_FULL': None,\n",
       "  'LightGBM_r196_BAG_L1_FULL': None,\n",
       "  'CatBoost_r167_BAG_L1_FULL': None,\n",
       "  'NeuralNetFastAI_r95_BAG_L1_FULL': None,\n",
       "  'XGBoost_r98_BAG_L1_FULL': None,\n",
       "  'LightGBM_r15_BAG_L1_FULL': None,\n",
       "  'CatBoost_r86_BAG_L1_FULL': None,\n",
       "  'NeuralNetFastAI_r37_BAG_L1_FULL': None,\n",
       "  'CatBoost_r49_BAG_L1_FULL': None,\n",
       "  'LightGBM_r143_BAG_L1_FULL': None,\n",
       "  'NeuralNetFastAI_r134_BAG_L1_FULL': None,\n",
       "  'LightGBM_r94_BAG_L1_FULL': None,\n",
       "  'CatBoost_r128_BAG_L1_FULL': None,\n",
       "  'NeuralNetFastAI_r111_BAG_L1_FULL': None,\n",
       "  'NeuralNetFastAI_r65_BAG_L1_FULL': None,\n",
       "  'NeuralNetFastAI_r88_BAG_L1_FULL': None,\n",
       "  'LightGBM_r30_BAG_L1_FULL': None,\n",
       "  'XGBoost_r49_BAG_L1_FULL': None,\n",
       "  'CatBoost_r5_BAG_L1_FULL': None,\n",
       "  'CatBoost_r143_BAG_L1_FULL': None,\n",
       "  'XGBoost_r31_BAG_L1_FULL': None,\n",
       "  'NeuralNetFastAI_r160_BAG_L1_FULL': None,\n",
       "  'CatBoost_r60_BAG_L1_FULL': None,\n",
       "  'LightGBM_r135_BAG_L1_FULL': None,\n",
       "  'XGBoost_r22_BAG_L1_FULL': None,\n",
       "  'NeuralNetFastAI_r69_BAG_L1_FULL': None,\n",
       "  'CatBoost_r6_BAG_L1_FULL': None,\n",
       "  'NeuralNetFastAI_r138_BAG_L1_FULL': None,\n",
       "  'LightGBM_r121_BAG_L1_FULL': None,\n",
       "  'NeuralNetFastAI_r172_BAG_L1_FULL': None,\n",
       "  'CatBoost_r180_BAG_L1_FULL': None,\n",
       "  'WeightedEnsemble_L2_FULL': None},\n",
       " 'num_bag_folds': 8,\n",
       " 'max_stack_level': 2,\n",
       " 'num_classes': 2,\n",
       " 'model_hyperparams': {'LightGBMXT_BAG_L1': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': False},\n",
       "  'LightGBM_BAG_L1': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': False},\n",
       "  'CatBoost_BAG_L1': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': False},\n",
       "  'NeuralNetFastAI_BAG_L1': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': False},\n",
       "  'XGBoost_BAG_L1': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': False},\n",
       "  'LightGBMLarge_BAG_L1': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': False},\n",
       "  'CatBoost_r177_BAG_L1': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': False},\n",
       "  'LightGBM_r131_BAG_L1': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': False},\n",
       "  'NeuralNetFastAI_r191_BAG_L1': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': False},\n",
       "  'CatBoost_r9_BAG_L1': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': False},\n",
       "  'LightGBM_r96_BAG_L1': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': False},\n",
       "  'XGBoost_r33_BAG_L1': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': False},\n",
       "  'CatBoost_r137_BAG_L1': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': False},\n",
       "  'NeuralNetFastAI_r102_BAG_L1': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': False},\n",
       "  'CatBoost_r13_BAG_L1': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': False},\n",
       "  'LightGBM_r188_BAG_L1': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': False},\n",
       "  'NeuralNetFastAI_r145_BAG_L1': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': False},\n",
       "  'XGBoost_r89_BAG_L1': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': False},\n",
       "  'LightGBM_r130_BAG_L1': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': False},\n",
       "  'CatBoost_r50_BAG_L1': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': False},\n",
       "  'NeuralNetFastAI_r11_BAG_L1': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': False},\n",
       "  'XGBoost_r194_BAG_L1': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': False},\n",
       "  'CatBoost_r69_BAG_L1': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': False},\n",
       "  'NeuralNetFastAI_r103_BAG_L1': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': False},\n",
       "  'LightGBM_r161_BAG_L1': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': False},\n",
       "  'NeuralNetFastAI_r143_BAG_L1': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': False},\n",
       "  'CatBoost_r70_BAG_L1': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': False},\n",
       "  'NeuralNetFastAI_r156_BAG_L1': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': False},\n",
       "  'LightGBM_r196_BAG_L1': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': False},\n",
       "  'CatBoost_r167_BAG_L1': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': False},\n",
       "  'NeuralNetFastAI_r95_BAG_L1': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': False},\n",
       "  'XGBoost_r98_BAG_L1': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': False},\n",
       "  'LightGBM_r15_BAG_L1': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': False},\n",
       "  'CatBoost_r86_BAG_L1': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': False},\n",
       "  'NeuralNetFastAI_r37_BAG_L1': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': False},\n",
       "  'CatBoost_r49_BAG_L1': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': False},\n",
       "  'LightGBM_r143_BAG_L1': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': False},\n",
       "  'NeuralNetFastAI_r134_BAG_L1': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': False},\n",
       "  'LightGBM_r94_BAG_L1': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': False},\n",
       "  'CatBoost_r128_BAG_L1': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': False},\n",
       "  'NeuralNetFastAI_r111_BAG_L1': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': False},\n",
       "  'NeuralNetFastAI_r65_BAG_L1': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': False},\n",
       "  'NeuralNetFastAI_r88_BAG_L1': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': False},\n",
       "  'LightGBM_r30_BAG_L1': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': False},\n",
       "  'XGBoost_r49_BAG_L1': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': False},\n",
       "  'CatBoost_r5_BAG_L1': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': False},\n",
       "  'CatBoost_r143_BAG_L1': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': False},\n",
       "  'XGBoost_r31_BAG_L1': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': False},\n",
       "  'NeuralNetFastAI_r160_BAG_L1': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': False},\n",
       "  'CatBoost_r60_BAG_L1': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': False},\n",
       "  'LightGBM_r135_BAG_L1': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': False},\n",
       "  'XGBoost_r22_BAG_L1': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': False},\n",
       "  'NeuralNetFastAI_r69_BAG_L1': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': False},\n",
       "  'CatBoost_r6_BAG_L1': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': False},\n",
       "  'NeuralNetFastAI_r138_BAG_L1': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': False},\n",
       "  'LightGBM_r121_BAG_L1': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': False},\n",
       "  'NeuralNetFastAI_r172_BAG_L1': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': False},\n",
       "  'CatBoost_r180_BAG_L1': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': False},\n",
       "  'WeightedEnsemble_L2': {'use_orig_features': False,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True},\n",
       "  'LightGBMXT_BAG_L1_FULL': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True},\n",
       "  'LightGBM_BAG_L1_FULL': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True},\n",
       "  'CatBoost_BAG_L1_FULL': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True},\n",
       "  'NeuralNetFastAI_BAG_L1_FULL': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True},\n",
       "  'XGBoost_BAG_L1_FULL': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True},\n",
       "  'LightGBMLarge_BAG_L1_FULL': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True},\n",
       "  'CatBoost_r177_BAG_L1_FULL': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True},\n",
       "  'LightGBM_r131_BAG_L1_FULL': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True},\n",
       "  'NeuralNetFastAI_r191_BAG_L1_FULL': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True},\n",
       "  'CatBoost_r9_BAG_L1_FULL': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True},\n",
       "  'LightGBM_r96_BAG_L1_FULL': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True},\n",
       "  'XGBoost_r33_BAG_L1_FULL': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True},\n",
       "  'CatBoost_r137_BAG_L1_FULL': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True},\n",
       "  'NeuralNetFastAI_r102_BAG_L1_FULL': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True},\n",
       "  'CatBoost_r13_BAG_L1_FULL': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True},\n",
       "  'LightGBM_r188_BAG_L1_FULL': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True},\n",
       "  'NeuralNetFastAI_r145_BAG_L1_FULL': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True},\n",
       "  'XGBoost_r89_BAG_L1_FULL': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True},\n",
       "  'LightGBM_r130_BAG_L1_FULL': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True},\n",
       "  'CatBoost_r50_BAG_L1_FULL': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True},\n",
       "  'NeuralNetFastAI_r11_BAG_L1_FULL': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True},\n",
       "  'XGBoost_r194_BAG_L1_FULL': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True},\n",
       "  'CatBoost_r69_BAG_L1_FULL': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True},\n",
       "  'NeuralNetFastAI_r103_BAG_L1_FULL': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True},\n",
       "  'LightGBM_r161_BAG_L1_FULL': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True},\n",
       "  'NeuralNetFastAI_r143_BAG_L1_FULL': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True},\n",
       "  'CatBoost_r70_BAG_L1_FULL': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True},\n",
       "  'NeuralNetFastAI_r156_BAG_L1_FULL': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True},\n",
       "  'LightGBM_r196_BAG_L1_FULL': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True},\n",
       "  'CatBoost_r167_BAG_L1_FULL': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True},\n",
       "  'NeuralNetFastAI_r95_BAG_L1_FULL': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True},\n",
       "  'XGBoost_r98_BAG_L1_FULL': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True},\n",
       "  'LightGBM_r15_BAG_L1_FULL': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True},\n",
       "  'CatBoost_r86_BAG_L1_FULL': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True},\n",
       "  'NeuralNetFastAI_r37_BAG_L1_FULL': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True},\n",
       "  'CatBoost_r49_BAG_L1_FULL': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True},\n",
       "  'LightGBM_r143_BAG_L1_FULL': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True},\n",
       "  'NeuralNetFastAI_r134_BAG_L1_FULL': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True},\n",
       "  'LightGBM_r94_BAG_L1_FULL': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True},\n",
       "  'CatBoost_r128_BAG_L1_FULL': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True},\n",
       "  'NeuralNetFastAI_r111_BAG_L1_FULL': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True},\n",
       "  'NeuralNetFastAI_r65_BAG_L1_FULL': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True},\n",
       "  'NeuralNetFastAI_r88_BAG_L1_FULL': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True},\n",
       "  'LightGBM_r30_BAG_L1_FULL': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True},\n",
       "  'XGBoost_r49_BAG_L1_FULL': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True},\n",
       "  'CatBoost_r5_BAG_L1_FULL': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True},\n",
       "  'CatBoost_r143_BAG_L1_FULL': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True},\n",
       "  'XGBoost_r31_BAG_L1_FULL': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True},\n",
       "  'NeuralNetFastAI_r160_BAG_L1_FULL': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True},\n",
       "  'CatBoost_r60_BAG_L1_FULL': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True},\n",
       "  'LightGBM_r135_BAG_L1_FULL': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True},\n",
       "  'XGBoost_r22_BAG_L1_FULL': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True},\n",
       "  'NeuralNetFastAI_r69_BAG_L1_FULL': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True},\n",
       "  'CatBoost_r6_BAG_L1_FULL': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True},\n",
       "  'NeuralNetFastAI_r138_BAG_L1_FULL': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True},\n",
       "  'LightGBM_r121_BAG_L1_FULL': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True},\n",
       "  'NeuralNetFastAI_r172_BAG_L1_FULL': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True},\n",
       "  'CatBoost_r180_BAG_L1_FULL': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True},\n",
       "  'WeightedEnsemble_L2_FULL': {'use_orig_features': False,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True}},\n",
       " 'leaderboard':                          model  score_val eval_metric  pred_time_val  \\\n",
       " 0          WeightedEnsemble_L2   0.977686     roc_auc       0.207192   \n",
       " 1          CatBoost_r69_BAG_L1   0.975975     roc_auc       0.063878   \n",
       " 2            LightGBMXT_BAG_L1   0.975899     roc_auc       0.035680   \n",
       " 3          LightGBM_r30_BAG_L1   0.974239     roc_auc       0.069385   \n",
       " 4         LightGBM_r188_BAG_L1   0.974188     roc_auc       0.035332   \n",
       " ..                         ...        ...         ...            ...   \n",
       " 113  CatBoost_r143_BAG_L1_FULL        NaN     roc_auc            NaN   \n",
       " 114   CatBoost_r13_BAG_L1_FULL        NaN     roc_auc            NaN   \n",
       " 115  CatBoost_r137_BAG_L1_FULL        NaN     roc_auc            NaN   \n",
       " 116  CatBoost_r128_BAG_L1_FULL        NaN     roc_auc            NaN   \n",
       " 117       CatBoost_BAG_L1_FULL        NaN     roc_auc            NaN   \n",
       " \n",
       "       fit_time  pred_time_val_marginal  fit_time_marginal  stack_level  \\\n",
       " 0    41.759184                0.001023           0.033920            2   \n",
       " 1    29.564252                0.063878          29.564252            1   \n",
       " 2     1.250397                0.035680           1.250397            1   \n",
       " 3     3.286644                0.069385           3.286644            1   \n",
       " 4     2.354293                0.035332           2.354293            1   \n",
       " ..         ...                     ...                ...          ...   \n",
       " 113   5.087612                     NaN           5.087612            1   \n",
       " 114  38.225583                     NaN          38.225583            1   \n",
       " 115   5.779315                     NaN           5.779315            1   \n",
       " 116  79.017386                     NaN          79.017386            1   \n",
       " 117   6.363546                     NaN           6.363546            1   \n",
       " \n",
       "      can_infer  fit_order  \n",
       " 0        False         59  \n",
       " 1        False         23  \n",
       " 2        False          1  \n",
       " 3        False         44  \n",
       " 4        False         16  \n",
       " ..         ...        ...  \n",
       " 113       True        106  \n",
       " 114       True         74  \n",
       " 115       True         72  \n",
       " 116       True         99  \n",
       " 117       True         62  \n",
       " \n",
       " [118 rows x 10 columns]}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.fit_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "auxiliary_metrics = ['balanced_accuracy', 'f1', 'f1_macro', 'f1_micro', 'roc_auc', 'average_precision', 'precision', 'recall', 'log_loss', 'pac_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluation: roc_auc on test data: 0.987012987012987\n",
      "Evaluations on test data:\n",
      "{\n",
      "    \"roc_auc\": 0.987012987012987,\n",
      "    \"accuracy\": 0.94,\n",
      "    \"balanced_accuracy\": 0.9391233766233766,\n",
      "    \"mcc\": 0.8782467532467533,\n",
      "    \"f1\": 0.9464285714285714,\n",
      "    \"precision\": 0.9464285714285714,\n",
      "    \"recall\": 0.9464285714285714\n",
      "}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'roc_auc': 0.987012987012987,\n",
       " 'accuracy': 0.94,\n",
       " 'balanced_accuracy': 0.9391233766233766,\n",
       " 'mcc': 0.8782467532467533,\n",
       " 'f1': 0.9464285714285714,\n",
       " 'precision': 0.9464285714285714,\n",
       " 'recall': 0.9464285714285714}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.evaluate(\n",
    "    df_test,\n",
    "    silent = False,\n",
    "    auxiliary_metrics = auxiliary_metrics\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'WeightedEnsemble_L2_FULL'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.model_best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictors = predictor.leaderboard(\n",
    "    df_test,\n",
    "    extra_metrics = auxiliary_metrics,\n",
    "    extra_info=True,\n",
    "    silent=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>score_test</th>\n",
       "      <th>balanced_accuracy</th>\n",
       "      <th>f1</th>\n",
       "      <th>f1_macro</th>\n",
       "      <th>f1_micro</th>\n",
       "      <th>roc_auc</th>\n",
       "      <th>average_precision</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>...</th>\n",
       "      <th>hyperparameters</th>\n",
       "      <th>hyperparameters_fit</th>\n",
       "      <th>ag_args_fit</th>\n",
       "      <th>features</th>\n",
       "      <th>compile_time</th>\n",
       "      <th>child_hyperparameters</th>\n",
       "      <th>child_hyperparameters_fit</th>\n",
       "      <th>child_ag_args_fit</th>\n",
       "      <th>ancestors</th>\n",
       "      <th>descendants</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LightGBM_r143_BAG_L1_FULL</td>\n",
       "      <td>0.992289</td>\n",
       "      <td>0.939123</td>\n",
       "      <td>0.946429</td>\n",
       "      <td>0.939123</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.992289</td>\n",
       "      <td>0.994303</td>\n",
       "      <td>0.946429</td>\n",
       "      <td>0.946429</td>\n",
       "      <td>...</td>\n",
       "      <td>{'use_orig_features': True, 'valid_stacker': True, 'max_base_models': 0, 'max_base_models_per_type': 'auto', 'save_bag_folds': True}</td>\n",
       "      <td>{}</td>\n",
       "      <td>{'max_memory_usage_ratio': 1.15, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': None, 'valid_special_types': None, 'ignored_type_group_special': None, 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'temperature_scalar': None, 'drop_unique': False}</td>\n",
       "      <td>[eval-TLP-Tavec-14_ESem_RL_CP-PD, clin-Hipercolesterolemia, clin-reservaCognitiva_idiomas, clin-reservaCognitiva_escolaridad, ques-MMSE-fijacion-PD, eval-TLP-FigRey-totalMemoria-PD, clin-tipoAlcohol.capital_ratio, clin-Hipertension, eval-TLP-Tavec-25_Discriminabilidad-PD, eval-TLP-Tavec-2_RI_A5-PD, ques-Sus-total-PD, ques-NavEspacial-resultadosWFQ_SA-PD, clin-tipoAlcohol.symbol_ratio. , eval-TLP-Tavec-20_P-PD, demo-fechaNacimiento.day, eval-TLP-Tavec-28_RL_CP_frente_RI_A5-PD, ques-QuejasMemo-Total-PD, demo-rangoEdad, eval-TLP-Tavec-4_RI_B-PD, ques-MMSE-escolaridad-PD, eval-TLP-FigRey-Durac...</td>\n",
       "      <td>None</td>\n",
       "      <td>{'learning_rate': 0.01343464462043561, 'extra_trees': False, 'feature_fraction': 0.9408897917880529, 'min_data_in_leaf': 21, 'num_leaves': 178, 'num_boost_round': 472}</td>\n",
       "      <td>{'num_boost_round': 472}</td>\n",
       "      <td>{'max_memory_usage_ratio': 1.0, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': ['bool', 'int', 'float', 'category'], 'valid_special_types': None, 'ignored_type_group_special': None, 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'temperature_scalar': None}</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LightGBM_BAG_L1_FULL</td>\n",
       "      <td>0.991883</td>\n",
       "      <td>0.948052</td>\n",
       "      <td>0.955752</td>\n",
       "      <td>0.949140</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.991883</td>\n",
       "      <td>0.993962</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>0.964286</td>\n",
       "      <td>...</td>\n",
       "      <td>{'use_orig_features': True, 'valid_stacker': True, 'max_base_models': 0, 'max_base_models_per_type': 'auto', 'save_bag_folds': True}</td>\n",
       "      <td>{}</td>\n",
       "      <td>{'max_memory_usage_ratio': 1.15, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': None, 'valid_special_types': None, 'ignored_type_group_special': None, 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'temperature_scalar': None, 'drop_unique': False}</td>\n",
       "      <td>[eval-TLP-Tavec-14_ESem_RL_CP-PD, clin-Hipercolesterolemia, clin-reservaCognitiva_idiomas, clin-reservaCognitiva_escolaridad, ques-MMSE-fijacion-PD, eval-TLP-FigRey-totalMemoria-PD, clin-tipoAlcohol.capital_ratio, clin-Hipertension, eval-TLP-Tavec-25_Discriminabilidad-PD, eval-TLP-Tavec-2_RI_A5-PD, ques-Sus-total-PD, ques-NavEspacial-resultadosWFQ_SA-PD, clin-tipoAlcohol.symbol_ratio. , eval-TLP-Tavec-20_P-PD, demo-fechaNacimiento.day, eval-TLP-Tavec-28_RL_CP_frente_RI_A5-PD, ques-QuejasMemo-Total-PD, demo-rangoEdad, eval-TLP-Tavec-4_RI_B-PD, ques-MMSE-escolaridad-PD, eval-TLP-FigRey-Durac...</td>\n",
       "      <td>None</td>\n",
       "      <td>{'learning_rate': 0.05, 'num_boost_round': 122}</td>\n",
       "      <td>{'num_boost_round': 122}</td>\n",
       "      <td>{'max_memory_usage_ratio': 1.0, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': ['bool', 'int', 'float', 'category'], 'valid_special_types': None, 'ignored_type_group_special': None, 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'temperature_scalar': None}</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CatBoost_r13_BAG_L1_FULL</td>\n",
       "      <td>0.989854</td>\n",
       "      <td>0.935065</td>\n",
       "      <td>0.934579</td>\n",
       "      <td>0.929655</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.989854</td>\n",
       "      <td>0.992096</td>\n",
       "      <td>0.980392</td>\n",
       "      <td>0.892857</td>\n",
       "      <td>...</td>\n",
       "      <td>{'use_orig_features': True, 'valid_stacker': True, 'max_base_models': 0, 'max_base_models_per_type': 'auto', 'save_bag_folds': True}</td>\n",
       "      <td>{}</td>\n",
       "      <td>{'max_memory_usage_ratio': 1.15, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': None, 'valid_special_types': None, 'ignored_type_group_special': None, 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'temperature_scalar': None, 'drop_unique': False}</td>\n",
       "      <td>[eval-TLP-Tavec-14_ESem_RL_CP-PD, clin-Hipercolesterolemia, clin-reservaCognitiva_idiomas, clin-reservaCognitiva_escolaridad, ques-MMSE-fijacion-PD, eval-TLP-FigRey-totalMemoria-PD, clin-tipoAlcohol.capital_ratio, clin-Hipertension, eval-TLP-Tavec-25_Discriminabilidad-PD, eval-TLP-Tavec-2_RI_A5-PD, ques-Sus-total-PD, ques-NavEspacial-resultadosWFQ_SA-PD, clin-tipoAlcohol.symbol_ratio. , eval-TLP-Tavec-20_P-PD, demo-fechaNacimiento.day, eval-TLP-Tavec-28_RL_CP_frente_RI_A5-PD, ques-QuejasMemo-Total-PD, demo-rangoEdad, eval-TLP-Tavec-4_RI_B-PD, ques-MMSE-escolaridad-PD, eval-TLP-FigRey-Durac...</td>\n",
       "      <td>None</td>\n",
       "      <td>{'iterations': 1098, 'learning_rate': 0.017301189655111057, 'random_seed': 0, 'allow_writing_files': False, 'eval_metric': 'Logloss', 'depth': 8, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 3.3274013177541373, 'max_ctr_complexity': 5, 'one_hot_max_size': 10}</td>\n",
       "      <td>{'iterations': 1098}</td>\n",
       "      <td>{'max_memory_usage_ratio': 1.0, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': ['bool', 'int', 'float', 'category'], 'valid_special_types': None, 'ignored_type_group_special': None, 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'temperature_scalar': None}</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CatBoost_r167_BAG_L1_FULL</td>\n",
       "      <td>0.989448</td>\n",
       "      <td>0.921266</td>\n",
       "      <td>0.927273</td>\n",
       "      <td>0.919192</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.989448</td>\n",
       "      <td>0.991856</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>0.910714</td>\n",
       "      <td>...</td>\n",
       "      <td>{'use_orig_features': True, 'valid_stacker': True, 'max_base_models': 0, 'max_base_models_per_type': 'auto', 'save_bag_folds': True}</td>\n",
       "      <td>{}</td>\n",
       "      <td>{'max_memory_usage_ratio': 1.15, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': None, 'valid_special_types': None, 'ignored_type_group_special': None, 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'temperature_scalar': None, 'drop_unique': False}</td>\n",
       "      <td>[eval-TLP-Tavec-14_ESem_RL_CP-PD, clin-Hipercolesterolemia, clin-reservaCognitiva_idiomas, clin-reservaCognitiva_escolaridad, ques-MMSE-fijacion-PD, eval-TLP-FigRey-totalMemoria-PD, clin-tipoAlcohol.capital_ratio, clin-Hipertension, eval-TLP-Tavec-25_Discriminabilidad-PD, eval-TLP-Tavec-2_RI_A5-PD, ques-Sus-total-PD, ques-NavEspacial-resultadosWFQ_SA-PD, clin-tipoAlcohol.symbol_ratio. , eval-TLP-Tavec-20_P-PD, demo-fechaNacimiento.day, eval-TLP-Tavec-28_RL_CP_frente_RI_A5-PD, ques-QuejasMemo-Total-PD, demo-rangoEdad, eval-TLP-Tavec-4_RI_B-PD, ques-MMSE-escolaridad-PD, eval-TLP-FigRey-Durac...</td>\n",
       "      <td>None</td>\n",
       "      <td>{'iterations': 160, 'learning_rate': 0.08481607830570326, 'random_seed': 0, 'allow_writing_files': False, 'eval_metric': 'Logloss', 'depth': 7, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 4.522712492188319, 'max_ctr_complexity': 3, 'one_hot_max_size': 2}</td>\n",
       "      <td>{'iterations': 160}</td>\n",
       "      <td>{'max_memory_usage_ratio': 1.0, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': ['bool', 'int', 'float', 'category'], 'valid_special_types': None, 'ignored_type_group_special': None, 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'temperature_scalar': None}</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LightGBM_r30_BAG_L1_FULL</td>\n",
       "      <td>0.989448</td>\n",
       "      <td>0.930195</td>\n",
       "      <td>0.936937</td>\n",
       "      <td>0.929143</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.989448</td>\n",
       "      <td>0.991856</td>\n",
       "      <td>0.945455</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>...</td>\n",
       "      <td>{'use_orig_features': True, 'valid_stacker': True, 'max_base_models': 0, 'max_base_models_per_type': 'auto', 'save_bag_folds': True}</td>\n",
       "      <td>{}</td>\n",
       "      <td>{'max_memory_usage_ratio': 1.15, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': None, 'valid_special_types': None, 'ignored_type_group_special': None, 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'temperature_scalar': None, 'drop_unique': False}</td>\n",
       "      <td>[eval-TLP-Tavec-14_ESem_RL_CP-PD, clin-Hipercolesterolemia, clin-reservaCognitiva_idiomas, clin-reservaCognitiva_escolaridad, ques-MMSE-fijacion-PD, eval-TLP-FigRey-totalMemoria-PD, clin-tipoAlcohol.capital_ratio, clin-Hipertension, eval-TLP-Tavec-25_Discriminabilidad-PD, eval-TLP-Tavec-2_RI_A5-PD, ques-Sus-total-PD, ques-NavEspacial-resultadosWFQ_SA-PD, clin-tipoAlcohol.symbol_ratio. , eval-TLP-Tavec-20_P-PD, demo-fechaNacimiento.day, eval-TLP-Tavec-28_RL_CP_frente_RI_A5-PD, ques-QuejasMemo-Total-PD, demo-rangoEdad, eval-TLP-Tavec-4_RI_B-PD, ques-MMSE-escolaridad-PD, eval-TLP-FigRey-Durac...</td>\n",
       "      <td>None</td>\n",
       "      <td>{'learning_rate': 0.010534290864227067, 'extra_trees': True, 'feature_fraction': 0.9773131270704629, 'min_data_in_leaf': 21, 'num_leaves': 111, 'num_boost_round': 1195}</td>\n",
       "      <td>{'num_boost_round': 1195}</td>\n",
       "      <td>{'max_memory_usage_ratio': 1.0, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': ['bool', 'int', 'float', 'category'], 'valid_special_types': None, 'ignored_type_group_special': None, 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'temperature_scalar': None}</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>NeuralNetFastAI_r65_BAG_L1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>{'use_orig_features': True, 'valid_stacker': True, 'max_base_models': 0, 'max_base_models_per_type': 'auto', 'save_bag_folds': False}</td>\n",
       "      <td>{}</td>\n",
       "      <td>{'max_memory_usage_ratio': 1.0, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': None, 'valid_special_types': None, 'ignored_type_group_special': None, 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'temperature_scalar': None, 'drop_unique': False}</td>\n",
       "      <td>[eval-TLP-Tavec-14_ESem_RL_CP-PD, clin-Hipercolesterolemia, clin-reservaCognitiva_idiomas, clin-reservaCognitiva_escolaridad, ques-MMSE-fijacion-PD, eval-TLP-FigRey-totalMemoria-PD, clin-tipoAlcohol.capital_ratio, clin-Hipertension, eval-TLP-Tavec-25_Discriminabilidad-PD, eval-TLP-Tavec-2_RI_A5-PD, ques-Sus-total-PD, ques-NavEspacial-resultadosWFQ_SA-PD, clin-tipoAlcohol.symbol_ratio. , eval-TLP-Tavec-20_P-PD, demo-fechaNacimiento.day, eval-TLP-Tavec-28_RL_CP_frente_RI_A5-PD, ques-QuejasMemo-Total-PD, demo-rangoEdad, eval-TLP-Tavec-4_RI_B-PD, ques-MMSE-escolaridad-PD, eval-TLP-FigRey-Durac...</td>\n",
       "      <td>None</td>\n",
       "      <td>{'layers': [400], 'emb_drop': 0.22771721361129746, 'ps': 0.3734259772256502, 'bs': 1024, 'lr': 0.0005383511954451698, 'epochs': 38, 'early.stopping.min_delta': 0.0001, 'early.stopping.patience': 20, 'smoothing': 0.0}</td>\n",
       "      <td>{'epochs': 38, 'best_epoch': 16}</td>\n",
       "      <td>{'max_memory_usage_ratio': 1.0, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': ['bool', 'int', 'float', 'category'], 'valid_special_types': None, 'ignored_type_group_special': ['text_ngram', 'text_as_category'], 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'temperature_scalar': None}</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>NeuralNetFastAI_r69_BAG_L1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>{'use_orig_features': True, 'valid_stacker': True, 'max_base_models': 0, 'max_base_models_per_type': 'auto', 'save_bag_folds': False}</td>\n",
       "      <td>{}</td>\n",
       "      <td>{'max_memory_usage_ratio': 1.0, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': None, 'valid_special_types': None, 'ignored_type_group_special': None, 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'temperature_scalar': None, 'drop_unique': False}</td>\n",
       "      <td>[eval-TLP-Tavec-14_ESem_RL_CP-PD, clin-Hipercolesterolemia, clin-reservaCognitiva_idiomas, clin-reservaCognitiva_escolaridad, ques-MMSE-fijacion-PD, eval-TLP-FigRey-totalMemoria-PD, clin-tipoAlcohol.capital_ratio, clin-Hipertension, eval-TLP-Tavec-25_Discriminabilidad-PD, eval-TLP-Tavec-2_RI_A5-PD, ques-Sus-total-PD, ques-NavEspacial-resultadosWFQ_SA-PD, clin-tipoAlcohol.symbol_ratio. , eval-TLP-Tavec-20_P-PD, demo-fechaNacimiento.day, eval-TLP-Tavec-28_RL_CP_frente_RI_A5-PD, ques-QuejasMemo-Total-PD, demo-rangoEdad, eval-TLP-Tavec-4_RI_B-PD, ques-MMSE-escolaridad-PD, eval-TLP-FigRey-Durac...</td>\n",
       "      <td>None</td>\n",
       "      <td>{'layers': [200, 100, 50], 'emb_drop': 0.3209601865656554, 'ps': 0.19846319260751663, 'bs': 128, 'lr': 0.019935403046870463, 'epochs': 21, 'early.stopping.min_delta': 0.0001, 'early.stopping.patience': 20, 'smoothing': 0.0}</td>\n",
       "      <td>{'epochs': 21, 'best_epoch': 6}</td>\n",
       "      <td>{'max_memory_usage_ratio': 1.0, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': ['bool', 'int', 'float', 'category'], 'valid_special_types': None, 'ignored_type_group_special': ['text_ngram', 'text_as_category'], 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'temperature_scalar': None}</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>NeuralNetFastAI_r172_BAG_L1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>{'use_orig_features': True, 'valid_stacker': True, 'max_base_models': 0, 'max_base_models_per_type': 'auto', 'save_bag_folds': False}</td>\n",
       "      <td>{}</td>\n",
       "      <td>{'max_memory_usage_ratio': 1.0, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': None, 'valid_special_types': None, 'ignored_type_group_special': None, 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'temperature_scalar': None, 'drop_unique': False}</td>\n",
       "      <td>[eval-TLP-Tavec-14_ESem_RL_CP-PD, clin-Hipercolesterolemia, clin-reservaCognitiva_idiomas, clin-reservaCognitiva_escolaridad, ques-MMSE-fijacion-PD, eval-TLP-FigRey-totalMemoria-PD, clin-tipoAlcohol.capital_ratio, clin-Hipertension, eval-TLP-Tavec-25_Discriminabilidad-PD, eval-TLP-Tavec-2_RI_A5-PD, ques-Sus-total-PD, ques-NavEspacial-resultadosWFQ_SA-PD, clin-tipoAlcohol.symbol_ratio. , eval-TLP-Tavec-20_P-PD, demo-fechaNacimiento.day, eval-TLP-Tavec-28_RL_CP_frente_RI_A5-PD, ques-QuejasMemo-Total-PD, demo-rangoEdad, eval-TLP-Tavec-4_RI_B-PD, ques-MMSE-escolaridad-PD, eval-TLP-FigRey-Durac...</td>\n",
       "      <td>None</td>\n",
       "      <td>{'layers': [400], 'emb_drop': 0.05604276533830355, 'ps': 0.022591301744255762, 'bs': 512, 'lr': 0.027320709383189166, 'epochs': 32, 'early.stopping.min_delta': 0.0001, 'early.stopping.patience': 20, 'smoothing': 0.0}</td>\n",
       "      <td>{'epochs': 32, 'best_epoch': 1}</td>\n",
       "      <td>{'max_memory_usage_ratio': 1.0, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': ['bool', 'int', 'float', 'category'], 'valid_special_types': None, 'ignored_type_group_special': ['text_ngram', 'text_as_category'], 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'temperature_scalar': None}</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>NeuralNetFastAI_r102_BAG_L1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>{'use_orig_features': True, 'valid_stacker': True, 'max_base_models': 0, 'max_base_models_per_type': 'auto', 'save_bag_folds': False}</td>\n",
       "      <td>{}</td>\n",
       "      <td>{'max_memory_usage_ratio': 1.0, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': None, 'valid_special_types': None, 'ignored_type_group_special': None, 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'temperature_scalar': None, 'drop_unique': False}</td>\n",
       "      <td>[eval-TLP-Tavec-14_ESem_RL_CP-PD, clin-Hipercolesterolemia, clin-reservaCognitiva_idiomas, clin-reservaCognitiva_escolaridad, ques-MMSE-fijacion-PD, eval-TLP-FigRey-totalMemoria-PD, clin-tipoAlcohol.capital_ratio, clin-Hipertension, eval-TLP-Tavec-25_Discriminabilidad-PD, eval-TLP-Tavec-2_RI_A5-PD, ques-Sus-total-PD, ques-NavEspacial-resultadosWFQ_SA-PD, clin-tipoAlcohol.symbol_ratio. , eval-TLP-Tavec-20_P-PD, demo-fechaNacimiento.day, eval-TLP-Tavec-28_RL_CP_frente_RI_A5-PD, ques-QuejasMemo-Total-PD, demo-rangoEdad, eval-TLP-Tavec-4_RI_B-PD, ques-MMSE-escolaridad-PD, eval-TLP-FigRey-Durac...</td>\n",
       "      <td>None</td>\n",
       "      <td>{'layers': [200, 100], 'emb_drop': 0.05070411322605811, 'ps': 0.10393466140748028, 'bs': 2048, 'lr': 0.08974235041576624, 'epochs': 29, 'early.stopping.min_delta': 0.0001, 'early.stopping.patience': 20, 'smoothing': 0.0}</td>\n",
       "      <td>{'epochs': 29, 'best_epoch': 5}</td>\n",
       "      <td>{'max_memory_usage_ratio': 1.0, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': ['bool', 'int', 'float', 'category'], 'valid_special_types': None, 'ignored_type_group_special': ['text_ngram', 'text_as_category'], 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'temperature_scalar': None}</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>NeuralNetFastAI_r11_BAG_L1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>{'use_orig_features': True, 'valid_stacker': True, 'max_base_models': 0, 'max_base_models_per_type': 'auto', 'save_bag_folds': False}</td>\n",
       "      <td>{}</td>\n",
       "      <td>{'max_memory_usage_ratio': 1.0, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': None, 'valid_special_types': None, 'ignored_type_group_special': None, 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'temperature_scalar': None, 'drop_unique': False}</td>\n",
       "      <td>[eval-TLP-Tavec-14_ESem_RL_CP-PD, clin-Hipercolesterolemia, clin-reservaCognitiva_idiomas, clin-reservaCognitiva_escolaridad, ques-MMSE-fijacion-PD, eval-TLP-FigRey-totalMemoria-PD, clin-tipoAlcohol.capital_ratio, clin-Hipertension, eval-TLP-Tavec-25_Discriminabilidad-PD, eval-TLP-Tavec-2_RI_A5-PD, ques-Sus-total-PD, ques-NavEspacial-resultadosWFQ_SA-PD, clin-tipoAlcohol.symbol_ratio. , eval-TLP-Tavec-20_P-PD, demo-fechaNacimiento.day, eval-TLP-Tavec-28_RL_CP_frente_RI_A5-PD, ques-QuejasMemo-Total-PD, demo-rangoEdad, eval-TLP-Tavec-4_RI_B-PD, ques-MMSE-escolaridad-PD, eval-TLP-FigRey-Durac...</td>\n",
       "      <td>None</td>\n",
       "      <td>{'layers': [800, 400], 'emb_drop': 0.026897798530914306, 'ps': 0.4569532219038436, 'bs': 128, 'lr': 0.08045277634470181, 'epochs': 31, 'early.stopping.min_delta': 0.0001, 'early.stopping.patience': 20, 'smoothing': 0.0}</td>\n",
       "      <td>{'epochs': 31, 'best_epoch': 3}</td>\n",
       "      <td>{'max_memory_usage_ratio': 1.0, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': ['bool', 'int', 'float', 'category'], 'valid_special_types': None, 'ignored_type_group_special': ['text_ngram', 'text_as_category'], 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'temperature_scalar': None}</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>118 rows Ã— 45 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           model  score_test  balanced_accuracy        f1  \\\n",
       "0      LightGBM_r143_BAG_L1_FULL    0.992289           0.939123  0.946429   \n",
       "1           LightGBM_BAG_L1_FULL    0.991883           0.948052  0.955752   \n",
       "2       CatBoost_r13_BAG_L1_FULL    0.989854           0.935065  0.934579   \n",
       "3      CatBoost_r167_BAG_L1_FULL    0.989448           0.921266  0.927273   \n",
       "4       LightGBM_r30_BAG_L1_FULL    0.989448           0.930195  0.936937   \n",
       "..                           ...         ...                ...       ...   \n",
       "113   NeuralNetFastAI_r65_BAG_L1         NaN                NaN       NaN   \n",
       "114   NeuralNetFastAI_r69_BAG_L1         NaN                NaN       NaN   \n",
       "115  NeuralNetFastAI_r172_BAG_L1         NaN                NaN       NaN   \n",
       "116  NeuralNetFastAI_r102_BAG_L1         NaN                NaN       NaN   \n",
       "117   NeuralNetFastAI_r11_BAG_L1         NaN                NaN       NaN   \n",
       "\n",
       "     f1_macro  f1_micro   roc_auc  average_precision  precision    recall  \\\n",
       "0    0.939123      0.94  0.992289           0.994303   0.946429  0.946429   \n",
       "1    0.949140      0.95  0.991883           0.993962   0.947368  0.964286   \n",
       "2    0.929655      0.93  0.989854           0.992096   0.980392  0.892857   \n",
       "3    0.919192      0.92  0.989448           0.991856   0.944444  0.910714   \n",
       "4    0.929143      0.93  0.989448           0.991856   0.945455  0.928571   \n",
       "..        ...       ...       ...                ...        ...       ...   \n",
       "113       NaN       NaN       NaN                NaN        NaN       NaN   \n",
       "114       NaN       NaN       NaN                NaN        NaN       NaN   \n",
       "115       NaN       NaN       NaN                NaN        NaN       NaN   \n",
       "116       NaN       NaN       NaN                NaN        NaN       NaN   \n",
       "117       NaN       NaN       NaN                NaN        NaN       NaN   \n",
       "\n",
       "     ...  \\\n",
       "0    ...   \n",
       "1    ...   \n",
       "2    ...   \n",
       "3    ...   \n",
       "4    ...   \n",
       "..   ...   \n",
       "113  ...   \n",
       "114  ...   \n",
       "115  ...   \n",
       "116  ...   \n",
       "117  ...   \n",
       "\n",
       "                                                                                                                           hyperparameters  \\\n",
       "0     {'use_orig_features': True, 'valid_stacker': True, 'max_base_models': 0, 'max_base_models_per_type': 'auto', 'save_bag_folds': True}   \n",
       "1     {'use_orig_features': True, 'valid_stacker': True, 'max_base_models': 0, 'max_base_models_per_type': 'auto', 'save_bag_folds': True}   \n",
       "2     {'use_orig_features': True, 'valid_stacker': True, 'max_base_models': 0, 'max_base_models_per_type': 'auto', 'save_bag_folds': True}   \n",
       "3     {'use_orig_features': True, 'valid_stacker': True, 'max_base_models': 0, 'max_base_models_per_type': 'auto', 'save_bag_folds': True}   \n",
       "4     {'use_orig_features': True, 'valid_stacker': True, 'max_base_models': 0, 'max_base_models_per_type': 'auto', 'save_bag_folds': True}   \n",
       "..                                                                                                                                     ...   \n",
       "113  {'use_orig_features': True, 'valid_stacker': True, 'max_base_models': 0, 'max_base_models_per_type': 'auto', 'save_bag_folds': False}   \n",
       "114  {'use_orig_features': True, 'valid_stacker': True, 'max_base_models': 0, 'max_base_models_per_type': 'auto', 'save_bag_folds': False}   \n",
       "115  {'use_orig_features': True, 'valid_stacker': True, 'max_base_models': 0, 'max_base_models_per_type': 'auto', 'save_bag_folds': False}   \n",
       "116  {'use_orig_features': True, 'valid_stacker': True, 'max_base_models': 0, 'max_base_models_per_type': 'auto', 'save_bag_folds': False}   \n",
       "117  {'use_orig_features': True, 'valid_stacker': True, 'max_base_models': 0, 'max_base_models_per_type': 'auto', 'save_bag_folds': False}   \n",
       "\n",
       "     hyperparameters_fit  \\\n",
       "0                     {}   \n",
       "1                     {}   \n",
       "2                     {}   \n",
       "3                     {}   \n",
       "4                     {}   \n",
       "..                   ...   \n",
       "113                   {}   \n",
       "114                   {}   \n",
       "115                   {}   \n",
       "116                   {}   \n",
       "117                   {}   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                              ag_args_fit  \\\n",
       "0    {'max_memory_usage_ratio': 1.15, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': None, 'valid_special_types': None, 'ignored_type_group_special': None, 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'temperature_scalar': None, 'drop_unique': False}   \n",
       "1    {'max_memory_usage_ratio': 1.15, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': None, 'valid_special_types': None, 'ignored_type_group_special': None, 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'temperature_scalar': None, 'drop_unique': False}   \n",
       "2    {'max_memory_usage_ratio': 1.15, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': None, 'valid_special_types': None, 'ignored_type_group_special': None, 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'temperature_scalar': None, 'drop_unique': False}   \n",
       "3    {'max_memory_usage_ratio': 1.15, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': None, 'valid_special_types': None, 'ignored_type_group_special': None, 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'temperature_scalar': None, 'drop_unique': False}   \n",
       "4    {'max_memory_usage_ratio': 1.15, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': None, 'valid_special_types': None, 'ignored_type_group_special': None, 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'temperature_scalar': None, 'drop_unique': False}   \n",
       "..                                                                                                                                                                                                                                                                                                                                                                                    ...   \n",
       "113   {'max_memory_usage_ratio': 1.0, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': None, 'valid_special_types': None, 'ignored_type_group_special': None, 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'temperature_scalar': None, 'drop_unique': False}   \n",
       "114   {'max_memory_usage_ratio': 1.0, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': None, 'valid_special_types': None, 'ignored_type_group_special': None, 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'temperature_scalar': None, 'drop_unique': False}   \n",
       "115   {'max_memory_usage_ratio': 1.0, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': None, 'valid_special_types': None, 'ignored_type_group_special': None, 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'temperature_scalar': None, 'drop_unique': False}   \n",
       "116   {'max_memory_usage_ratio': 1.0, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': None, 'valid_special_types': None, 'ignored_type_group_special': None, 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'temperature_scalar': None, 'drop_unique': False}   \n",
       "117   {'max_memory_usage_ratio': 1.0, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': None, 'valid_special_types': None, 'ignored_type_group_special': None, 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'temperature_scalar': None, 'drop_unique': False}   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    features  \\\n",
       "0    [eval-TLP-Tavec-14_ESem_RL_CP-PD, clin-Hipercolesterolemia, clin-reservaCognitiva_idiomas, clin-reservaCognitiva_escolaridad, ques-MMSE-fijacion-PD, eval-TLP-FigRey-totalMemoria-PD, clin-tipoAlcohol.capital_ratio, clin-Hipertension, eval-TLP-Tavec-25_Discriminabilidad-PD, eval-TLP-Tavec-2_RI_A5-PD, ques-Sus-total-PD, ques-NavEspacial-resultadosWFQ_SA-PD, clin-tipoAlcohol.symbol_ratio. , eval-TLP-Tavec-20_P-PD, demo-fechaNacimiento.day, eval-TLP-Tavec-28_RL_CP_frente_RI_A5-PD, ques-QuejasMemo-Total-PD, demo-rangoEdad, eval-TLP-Tavec-4_RI_B-PD, ques-MMSE-escolaridad-PD, eval-TLP-FigRey-Durac...   \n",
       "1    [eval-TLP-Tavec-14_ESem_RL_CP-PD, clin-Hipercolesterolemia, clin-reservaCognitiva_idiomas, clin-reservaCognitiva_escolaridad, ques-MMSE-fijacion-PD, eval-TLP-FigRey-totalMemoria-PD, clin-tipoAlcohol.capital_ratio, clin-Hipertension, eval-TLP-Tavec-25_Discriminabilidad-PD, eval-TLP-Tavec-2_RI_A5-PD, ques-Sus-total-PD, ques-NavEspacial-resultadosWFQ_SA-PD, clin-tipoAlcohol.symbol_ratio. , eval-TLP-Tavec-20_P-PD, demo-fechaNacimiento.day, eval-TLP-Tavec-28_RL_CP_frente_RI_A5-PD, ques-QuejasMemo-Total-PD, demo-rangoEdad, eval-TLP-Tavec-4_RI_B-PD, ques-MMSE-escolaridad-PD, eval-TLP-FigRey-Durac...   \n",
       "2    [eval-TLP-Tavec-14_ESem_RL_CP-PD, clin-Hipercolesterolemia, clin-reservaCognitiva_idiomas, clin-reservaCognitiva_escolaridad, ques-MMSE-fijacion-PD, eval-TLP-FigRey-totalMemoria-PD, clin-tipoAlcohol.capital_ratio, clin-Hipertension, eval-TLP-Tavec-25_Discriminabilidad-PD, eval-TLP-Tavec-2_RI_A5-PD, ques-Sus-total-PD, ques-NavEspacial-resultadosWFQ_SA-PD, clin-tipoAlcohol.symbol_ratio. , eval-TLP-Tavec-20_P-PD, demo-fechaNacimiento.day, eval-TLP-Tavec-28_RL_CP_frente_RI_A5-PD, ques-QuejasMemo-Total-PD, demo-rangoEdad, eval-TLP-Tavec-4_RI_B-PD, ques-MMSE-escolaridad-PD, eval-TLP-FigRey-Durac...   \n",
       "3    [eval-TLP-Tavec-14_ESem_RL_CP-PD, clin-Hipercolesterolemia, clin-reservaCognitiva_idiomas, clin-reservaCognitiva_escolaridad, ques-MMSE-fijacion-PD, eval-TLP-FigRey-totalMemoria-PD, clin-tipoAlcohol.capital_ratio, clin-Hipertension, eval-TLP-Tavec-25_Discriminabilidad-PD, eval-TLP-Tavec-2_RI_A5-PD, ques-Sus-total-PD, ques-NavEspacial-resultadosWFQ_SA-PD, clin-tipoAlcohol.symbol_ratio. , eval-TLP-Tavec-20_P-PD, demo-fechaNacimiento.day, eval-TLP-Tavec-28_RL_CP_frente_RI_A5-PD, ques-QuejasMemo-Total-PD, demo-rangoEdad, eval-TLP-Tavec-4_RI_B-PD, ques-MMSE-escolaridad-PD, eval-TLP-FigRey-Durac...   \n",
       "4    [eval-TLP-Tavec-14_ESem_RL_CP-PD, clin-Hipercolesterolemia, clin-reservaCognitiva_idiomas, clin-reservaCognitiva_escolaridad, ques-MMSE-fijacion-PD, eval-TLP-FigRey-totalMemoria-PD, clin-tipoAlcohol.capital_ratio, clin-Hipertension, eval-TLP-Tavec-25_Discriminabilidad-PD, eval-TLP-Tavec-2_RI_A5-PD, ques-Sus-total-PD, ques-NavEspacial-resultadosWFQ_SA-PD, clin-tipoAlcohol.symbol_ratio. , eval-TLP-Tavec-20_P-PD, demo-fechaNacimiento.day, eval-TLP-Tavec-28_RL_CP_frente_RI_A5-PD, ques-QuejasMemo-Total-PD, demo-rangoEdad, eval-TLP-Tavec-4_RI_B-PD, ques-MMSE-escolaridad-PD, eval-TLP-FigRey-Durac...   \n",
       "..                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       ...   \n",
       "113  [eval-TLP-Tavec-14_ESem_RL_CP-PD, clin-Hipercolesterolemia, clin-reservaCognitiva_idiomas, clin-reservaCognitiva_escolaridad, ques-MMSE-fijacion-PD, eval-TLP-FigRey-totalMemoria-PD, clin-tipoAlcohol.capital_ratio, clin-Hipertension, eval-TLP-Tavec-25_Discriminabilidad-PD, eval-TLP-Tavec-2_RI_A5-PD, ques-Sus-total-PD, ques-NavEspacial-resultadosWFQ_SA-PD, clin-tipoAlcohol.symbol_ratio. , eval-TLP-Tavec-20_P-PD, demo-fechaNacimiento.day, eval-TLP-Tavec-28_RL_CP_frente_RI_A5-PD, ques-QuejasMemo-Total-PD, demo-rangoEdad, eval-TLP-Tavec-4_RI_B-PD, ques-MMSE-escolaridad-PD, eval-TLP-FigRey-Durac...   \n",
       "114  [eval-TLP-Tavec-14_ESem_RL_CP-PD, clin-Hipercolesterolemia, clin-reservaCognitiva_idiomas, clin-reservaCognitiva_escolaridad, ques-MMSE-fijacion-PD, eval-TLP-FigRey-totalMemoria-PD, clin-tipoAlcohol.capital_ratio, clin-Hipertension, eval-TLP-Tavec-25_Discriminabilidad-PD, eval-TLP-Tavec-2_RI_A5-PD, ques-Sus-total-PD, ques-NavEspacial-resultadosWFQ_SA-PD, clin-tipoAlcohol.symbol_ratio. , eval-TLP-Tavec-20_P-PD, demo-fechaNacimiento.day, eval-TLP-Tavec-28_RL_CP_frente_RI_A5-PD, ques-QuejasMemo-Total-PD, demo-rangoEdad, eval-TLP-Tavec-4_RI_B-PD, ques-MMSE-escolaridad-PD, eval-TLP-FigRey-Durac...   \n",
       "115  [eval-TLP-Tavec-14_ESem_RL_CP-PD, clin-Hipercolesterolemia, clin-reservaCognitiva_idiomas, clin-reservaCognitiva_escolaridad, ques-MMSE-fijacion-PD, eval-TLP-FigRey-totalMemoria-PD, clin-tipoAlcohol.capital_ratio, clin-Hipertension, eval-TLP-Tavec-25_Discriminabilidad-PD, eval-TLP-Tavec-2_RI_A5-PD, ques-Sus-total-PD, ques-NavEspacial-resultadosWFQ_SA-PD, clin-tipoAlcohol.symbol_ratio. , eval-TLP-Tavec-20_P-PD, demo-fechaNacimiento.day, eval-TLP-Tavec-28_RL_CP_frente_RI_A5-PD, ques-QuejasMemo-Total-PD, demo-rangoEdad, eval-TLP-Tavec-4_RI_B-PD, ques-MMSE-escolaridad-PD, eval-TLP-FigRey-Durac...   \n",
       "116  [eval-TLP-Tavec-14_ESem_RL_CP-PD, clin-Hipercolesterolemia, clin-reservaCognitiva_idiomas, clin-reservaCognitiva_escolaridad, ques-MMSE-fijacion-PD, eval-TLP-FigRey-totalMemoria-PD, clin-tipoAlcohol.capital_ratio, clin-Hipertension, eval-TLP-Tavec-25_Discriminabilidad-PD, eval-TLP-Tavec-2_RI_A5-PD, ques-Sus-total-PD, ques-NavEspacial-resultadosWFQ_SA-PD, clin-tipoAlcohol.symbol_ratio. , eval-TLP-Tavec-20_P-PD, demo-fechaNacimiento.day, eval-TLP-Tavec-28_RL_CP_frente_RI_A5-PD, ques-QuejasMemo-Total-PD, demo-rangoEdad, eval-TLP-Tavec-4_RI_B-PD, ques-MMSE-escolaridad-PD, eval-TLP-FigRey-Durac...   \n",
       "117  [eval-TLP-Tavec-14_ESem_RL_CP-PD, clin-Hipercolesterolemia, clin-reservaCognitiva_idiomas, clin-reservaCognitiva_escolaridad, ques-MMSE-fijacion-PD, eval-TLP-FigRey-totalMemoria-PD, clin-tipoAlcohol.capital_ratio, clin-Hipertension, eval-TLP-Tavec-25_Discriminabilidad-PD, eval-TLP-Tavec-2_RI_A5-PD, ques-Sus-total-PD, ques-NavEspacial-resultadosWFQ_SA-PD, clin-tipoAlcohol.symbol_ratio. , eval-TLP-Tavec-20_P-PD, demo-fechaNacimiento.day, eval-TLP-Tavec-28_RL_CP_frente_RI_A5-PD, ques-QuejasMemo-Total-PD, demo-rangoEdad, eval-TLP-Tavec-4_RI_B-PD, ques-MMSE-escolaridad-PD, eval-TLP-FigRey-Durac...   \n",
       "\n",
       "     compile_time  \\\n",
       "0            None   \n",
       "1            None   \n",
       "2            None   \n",
       "3            None   \n",
       "4            None   \n",
       "..            ...   \n",
       "113          None   \n",
       "114          None   \n",
       "115          None   \n",
       "116          None   \n",
       "117          None   \n",
       "\n",
       "                                                                                                                                                                                                                                                     child_hyperparameters  \\\n",
       "0                                                                                                  {'learning_rate': 0.01343464462043561, 'extra_trees': False, 'feature_fraction': 0.9408897917880529, 'min_data_in_leaf': 21, 'num_leaves': 178, 'num_boost_round': 472}   \n",
       "1                                                                                                                                                                                                                          {'learning_rate': 0.05, 'num_boost_round': 122}   \n",
       "2    {'iterations': 1098, 'learning_rate': 0.017301189655111057, 'random_seed': 0, 'allow_writing_files': False, 'eval_metric': 'Logloss', 'depth': 8, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 3.3274013177541373, 'max_ctr_complexity': 5, 'one_hot_max_size': 10}   \n",
       "3        {'iterations': 160, 'learning_rate': 0.08481607830570326, 'random_seed': 0, 'allow_writing_files': False, 'eval_metric': 'Logloss', 'depth': 7, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 4.522712492188319, 'max_ctr_complexity': 3, 'one_hot_max_size': 2}   \n",
       "4                                                                                                 {'learning_rate': 0.010534290864227067, 'extra_trees': True, 'feature_fraction': 0.9773131270704629, 'min_data_in_leaf': 21, 'num_leaves': 111, 'num_boost_round': 1195}   \n",
       "..                                                                                                                                                                                                                                                                     ...   \n",
       "113                                               {'layers': [400], 'emb_drop': 0.22771721361129746, 'ps': 0.3734259772256502, 'bs': 1024, 'lr': 0.0005383511954451698, 'epochs': 38, 'early.stopping.min_delta': 0.0001, 'early.stopping.patience': 20, 'smoothing': 0.0}   \n",
       "114                                        {'layers': [200, 100, 50], 'emb_drop': 0.3209601865656554, 'ps': 0.19846319260751663, 'bs': 128, 'lr': 0.019935403046870463, 'epochs': 21, 'early.stopping.min_delta': 0.0001, 'early.stopping.patience': 20, 'smoothing': 0.0}   \n",
       "115                                               {'layers': [400], 'emb_drop': 0.05604276533830355, 'ps': 0.022591301744255762, 'bs': 512, 'lr': 0.027320709383189166, 'epochs': 32, 'early.stopping.min_delta': 0.0001, 'early.stopping.patience': 20, 'smoothing': 0.0}   \n",
       "116                                           {'layers': [200, 100], 'emb_drop': 0.05070411322605811, 'ps': 0.10393466140748028, 'bs': 2048, 'lr': 0.08974235041576624, 'epochs': 29, 'early.stopping.min_delta': 0.0001, 'early.stopping.patience': 20, 'smoothing': 0.0}   \n",
       "117                                            {'layers': [800, 400], 'emb_drop': 0.026897798530914306, 'ps': 0.4569532219038436, 'bs': 128, 'lr': 0.08045277634470181, 'epochs': 31, 'early.stopping.min_delta': 0.0001, 'early.stopping.patience': 20, 'smoothing': 0.0}   \n",
       "\n",
       "            child_hyperparameters_fit  \\\n",
       "0            {'num_boost_round': 472}   \n",
       "1            {'num_boost_round': 122}   \n",
       "2                {'iterations': 1098}   \n",
       "3                 {'iterations': 160}   \n",
       "4           {'num_boost_round': 1195}   \n",
       "..                                ...   \n",
       "113  {'epochs': 38, 'best_epoch': 16}   \n",
       "114   {'epochs': 21, 'best_epoch': 6}   \n",
       "115   {'epochs': 32, 'best_epoch': 1}   \n",
       "116   {'epochs': 29, 'best_epoch': 5}   \n",
       "117   {'epochs': 31, 'best_epoch': 3}   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                               child_ag_args_fit  \\\n",
       "0                                  {'max_memory_usage_ratio': 1.0, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': ['bool', 'int', 'float', 'category'], 'valid_special_types': None, 'ignored_type_group_special': None, 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'temperature_scalar': None}   \n",
       "1                                  {'max_memory_usage_ratio': 1.0, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': ['bool', 'int', 'float', 'category'], 'valid_special_types': None, 'ignored_type_group_special': None, 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'temperature_scalar': None}   \n",
       "2                                  {'max_memory_usage_ratio': 1.0, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': ['bool', 'int', 'float', 'category'], 'valid_special_types': None, 'ignored_type_group_special': None, 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'temperature_scalar': None}   \n",
       "3                                  {'max_memory_usage_ratio': 1.0, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': ['bool', 'int', 'float', 'category'], 'valid_special_types': None, 'ignored_type_group_special': None, 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'temperature_scalar': None}   \n",
       "4                                  {'max_memory_usage_ratio': 1.0, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': ['bool', 'int', 'float', 'category'], 'valid_special_types': None, 'ignored_type_group_special': None, 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'temperature_scalar': None}   \n",
       "..                                                                                                                                                                                                                                                                                                                                                                                                                           ...   \n",
       "113  {'max_memory_usage_ratio': 1.0, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': ['bool', 'int', 'float', 'category'], 'valid_special_types': None, 'ignored_type_group_special': ['text_ngram', 'text_as_category'], 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'temperature_scalar': None}   \n",
       "114  {'max_memory_usage_ratio': 1.0, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': ['bool', 'int', 'float', 'category'], 'valid_special_types': None, 'ignored_type_group_special': ['text_ngram', 'text_as_category'], 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'temperature_scalar': None}   \n",
       "115  {'max_memory_usage_ratio': 1.0, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': ['bool', 'int', 'float', 'category'], 'valid_special_types': None, 'ignored_type_group_special': ['text_ngram', 'text_as_category'], 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'temperature_scalar': None}   \n",
       "116  {'max_memory_usage_ratio': 1.0, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': ['bool', 'int', 'float', 'category'], 'valid_special_types': None, 'ignored_type_group_special': ['text_ngram', 'text_as_category'], 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'temperature_scalar': None}   \n",
       "117  {'max_memory_usage_ratio': 1.0, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': ['bool', 'int', 'float', 'category'], 'valid_special_types': None, 'ignored_type_group_special': ['text_ngram', 'text_as_category'], 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'temperature_scalar': None}   \n",
       "\n",
       "     ancestors  descendants  \n",
       "0           []           []  \n",
       "1           []           []  \n",
       "2           []           []  \n",
       "3           []           []  \n",
       "4           []           []  \n",
       "..         ...          ...  \n",
       "113         []           []  \n",
       "114         []           []  \n",
       "115         []           []  \n",
       "116         []           []  \n",
       "117         []           []  \n",
       "\n",
       "[118 rows x 45 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictors.to_excel(\n",
    "    '../../data/tlp/predictors.xlsx',\n",
    "    index=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "These features in provided data are not utilized by the predictor and will be ignored: ['clin-Covid_sintomaSarpullido']\n",
      "Computing feature importance via permutation shuffling for 78 features using 396 rows with 5 shuffle sets...\n",
      "\t46.52s\t= Expected runtime (9.3s per shuffle set)\n",
      "\t17.61s\t= Actual runtime (Completed 5 of 5 shuffle sets)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>importance</th>\n",
       "      <th>stddev</th>\n",
       "      <th>p_value</th>\n",
       "      <th>n</th>\n",
       "      <th>p99_high</th>\n",
       "      <th>p99_low</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>eval-TLP-Stroop-color-PD</th>\n",
       "      <td>0.004131</td>\n",
       "      <td>0.001049</td>\n",
       "      <td>0.000459</td>\n",
       "      <td>5</td>\n",
       "      <td>0.006291</td>\n",
       "      <td>0.001971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>demo-genero</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eval-TLP-Tavec-5_Rg_Pr-PD</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eval-TLP-Tavec-12_ESem_RI_A-PD</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eval-TLP-Tavec-11_RCl_LP-PD</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ques-Sus-totalPar-PD</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ques-NavEspacial-resultadosWFQ_DE-PD</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ques-NavEspacial-resultadosWFQ_SA-PD</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ques-NavEspacial-resultadosWFQ_NO-PD</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eval-TLP-Tavec-33_Recon_Ac_frente_RCl_LP-PD</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>78 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             importance    stddev   p_value  \\\n",
       "eval-TLP-Stroop-color-PD                       0.004131  0.001049  0.000459   \n",
       "demo-genero                                    0.000000  0.000000  0.500000   \n",
       "eval-TLP-Tavec-5_Rg_Pr-PD                      0.000000  0.000000  0.500000   \n",
       "eval-TLP-Tavec-12_ESem_RI_A-PD                 0.000000  0.000000  0.500000   \n",
       "eval-TLP-Tavec-11_RCl_LP-PD                    0.000000  0.000000  0.500000   \n",
       "...                                                 ...       ...       ...   \n",
       "ques-Sus-totalPar-PD                           0.000000  0.000000  0.500000   \n",
       "ques-NavEspacial-resultadosWFQ_DE-PD           0.000000  0.000000  0.500000   \n",
       "ques-NavEspacial-resultadosWFQ_SA-PD           0.000000  0.000000  0.500000   \n",
       "ques-NavEspacial-resultadosWFQ_NO-PD           0.000000  0.000000  0.500000   \n",
       "eval-TLP-Tavec-33_Recon_Ac_frente_RCl_LP-PD    0.000000  0.000000  0.500000   \n",
       "\n",
       "                                             n  p99_high   p99_low  \n",
       "eval-TLP-Stroop-color-PD                     5  0.006291  0.001971  \n",
       "demo-genero                                  5  0.000000  0.000000  \n",
       "eval-TLP-Tavec-5_Rg_Pr-PD                    5  0.000000  0.000000  \n",
       "eval-TLP-Tavec-12_ESem_RI_A-PD               5  0.000000  0.000000  \n",
       "eval-TLP-Tavec-11_RCl_LP-PD                  5  0.000000  0.000000  \n",
       "...                                         ..       ...       ...  \n",
       "ques-Sus-totalPar-PD                         5  0.000000  0.000000  \n",
       "ques-NavEspacial-resultadosWFQ_DE-PD         5  0.000000  0.000000  \n",
       "ques-NavEspacial-resultadosWFQ_SA-PD         5  0.000000  0.000000  \n",
       "ques-NavEspacial-resultadosWFQ_NO-PD         5  0.000000  0.000000  \n",
       "eval-TLP-Tavec-33_Recon_Ac_frente_RCl_LP-PD  5  0.000000  0.000000  \n",
       "\n",
       "[78 rows x 6 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.feature_importance(data=df_train)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
