{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from autogluon.tabular import TabularPredictor\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../../data/tlp/preprocesado.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>demo-genero</th>\n",
       "      <th>demo-fechaEvaluacion</th>\n",
       "      <th>demo-fechaNacimiento</th>\n",
       "      <th>demo-rangoEdad</th>\n",
       "      <th>demo-edad</th>\n",
       "      <th>clin-reservaCognitiva_total</th>\n",
       "      <th>clin-reservaCognitiva_idiomas</th>\n",
       "      <th>clin-reservaCognitiva_ocupacion</th>\n",
       "      <th>clin-reservaCognitiva_escolaridad</th>\n",
       "      <th>clin-ansiedad</th>\n",
       "      <th>...</th>\n",
       "      <th>eval-TLP-Tavec-25_Discriminabilidad-PD</th>\n",
       "      <th>eval-TLP-Tavec-26_Sesgo-PD</th>\n",
       "      <th>eval-TLP-Tavec-27_RI_B_frente_RI_A1-PD</th>\n",
       "      <th>eval-TLP-Tavec-28_RL_CP_frente_RI_A5-PD</th>\n",
       "      <th>eval-TLP-Tavec-29_RCl_Cp_frente_RCl_LP-PD</th>\n",
       "      <th>eval-TLP-Tavec-30_RL_LP_frente_RL_CP-PD</th>\n",
       "      <th>eval-TLP-Tavec-31_RCl_LP_frente_RL_LP-PD</th>\n",
       "      <th>eval-TLP-Tavec-32_Recon_Ac_frente_RL_LP-PD</th>\n",
       "      <th>eval-TLP-Tavec-33_Recon_Ac_frente_RCl_LP-PD</th>\n",
       "      <th>ED_2Clases</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>2024-02-22T00:00:00</td>\n",
       "      <td>1942-05-08T00:00:00</td>\n",
       "      <td>Rango3</td>\n",
       "      <td>81</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>84.09</td>\n",
       "      <td>0.14</td>\n",
       "      <td>-20.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>33.33</td>\n",
       "      <td>37.50</td>\n",
       "      <td>-33.33</td>\n",
       "      <td>-38.46</td>\n",
       "      <td>-7.69</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2024-06-26T00:00:00</td>\n",
       "      <td>1948-10-07T00:00:00</td>\n",
       "      <td>Rango3</td>\n",
       "      <td>75</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>79.55</td>\n",
       "      <td>-0.33</td>\n",
       "      <td>-71.43</td>\n",
       "      <td>12.50</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-20.00</td>\n",
       "      <td>-20.00</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2024-05-14T00:00:00</td>\n",
       "      <td>1952-05-08T00:00:00</td>\n",
       "      <td>Rango2</td>\n",
       "      <td>72</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>88.64</td>\n",
       "      <td>-0.60</td>\n",
       "      <td>-14.29</td>\n",
       "      <td>75.00</td>\n",
       "      <td>25.00</td>\n",
       "      <td>-20.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-16.67</td>\n",
       "      <td>-16.67</td>\n",
       "      <td>H</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>2024-04-10T00:00:00</td>\n",
       "      <td>1964-01-27T00:00:00</td>\n",
       "      <td>Rango1</td>\n",
       "      <td>60</td>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>90.91</td>\n",
       "      <td>0.60</td>\n",
       "      <td>60.00</td>\n",
       "      <td>16.67</td>\n",
       "      <td>0.00</td>\n",
       "      <td>50.00</td>\n",
       "      <td>-20.00</td>\n",
       "      <td>-50.00</td>\n",
       "      <td>-37.50</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>2024-05-14T00:00:00</td>\n",
       "      <td>1959-09-16T00:00:00</td>\n",
       "      <td>Rango1</td>\n",
       "      <td>64</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>86.36</td>\n",
       "      <td>-0.71</td>\n",
       "      <td>0.00</td>\n",
       "      <td>66.67</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-33.33</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-10.00</td>\n",
       "      <td>-10.00</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 80 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   demo-genero demo-fechaEvaluacion demo-fechaNacimiento demo-rangoEdad  \\\n",
       "0            2  2024-02-22T00:00:00  1942-05-08T00:00:00         Rango3   \n",
       "1            2  2024-06-26T00:00:00  1948-10-07T00:00:00         Rango3   \n",
       "2            2  2024-05-14T00:00:00  1952-05-08T00:00:00         Rango2   \n",
       "3            2  2024-04-10T00:00:00  1964-01-27T00:00:00         Rango1   \n",
       "4            2  2024-05-14T00:00:00  1959-09-16T00:00:00         Rango1   \n",
       "\n",
       "   demo-edad  clin-reservaCognitiva_total  clin-reservaCognitiva_idiomas  \\\n",
       "0         81                           12                              0   \n",
       "1         75                            8                              0   \n",
       "2         72                           11                              0   \n",
       "3         60                           18                              2   \n",
       "4         64                           13                              0   \n",
       "\n",
       "   clin-reservaCognitiva_ocupacion  clin-reservaCognitiva_escolaridad  \\\n",
       "0                                1                                  3   \n",
       "1                                1                                  3   \n",
       "2                                0                                  4   \n",
       "3                                1                                  4   \n",
       "4                                1                                  4   \n",
       "\n",
       "   clin-ansiedad  ...  eval-TLP-Tavec-25_Discriminabilidad-PD  \\\n",
       "0          False  ...                                   84.09   \n",
       "1           True  ...                                   79.55   \n",
       "2          False  ...                                   88.64   \n",
       "3          False  ...                                   90.91   \n",
       "4          False  ...                                   86.36   \n",
       "\n",
       "   eval-TLP-Tavec-26_Sesgo-PD  eval-TLP-Tavec-27_RI_B_frente_RI_A1-PD  \\\n",
       "0                        0.14                                  -20.00   \n",
       "1                       -0.33                                  -71.43   \n",
       "2                       -0.60                                  -14.29   \n",
       "3                        0.60                                   60.00   \n",
       "4                       -0.71                                    0.00   \n",
       "\n",
       "   eval-TLP-Tavec-28_RL_CP_frente_RI_A5-PD  \\\n",
       "0                                     0.00   \n",
       "1                                    12.50   \n",
       "2                                    75.00   \n",
       "3                                    16.67   \n",
       "4                                    66.67   \n",
       "\n",
       "   eval-TLP-Tavec-29_RCl_Cp_frente_RCl_LP-PD  \\\n",
       "0                                      33.33   \n",
       "1                                       0.00   \n",
       "2                                      25.00   \n",
       "3                                       0.00   \n",
       "4                                       0.00   \n",
       "\n",
       "   eval-TLP-Tavec-30_RL_LP_frente_RL_CP-PD  \\\n",
       "0                                    37.50   \n",
       "1                                     0.00   \n",
       "2                                   -20.00   \n",
       "3                                    50.00   \n",
       "4                                   -33.33   \n",
       "\n",
       "   eval-TLP-Tavec-31_RCl_LP_frente_RL_LP-PD  \\\n",
       "0                                    -33.33   \n",
       "1                                      0.00   \n",
       "2                                      0.00   \n",
       "3                                    -20.00   \n",
       "4                                      0.00   \n",
       "\n",
       "   eval-TLP-Tavec-32_Recon_Ac_frente_RL_LP-PD  \\\n",
       "0                                      -38.46   \n",
       "1                                      -20.00   \n",
       "2                                      -16.67   \n",
       "3                                      -50.00   \n",
       "4                                      -10.00   \n",
       "\n",
       "   eval-TLP-Tavec-33_Recon_Ac_frente_RCl_LP-PD ED_2Clases  \n",
       "0                                        -7.69          D  \n",
       "1                                       -20.00          D  \n",
       "2                                       -16.67          H  \n",
       "3                                       -37.50          D  \n",
       "4                                       -10.00          D  \n",
       "\n",
       "[5 rows x 80 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((251, 80), (63, 80))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train, df_test = train_test_split(df, test_size=0.2, random_state=42)\n",
    "df_train.shape, df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"AutogluonModels/synthetic/tvaes/v2\"\n"
     ]
    }
   ],
   "source": [
    "predictor= TabularPredictor(\n",
    "    label='ED_2Clases',\n",
    "    problem_type='binary',\n",
    "    eval_metric='roc_auc',\n",
    "    sample_weight='balance_weight',\n",
    "    path='AutogluonModels/synthetic/tvaes/v2'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.2\n",
      "Python Version:     3.10.2\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.26100\n",
      "CPU Count:          12\n",
      "Memory Avail:       9.83 GB / 15.94 GB (61.7%)\n",
      "Disk Space Avail:   106.24 GB / 446.36 GB (23.8%)\n",
      "===================================================\n",
      "Presets specified: ['high_quality']\n",
      "Setting dynamic_stacking from 'auto' to True. Reason: Enable dynamic_stacking when use_bag_holdout is disabled. (use_bag_holdout=False)\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=1\n",
      "Note: `save_bag_folds=False`! This will greatly reduce peak disk usage during fit (by ~8x), but runs the risk of an out-of-memory error during model refit if memory is small relative to the data size.\n",
      "\tYou can avoid this risk by setting `save_bag_folds=True`.\n",
      "DyStack is enabled (dynamic_stacking=True). AutoGluon will try to determine whether the input data is affected by stacked overfitting and enable or disable stacking as a consequence.\n",
      "\tThis is used to identify the optimal `num_stack_levels` value. Copies of AutoGluon will be fit on subsets of the data. Then holdout validation data is used to detect stacked overfitting.\n",
      "\tRunning DyStack for up to 1800s of the 7200s of remaining time (25%).\n",
      "\tRunning DyStack sub-fit in a ray process to avoid memory leakage. Enabling ray logging (enable_ray_logging=True). Specify `ds_args={'enable_ray_logging': False}` if you experience logging issues.\n",
      "2025-01-29 23:59:04,357\tINFO worker.py:1743 -- Started a local Ray instance. View the dashboard at \u001b[1m\u001b[32m127.0.0.1:8265 \u001b[39m\u001b[22m\n",
      "\t\tContext path: \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\autogluon\\tlp\\AutogluonModels\\synthetic\\tvaes\\v2\\ds_sub_fit\\sub_fit_ho\"\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m Running DyStack sub-fit ...\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m Using predefined sample weighting strategy: balance_weight. Evaluation metrics will ignore sample weights, specify weight_evaluation=True to instead report weighted metrics.\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m Beginning AutoGluon training ... Time limit = 1795s\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m AutoGluon will save models to \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\autogluon\\tlp\\AutogluonModels\\synthetic\\tvaes\\v2\\ds_sub_fit\\sub_fit_ho\"\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m Train Data Rows:    223\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m Train Data Columns: 79\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m Label Column:       ED_2Clases\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m Problem Type:       binary\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m Preprocessing data ...\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m Selected class <--> label mapping:  class 1 = H, class 0 = D\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m \tNote: For your binary classification, AutoGluon arbitrarily selected which label-value represents positive (H) vs negative (D) class.\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m \tTo explicitly set the positive_class, either rename classes to 1 and 0, or specify positive_class in Predictor init.\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m Assigning sample weights to balance differences in frequency of classes.\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m Using Feature Generators to preprocess the data ...\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m Fitting AutoMLPipelineFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m \tAvailable Memory:                    9554.40 MB\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m \tTrain Data (Original)  Memory Usage: 0.17 MB (0.0% of available memory)\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m \tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m \tStage 1 Generators:\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m \t\tFitting AsTypeFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m \t\t\tNote: Converting 10 features to boolean dtype as they only contain 2 unique values.\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m \tStage 2 Generators:\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m \t\tFitting FillNaFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m \tStage 3 Generators:\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m \t\tFitting IdentityFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m \t\tFitting CategoryFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m \t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m \t\tFitting DatetimeFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m \t\tFitting TextSpecialFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m \t\t\tFitting BinnedFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m \t\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m \t\tFitting TextNgramFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m \t\t\tFitting CountVectorizer for text features: ['clin-tipoAlcohol']\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m \t\t\tRemoving text_ngram feature due to error: '__nlp__'\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m \tStage 4 Generators:\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m \t\tFitting DropUniqueFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m \tStage 5 Generators:\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m \t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m \tUseless Original Features (Count: 1): ['clin-Covid_sintomaSarpullido']\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m \t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m \t\tThis is typically a feature which has the same value for all rows.\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m \t\tThese features do not need to be present at inference time.\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m \tTypes of features in original data (raw dtype, special dtypes):\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m \t\t('bool', [])                       :  8 | ['clin-ansiedad', 'clin-depresion', 'clin-cardiopatiaIsquemica', 'clin-diabetes', 'clin-Hipercolesterolemia', ...]\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m \t\t('float', [])                      : 17 | ['clin-numCigarros', 'clin-aÃ±osSinFumar', 'ques-Sus-total-PD', 'eval-TLP-FigRey-totalCopia-PD', 'eval-TLP-FigRey-totalMemoria-PD', ...]\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m \t\t('int', [])                        : 49 | ['demo-genero', 'demo-edad', 'clin-reservaCognitiva_total', 'clin-reservaCognitiva_idiomas', 'clin-reservaCognitiva_ocupacion', ...]\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m \t\t('object', [])                     :  1 | ['demo-rangoEdad']\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m \t\t('object', ['datetime_as_object']) :  2 | ['demo-fechaEvaluacion', 'demo-fechaNacimiento']\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m \t\t('object', ['text'])               :  1 | ['clin-tipoAlcohol']\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m \tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m \t\t('category', [])                    :  1 | ['demo-rangoEdad']\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m \t\t('category', ['text_as_category'])  :  1 | ['clin-tipoAlcohol']\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m \t\t('float', [])                       : 17 | ['clin-numCigarros', 'clin-aÃ±osSinFumar', 'ques-Sus-total-PD', 'eval-TLP-FigRey-totalCopia-PD', 'eval-TLP-FigRey-totalMemoria-PD', ...]\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m \t\t('int', [])                         : 47 | ['demo-edad', 'clin-reservaCognitiva_total', 'clin-reservaCognitiva_idiomas', 'clin-reservaCognitiva_ocupacion', 'clin-reservaCognitiva_escolaridad', ...]\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m \t\t('int', ['binned', 'text_special']) : 10 | ['clin-tipoAlcohol.char_count', 'clin-tipoAlcohol.word_count', 'clin-tipoAlcohol.capital_ratio', 'clin-tipoAlcohol.lower_ratio', 'clin-tipoAlcohol.digit_ratio', ...]\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m \t\t('int', ['bool'])                   : 10 | ['demo-genero', 'clin-ansiedad', 'clin-depresion', 'clin-cardiopatiaIsquemica', 'clin-diabetes', ...]\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m \t\t('int', ['datetime_as_int'])        :  9 | ['demo-fechaEvaluacion', 'demo-fechaEvaluacion.month', 'demo-fechaEvaluacion.day', 'demo-fechaEvaluacion.dayofweek', 'demo-fechaNacimiento', ...]\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m \t0.2s = Fit runtime\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m \t78 features in original data used to generate 95 features in processed data.\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m \tTrain Data (Processed) Memory Usage: 0.13 MB (0.0% of available memory)\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m Data preprocessing and feature engineering runtime = 0.19s ...\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m AutoGluon will gauge predictive performance using evaluation metric: 'roc_auc'\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m \tThis metric expects predicted probabilities rather than predicted class labels, so you'll need to use predict_proba() instead of predict()\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m \tTo change this, specify the eval_metric parameter of Predictor()\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m Large model count detected (112 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m User-specified model hyperparameters to be fit:\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m {\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m \t'NN_TORCH': [{}, {'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2}}, {'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7}}],\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m \t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m \t'CAT': [{}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5}}],\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m \t'XGB': [{}, {'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'name_suffix': '_r33', 'priority': -8}}, {'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'name_suffix': '_r89', 'priority': -16}}],\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m \t'FASTAI': [{}, {'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4}}, {'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11}}],\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m \t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m \t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m \t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m }\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m Excluded models: ['RF', 'KNN', 'XT'] (Specified by `excluded_model_types`)\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m Fitting 90 L1 models, fit_strategy=\"sequential\" ...\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 1196.47s of the 1795.15s of remaining time.\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.20%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=17820)\u001b[0m [1000]\tvalid_set's binary_logloss: 0.0845211\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_dystack pid=24628)\u001b[0m \t0.9354\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m \t1.41s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m \t0.01s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m Fitting model: LightGBM_BAG_L1 ... Training model for up to 1189.91s of the 1788.59s of remaining time.\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.21%)\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m \t0.9142\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m \t0.94s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m \t0.03s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m Fitting model: CatBoost_BAG_L1 ... Training model for up to 1185.78s of the 1784.47s of remaining time.\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.44%)\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m \t0.9172\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m \t26.73s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m \t0.07s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 1155.66s of the 1754.34s of remaining time.\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.02%)\n",
      "\u001b[36m(_ray_fit pid=12716)\u001b[0m No improvement since epoch 3: early stopping\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m \t0.8903\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m \t6.48s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m \t0.1s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m Fitting model: XGBoost_BAG_L1 ... Training model for up to 1145.91s of the 1744.60s of remaining time.\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.57%)\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m \t0.896\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m \t2.08s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m \t0.03s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m Fitting model: NeuralNetTorch_BAG_L1 ... Training model for up to 1139.83s of the 1738.51s of remaining time.\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.01%)\n",
      "\u001b[36m(_ray_fit pid=7316)\u001b[0m No improvement since epoch 9: early stopping\u001b[32m [repeated 3x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/ray-logging.html#log-deduplication for more options.)\u001b[0m\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m \tWarning: Exception caused NeuralNetTorch_BAG_L1 to fail during training... Skipping this model.\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m \t\t\u001b[36mray::_ray_fit()\u001b[39m (pid=3216, ip=127.0.0.1)\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m   File \"python\\ray\\_raylet.pyx\", line 1889, in ray._raylet.execute_task\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m     fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m     out = self._fit(**kwargs)\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 201, in _fit\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m     train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m     dataset = self._process_train_data(\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m     self.processor = create_preprocessor(\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\utils\\data_preprocessor.py\", line 40, in create_preprocessor\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m     return ColumnTransformer(\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m Detailed Traceback:\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 2106, in _train_and_save\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m     model = self._train_single(**model_fit_kwargs)\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 1993, in _train_single\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m     model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m     out = self._fit(**kwargs)\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\stacker_ensemble_model.py\", line 270, in _fit\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m     return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\bagged_ensemble_model.py\", line 298, in _fit\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m     self._fit_folds(\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\bagged_ensemble_model.py\", line 724, in _fit_folds\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m     fold_fitting_strategy.after_all_folds_scheduled()\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 690, in after_all_folds_scheduled\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m     self._run_parallel(X, y, X_pseudo, y_pseudo, model_base_ref, time_limit_fold, head_node_id)\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 631, in _run_parallel\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m     self._process_fold_results(finished, unfinished, fold_ctx)\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 587, in _process_fold_results\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m     raise processed_exception\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 550, in _process_fold_results\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m     fold_model, pred_proba, time_start_fit, time_end_fit, predict_time, predict_1_time, predict_n_size, fit_num_cpus, fit_num_gpus = self.ray.get(finished)\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m     return fn(*args, **kwargs)\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\client_mode_hook.py\", line 103, in wrapper\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m     return func(*args, **kwargs)\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\worker.py\", line 2667, in get\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m     values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\worker.py\", line 864, in get_objects\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m     raise value.as_instanceof_cause()\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m ray.exceptions.RayTaskError(TypeError): \u001b[36mray::_ray_fit()\u001b[39m (pid=3216, ip=127.0.0.1)\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m   File \"python\\ray\\_raylet.pyx\", line 1889, in ray._raylet.execute_task\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m     fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m     out = self._fit(**kwargs)\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 201, in _fit\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m     train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m     dataset = self._process_train_data(\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m     self.processor = create_preprocessor(\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\utils\\data_preprocessor.py\", line 40, in create_preprocessor\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m     return ColumnTransformer(\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m Fitting model: LightGBMLarge_BAG_L1 ... Training model for up to 1133.05s of the 1731.73s of remaining time.\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=1.07%)\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m \t0.8862\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m \t1.26s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m \t0.03s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m Fitting model: CatBoost_r177_BAG_L1 ... Training model for up to 1128.32s of the 1727.01s of remaining time.\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.59%)\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m \t0.9213\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m \t13.22s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m \t0.06s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m Fitting model: NeuralNetTorch_r79_BAG_L1 ... Training model for up to 1111.52s of the 1710.20s of remaining time.\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.01%)\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m \tWarning: Exception caused NeuralNetTorch_r79_BAG_L1 to fail during training... Skipping this model.\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m \t\t\u001b[36mray::_ray_fit()\u001b[39m (pid=23712, ip=127.0.0.1)\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m   File \"python\\ray\\_raylet.pyx\", line 1889, in ray._raylet.execute_task\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m     fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m     out = self._fit(**kwargs)\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 201, in _fit\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m     train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m     dataset = self._process_train_data(\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m     self.processor = create_preprocessor(\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\utils\\data_preprocessor.py\", line 40, in create_preprocessor\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m     return ColumnTransformer(\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m Detailed Traceback:\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 2106, in _train_and_save\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m     model = self._train_single(**model_fit_kwargs)\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 1993, in _train_single\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m     model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m     out = self._fit(**kwargs)\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\stacker_ensemble_model.py\", line 270, in _fit\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m     return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\bagged_ensemble_model.py\", line 298, in _fit\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m     self._fit_folds(\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\bagged_ensemble_model.py\", line 724, in _fit_folds\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m     fold_fitting_strategy.after_all_folds_scheduled()\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 690, in after_all_folds_scheduled\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m     self._run_parallel(X, y, X_pseudo, y_pseudo, model_base_ref, time_limit_fold, head_node_id)\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 631, in _run_parallel\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m     self._process_fold_results(finished, unfinished, fold_ctx)\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 587, in _process_fold_results\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m     raise processed_exception\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 550, in _process_fold_results\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m     fold_model, pred_proba, time_start_fit, time_end_fit, predict_time, predict_1_time, predict_n_size, fit_num_cpus, fit_num_gpus = self.ray.get(finished)\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m     return fn(*args, **kwargs)\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\client_mode_hook.py\", line 103, in wrapper\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m     return func(*args, **kwargs)\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\worker.py\", line 2667, in get\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m     values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\worker.py\", line 864, in get_objects\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m     raise value.as_instanceof_cause()\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m ray.exceptions.RayTaskError(TypeError): \u001b[36mray::_ray_fit()\u001b[39m (pid=23712, ip=127.0.0.1)\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m   File \"python\\ray\\_raylet.pyx\", line 1889, in ray._raylet.execute_task\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m     fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m     out = self._fit(**kwargs)\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 201, in _fit\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m     train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m     dataset = self._process_train_data(\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m     self.processor = create_preprocessor(\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\utils\\data_preprocessor.py\", line 40, in create_preprocessor\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m     return ColumnTransformer(\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m Fitting model: LightGBM_r131_BAG_L1 ... Training model for up to 1104.78s of the 1703.46s of remaining time.\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.58%)\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m \t0.9106\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m \t1.38s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m \t0.03s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m Fitting model: NeuralNetFastAI_r191_BAG_L1 ... Training model for up to 1100.00s of the 1698.69s of remaining time.\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.03%)\n",
      "\u001b[36m(_ray_fit pid=31984)\u001b[0m No improvement since epoch 1: early stopping\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m \t0.8779\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m \t9.22s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m \t0.13s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m Fitting model: CatBoost_r9_BAG_L1 ... Training model for up to 1087.41s of the 1686.09s of remaining time.\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=2.48%)\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_ray_fit pid=31232)\u001b[0m No improvement since epoch 20: early stopping\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=10452)\u001b[0m \tRan out of time, early stopping on iteration 9917.\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m \t0.9264\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m \t871.38s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m \t0.08s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m Fitting model: LightGBM_r96_BAG_L1 ... Training model for up to 212.55s of the 811.23s of remaining time.\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.12%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=27340)\u001b[0m [1000]\tvalid_set's binary_logloss: 0.290078\n",
      "\u001b[36m(_ray_fit pid=14036)\u001b[0m [1000]\tvalid_set's binary_logloss: 0.465974\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_dystack pid=24628)\u001b[0m \t0.9218\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m \t5.45s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m \t0.04s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m Fitting model: NeuralNetTorch_r22_BAG_L1 ... Training model for up to 203.85s of the 802.54s of remaining time.\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.01%)\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m \tWarning: Exception caused NeuralNetTorch_r22_BAG_L1 to fail during training... Skipping this model.\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m \t\t\u001b[36mray::_ray_fit()\u001b[39m (pid=32156, ip=127.0.0.1)\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m   File \"python\\ray\\_raylet.pyx\", line 1889, in ray._raylet.execute_task\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m     fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m     out = self._fit(**kwargs)\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 201, in _fit\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m     train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m     dataset = self._process_train_data(\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m     self.processor = create_preprocessor(\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\utils\\data_preprocessor.py\", line 40, in create_preprocessor\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m     return ColumnTransformer(\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m Detailed Traceback:\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 2106, in _train_and_save\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m     model = self._train_single(**model_fit_kwargs)\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 1993, in _train_single\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m     model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m     out = self._fit(**kwargs)\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\stacker_ensemble_model.py\", line 270, in _fit\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m     return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\bagged_ensemble_model.py\", line 298, in _fit\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m     self._fit_folds(\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\bagged_ensemble_model.py\", line 724, in _fit_folds\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m     fold_fitting_strategy.after_all_folds_scheduled()\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 690, in after_all_folds_scheduled\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m     self._run_parallel(X, y, X_pseudo, y_pseudo, model_base_ref, time_limit_fold, head_node_id)\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 631, in _run_parallel\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m     self._process_fold_results(finished, unfinished, fold_ctx)\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 587, in _process_fold_results\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m     raise processed_exception\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 550, in _process_fold_results\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m     fold_model, pred_proba, time_start_fit, time_end_fit, predict_time, predict_1_time, predict_n_size, fit_num_cpus, fit_num_gpus = self.ray.get(finished)\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m     return fn(*args, **kwargs)\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\client_mode_hook.py\", line 103, in wrapper\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m     return func(*args, **kwargs)\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\worker.py\", line 2667, in get\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m     values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\worker.py\", line 864, in get_objects\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m     raise value.as_instanceof_cause()\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m ray.exceptions.RayTaskError(TypeError): \u001b[36mray::_ray_fit()\u001b[39m (pid=32156, ip=127.0.0.1)\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m   File \"python\\ray\\_raylet.pyx\", line 1889, in ray._raylet.execute_task\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m     fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m     out = self._fit(**kwargs)\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 201, in _fit\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m     train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m     dataset = self._process_train_data(\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m     self.processor = create_preprocessor(\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\utils\\data_preprocessor.py\", line 40, in create_preprocessor\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m     return ColumnTransformer(\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): \u001b[36mray::_ray_fit()\u001b[39m (pid=14192, ip=127.0.0.1)\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m   File \"python\\ray\\_raylet.pyx\", line 1889, in ray._raylet.execute_task\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m     fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m     out = self._fit(**kwargs)\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 201, in _fit\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m     train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m     dataset = self._process_train_data(\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m     self.processor = create_preprocessor(\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\utils\\data_preprocessor.py\", line 40, in create_preprocessor\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m     return ColumnTransformer(\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m Fitting model: XGBoost_r33_BAG_L1 ... Training model for up to 197.66s of the 796.34s of remaining time.\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=4.76%)\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m \t0.9003\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m \t2.07s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m \t0.04s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m Fitting model: CatBoost_r137_BAG_L1 ... Training model for up to 192.38s of the 791.06s of remaining time.\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.16%)\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m \t0.9288\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m \t20.95s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m \t0.03s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m Fitting model: NeuralNetFastAI_r102_BAG_L1 ... Training model for up to 168.03s of the 766.71s of remaining time.\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.02%)\n",
      "\u001b[36m(_ray_fit pid=27268)\u001b[0m No improvement since epoch 0: early stopping\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m \t0.8961\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m \t6.44s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m \t0.1s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m Fitting model: CatBoost_r13_BAG_L1 ... Training model for up to 158.40s of the 757.08s of remaining time.\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=3.42%)\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m \t0.9151\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m \t24.38s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m \t0.05s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m Fitting model: LightGBM_r188_BAG_L1 ... Training model for up to 130.08s of the 728.77s of remaining time.\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=1.05%)\n",
      "\u001b[36m(_ray_fit pid=25140)\u001b[0m No improvement since epoch 5: early stopping\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m \t0.9262\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m \t0.95s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m \t0.03s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m Fitting model: NeuralNetFastAI_r145_BAG_L1 ... Training model for up to 125.96s of the 724.64s of remaining time.\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.03%)\n",
      "\u001b[36m(_ray_fit pid=30396)\u001b[0m No improvement since epoch 7: early stopping\n",
      "\u001b[36m(_ray_fit pid=10640)\u001b[0m No improvement since epoch 7: early stopping\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m \t0.8518\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m \t5.6s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m \t0.11s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m Fitting model: XGBoost_r89_BAG_L1 ... Training model for up to 116.85s of the 715.53s of remaining time.\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.90%)\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m \t0.9123\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m \t2.3s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m \t0.07s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m Fitting model: NeuralNetTorch_r30_BAG_L1 ... Training model for up to 110.57s of the 709.26s of remaining time.\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.01%)\n",
      "\u001b[36m(_ray_fit pid=17264)\u001b[0m No improvement since epoch 8: early stopping\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m \tWarning: Exception caused NeuralNetTorch_r30_BAG_L1 to fail during training... Skipping this model.\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m \t\t\u001b[36mray::_ray_fit()\u001b[39m (pid=1496, ip=127.0.0.1)\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m   File \"python\\ray\\_raylet.pyx\", line 1889, in ray._raylet.execute_task\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m     fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m     out = self._fit(**kwargs)\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 201, in _fit\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m     train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m     dataset = self._process_train_data(\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m     self.processor = create_preprocessor(\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\utils\\data_preprocessor.py\", line 40, in create_preprocessor\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m     return ColumnTransformer(\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m Detailed Traceback:\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 2106, in _train_and_save\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m     model = self._train_single(**model_fit_kwargs)\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 1993, in _train_single\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m     model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m     out = self._fit(**kwargs)\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\stacker_ensemble_model.py\", line 270, in _fit\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m     return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\bagged_ensemble_model.py\", line 298, in _fit\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m     self._fit_folds(\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\bagged_ensemble_model.py\", line 724, in _fit_folds\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m     fold_fitting_strategy.after_all_folds_scheduled()\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 690, in after_all_folds_scheduled\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m     self._run_parallel(X, y, X_pseudo, y_pseudo, model_base_ref, time_limit_fold, head_node_id)\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 631, in _run_parallel\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m     self._process_fold_results(finished, unfinished, fold_ctx)\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 587, in _process_fold_results\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m     raise processed_exception\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 550, in _process_fold_results\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m     fold_model, pred_proba, time_start_fit, time_end_fit, predict_time, predict_1_time, predict_n_size, fit_num_cpus, fit_num_gpus = self.ray.get(finished)\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m     return fn(*args, **kwargs)\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\client_mode_hook.py\", line 103, in wrapper\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m     return func(*args, **kwargs)\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\worker.py\", line 2667, in get\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m     values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\worker.py\", line 864, in get_objects\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m     raise value.as_instanceof_cause()\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m ray.exceptions.RayTaskError(TypeError): \u001b[36mray::_ray_fit()\u001b[39m (pid=1496, ip=127.0.0.1)\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m   File \"python\\ray\\_raylet.pyx\", line 1889, in ray._raylet.execute_task\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m     fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m     out = self._fit(**kwargs)\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 201, in _fit\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m     train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m     dataset = self._process_train_data(\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m     self.processor = create_preprocessor(\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\utils\\data_preprocessor.py\", line 40, in create_preprocessor\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m     return ColumnTransformer(\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m Fitting model: LightGBM_r130_BAG_L1 ... Training model for up to 104.07s of the 702.75s of remaining time.\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=1.14%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=1756)\u001b[0m [1000]\tvalid_set's binary_logloss: 0.119585\u001b[32m [repeated 19x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_dystack pid=24628)\u001b[0m \t0.9047\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m \t1.27s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m \t0.02s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m Fitting model: NeuralNetTorch_r86_BAG_L1 ... Training model for up to 99.41s of the 698.09s of remaining time.\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.02%)\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m \tWarning: Exception caused NeuralNetTorch_r86_BAG_L1 to fail during training... Skipping this model.\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m \t\t\u001b[36mray::_ray_fit()\u001b[39m (pid=31364, ip=127.0.0.1)\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m   File \"python\\ray\\_raylet.pyx\", line 1889, in ray._raylet.execute_task\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m     fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m     out = self._fit(**kwargs)\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 201, in _fit\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m     train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m     dataset = self._process_train_data(\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m     self.processor = create_preprocessor(\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\utils\\data_preprocessor.py\", line 40, in create_preprocessor\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m     return ColumnTransformer(\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m Detailed Traceback:\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 2106, in _train_and_save\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m     model = self._train_single(**model_fit_kwargs)\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 1993, in _train_single\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m     model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m     out = self._fit(**kwargs)\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\stacker_ensemble_model.py\", line 270, in _fit\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m     return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\bagged_ensemble_model.py\", line 298, in _fit\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m     self._fit_folds(\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\bagged_ensemble_model.py\", line 724, in _fit_folds\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m     fold_fitting_strategy.after_all_folds_scheduled()\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 690, in after_all_folds_scheduled\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m     self._run_parallel(X, y, X_pseudo, y_pseudo, model_base_ref, time_limit_fold, head_node_id)\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 631, in _run_parallel\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m     self._process_fold_results(finished, unfinished, fold_ctx)\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 587, in _process_fold_results\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m     raise processed_exception\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 550, in _process_fold_results\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m     fold_model, pred_proba, time_start_fit, time_end_fit, predict_time, predict_1_time, predict_n_size, fit_num_cpus, fit_num_gpus = self.ray.get(finished)\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m     return fn(*args, **kwargs)\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\client_mode_hook.py\", line 103, in wrapper\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m     return func(*args, **kwargs)\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\worker.py\", line 2667, in get\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m     values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\worker.py\", line 864, in get_objects\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m     raise value.as_instanceof_cause()\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m ray.exceptions.RayTaskError(TypeError): \u001b[36mray::_ray_fit()\u001b[39m (pid=31364, ip=127.0.0.1)\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m   File \"python\\ray\\_raylet.pyx\", line 1889, in ray._raylet.execute_task\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m     fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m     out = self._fit(**kwargs)\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 201, in _fit\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m     train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m     dataset = self._process_train_data(\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m     self.processor = create_preprocessor(\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\utils\\data_preprocessor.py\", line 40, in create_preprocessor\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m     return ColumnTransformer(\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m Fitting model: CatBoost_r50_BAG_L1 ... Training model for up to 92.45s of the 691.13s of remaining time.\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.39%)\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m \t0.9215\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m \t14.63s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m \t0.06s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m Fitting model: NeuralNetFastAI_r11_BAG_L1 ... Training model for up to 74.37s of the 673.05s of remaining time.\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.05%)\n",
      "\u001b[36m(_ray_fit pid=5684)\u001b[0m No improvement since epoch 0: early stopping\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m \t0.8649\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m \t6.84s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m \t0.09s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m Fitting model: XGBoost_r194_BAG_L1 ... Training model for up to 64.31s of the 662.99s of remaining time.\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=5.55%)\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m \t0.9112\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m \t10.6s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m \t0.12s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m Fitting model: CatBoost_r69_BAG_L1 ... Training model for up to 49.75s of the 648.44s of remaining time.\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.46%)\n",
      "\u001b[36m(_ray_fit pid=13156)\u001b[0m No improvement since epoch 7: early stopping\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m \t0.9194\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m \t33.57s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m \t0.05s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m Fitting model: NeuralNetFastAI_r103_BAG_L1 ... Training model for up to 12.97s of the 611.65s of remaining time.\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.04%)\n",
      "\u001b[36m(_ray_fit pid=26220)\u001b[0m No improvement since epoch 2: early stopping\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m \t0.8852\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m \t7.78s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m \t0.07s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m Fitting model: NeuralNetTorch_r14_BAG_L1 ... Training model for up to 1.95s of the 600.63s of remaining time.\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.03%)\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m \tWarning: Exception caused NeuralNetTorch_r14_BAG_L1 to fail during training... Skipping this model.\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m \t\t\u001b[36mray::_ray_fit()\u001b[39m (pid=15976, ip=127.0.0.1)\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m   File \"python\\ray\\_raylet.pyx\", line 1889, in ray._raylet.execute_task\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m     fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m     out = self._fit(**kwargs)\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 201, in _fit\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m     train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m     dataset = self._process_train_data(\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m     self.processor = create_preprocessor(\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\utils\\data_preprocessor.py\", line 40, in create_preprocessor\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m     return ColumnTransformer(\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m Detailed Traceback:\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 2106, in _train_and_save\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m     model = self._train_single(**model_fit_kwargs)\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 1993, in _train_single\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m     model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m     out = self._fit(**kwargs)\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\stacker_ensemble_model.py\", line 270, in _fit\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m     return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\bagged_ensemble_model.py\", line 298, in _fit\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m     self._fit_folds(\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\bagged_ensemble_model.py\", line 724, in _fit_folds\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m     fold_fitting_strategy.after_all_folds_scheduled()\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 690, in after_all_folds_scheduled\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m     self._run_parallel(X, y, X_pseudo, y_pseudo, model_base_ref, time_limit_fold, head_node_id)\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 631, in _run_parallel\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m     self._process_fold_results(finished, unfinished, fold_ctx)\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 587, in _process_fold_results\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m     raise processed_exception\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 550, in _process_fold_results\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m     fold_model, pred_proba, time_start_fit, time_end_fit, predict_time, predict_1_time, predict_n_size, fit_num_cpus, fit_num_gpus = self.ray.get(finished)\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m     return fn(*args, **kwargs)\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\client_mode_hook.py\", line 103, in wrapper\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m     return func(*args, **kwargs)\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\worker.py\", line 2667, in get\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m     values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\worker.py\", line 864, in get_objects\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m     raise value.as_instanceof_cause()\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m ray.exceptions.RayTaskError(TypeError): \u001b[36mray::_ray_fit()\u001b[39m (pid=15976, ip=127.0.0.1)\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m   File \"python\\ray\\_raylet.pyx\", line 1889, in ray._raylet.execute_task\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m     fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m     out = self._fit(**kwargs)\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 201, in _fit\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m     train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m     dataset = self._process_train_data(\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m     self.processor = create_preprocessor(\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\utils\\data_preprocessor.py\", line 40, in create_preprocessor\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m     return ColumnTransformer(\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "\u001b[36m(_ray_fit pid=17108)\u001b[0m No improvement since epoch 23: early stopping\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m Fitting model: WeightedEnsemble_L2 ... Training model for up to 360.00s of the 593.38s of remaining time.\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m \tEnsemble Weights: {'LightGBMXT_BAG_L1': 0.417, 'NeuralNetFastAI_r102_BAG_L1': 0.333, 'CatBoost_r137_BAG_L1': 0.25}\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m \t0.9501\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m \t0.04s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m \t0.0s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m Excluded models: ['RF', 'KNN', 'XT'] (Specified by `excluded_model_types`)\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m Fitting 90 L2 models, fit_strategy=\"sequential\" ...\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m Fitting model: LightGBMXT_BAG_L2 ... Training model for up to 593.35s of the 593.25s of remaining time.\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.78%)\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m \t0.9412\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m \t1.05s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m \t0.05s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m Fitting model: LightGBM_BAG_L2 ... Training model for up to 588.98s of the 588.88s of remaining time.\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=1.08%)\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m \t0.9511\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m \t1.08s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m \t0.06s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m Fitting model: CatBoost_BAG_L2 ... Training model for up to 584.34s of the 584.24s of remaining time.\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=2.18%)\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m \t0.9503\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m \t58.57s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m \t0.08s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m Fitting model: NeuralNetFastAI_BAG_L2 ... Training model for up to 522.23s of the 522.13s of remaining time.\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.04%)\n",
      "\u001b[36m(_ray_fit pid=7088)\u001b[0m No improvement since epoch 1: early stopping\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m \t0.8851\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m \t6.73s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m \t0.09s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m Fitting model: XGBoost_BAG_L2 ... Training model for up to 512.32s of the 512.20s of remaining time.\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=2.03%)\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m \t0.9436\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m \t1.19s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m \t0.07s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m Fitting model: NeuralNetTorch_BAG_L2 ... Training model for up to 507.43s of the 507.33s of remaining time.\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.03%)\n",
      "\u001b[36m(_ray_fit pid=28440)\u001b[0m No improvement since epoch 7: early stopping\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m \tWarning: Exception caused NeuralNetTorch_BAG_L2 to fail during training... Skipping this model.\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m \t\t\u001b[36mray::_ray_fit()\u001b[39m (pid=22840, ip=127.0.0.1)\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m   File \"python\\ray\\_raylet.pyx\", line 1889, in ray._raylet.execute_task\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m     fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m     out = self._fit(**kwargs)\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 201, in _fit\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m     train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m     dataset = self._process_train_data(\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m     self.processor = create_preprocessor(\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\utils\\data_preprocessor.py\", line 40, in create_preprocessor\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m     return ColumnTransformer(\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m Detailed Traceback:\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 2106, in _train_and_save\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m     model = self._train_single(**model_fit_kwargs)\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 1993, in _train_single\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m     model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m     out = self._fit(**kwargs)\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\stacker_ensemble_model.py\", line 270, in _fit\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m     return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\bagged_ensemble_model.py\", line 298, in _fit\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m     self._fit_folds(\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\bagged_ensemble_model.py\", line 724, in _fit_folds\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m     fold_fitting_strategy.after_all_folds_scheduled()\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 690, in after_all_folds_scheduled\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m     self._run_parallel(X, y, X_pseudo, y_pseudo, model_base_ref, time_limit_fold, head_node_id)\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 631, in _run_parallel\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m     self._process_fold_results(finished, unfinished, fold_ctx)\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 587, in _process_fold_results\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m     raise processed_exception\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 550, in _process_fold_results\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m     fold_model, pred_proba, time_start_fit, time_end_fit, predict_time, predict_1_time, predict_n_size, fit_num_cpus, fit_num_gpus = self.ray.get(finished)\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m     return fn(*args, **kwargs)\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\client_mode_hook.py\", line 103, in wrapper\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m     return func(*args, **kwargs)\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\worker.py\", line 2667, in get\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m     values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\worker.py\", line 864, in get_objects\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m     raise value.as_instanceof_cause()\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m ray.exceptions.RayTaskError(TypeError): \u001b[36mray::_ray_fit()\u001b[39m (pid=22840, ip=127.0.0.1)\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m   File \"python\\ray\\_raylet.pyx\", line 1889, in ray._raylet.execute_task\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m     fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m     out = self._fit(**kwargs)\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 201, in _fit\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m     train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m     dataset = self._process_train_data(\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m     self.processor = create_preprocessor(\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\utils\\data_preprocessor.py\", line 40, in create_preprocessor\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m     return ColumnTransformer(\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m Fitting model: LightGBMLarge_BAG_L2 ... Training model for up to 500.60s of the 500.48s of remaining time.\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=4.27%)\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m \t0.9412\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m \t1.57s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m \t0.05s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m Fitting model: CatBoost_r177_BAG_L2 ... Training model for up to 495.57s of the 495.47s of remaining time.\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=3.13%)\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m \t0.9456\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m \t26.38s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m \t0.07s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m Fitting model: NeuralNetTorch_r79_BAG_L2 ... Training model for up to 465.56s of the 465.46s of remaining time.\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.04%)\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m \tWarning: Exception caused NeuralNetTorch_r79_BAG_L2 to fail during training... Skipping this model.\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m \t\t\u001b[36mray::_ray_fit()\u001b[39m (pid=7116, ip=127.0.0.1)\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m   File \"python\\ray\\_raylet.pyx\", line 1889, in ray._raylet.execute_task\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m     fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m     out = self._fit(**kwargs)\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 201, in _fit\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m     train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m     dataset = self._process_train_data(\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m     self.processor = create_preprocessor(\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\utils\\data_preprocessor.py\", line 40, in create_preprocessor\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m     return ColumnTransformer(\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m Detailed Traceback:\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 2106, in _train_and_save\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m     model = self._train_single(**model_fit_kwargs)\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 1993, in _train_single\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m     model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m     out = self._fit(**kwargs)\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\stacker_ensemble_model.py\", line 270, in _fit\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m     return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\bagged_ensemble_model.py\", line 298, in _fit\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m     self._fit_folds(\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\bagged_ensemble_model.py\", line 724, in _fit_folds\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m     fold_fitting_strategy.after_all_folds_scheduled()\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 690, in after_all_folds_scheduled\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m     self._run_parallel(X, y, X_pseudo, y_pseudo, model_base_ref, time_limit_fold, head_node_id)\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 631, in _run_parallel\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m     self._process_fold_results(finished, unfinished, fold_ctx)\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 587, in _process_fold_results\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m     raise processed_exception\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 550, in _process_fold_results\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m     fold_model, pred_proba, time_start_fit, time_end_fit, predict_time, predict_1_time, predict_n_size, fit_num_cpus, fit_num_gpus = self.ray.get(finished)\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m     return fn(*args, **kwargs)\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\client_mode_hook.py\", line 103, in wrapper\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m     return func(*args, **kwargs)\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\worker.py\", line 2667, in get\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m     values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\worker.py\", line 864, in get_objects\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m     raise value.as_instanceof_cause()\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m ray.exceptions.RayTaskError(TypeError): \u001b[36mray::_ray_fit()\u001b[39m (pid=7116, ip=127.0.0.1)\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m   File \"python\\ray\\_raylet.pyx\", line 1889, in ray._raylet.execute_task\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m     fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m     out = self._fit(**kwargs)\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 201, in _fit\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m     train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m     dataset = self._process_train_data(\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m     self.processor = create_preprocessor(\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\utils\\data_preprocessor.py\", line 40, in create_preprocessor\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m     return ColumnTransformer(\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m Fitting model: LightGBM_r131_BAG_L2 ... Training model for up to 457.83s of the 457.73s of remaining time.\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=5.99%)\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m \t0.9424\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m \t1.59s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m \t0.03s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m Fitting model: NeuralNetFastAI_r191_BAG_L2 ... Training model for up to 450.40s of the 450.30s of remaining time.\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.10%)\n",
      "\u001b[36m(_ray_fit pid=5700)\u001b[0m No improvement since epoch 0: early stopping\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m \t0.894\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m \t11.88s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m \t0.14s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m Fitting model: CatBoost_r9_BAG_L2 ... Training model for up to 435.04s of the 434.94s of remaining time.\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=4.18%)\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_ray_fit pid=12824)\u001b[0m No improvement since epoch 10: early stopping\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_ray_fit pid=25112)\u001b[0m \tRan out of time, early stopping on iteration 3963.\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m \t0.953\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m \t348.35s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m \t0.08s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m Fitting model: LightGBM_r96_BAG_L2 ... Training model for up to 83.25s of the 83.15s of remaining time.\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.27%)\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=20568)\u001b[0m [1000]\tvalid_set's binary_logloss: 0.238997\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_dystack pid=24628)\u001b[0m \t0.933\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m \t1.27s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m \t0.02s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m Fitting model: NeuralNetTorch_r22_BAG_L2 ... Training model for up to 78.71s of the 78.60s of remaining time.\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.02%)\n",
      "\u001b[36m(_ray_fit pid=11104)\u001b[0m \tRan out of time, early stopping on iteration 4335.\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m \tWarning: Exception caused NeuralNetTorch_r22_BAG_L2 to fail during training... Skipping this model.\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m \t\t\u001b[36mray::_ray_fit()\u001b[39m (pid=8524, ip=127.0.0.1)\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m   File \"python\\ray\\_raylet.pyx\", line 1889, in ray._raylet.execute_task\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m     fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m     out = self._fit(**kwargs)\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 201, in _fit\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m     train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m     dataset = self._process_train_data(\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m     self.processor = create_preprocessor(\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\utils\\data_preprocessor.py\", line 40, in create_preprocessor\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m     return ColumnTransformer(\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m Detailed Traceback:\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 2106, in _train_and_save\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m     model = self._train_single(**model_fit_kwargs)\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 1993, in _train_single\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m     model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m     out = self._fit(**kwargs)\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\stacker_ensemble_model.py\", line 270, in _fit\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m     return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\bagged_ensemble_model.py\", line 298, in _fit\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m     self._fit_folds(\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\bagged_ensemble_model.py\", line 724, in _fit_folds\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m     fold_fitting_strategy.after_all_folds_scheduled()\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 690, in after_all_folds_scheduled\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m     self._run_parallel(X, y, X_pseudo, y_pseudo, model_base_ref, time_limit_fold, head_node_id)\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 631, in _run_parallel\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m     self._process_fold_results(finished, unfinished, fold_ctx)\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 587, in _process_fold_results\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m     raise processed_exception\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 550, in _process_fold_results\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m     fold_model, pred_proba, time_start_fit, time_end_fit, predict_time, predict_1_time, predict_n_size, fit_num_cpus, fit_num_gpus = self.ray.get(finished)\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m     return fn(*args, **kwargs)\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\client_mode_hook.py\", line 103, in wrapper\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m     return func(*args, **kwargs)\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\worker.py\", line 2667, in get\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m     values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\worker.py\", line 864, in get_objects\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m     raise value.as_instanceof_cause()\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m ray.exceptions.RayTaskError(TypeError): \u001b[36mray::_ray_fit()\u001b[39m (pid=8524, ip=127.0.0.1)\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m   File \"python\\ray\\_raylet.pyx\", line 1889, in ray._raylet.execute_task\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m     fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m     out = self._fit(**kwargs)\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 201, in _fit\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m     train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m     dataset = self._process_train_data(\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m     self.processor = create_preprocessor(\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\utils\\data_preprocessor.py\", line 40, in create_preprocessor\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m     return ColumnTransformer(\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): \u001b[36mray::_ray_fit()\u001b[39m (pid=33552, ip=127.0.0.1)\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m   File \"python\\ray\\_raylet.pyx\", line 1889, in ray._raylet.execute_task\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m     fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m     out = self._fit(**kwargs)\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 201, in _fit\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m     train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m     dataset = self._process_train_data(\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m     self.processor = create_preprocessor(\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\utils\\data_preprocessor.py\", line 40, in create_preprocessor\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m     return ColumnTransformer(\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m Fitting model: XGBoost_r33_BAG_L2 ... Training model for up to 72.23s of the 72.13s of remaining time.\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m \tMemory not enough to fit 8 folds in parallel. Will train 4 folds in parallel instead (Estimated 15.25% memory usage per fold, 61.01%/80.00% total).\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=3, gpus=0, memory=15.25%)\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m \t0.942\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m \t5.82s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m \t0.04s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m Fitting model: CatBoost_r137_BAG_L2 ... Training model for up to 63.95s of the 63.83s of remaining time.\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.40%)\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m \t0.9485\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m \t33.92s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m \t0.07s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m Fitting model: NeuralNetFastAI_r102_BAG_L2 ... Training model for up to 26.66s of the 26.56s of remaining time.\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.05%)\n",
      "\u001b[36m(_ray_fit pid=24656)\u001b[0m No improvement since epoch 0: early stopping\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m \t0.9015\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m \t7.05s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m \t0.09s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m Fitting model: CatBoost_r13_BAG_L2 ... Training model for up to 16.42s of the 16.31s of remaining time.\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m \tMemory not enough to fit 8 folds in parallel. Will train 4 folds in parallel instead (Estimated 15.49% memory usage per fold, 61.98%/80.00% total).\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=3, gpus=0, memory=15.49%)\n",
      "\u001b[36m(_ray_fit pid=13700)\u001b[0m \tRan out of time, early stopping on iteration 399.\n",
      "\u001b[36m(_ray_fit pid=21348)\u001b[0m No improvement since epoch 8: early stopping\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=21876)\u001b[0m \tRan out of time, early stopping on iteration 404.\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m \t0.9378\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m \t15.62s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m \t0.08s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m Fitting model: WeightedEnsemble_L3 ... Training model for up to 360.00s of the -2.45s of remaining time.\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m \tEnsemble Weights: {'LightGBM_BAG_L2': 0.333, 'CatBoost_r9_BAG_L2': 0.333, 'NeuralNetFastAI_r102_BAG_L2': 0.333}\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m \t0.9607\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m \t0.03s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m \t0.0s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m AutoGluon training complete, total runtime = 1797.84s ... Best model: WeightedEnsemble_L3 | Estimated inference throughput: 63.3 rows/s (28 batch size)\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m Automatically performing refit_full as a post-fit operation (due to `.fit(..., refit_full=True)`\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m Refitting models via `predictor.refit_full` using all of the data (combined train and validation)...\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m \tModels trained in this way will have the suffix \"_FULL\" and have NaN validation score.\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m \tThis process is not bound by time_limit, but should take less time than the original `predictor.fit` call.\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m \tTo learn more, refer to the `.refit_full` method docstring which explains how \"_FULL\" models differ from normal models.\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m Fitting model: LightGBMXT_BAG_L1_FULL ...\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m \t0.37s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m Fitting model: LightGBM_BAG_L1_FULL ...\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m \t0.09s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m Fitting model: CatBoost_BAG_L1_FULL ...\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m \t4.59s\t = Training   runtime\n",
      "\u001b[36m(_ray_fit pid=28704)\u001b[0m \tRan out of time, early stopping on iteration 404.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m Fitting model: NeuralNetFastAI_BAG_L1_FULL ...\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m \tStopping at the best epoch learned earlier - 10.\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m \t1.09s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m Fitting model: XGBoost_BAG_L1_FULL ...\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m \t0.13s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m Fitting model: LightGBMLarge_BAG_L1_FULL ...\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m \t0.18s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m Fitting model: CatBoost_r177_BAG_L1_FULL ...\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m \t0.51s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m Fitting model: LightGBM_r131_BAG_L1_FULL ...\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m \t0.19s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m Fitting model: NeuralNetFastAI_r191_BAG_L1_FULL ...\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m \tStopping at the best epoch learned earlier - 6.\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m \t0.99s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m Fitting model: CatBoost_r9_BAG_L1_FULL ...\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m \t74.53s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m Fitting model: LightGBM_r96_BAG_L1_FULL ...\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m \t0.32s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m Fitting model: XGBoost_r33_BAG_L1_FULL ...\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m \t0.23s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m Fitting model: CatBoost_r137_BAG_L1_FULL ...\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m \t3.82s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m Fitting model: NeuralNetFastAI_r102_BAG_L1_FULL ...\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m \tStopping at the best epoch learned earlier - 10.\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m \t0.86s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m Fitting model: CatBoost_r13_BAG_L1_FULL ...\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m \t2.57s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m Fitting model: LightGBM_r188_BAG_L1_FULL ...\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m \t0.15s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m Fitting model: NeuralNetFastAI_r145_BAG_L1_FULL ...\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m \tStopping at the best epoch learned earlier - 11.\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m \t0.45s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m Fitting model: XGBoost_r89_BAG_L1_FULL ...\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m \t0.16s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m Fitting model: LightGBM_r130_BAG_L1_FULL ...\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m \t0.12s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m Fitting model: CatBoost_r50_BAG_L1_FULL ...\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m \t1.2s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m Fitting model: NeuralNetFastAI_r11_BAG_L1_FULL ...\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m \tStopping at the best epoch learned earlier - 5.\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m \t0.27s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m Fitting model: XGBoost_r194_BAG_L1_FULL ...\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m \t0.64s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m Fitting model: CatBoost_r69_BAG_L1_FULL ...\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m \t4.41s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m Fitting model: NeuralNetFastAI_r103_BAG_L1_FULL ...\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m \tStopping at the best epoch learned earlier - 12.\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m \t1.06s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m Fitting model: WeightedEnsemble_L2_FULL | Skipping fit via cloning parent ...\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m \tEnsemble Weights: {'LightGBMXT_BAG_L1': 0.417, 'NeuralNetFastAI_r102_BAG_L1': 0.333, 'CatBoost_r137_BAG_L1': 0.25}\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m \t0.04s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m Fitting 1 L2 models, fit_strategy=\"sequential\" ...\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m Fitting model: LightGBMXT_BAG_L2_FULL ...\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m \t0.12s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m Fitting 1 L2 models, fit_strategy=\"sequential\" ...\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m Fitting model: LightGBM_BAG_L2_FULL ...\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m \t0.11s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m Fitting 1 L2 models, fit_strategy=\"sequential\" ...\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m Fitting model: CatBoost_BAG_L2_FULL ...\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m \t9.97s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m Fitting 1 L2 models, fit_strategy=\"sequential\" ...\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m Fitting model: NeuralNetFastAI_BAG_L2_FULL ...\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m \tStopping at the best epoch learned earlier - 4.\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m \t0.46s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m Fitting 1 L2 models, fit_strategy=\"sequential\" ...\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m Fitting model: XGBoost_BAG_L2_FULL ...\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m \t0.07s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m Fitting 1 L2 models, fit_strategy=\"sequential\" ...\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m Fitting model: LightGBMLarge_BAG_L2_FULL ...\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m \t0.22s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m Fitting 1 L2 models, fit_strategy=\"sequential\" ...\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m Fitting model: CatBoost_r177_BAG_L2_FULL ...\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m \t1.11s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m Fitting 1 L2 models, fit_strategy=\"sequential\" ...\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m Fitting model: LightGBM_r131_BAG_L2_FULL ...\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m \t0.15s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m Fitting 1 L2 models, fit_strategy=\"sequential\" ...\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m Fitting model: NeuralNetFastAI_r191_BAG_L2_FULL ...\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m \tStopping at the best epoch learned earlier - 6.\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m \t0.73s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m Fitting 1 L2 models, fit_strategy=\"sequential\" ...\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m Fitting model: CatBoost_r9_BAG_L2_FULL ...\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m \t62.55s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m Fitting 1 L2 models, fit_strategy=\"sequential\" ...\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m Fitting model: LightGBM_r96_BAG_L2_FULL ...\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m \t0.14s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m Fitting 1 L2 models, fit_strategy=\"sequential\" ...\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m Fitting model: XGBoost_r33_BAG_L2_FULL ...\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m \t0.21s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m Fitting 1 L2 models, fit_strategy=\"sequential\" ...\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m Fitting model: CatBoost_r137_BAG_L2_FULL ...\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m \t7.22s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m Fitting 1 L2 models, fit_strategy=\"sequential\" ...\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m Fitting model: NeuralNetFastAI_r102_BAG_L2_FULL ...\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m \tStopping at the best epoch learned earlier - 5.\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m \t0.51s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m Fitting 1 L2 models, fit_strategy=\"sequential\" ...\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m Fitting model: CatBoost_r13_BAG_L2_FULL ...\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m \t1.89s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m Fitting model: WeightedEnsemble_L3_FULL | Skipping fit via cloning parent ...\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m \tEnsemble Weights: {'LightGBM_BAG_L2': 0.333, 'CatBoost_r9_BAG_L2': 0.333, 'NeuralNetFastAI_r102_BAG_L2': 0.333}\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m \t0.03s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m Updated best model to \"WeightedEnsemble_L3_FULL\" (Previously \"WeightedEnsemble_L3\"). AutoGluon will default to using \"WeightedEnsemble_L3_FULL\" for predict() and predict_proba().\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m Refit complete, total runtime = 189.26s ... Best model: \"WeightedEnsemble_L3_FULL\"\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\autogluon\\tlp\\AutogluonModels\\synthetic\\tvaes\\v2\\ds_sub_fit\\sub_fit_ho\")\n",
      "\u001b[36m(_dystack pid=24628)\u001b[0m Deleting DyStack predictor artifacts (clean_up_fits=True) ...\n",
      "Leaderboard on holdout data (DyStack):\n",
      "                               model  score_holdout  score_val eval_metric  pred_time_test pred_time_val   fit_time  pred_time_test_marginal pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
      "0        NeuralNetFastAI_BAG_L1_FULL       0.986395   0.890291     roc_auc        0.039248          None   1.092583                 0.039248                   None           1.092583            1       True          4\n",
      "1   NeuralNetFastAI_r145_BAG_L1_FULL       0.986395   0.851796     roc_auc        0.050247          None   0.450143                 0.050247                   None           0.450143            1       True         17\n",
      "2            XGBoost_r33_BAG_L2_FULL       0.986395   0.942044     roc_auc        0.174826          None   5.426173                 0.038372                   None           0.214794            2       True         37\n",
      "3    NeuralNetFastAI_r11_BAG_L1_FULL       0.979592   0.864949     roc_auc        0.046350          None   0.268488                 0.046350                   None           0.268488            1       True         21\n",
      "4          CatBoost_r177_BAG_L2_FULL       0.972789   0.945573     roc_auc        0.160572          None   6.322999                 0.024117                   None           1.111621            2       True         32\n",
      "5                XGBoost_BAG_L2_FULL       0.972789   0.943648     roc_auc        0.169695          None   5.285017                 0.033240                   None           0.073639            2       True         30\n",
      "6               CatBoost_BAG_L1_FULL       0.965986   0.917237     roc_auc        0.034242          None   4.589928                 0.034242                   None           4.589928            1       True          3\n",
      "7   NeuralNetFastAI_r102_BAG_L1_FULL       0.965986   0.896065     roc_auc        0.047375          None   0.861984                 0.047375                   None           0.861984            1       True         14\n",
      "8           WeightedEnsemble_L2_FULL       0.965986   0.950064     roc_auc        0.109235          None   5.088333                 0.013148                   None           0.035861            2       True         25\n",
      "9           CatBoost_r13_BAG_L2_FULL       0.965986   0.937767     roc_auc        0.163571          None   7.099049                 0.027116                   None           1.887671            2       True         40\n",
      "10          WeightedEnsemble_L3_FULL       0.965986   0.960650     roc_auc        0.248364          None  68.420329                 0.010201                   None           0.032845            3       True         41\n",
      "11  NeuralNetFastAI_r102_BAG_L2_FULL       0.962585   0.901465     roc_auc        0.181805          None   5.719416                 0.045350                   None           0.508038            2       True         39\n",
      "12              LightGBM_BAG_L2_FULL       0.959184   0.951133     roc_auc        0.158567          None   5.324610                 0.022113                   None           0.113231            2       True         27\n",
      "13         LightGBM_r131_BAG_L2_FULL       0.959184   0.942365     roc_auc        0.161675          None   5.360247                 0.025220                   None           0.148868            2       True         33\n",
      "14         CatBoost_r137_BAG_L2_FULL       0.959184   0.948460     roc_auc        0.163568          None  12.431777                 0.027113                   None           7.220398            2       True         38\n",
      "15          CatBoost_r13_BAG_L1_FULL       0.952381   0.915098     roc_auc        0.029176          None   2.567806                 0.029176                   None           2.567806            1       True         15\n",
      "16          LightGBM_r96_BAG_L2_FULL       0.952381   0.932956     roc_auc        0.161726          None   5.346666                 0.025271                   None           0.135287            2       True         36\n",
      "17              CatBoost_BAG_L2_FULL       0.952381   0.950278     roc_auc        0.162582          None  15.176392                 0.026127                   None           9.965013            2       True         28\n",
      "18          CatBoost_r69_BAG_L1_FULL       0.945578   0.919376     roc_auc        0.023334          None   4.407024                 0.023334                   None           4.407024            1       True         23\n",
      "19         LightGBM_r188_BAG_L1_FULL       0.945578   0.926219     roc_auc        0.026268          None   0.154883                 0.026268                   None           0.154883            1       True         16\n",
      "20           CatBoost_r9_BAG_L1_FULL       0.945578   0.926433     roc_auc        0.036321          None  74.530327                 0.036321                   None          74.530327            1       True         10\n",
      "21           CatBoost_r9_BAG_L2_FULL       0.945578   0.952951     roc_auc        0.170699          None  67.766216                 0.034245                   None          62.554837            2       True         35\n",
      "22            LightGBMXT_BAG_L2_FULL       0.945578   0.941189     roc_auc        0.162679          None   5.333433                 0.026225                   None           0.122055            2       True         26\n",
      "23       NeuralNetFastAI_BAG_L2_FULL       0.945578   0.885051     roc_auc        0.179788          None   5.666777                 0.043333                   None           0.455398            2       True         29\n",
      "24  NeuralNetFastAI_r191_BAG_L2_FULL       0.945578   0.894033     roc_auc        0.183694          None   5.942616                 0.047240                   None           0.731237            2       True         34\n",
      "25          CatBoost_r50_BAG_L1_FULL       0.938776   0.921514     roc_auc        0.024117          None   1.197917                 0.024117                   None           1.197917            1       True         20\n",
      "26         LightGBMLarge_BAG_L2_FULL       0.938776   0.941189     roc_auc        0.161569          None   5.432231                 0.025114                   None           0.220853            2       True         31\n",
      "27         CatBoost_r177_BAG_L1_FULL       0.931973   0.921300     roc_auc        0.026383          None   0.509196                 0.026383                   None           0.509196            1       True          7\n",
      "28         CatBoost_r137_BAG_L1_FULL       0.931973   0.928785     roc_auc        0.026553          None   3.822772                 0.026553                   None           3.822772            1       True         13\n",
      "29  NeuralNetFastAI_r103_BAG_L1_FULL       0.925170   0.885158     roc_auc        0.052281          None   1.055999                 0.052281                   None           1.055999            1       True         24\n",
      "30         LightGBMLarge_BAG_L1_FULL       0.925170   0.886228     roc_auc        0.022121          None   0.179036                 0.022121                   None           0.179036            1       True          6\n",
      "31         LightGBM_r131_BAG_L1_FULL       0.918367   0.910607     roc_auc        0.027121          None   0.186608                 0.027121                   None           0.186608            1       True          8\n",
      "32           XGBoost_r33_BAG_L1_FULL       0.918367   0.900342     roc_auc        0.041160          None   0.229116                 0.041160                   None           0.229116            1       True         12\n",
      "33            LightGBMXT_BAG_L1_FULL       0.911565   0.935415     roc_auc        0.022160          None   0.367715                 0.022160                   None           0.367715            1       True          1\n",
      "34          LightGBM_r96_BAG_L1_FULL       0.897959   0.921835     roc_auc        0.037210          None   0.318628                 0.037210                   None           0.318628            1       True         11\n",
      "35              LightGBM_BAG_L1_FULL       0.884354   0.914243     roc_auc        0.019146          None   0.092844                 0.019146                   None           0.092844            1       True          2\n",
      "36          XGBoost_r194_BAG_L1_FULL       0.884354   0.911249     roc_auc        0.064335          None   0.639790                 0.064335                   None           0.639790            1       True         22\n",
      "37           XGBoost_r89_BAG_L1_FULL       0.877551   0.912318     roc_auc        0.040367          None   0.158907                 0.040367                   None           0.158907            1       True         18\n",
      "38               XGBoost_BAG_L1_FULL       0.857143   0.896012     roc_auc        0.036247          None   0.128335                 0.036247                   None           0.128335            1       True          5\n",
      "39         LightGBM_r130_BAG_L1_FULL       0.850340   0.904726     roc_auc        0.022120          None   0.116455                 0.022120                   None           0.116455            1       True         19\n",
      "40  NeuralNetFastAI_r191_BAG_L1_FULL       0.680272   0.877887     roc_auc        0.046356          None   0.994727                 0.046356                   None           0.994727            1       True          9\n",
      "\t0\t = Optimal   num_stack_levels (Stacked Overfitting Occurred: True)\n",
      "\t1996s\t = DyStack   runtime |\t5204s\t = Remaining runtime\n",
      "Starting main fit with num_stack_levels=0.\n",
      "\tFor future fit calls on this dataset, you can skip DyStack to save time: `predictor.fit(..., dynamic_stacking=False, num_stack_levels=0)`\n",
      "Using predefined sample weighting strategy: balance_weight. Evaluation metrics will ignore sample weights, specify weight_evaluation=True to instead report weighted metrics.\n",
      "Beginning AutoGluon training ... Time limit = 5204s\n",
      "AutoGluon will save models to \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\autogluon\\tlp\\AutogluonModels\\synthetic\\tvaes\\v2\"\n",
      "Train Data Rows:    251\n",
      "Train Data Columns: 79\n",
      "Label Column:       ED_2Clases\n",
      "Problem Type:       binary\n",
      "Preprocessing data ...\n",
      "Selected class <--> label mapping:  class 1 = H, class 0 = D\n",
      "\tNote: For your binary classification, AutoGluon arbitrarily selected which label-value represents positive (H) vs negative (D) class.\n",
      "\tTo explicitly set the positive_class, either rename classes to 1 and 0, or specify positive_class in Predictor init.\n",
      "Assigning sample weights to balance differences in frequency of classes.\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    3417.05 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.19 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 10 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\t\tFitting DatetimeFeatureGenerator...\n",
      "\t\tFitting TextSpecialFeatureGenerator...\n",
      "\t\t\tFitting BinnedFeatureGenerator...\n",
      "\t\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\t\tFitting TextNgramFeatureGenerator...\n",
      "\t\t\tFitting CountVectorizer for text features: ['clin-tipoAlcohol']\n",
      "\t\t\tRemoving text_ngram feature due to error: '__nlp__'\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUseless Original Features (Count: 1): ['clin-Covid_sintomaSarpullido']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('bool', [])                       :  8 | ['clin-ansiedad', 'clin-depresion', 'clin-cardiopatiaIsquemica', 'clin-diabetes', 'clin-Hipercolesterolemia', ...]\n",
      "\t\t('float', [])                      : 17 | ['clin-numCigarros', 'clin-aÃ±osSinFumar', 'ques-Sus-total-PD', 'eval-TLP-FigRey-totalCopia-PD', 'eval-TLP-FigRey-totalMemoria-PD', ...]\n",
      "\t\t('int', [])                        : 49 | ['demo-genero', 'demo-edad', 'clin-reservaCognitiva_total', 'clin-reservaCognitiva_idiomas', 'clin-reservaCognitiva_ocupacion', ...]\n",
      "\t\t('object', [])                     :  1 | ['demo-rangoEdad']\n",
      "\t\t('object', ['datetime_as_object']) :  2 | ['demo-fechaEvaluacion', 'demo-fechaNacimiento']\n",
      "\t\t('object', ['text'])               :  1 | ['clin-tipoAlcohol']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', [])                    :  1 | ['demo-rangoEdad']\n",
      "\t\t('category', ['text_as_category'])  :  1 | ['clin-tipoAlcohol']\n",
      "\t\t('float', [])                       : 17 | ['clin-numCigarros', 'clin-aÃ±osSinFumar', 'ques-Sus-total-PD', 'eval-TLP-FigRey-totalCopia-PD', 'eval-TLP-FigRey-totalMemoria-PD', ...]\n",
      "\t\t('int', [])                         : 47 | ['demo-edad', 'clin-reservaCognitiva_total', 'clin-reservaCognitiva_idiomas', 'clin-reservaCognitiva_ocupacion', 'clin-reservaCognitiva_escolaridad', ...]\n",
      "\t\t('int', ['binned', 'text_special']) : 10 | ['clin-tipoAlcohol.char_count', 'clin-tipoAlcohol.word_count', 'clin-tipoAlcohol.capital_ratio', 'clin-tipoAlcohol.lower_ratio', 'clin-tipoAlcohol.digit_ratio', ...]\n",
      "\t\t('int', ['bool'])                   : 10 | ['demo-genero', 'clin-ansiedad', 'clin-depresion', 'clin-cardiopatiaIsquemica', 'clin-diabetes', ...]\n",
      "\t\t('int', ['datetime_as_int'])        :  9 | ['demo-fechaEvaluacion', 'demo-fechaEvaluacion.month', 'demo-fechaEvaluacion.day', 'demo-fechaEvaluacion.dayofweek', 'demo-fechaNacimiento', ...]\n",
      "\t0.2s = Fit runtime\n",
      "\t78 features in original data used to generate 95 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.15 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.23s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'roc_auc'\n",
      "\tThis metric expects predicted probabilities rather than predicted class labels, so you'll need to use predict_proba() instead of predict()\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Large model count detected (112 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': [{}, {'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2}}, {'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7}}],\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\n",
      "\t'CAT': [{}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5}}],\n",
      "\t'XGB': [{}, {'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'name_suffix': '_r33', 'priority': -8}}, {'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'name_suffix': '_r89', 'priority': -16}}],\n",
      "\t'FASTAI': [{}, {'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4}}, {'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11}}],\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "Excluded models: ['XT', 'KNN', 'RF'] (Specified by `excluded_model_types`)\n",
      "Fitting 90 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 5204.03s of the 5204.02s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.57%)\n",
      "\t0.9422\t = Validation score   (roc_auc)\n",
      "\t1.58s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 5197.10s of the 5197.09s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.75%)\n",
      "\t0.9117\t = Validation score   (roc_auc)\n",
      "\t1.97s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L1 ... Training model for up to 5192.78s of the 5192.77s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=1.70%)\n",
      "\t0.9233\t = Validation score   (roc_auc)\n",
      "\t42.84s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 5147.29s of the 5147.28s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.05%)\n",
      "\t0.879\t = Validation score   (roc_auc)\n",
      "\t7.84s\t = Training   runtime\n",
      "\t0.09s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L1 ... Training model for up to 5136.98s of the 5136.96s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=1.72%)\n",
      "\t0.9032\t = Validation score   (roc_auc)\n",
      "\t2.61s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_BAG_L1 ... Training model for up to 5130.95s of the 5130.94s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.02%)\n",
      "\tWarning: Exception caused NeuralNetTorch_BAG_L1 to fail during training... Skipping this model.\n",
      "\t\t\u001b[36mray::_ray_fit()\u001b[39m (pid=32400, ip=127.0.0.1)\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1889, in ray._raylet.execute_task\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 201, in _fit\n",
      "    train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "    dataset = self._process_train_data(\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "    self.processor = create_preprocessor(\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\utils\\data_preprocessor.py\", line 40, in create_preprocessor\n",
      "    return ColumnTransformer(\n",
      "TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 2106, in _train_and_save\n",
      "    model = self._train_single(**model_fit_kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 1993, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\stacker_ensemble_model.py\", line 270, in _fit\n",
      "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\bagged_ensemble_model.py\", line 298, in _fit\n",
      "    self._fit_folds(\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\bagged_ensemble_model.py\", line 724, in _fit_folds\n",
      "    fold_fitting_strategy.after_all_folds_scheduled()\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 690, in after_all_folds_scheduled\n",
      "    self._run_parallel(X, y, X_pseudo, y_pseudo, model_base_ref, time_limit_fold, head_node_id)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 631, in _run_parallel\n",
      "    self._process_fold_results(finished, unfinished, fold_ctx)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 587, in _process_fold_results\n",
      "    raise processed_exception\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 550, in _process_fold_results\n",
      "    fold_model, pred_proba, time_start_fit, time_end_fit, predict_time, predict_1_time, predict_n_size, fit_num_cpus, fit_num_gpus = self.ray.get(finished)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\worker.py\", line 2667, in get\n",
      "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\worker.py\", line 864, in get_objects\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(TypeError): \u001b[36mray::_ray_fit()\u001b[39m (pid=32400, ip=127.0.0.1)\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1889, in ray._raylet.execute_task\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 201, in _fit\n",
      "    train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "    dataset = self._process_train_data(\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "    self.processor = create_preprocessor(\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\utils\\data_preprocessor.py\", line 40, in create_preprocessor\n",
      "    return ColumnTransformer(\n",
      "TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "Fitting model: LightGBMLarge_BAG_L1 ... Training model for up to 5125.54s of the 5125.53s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=2.28%)\n",
      "\t0.8736\t = Validation score   (roc_auc)\n",
      "\t2.26s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: CatBoost_r177_BAG_L1 ... Training model for up to 5120.65s of the 5120.64s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=1.02%)\n",
      "2025-01-30 00:33:41,933\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-30 00:33:41,942\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-30 00:33:41,946\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-30 00:33:41,949\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-30 00:33:41,973\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-30 00:33:41,990\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-30 00:33:41,993\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\t0.9266\t = Validation score   (roc_auc)\n",
      "\t83.47s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r79_BAG_L1 ... Training model for up to 5034.38s of the 5034.36s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.02%)\n",
      "\tWarning: Exception caused NeuralNetTorch_r79_BAG_L1 to fail during training... Skipping this model.\n",
      "\t\t\u001b[36mray::_ray_fit()\u001b[39m (pid=30696, ip=127.0.0.1)\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1889, in ray._raylet.execute_task\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 201, in _fit\n",
      "    train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "    dataset = self._process_train_data(\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "    self.processor = create_preprocessor(\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\utils\\data_preprocessor.py\", line 40, in create_preprocessor\n",
      "    return ColumnTransformer(\n",
      "TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 2106, in _train_and_save\n",
      "    model = self._train_single(**model_fit_kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 1993, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\stacker_ensemble_model.py\", line 270, in _fit\n",
      "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\bagged_ensemble_model.py\", line 298, in _fit\n",
      "    self._fit_folds(\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\bagged_ensemble_model.py\", line 724, in _fit_folds\n",
      "    fold_fitting_strategy.after_all_folds_scheduled()\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 690, in after_all_folds_scheduled\n",
      "    self._run_parallel(X, y, X_pseudo, y_pseudo, model_base_ref, time_limit_fold, head_node_id)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 631, in _run_parallel\n",
      "    self._process_fold_results(finished, unfinished, fold_ctx)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 587, in _process_fold_results\n",
      "    raise processed_exception\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 550, in _process_fold_results\n",
      "    fold_model, pred_proba, time_start_fit, time_end_fit, predict_time, predict_1_time, predict_n_size, fit_num_cpus, fit_num_gpus = self.ray.get(finished)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\worker.py\", line 2667, in get\n",
      "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\worker.py\", line 864, in get_objects\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(TypeError): \u001b[36mray::_ray_fit()\u001b[39m (pid=30696, ip=127.0.0.1)\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1889, in ray._raylet.execute_task\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 201, in _fit\n",
      "    train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "    dataset = self._process_train_data(\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "    self.processor = create_preprocessor(\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\utils\\data_preprocessor.py\", line 40, in create_preprocessor\n",
      "    return ColumnTransformer(\n",
      "TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "Fitting model: LightGBM_r131_BAG_L1 ... Training model for up to 5028.98s of the 5028.96s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.80%)\n",
      "\t0.9162\t = Validation score   (roc_auc)\n",
      "\t2.13s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r191_BAG_L1 ... Training model for up to 5024.41s of the 5024.40s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.04%)\n",
      "2025-01-30 00:35:19,013\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-30 00:35:19,030\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-30 00:35:19,033\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-30 00:35:19,036\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-30 00:35:19,039\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-30 00:35:19,044\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\t0.8851\t = Validation score   (roc_auc)\n",
      "\t10.35s\t = Training   runtime\n",
      "\t0.11s\t = Validation runtime\n",
      "Fitting model: CatBoost_r9_BAG_L1 ... Training model for up to 5011.46s of the 5011.45s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=3.31%)\n",
      "\t0.9236\t = Validation score   (roc_auc)\n",
      "\t80.56s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: LightGBM_r96_BAG_L1 ... Training model for up to 4928.37s of the 4928.35s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.19%)\n",
      "\t0.915\t = Validation score   (roc_auc)\n",
      "\t3.94s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r22_BAG_L1 ... Training model for up to 4922.09s of the 4922.08s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.02%)\n",
      "\tWarning: Exception caused NeuralNetTorch_r22_BAG_L1 to fail during training... Skipping this model.\n",
      "\t\t\u001b[36mray::_ray_fit()\u001b[39m (pid=14192, ip=127.0.0.1)\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1889, in ray._raylet.execute_task\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 201, in _fit\n",
      "    train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "    dataset = self._process_train_data(\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "    self.processor = create_preprocessor(\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\utils\\data_preprocessor.py\", line 40, in create_preprocessor\n",
      "    return ColumnTransformer(\n",
      "TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 2106, in _train_and_save\n",
      "    model = self._train_single(**model_fit_kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 1993, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\stacker_ensemble_model.py\", line 270, in _fit\n",
      "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\bagged_ensemble_model.py\", line 298, in _fit\n",
      "    self._fit_folds(\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\bagged_ensemble_model.py\", line 724, in _fit_folds\n",
      "    fold_fitting_strategy.after_all_folds_scheduled()\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 690, in after_all_folds_scheduled\n",
      "    self._run_parallel(X, y, X_pseudo, y_pseudo, model_base_ref, time_limit_fold, head_node_id)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 631, in _run_parallel\n",
      "    self._process_fold_results(finished, unfinished, fold_ctx)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 587, in _process_fold_results\n",
      "    raise processed_exception\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 550, in _process_fold_results\n",
      "    fold_model, pred_proba, time_start_fit, time_end_fit, predict_time, predict_1_time, predict_n_size, fit_num_cpus, fit_num_gpus = self.ray.get(finished)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\worker.py\", line 2667, in get\n",
      "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\worker.py\", line 864, in get_objects\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(TypeError): \u001b[36mray::_ray_fit()\u001b[39m (pid=14192, ip=127.0.0.1)\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1889, in ray._raylet.execute_task\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 201, in _fit\n",
      "    train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "    dataset = self._process_train_data(\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "    self.processor = create_preprocessor(\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\utils\\data_preprocessor.py\", line 40, in create_preprocessor\n",
      "    return ColumnTransformer(\n",
      "TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "Fitting model: XGBoost_r33_BAG_L1 ... Training model for up to 4916.98s of the 4916.96s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=8.00%)\n",
      "2025-01-30 00:37:10,256\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-30 00:37:10,259\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-30 00:37:10,261\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-30 00:37:10,264\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\t0.9088\t = Validation score   (roc_auc)\n",
      "\t3.16s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: CatBoost_r137_BAG_L1 ... Training model for up to 4911.34s of the 4911.32s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.24%)\n",
      "\t0.924\t = Validation score   (roc_auc)\n",
      "\t72.49s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r102_BAG_L1 ... Training model for up to 4836.40s of the 4836.38s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.04%)\n",
      "\t0.9014\t = Validation score   (roc_auc)\n",
      "\t7.2s\t = Training   runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitting model: CatBoost_r13_BAG_L1 ... Training model for up to 4826.88s of the 4826.87s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=5.83%)\n",
      "2025-01-30 00:42:12,960\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\t0.9222\t = Validation score   (roc_auc)\n",
      "\t229.94s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: LightGBM_r188_BAG_L1 ... Training model for up to 4593.86s of the 4593.84s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=1.52%)\n",
      "\t0.9346\t = Validation score   (roc_auc)\n",
      "\t2.07s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r145_BAG_L1 ... Training model for up to 4589.42s of the 4589.40s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.04%)\n",
      "\t0.8495\t = Validation score   (roc_auc)\n",
      "\t5.98s\t = Training   runtime\n",
      "\t0.09s\t = Validation runtime\n",
      "Fitting model: XGBoost_r89_BAG_L1 ... Training model for up to 4580.91s of the 4580.90s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=1.55%)\n",
      "\t0.9082\t = Validation score   (roc_auc)\n",
      "\t1.84s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r30_BAG_L1 ... Training model for up to 4575.90s of the 4575.89s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.02%)\n",
      "\tWarning: Exception caused NeuralNetTorch_r30_BAG_L1 to fail during training... Skipping this model.\n",
      "\t\t\u001b[36mray::_ray_fit()\u001b[39m (pid=14900, ip=127.0.0.1)\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1889, in ray._raylet.execute_task\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 201, in _fit\n",
      "    train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "    dataset = self._process_train_data(\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "    self.processor = create_preprocessor(\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\utils\\data_preprocessor.py\", line 40, in create_preprocessor\n",
      "    return ColumnTransformer(\n",
      "TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 2106, in _train_and_save\n",
      "    model = self._train_single(**model_fit_kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 1993, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\stacker_ensemble_model.py\", line 270, in _fit\n",
      "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\bagged_ensemble_model.py\", line 298, in _fit\n",
      "    self._fit_folds(\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\bagged_ensemble_model.py\", line 724, in _fit_folds\n",
      "    fold_fitting_strategy.after_all_folds_scheduled()\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 690, in after_all_folds_scheduled\n",
      "    self._run_parallel(X, y, X_pseudo, y_pseudo, model_base_ref, time_limit_fold, head_node_id)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 631, in _run_parallel\n",
      "    self._process_fold_results(finished, unfinished, fold_ctx)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 587, in _process_fold_results\n",
      "    raise processed_exception\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 550, in _process_fold_results\n",
      "    fold_model, pred_proba, time_start_fit, time_end_fit, predict_time, predict_1_time, predict_n_size, fit_num_cpus, fit_num_gpus = self.ray.get(finished)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\worker.py\", line 2667, in get\n",
      "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\worker.py\", line 864, in get_objects\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(TypeError): \u001b[36mray::_ray_fit()\u001b[39m (pid=14900, ip=127.0.0.1)\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1889, in ray._raylet.execute_task\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 201, in _fit\n",
      "    train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "    dataset = self._process_train_data(\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "    self.processor = create_preprocessor(\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\utils\\data_preprocessor.py\", line 40, in create_preprocessor\n",
      "    return ColumnTransformer(\n",
      "TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "Fitting model: LightGBM_r130_BAG_L1 ... Training model for up to 4570.11s of the 4570.10s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=1.55%)\n",
      "\t0.9042\t = Validation score   (roc_auc)\n",
      "\t2.0s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r86_BAG_L1 ... Training model for up to 4565.47s of the 4565.45s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.02%)\n",
      "2025-01-30 00:42:57,206\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-30 00:42:57,210\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-30 00:42:57,213\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-30 00:42:57,216\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-30 00:42:57,220\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-30 00:42:57,223\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-30 00:42:57,227\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\tWarning: Exception caused NeuralNetTorch_r86_BAG_L1 to fail during training... Skipping this model.\n",
      "\t\t\u001b[36mray::_ray_fit()\u001b[39m (pid=9052, ip=127.0.0.1)\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1889, in ray._raylet.execute_task\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 201, in _fit\n",
      "    train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "    dataset = self._process_train_data(\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "    self.processor = create_preprocessor(\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\utils\\data_preprocessor.py\", line 40, in create_preprocessor\n",
      "    return ColumnTransformer(\n",
      "TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 2106, in _train_and_save\n",
      "    model = self._train_single(**model_fit_kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 1993, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\stacker_ensemble_model.py\", line 270, in _fit\n",
      "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\bagged_ensemble_model.py\", line 298, in _fit\n",
      "    self._fit_folds(\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\bagged_ensemble_model.py\", line 724, in _fit_folds\n",
      "    fold_fitting_strategy.after_all_folds_scheduled()\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 690, in after_all_folds_scheduled\n",
      "    self._run_parallel(X, y, X_pseudo, y_pseudo, model_base_ref, time_limit_fold, head_node_id)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 631, in _run_parallel\n",
      "    self._process_fold_results(finished, unfinished, fold_ctx)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 587, in _process_fold_results\n",
      "    raise processed_exception\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 550, in _process_fold_results\n",
      "    fold_model, pred_proba, time_start_fit, time_end_fit, predict_time, predict_1_time, predict_n_size, fit_num_cpus, fit_num_gpus = self.ray.get(finished)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\worker.py\", line 2667, in get\n",
      "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\worker.py\", line 864, in get_objects\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(TypeError): \u001b[36mray::_ray_fit()\u001b[39m (pid=9052, ip=127.0.0.1)\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1889, in ray._raylet.execute_task\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 201, in _fit\n",
      "    train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "    dataset = self._process_train_data(\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "    self.processor = create_preprocessor(\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\utils\\data_preprocessor.py\", line 40, in create_preprocessor\n",
      "    return ColumnTransformer(\n",
      "TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "Fitting model: CatBoost_r50_BAG_L1 ... Training model for up to 4559.90s of the 4559.89s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.37%)\n",
      "2025-01-30 00:43:07,327\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-30 00:43:07,330\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-30 00:43:07,333\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\t0.9326\t = Validation score   (roc_auc)\n",
      "\t16.34s\t = Training   runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r11_BAG_L1 ... Training model for up to 4540.95s of the 4540.94s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.05%)\n",
      "\t0.8508\t = Validation score   (roc_auc)\n",
      "\t7.32s\t = Training   runtime\n",
      "\t0.11s\t = Validation runtime\n",
      "Fitting model: XGBoost_r194_BAG_L1 ... Training model for up to 4531.22s of the 4531.21s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=4.12%)\n",
      "\t0.912\t = Validation score   (roc_auc)\n",
      "\t2.21s\t = Training   runtime\n",
      "\t0.12s\t = Validation runtime\n",
      "Fitting model: CatBoost_r69_BAG_L1 ... Training model for up to 4525.30s of the 4525.29s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.42%)\n",
      "2025-01-30 00:44:04,991\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-30 00:44:05,007\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-30 00:44:05,009\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\t0.9213\t = Validation score   (roc_auc)\n",
      "\t27.3s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r103_BAG_L1 ... Training model for up to 4495.21s of the 4495.20s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.03%)\n",
      "\t0.9066\t = Validation score   (roc_auc)\n",
      "\t8.54s\t = Training   runtime\n",
      "\t0.09s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r14_BAG_L1 ... Training model for up to 4484.27s of the 4484.26s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.02%)\n",
      "\tWarning: Exception caused NeuralNetTorch_r14_BAG_L1 to fail during training... Skipping this model.\n",
      "\t\t\u001b[36mray::_ray_fit()\u001b[39m (pid=7444, ip=127.0.0.1)\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1889, in ray._raylet.execute_task\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 201, in _fit\n",
      "    train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "    dataset = self._process_train_data(\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "    self.processor = create_preprocessor(\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\utils\\data_preprocessor.py\", line 40, in create_preprocessor\n",
      "    return ColumnTransformer(\n",
      "TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 2106, in _train_and_save\n",
      "    model = self._train_single(**model_fit_kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 1993, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\stacker_ensemble_model.py\", line 270, in _fit\n",
      "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\bagged_ensemble_model.py\", line 298, in _fit\n",
      "    self._fit_folds(\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\bagged_ensemble_model.py\", line 724, in _fit_folds\n",
      "    fold_fitting_strategy.after_all_folds_scheduled()\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 690, in after_all_folds_scheduled\n",
      "    self._run_parallel(X, y, X_pseudo, y_pseudo, model_base_ref, time_limit_fold, head_node_id)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 631, in _run_parallel\n",
      "    self._process_fold_results(finished, unfinished, fold_ctx)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 587, in _process_fold_results\n",
      "    raise processed_exception\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 550, in _process_fold_results\n",
      "    fold_model, pred_proba, time_start_fit, time_end_fit, predict_time, predict_1_time, predict_n_size, fit_num_cpus, fit_num_gpus = self.ray.get(finished)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\worker.py\", line 2667, in get\n",
      "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\worker.py\", line 864, in get_objects\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(TypeError): \u001b[36mray::_ray_fit()\u001b[39m (pid=7444, ip=127.0.0.1)\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1889, in ray._raylet.execute_task\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 201, in _fit\n",
      "    train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "    dataset = self._process_train_data(\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "    self.processor = create_preprocessor(\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\utils\\data_preprocessor.py\", line 40, in create_preprocessor\n",
      "    return ColumnTransformer(\n",
      "TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "Fitting model: LightGBM_r161_BAG_L1 ... Training model for up to 4478.40s of the 4478.38s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=3.78%)\n",
      "\t0.914\t = Validation score   (roc_auc)\n",
      "\t3.02s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r143_BAG_L1 ... Training model for up to 4472.81s of the 4472.80s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.03%)\n",
      "2025-01-30 00:44:29,310\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-30 00:44:29,313\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-30 00:44:29,317\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-30 00:44:29,320\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-30 00:44:29,323\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-30 00:44:29,328\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\t0.9246\t = Validation score   (roc_auc)\n",
      "\t7.86s\t = Training   runtime\n",
      "\t0.09s\t = Validation runtime\n",
      "Fitting model: CatBoost_r70_BAG_L1 ... Training model for up to 4462.48s of the 4462.46s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=1.34%)\n",
      "\t0.9263\t = Validation score   (roc_auc)\n",
      "\t33.15s\t = Training   runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r156_BAG_L1 ... Training model for up to 4425.99s of the 4425.97s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.03%)\n",
      "\t0.906\t = Validation score   (roc_auc)\n",
      "\t7.91s\t = Training   runtime\n",
      "\t0.09s\t = Validation runtime\n",
      "Fitting model: LightGBM_r196_BAG_L1 ... Training model for up to 4415.74s of the 4415.72s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=2.19%)\n",
      "\t0.9316\t = Validation score   (roc_auc)\n",
      "\t4.87s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: CatBoost_r167_BAG_L1 ... Training model for up to 4407.80s of the 4407.78s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=1.44%)\n",
      "\t0.9202\t = Validation score   (roc_auc)\n",
      "\t32.59s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r95_BAG_L1 ... Training model for up to 4372.84s of the 4372.83s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.03%)\n",
      "\t0.8358\t = Validation score   (roc_auc)\n",
      "\t5.91s\t = Training   runtime\n",
      "\t0.09s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r41_BAG_L1 ... Training model for up to 4364.57s of the 4364.55s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.03%)\n",
      "\tWarning: Exception caused NeuralNetTorch_r41_BAG_L1 to fail during training... Skipping this model.\n",
      "\t\t\u001b[36mray::_ray_fit()\u001b[39m (pid=16912, ip=127.0.0.1)\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1889, in ray._raylet.execute_task\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 201, in _fit\n",
      "    train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "    dataset = self._process_train_data(\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "    self.processor = create_preprocessor(\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\utils\\data_preprocessor.py\", line 40, in create_preprocessor\n",
      "    return ColumnTransformer(\n",
      "TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 2106, in _train_and_save\n",
      "    model = self._train_single(**model_fit_kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 1993, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\stacker_ensemble_model.py\", line 270, in _fit\n",
      "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\bagged_ensemble_model.py\", line 298, in _fit\n",
      "    self._fit_folds(\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\bagged_ensemble_model.py\", line 724, in _fit_folds\n",
      "    fold_fitting_strategy.after_all_folds_scheduled()\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 690, in after_all_folds_scheduled\n",
      "    self._run_parallel(X, y, X_pseudo, y_pseudo, model_base_ref, time_limit_fold, head_node_id)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 631, in _run_parallel\n",
      "    self._process_fold_results(finished, unfinished, fold_ctx)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 587, in _process_fold_results\n",
      "    raise processed_exception\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 550, in _process_fold_results\n",
      "    fold_model, pred_proba, time_start_fit, time_end_fit, predict_time, predict_1_time, predict_n_size, fit_num_cpus, fit_num_gpus = self.ray.get(finished)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\worker.py\", line 2667, in get\n",
      "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\worker.py\", line 864, in get_objects\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(TypeError): \u001b[36mray::_ray_fit()\u001b[39m (pid=16912, ip=127.0.0.1)\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1889, in ray._raylet.execute_task\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 201, in _fit\n",
      "    train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "    dataset = self._process_train_data(\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "    self.processor = create_preprocessor(\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\utils\\data_preprocessor.py\", line 40, in create_preprocessor\n",
      "    return ColumnTransformer(\n",
      "TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "Fitting model: XGBoost_r98_BAG_L1 ... Training model for up to 4358.34s of the 4358.33s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=3.26%)\n",
      "2025-01-30 00:46:29,655\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-30 00:46:29,659\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-30 00:46:29,662\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-30 00:46:29,665\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-30 00:46:29,668\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-30 00:46:29,672\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-30 00:46:29,676\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\t0.9187\t = Validation score   (roc_auc)\n",
      "\t6.51s\t = Training   runtime\n",
      "\t0.09s\t = Validation runtime\n",
      "Fitting model: LightGBM_r15_BAG_L1 ... Training model for up to 4349.17s of the 4349.16s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.26%)\n",
      "\t0.9073\t = Validation score   (roc_auc)\n",
      "\t2.18s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r158_BAG_L1 ... Training model for up to 4344.54s of the 4344.52s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.02%)\n",
      "\tWarning: Exception caused NeuralNetTorch_r158_BAG_L1 to fail during training... Skipping this model.\n",
      "\t\t\u001b[36mray::_ray_fit()\u001b[39m (pid=25520, ip=127.0.0.1)\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1889, in ray._raylet.execute_task\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 201, in _fit\n",
      "    train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "    dataset = self._process_train_data(\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "    self.processor = create_preprocessor(\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\utils\\data_preprocessor.py\", line 40, in create_preprocessor\n",
      "    return ColumnTransformer(\n",
      "TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 2106, in _train_and_save\n",
      "    model = self._train_single(**model_fit_kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 1993, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\stacker_ensemble_model.py\", line 270, in _fit\n",
      "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\bagged_ensemble_model.py\", line 298, in _fit\n",
      "    self._fit_folds(\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\bagged_ensemble_model.py\", line 724, in _fit_folds\n",
      "    fold_fitting_strategy.after_all_folds_scheduled()\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 690, in after_all_folds_scheduled\n",
      "    self._run_parallel(X, y, X_pseudo, y_pseudo, model_base_ref, time_limit_fold, head_node_id)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 631, in _run_parallel\n",
      "    self._process_fold_results(finished, unfinished, fold_ctx)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 587, in _process_fold_results\n",
      "    raise processed_exception\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 550, in _process_fold_results\n",
      "    fold_model, pred_proba, time_start_fit, time_end_fit, predict_time, predict_1_time, predict_n_size, fit_num_cpus, fit_num_gpus = self.ray.get(finished)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\worker.py\", line 2667, in get\n",
      "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\worker.py\", line 864, in get_objects\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(TypeError): \u001b[36mray::_ray_fit()\u001b[39m (pid=25520, ip=127.0.0.1)\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1889, in ray._raylet.execute_task\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 201, in _fit\n",
      "    train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "    dataset = self._process_train_data(\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "    self.processor = create_preprocessor(\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\utils\\data_preprocessor.py\", line 40, in create_preprocessor\n",
      "    return ColumnTransformer(\n",
      "TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "Fitting model: CatBoost_r86_BAG_L1 ... Training model for up to 4338.93s of the 4338.91s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=4.27%)\n",
      "2025-01-30 00:46:48,881\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-30 00:46:48,885\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-30 00:46:48,888\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-30 00:46:48,891\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-30 00:46:48,894\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-30 00:46:48,914\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-30 00:50:02,090\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-30 00:50:02,093\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-30 00:50:02,095\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-30 00:50:02,097\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-30 00:51:23,571\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-30 00:53:48,333\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\t0.9233\t = Validation score   (roc_auc)\n",
      "\t643.36s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r37_BAG_L1 ... Training model for up to 3692.85s of the 3692.84s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.03%)\n",
      "\t0.9021\t = Validation score   (roc_auc)\n",
      "\t8.51s\t = Training   runtime\n",
      "\t0.1s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r197_BAG_L1 ... Training model for up to 3681.94s of the 3681.92s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.03%)\n",
      "\tWarning: Exception caused NeuralNetTorch_r197_BAG_L1 to fail during training... Skipping this model.\n",
      "\t\t\u001b[36mray::_ray_fit()\u001b[39m (pid=23304, ip=127.0.0.1)\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1889, in ray._raylet.execute_task\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 201, in _fit\n",
      "    train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "    dataset = self._process_train_data(\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "    self.processor = create_preprocessor(\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\utils\\data_preprocessor.py\", line 40, in create_preprocessor\n",
      "    return ColumnTransformer(\n",
      "TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 2106, in _train_and_save\n",
      "    model = self._train_single(**model_fit_kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 1993, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\stacker_ensemble_model.py\", line 270, in _fit\n",
      "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\bagged_ensemble_model.py\", line 298, in _fit\n",
      "    self._fit_folds(\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\bagged_ensemble_model.py\", line 724, in _fit_folds\n",
      "    fold_fitting_strategy.after_all_folds_scheduled()\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 690, in after_all_folds_scheduled\n",
      "    self._run_parallel(X, y, X_pseudo, y_pseudo, model_base_ref, time_limit_fold, head_node_id)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 631, in _run_parallel\n",
      "    self._process_fold_results(finished, unfinished, fold_ctx)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 587, in _process_fold_results\n",
      "    raise processed_exception\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 550, in _process_fold_results\n",
      "    fold_model, pred_proba, time_start_fit, time_end_fit, predict_time, predict_1_time, predict_n_size, fit_num_cpus, fit_num_gpus = self.ray.get(finished)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\worker.py\", line 2667, in get\n",
      "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\worker.py\", line 864, in get_objects\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(TypeError): \u001b[36mray::_ray_fit()\u001b[39m (pid=23304, ip=127.0.0.1)\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1889, in ray._raylet.execute_task\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 201, in _fit\n",
      "    train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "    dataset = self._process_train_data(\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "    self.processor = create_preprocessor(\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\utils\\data_preprocessor.py\", line 40, in create_preprocessor\n",
      "    return ColumnTransformer(\n",
      "TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "Fitting model: CatBoost_r49_BAG_L1 ... Training model for up to 3676.15s of the 3676.13s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.25%)\n",
      "2025-01-30 00:57:51,056\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-30 00:57:51,060\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-30 00:57:51,063\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-30 00:57:51,067\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-30 00:57:51,070\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-30 00:57:51,074\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-30 00:57:51,078\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\t0.9274\t = Validation score   (roc_auc)\n",
      "\t30.59s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: LightGBM_r143_BAG_L1 ... Training model for up to 3643.00s of the 3642.99s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=1.87%)\n",
      "\t0.9127\t = Validation score   (roc_auc)\n",
      "\t2.55s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r134_BAG_L1 ... Training model for up to 3638.04s of the 3638.03s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.03%)\n",
      "\t0.8831\t = Validation score   (roc_auc)\n",
      "\t10.33s\t = Training   runtime\n",
      "\t0.1s\t = Validation runtime\n",
      "Fitting model: LightGBM_r94_BAG_L1 ... Training model for up to 3625.36s of the 3625.34s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.22%)\n",
      "\t0.9359\t = Validation score   (roc_auc)\n",
      "\t2.48s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r143_BAG_L1 ... Training model for up to 3620.29s of the 3620.28s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.02%)\n",
      "\tWarning: Exception caused NeuralNetTorch_r143_BAG_L1 to fail during training... Skipping this model.\n",
      "\t\t\u001b[36mray::_ray_fit()\u001b[39m (pid=32864, ip=127.0.0.1)\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1889, in ray._raylet.execute_task\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 201, in _fit\n",
      "    train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "    dataset = self._process_train_data(\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "    self.processor = create_preprocessor(\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\utils\\data_preprocessor.py\", line 40, in create_preprocessor\n",
      "    return ColumnTransformer(\n",
      "TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 2106, in _train_and_save\n",
      "    model = self._train_single(**model_fit_kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 1993, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\stacker_ensemble_model.py\", line 270, in _fit\n",
      "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\bagged_ensemble_model.py\", line 298, in _fit\n",
      "    self._fit_folds(\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\bagged_ensemble_model.py\", line 724, in _fit_folds\n",
      "    fold_fitting_strategy.after_all_folds_scheduled()\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 690, in after_all_folds_scheduled\n",
      "    self._run_parallel(X, y, X_pseudo, y_pseudo, model_base_ref, time_limit_fold, head_node_id)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 631, in _run_parallel\n",
      "    self._process_fold_results(finished, unfinished, fold_ctx)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 587, in _process_fold_results\n",
      "    raise processed_exception\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 550, in _process_fold_results\n",
      "    fold_model, pred_proba, time_start_fit, time_end_fit, predict_time, predict_1_time, predict_n_size, fit_num_cpus, fit_num_gpus = self.ray.get(finished)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\worker.py\", line 2667, in get\n",
      "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\worker.py\", line 864, in get_objects\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(TypeError): \u001b[36mray::_ray_fit()\u001b[39m (pid=32864, ip=127.0.0.1)\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1889, in ray._raylet.execute_task\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 201, in _fit\n",
      "    train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "    dataset = self._process_train_data(\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "    self.processor = create_preprocessor(\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\utils\\data_preprocessor.py\", line 40, in create_preprocessor\n",
      "    return ColumnTransformer(\n",
      "TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "Fitting model: CatBoost_r128_BAG_L1 ... Training model for up to 3614.86s of the 3614.85s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=3.58%)\n",
      "2025-01-30 00:58:52,718\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-30 00:58:52,723\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-30 00:58:52,726\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-30 00:58:52,730\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-30 00:58:52,734\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-30 00:58:52,737\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\t0.9216\t = Validation score   (roc_auc)\n",
      "\t81.11s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r111_BAG_L1 ... Training model for up to 3531.11s of the 3531.09s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.03%)\n",
      "\t0.903\t = Validation score   (roc_auc)\n",
      "\t6.88s\t = Training   runtime\n",
      "\t0.09s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r31_BAG_L1 ... Training model for up to 3521.84s of the 3521.83s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.03%)\n",
      "\tWarning: Exception caused NeuralNetTorch_r31_BAG_L1 to fail during training... Skipping this model.\n",
      "\t\t\u001b[36mray::_ray_fit()\u001b[39m (pid=31104, ip=127.0.0.1)\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1889, in ray._raylet.execute_task\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 201, in _fit\n",
      "    train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "    dataset = self._process_train_data(\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "    self.processor = create_preprocessor(\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\utils\\data_preprocessor.py\", line 40, in create_preprocessor\n",
      "    return ColumnTransformer(\n",
      "TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 2106, in _train_and_save\n",
      "    model = self._train_single(**model_fit_kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 1993, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\stacker_ensemble_model.py\", line 270, in _fit\n",
      "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\bagged_ensemble_model.py\", line 298, in _fit\n",
      "    self._fit_folds(\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\bagged_ensemble_model.py\", line 724, in _fit_folds\n",
      "    fold_fitting_strategy.after_all_folds_scheduled()\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 690, in after_all_folds_scheduled\n",
      "    self._run_parallel(X, y, X_pseudo, y_pseudo, model_base_ref, time_limit_fold, head_node_id)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 631, in _run_parallel\n",
      "    self._process_fold_results(finished, unfinished, fold_ctx)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 587, in _process_fold_results\n",
      "    raise processed_exception\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 550, in _process_fold_results\n",
      "    fold_model, pred_proba, time_start_fit, time_end_fit, predict_time, predict_1_time, predict_n_size, fit_num_cpus, fit_num_gpus = self.ray.get(finished)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\worker.py\", line 2667, in get\n",
      "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\worker.py\", line 864, in get_objects\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(TypeError): \u001b[36mray::_ray_fit()\u001b[39m (pid=31104, ip=127.0.0.1)\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1889, in ray._raylet.execute_task\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 201, in _fit\n",
      "    train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "    dataset = self._process_train_data(\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "    self.processor = create_preprocessor(\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\utils\\data_preprocessor.py\", line 40, in create_preprocessor\n",
      "    return ColumnTransformer(\n",
      "TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "Fitting model: NeuralNetFastAI_r65_BAG_L1 ... Training model for up to 3515.37s of the 3515.35s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.04%)\n",
      "2025-01-30 01:00:31,748\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-30 01:00:31,752\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-30 01:00:31,755\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-30 01:00:31,759\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-30 01:00:31,762\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-30 01:00:31,767\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-30 01:00:31,773\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\t0.8829\t = Validation score   (roc_auc)\n",
      "\t7.99s\t = Training   runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r88_BAG_L1 ... Training model for up to 3504.79s of the 3504.78s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.06%)\n",
      "\t0.8563\t = Validation score   (roc_auc)\n",
      "\t7.45s\t = Training   runtime\n",
      "\t0.09s\t = Validation runtime\n",
      "Fitting model: LightGBM_r30_BAG_L1 ... Training model for up to 3494.07s of the 3494.05s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=2.05%)\n",
      "\t0.9394\t = Validation score   (roc_auc)\n",
      "\t3.67s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: XGBoost_r49_BAG_L1 ... Training model for up to 3487.50s of the 3487.48s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=1.51%)\n",
      "\t0.898\t = Validation score   (roc_auc)\n",
      "\t2.28s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: CatBoost_r5_BAG_L1 ... Training model for up to 3482.82s of the 3482.80s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.24%)\n",
      "\t0.926\t = Validation score   (roc_auc)\n",
      "\t19.47s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r87_BAG_L1 ... Training model for up to 3460.55s of the 3460.53s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.02%)\n",
      "\tWarning: Exception caused NeuralNetTorch_r87_BAG_L1 to fail during training... Skipping this model.\n",
      "\t\t\u001b[36mray::_ray_fit()\u001b[39m (pid=18484, ip=127.0.0.1)\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1889, in ray._raylet.execute_task\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 201, in _fit\n",
      "    train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "    dataset = self._process_train_data(\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "    self.processor = create_preprocessor(\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\utils\\data_preprocessor.py\", line 40, in create_preprocessor\n",
      "    return ColumnTransformer(\n",
      "TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 2106, in _train_and_save\n",
      "    model = self._train_single(**model_fit_kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 1993, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\stacker_ensemble_model.py\", line 270, in _fit\n",
      "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\bagged_ensemble_model.py\", line 298, in _fit\n",
      "    self._fit_folds(\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\bagged_ensemble_model.py\", line 724, in _fit_folds\n",
      "    fold_fitting_strategy.after_all_folds_scheduled()\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 690, in after_all_folds_scheduled\n",
      "    self._run_parallel(X, y, X_pseudo, y_pseudo, model_base_ref, time_limit_fold, head_node_id)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 631, in _run_parallel\n",
      "    self._process_fold_results(finished, unfinished, fold_ctx)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 587, in _process_fold_results\n",
      "    raise processed_exception\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 550, in _process_fold_results\n",
      "    fold_model, pred_proba, time_start_fit, time_end_fit, predict_time, predict_1_time, predict_n_size, fit_num_cpus, fit_num_gpus = self.ray.get(finished)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\worker.py\", line 2667, in get\n",
      "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\worker.py\", line 864, in get_objects\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(TypeError): \u001b[36mray::_ray_fit()\u001b[39m (pid=18484, ip=127.0.0.1)\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1889, in ray._raylet.execute_task\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 201, in _fit\n",
      "    train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "    dataset = self._process_train_data(\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "    self.processor = create_preprocessor(\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\utils\\data_preprocessor.py\", line 40, in create_preprocessor\n",
      "    return ColumnTransformer(\n",
      "TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "Fitting model: NeuralNetTorch_r71_BAG_L1 ... Training model for up to 3455.26s of the 3455.24s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.02%)\n",
      "\tWarning: Exception caused NeuralNetTorch_r71_BAG_L1 to fail during training... Skipping this model.\n",
      "\t\t\u001b[36mray::_ray_fit()\u001b[39m (pid=28948, ip=127.0.0.1)\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1889, in ray._raylet.execute_task\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 201, in _fit\n",
      "    train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "    dataset = self._process_train_data(\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "    self.processor = create_preprocessor(\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\utils\\data_preprocessor.py\", line 40, in create_preprocessor\n",
      "    return ColumnTransformer(\n",
      "TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 2106, in _train_and_save\n",
      "    model = self._train_single(**model_fit_kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 1993, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\stacker_ensemble_model.py\", line 270, in _fit\n",
      "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\bagged_ensemble_model.py\", line 298, in _fit\n",
      "    self._fit_folds(\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\bagged_ensemble_model.py\", line 724, in _fit_folds\n",
      "    fold_fitting_strategy.after_all_folds_scheduled()\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 690, in after_all_folds_scheduled\n",
      "    self._run_parallel(X, y, X_pseudo, y_pseudo, model_base_ref, time_limit_fold, head_node_id)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 631, in _run_parallel\n",
      "    self._process_fold_results(finished, unfinished, fold_ctx)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 587, in _process_fold_results\n",
      "    raise processed_exception\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 550, in _process_fold_results\n",
      "    fold_model, pred_proba, time_start_fit, time_end_fit, predict_time, predict_1_time, predict_n_size, fit_num_cpus, fit_num_gpus = self.ray.get(finished)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\worker.py\", line 2667, in get\n",
      "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\worker.py\", line 864, in get_objects\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(TypeError): \u001b[36mray::_ray_fit()\u001b[39m (pid=28948, ip=127.0.0.1)\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1889, in ray._raylet.execute_task\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 201, in _fit\n",
      "    train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "    dataset = self._process_train_data(\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "    self.processor = create_preprocessor(\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\utils\\data_preprocessor.py\", line 40, in create_preprocessor\n",
      "    return ColumnTransformer(\n",
      "TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "2025-01-30 01:01:32,354\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-30 01:01:32,358\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-30 01:01:32,362\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-30 01:01:32,365\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-30 01:01:32,369\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-30 01:01:32,373\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-30 01:01:32,377\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "Fitting model: CatBoost_r143_BAG_L1 ... Training model for up to 3449.69s of the 3449.67s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=1.85%)\n",
      "2025-01-30 01:01:37,487\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-30 01:01:37,493\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-30 01:01:37,496\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-30 01:01:37,499\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-30 01:01:37,502\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\t0.9072\t = Validation score   (roc_auc)\n",
      "\t59.95s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: XGBoost_r31_BAG_L1 ... Training model for up to 3387.10s of the 3387.08s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.85%)\n",
      "\t0.907\t = Validation score   (roc_auc)\n",
      "\t6.76s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r185_BAG_L1 ... Training model for up to 3377.96s of the 3377.94s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.02%)\n",
      "\tWarning: Exception caused NeuralNetTorch_r185_BAG_L1 to fail during training... Skipping this model.\n",
      "\t\t\u001b[36mray::_ray_fit()\u001b[39m (pid=22524, ip=127.0.0.1)\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1889, in ray._raylet.execute_task\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 201, in _fit\n",
      "    train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "    dataset = self._process_train_data(\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "    self.processor = create_preprocessor(\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\utils\\data_preprocessor.py\", line 40, in create_preprocessor\n",
      "    return ColumnTransformer(\n",
      "TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 2106, in _train_and_save\n",
      "    model = self._train_single(**model_fit_kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 1993, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\stacker_ensemble_model.py\", line 270, in _fit\n",
      "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\bagged_ensemble_model.py\", line 298, in _fit\n",
      "    self._fit_folds(\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\bagged_ensemble_model.py\", line 724, in _fit_folds\n",
      "    fold_fitting_strategy.after_all_folds_scheduled()\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 690, in after_all_folds_scheduled\n",
      "    self._run_parallel(X, y, X_pseudo, y_pseudo, model_base_ref, time_limit_fold, head_node_id)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 631, in _run_parallel\n",
      "    self._process_fold_results(finished, unfinished, fold_ctx)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 587, in _process_fold_results\n",
      "    raise processed_exception\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 550, in _process_fold_results\n",
      "    fold_model, pred_proba, time_start_fit, time_end_fit, predict_time, predict_1_time, predict_n_size, fit_num_cpus, fit_num_gpus = self.ray.get(finished)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\worker.py\", line 2667, in get\n",
      "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\worker.py\", line 864, in get_objects\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(TypeError): \u001b[36mray::_ray_fit()\u001b[39m (pid=22524, ip=127.0.0.1)\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1889, in ray._raylet.execute_task\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 201, in _fit\n",
      "    train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "    dataset = self._process_train_data(\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "    self.processor = create_preprocessor(\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\utils\\data_preprocessor.py\", line 40, in create_preprocessor\n",
      "    return ColumnTransformer(\n",
      "TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "Fitting model: NeuralNetFastAI_r160_BAG_L1 ... Training model for up to 3372.70s of the 3372.68s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.06%)\n",
      "2025-01-30 01:02:55,371\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-30 01:02:55,374\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-30 01:02:55,377\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-30 01:02:55,381\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-30 01:02:55,384\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-30 01:02:55,389\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\t0.8533\t = Validation score   (roc_auc)\n",
      "\t6.34s\t = Training   runtime\n",
      "\t0.09s\t = Validation runtime\n",
      "Fitting model: CatBoost_r60_BAG_L1 ... Training model for up to 3363.94s of the 3363.93s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.82%)\n",
      "\t0.9233\t = Validation score   (roc_auc)\n",
      "\t34.28s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: LightGBM_r135_BAG_L1 ... Training model for up to 3326.31s of the 3326.29s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=2.56%)\n",
      "\t0.9206\t = Validation score   (roc_auc)\n",
      "\t2.48s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: XGBoost_r22_BAG_L1 ... Training model for up to 3321.44s of the 3321.43s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.86%)\n",
      "\t0.9149\t = Validation score   (roc_auc)\n",
      "\t1.93s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r69_BAG_L1 ... Training model for up to 3317.18s of the 3317.17s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.04%)\n",
      "\t0.868\t = Validation score   (roc_auc)\n",
      "\t5.95s\t = Training   runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitting model: CatBoost_r6_BAG_L1 ... Training model for up to 3308.57s of the 3308.55s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.43%)\n",
      "\t0.9346\t = Validation score   (roc_auc)\n",
      "\t23.67s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r138_BAG_L1 ... Training model for up to 3281.55s of the 3281.53s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.04%)\n",
      "\t0.8617\t = Validation score   (roc_auc)\n",
      "\t6.66s\t = Training   runtime\n",
      "\t0.1s\t = Validation runtime\n",
      "Fitting model: LightGBM_r121_BAG_L1 ... Training model for up to 3272.50s of the 3272.49s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=5.34%)\n",
      "\t0.9214\t = Validation score   (roc_auc)\n",
      "\t2.87s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r172_BAG_L1 ... Training model for up to 3266.32s of the 3266.30s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.04%)\n",
      "\t0.8843\t = Validation score   (roc_auc)\n",
      "\t7.67s\t = Training   runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitting model: CatBoost_r180_BAG_L1 ... Training model for up to 3256.22s of the 3256.20s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=3.15%)\n",
      "2025-01-30 01:05:47,102\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\t0.9309\t = Validation score   (roc_auc)\n",
      "\t62.1s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r76_BAG_L1 ... Training model for up to 3190.62s of the 3190.61s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.02%)\n",
      "\tWarning: Exception caused NeuralNetTorch_r76_BAG_L1 to fail during training... Skipping this model.\n",
      "\t\t\u001b[36mray::_ray_fit()\u001b[39m (pid=30252, ip=127.0.0.1)\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1889, in ray._raylet.execute_task\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 201, in _fit\n",
      "    train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "    dataset = self._process_train_data(\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "    self.processor = create_preprocessor(\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\utils\\data_preprocessor.py\", line 40, in create_preprocessor\n",
      "    return ColumnTransformer(\n",
      "TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 2106, in _train_and_save\n",
      "    model = self._train_single(**model_fit_kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 1993, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\stacker_ensemble_model.py\", line 270, in _fit\n",
      "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\bagged_ensemble_model.py\", line 298, in _fit\n",
      "    self._fit_folds(\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\bagged_ensemble_model.py\", line 724, in _fit_folds\n",
      "    fold_fitting_strategy.after_all_folds_scheduled()\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 690, in after_all_folds_scheduled\n",
      "    self._run_parallel(X, y, X_pseudo, y_pseudo, model_base_ref, time_limit_fold, head_node_id)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 631, in _run_parallel\n",
      "    self._process_fold_results(finished, unfinished, fold_ctx)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 587, in _process_fold_results\n",
      "    raise processed_exception\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 550, in _process_fold_results\n",
      "    fold_model, pred_proba, time_start_fit, time_end_fit, predict_time, predict_1_time, predict_n_size, fit_num_cpus, fit_num_gpus = self.ray.get(finished)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\worker.py\", line 2667, in get\n",
      "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\worker.py\", line 864, in get_objects\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(TypeError): \u001b[36mray::_ray_fit()\u001b[39m (pid=30252, ip=127.0.0.1)\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1889, in ray._raylet.execute_task\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 201, in _fit\n",
      "    train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "    dataset = self._process_train_data(\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "    self.processor = create_preprocessor(\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\utils\\data_preprocessor.py\", line 40, in create_preprocessor\n",
      "    return ColumnTransformer(\n",
      "TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "Fitting model: NeuralNetTorch_r121_BAG_L1 ... Training model for up to 3185.45s of the 3185.43s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.02%)\n",
      "\tWarning: Exception caused NeuralNetTorch_r121_BAG_L1 to fail during training... Skipping this model.\n",
      "\t\t\u001b[36mray::_ray_fit()\u001b[39m (pid=28484, ip=127.0.0.1)\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1889, in ray._raylet.execute_task\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 201, in _fit\n",
      "    train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "    dataset = self._process_train_data(\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "    self.processor = create_preprocessor(\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\utils\\data_preprocessor.py\", line 40, in create_preprocessor\n",
      "    return ColumnTransformer(\n",
      "TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 2106, in _train_and_save\n",
      "    model = self._train_single(**model_fit_kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 1993, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\stacker_ensemble_model.py\", line 270, in _fit\n",
      "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\bagged_ensemble_model.py\", line 298, in _fit\n",
      "    self._fit_folds(\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\bagged_ensemble_model.py\", line 724, in _fit_folds\n",
      "    fold_fitting_strategy.after_all_folds_scheduled()\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 690, in after_all_folds_scheduled\n",
      "    self._run_parallel(X, y, X_pseudo, y_pseudo, model_base_ref, time_limit_fold, head_node_id)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 631, in _run_parallel\n",
      "    self._process_fold_results(finished, unfinished, fold_ctx)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 587, in _process_fold_results\n",
      "    raise processed_exception\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 550, in _process_fold_results\n",
      "    fold_model, pred_proba, time_start_fit, time_end_fit, predict_time, predict_1_time, predict_n_size, fit_num_cpus, fit_num_gpus = self.ray.get(finished)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\worker.py\", line 2667, in get\n",
      "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\worker.py\", line 864, in get_objects\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(TypeError): \u001b[36mray::_ray_fit()\u001b[39m (pid=28484, ip=127.0.0.1)\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1889, in ray._raylet.execute_task\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 201, in _fit\n",
      "    train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "    dataset = self._process_train_data(\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "    self.processor = create_preprocessor(\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\utils\\data_preprocessor.py\", line 40, in create_preprocessor\n",
      "    return ColumnTransformer(\n",
      "TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "2025-01-30 01:06:01,981\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-30 01:06:01,986\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-30 01:06:01,989\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-30 01:06:01,992\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-30 01:06:01,998\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-30 01:06:02,003\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "Fitting model: NeuralNetFastAI_r127_BAG_L1 ... Training model for up to 3180.07s of the 3180.05s of remaining time.\n",
      "2025-01-30 01:06:02,008\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.04%)\n",
      "2025-01-30 01:06:07,650\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-30 01:06:07,653\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-30 01:06:07,656\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-30 01:06:07,660\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-30 01:06:07,663\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-30 01:06:07,666\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\t0.8905\t = Validation score   (roc_auc)\n",
      "\t7.37s\t = Training   runtime\n",
      "\t0.09s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r194_BAG_L1 ... Training model for up to 3170.09s of the 3170.08s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.07%)\n",
      "\t0.8769\t = Validation score   (roc_auc)\n",
      "\t7.58s\t = Training   runtime\n",
      "\t0.1s\t = Validation runtime\n",
      "Fitting model: CatBoost_r12_BAG_L1 ... Training model for up to 3159.25s of the 3159.24s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=3.15%)\n",
      "\t0.9235\t = Validation score   (roc_auc)\n",
      "\t94.34s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r135_BAG_L1 ... Training model for up to 3061.80s of the 3061.78s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.02%)\n",
      "\tWarning: Exception caused NeuralNetTorch_r135_BAG_L1 to fail during training... Skipping this model.\n",
      "\t\t\u001b[36mray::_ray_fit()\u001b[39m (pid=33656, ip=127.0.0.1)\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1889, in ray._raylet.execute_task\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 201, in _fit\n",
      "    train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "    dataset = self._process_train_data(\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "    self.processor = create_preprocessor(\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\utils\\data_preprocessor.py\", line 40, in create_preprocessor\n",
      "    return ColumnTransformer(\n",
      "TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 2106, in _train_and_save\n",
      "    model = self._train_single(**model_fit_kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 1993, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\stacker_ensemble_model.py\", line 270, in _fit\n",
      "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\bagged_ensemble_model.py\", line 298, in _fit\n",
      "    self._fit_folds(\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\bagged_ensemble_model.py\", line 724, in _fit_folds\n",
      "    fold_fitting_strategy.after_all_folds_scheduled()\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 690, in after_all_folds_scheduled\n",
      "    self._run_parallel(X, y, X_pseudo, y_pseudo, model_base_ref, time_limit_fold, head_node_id)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 631, in _run_parallel\n",
      "    self._process_fold_results(finished, unfinished, fold_ctx)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 587, in _process_fold_results\n",
      "    raise processed_exception\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 550, in _process_fold_results\n",
      "    fold_model, pred_proba, time_start_fit, time_end_fit, predict_time, predict_1_time, predict_n_size, fit_num_cpus, fit_num_gpus = self.ray.get(finished)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\worker.py\", line 2667, in get\n",
      "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\worker.py\", line 864, in get_objects\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(TypeError): \u001b[36mray::_ray_fit()\u001b[39m (pid=33656, ip=127.0.0.1)\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1889, in ray._raylet.execute_task\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 201, in _fit\n",
      "    train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "    dataset = self._process_train_data(\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "    self.processor = create_preprocessor(\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\utils\\data_preprocessor.py\", line 40, in create_preprocessor\n",
      "    return ColumnTransformer(\n",
      "TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "Fitting model: NeuralNetFastAI_r4_BAG_L1 ... Training model for up to 3056.61s of the 3056.59s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.05%)\n",
      "2025-01-30 01:08:11,063\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-30 01:08:11,067\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-30 01:08:11,070\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-30 01:08:11,073\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-30 01:08:11,079\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-30 01:08:11,082\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-30 01:08:11,085\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\t0.9233\t = Validation score   (roc_auc)\n",
      "\t7.72s\t = Training   runtime\n",
      "\t0.09s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r36_BAG_L1 ... Training model for up to 3046.45s of the 3046.44s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.03%)\n",
      "\tWarning: Exception caused NeuralNetTorch_r36_BAG_L1 to fail during training... Skipping this model.\n",
      "\t\t\u001b[36mray::_ray_fit()\u001b[39m (pid=19436, ip=127.0.0.1)\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1889, in ray._raylet.execute_task\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 201, in _fit\n",
      "    train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "    dataset = self._process_train_data(\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "    self.processor = create_preprocessor(\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\utils\\data_preprocessor.py\", line 40, in create_preprocessor\n",
      "    return ColumnTransformer(\n",
      "TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 2106, in _train_and_save\n",
      "    model = self._train_single(**model_fit_kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 1993, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\stacker_ensemble_model.py\", line 270, in _fit\n",
      "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\bagged_ensemble_model.py\", line 298, in _fit\n",
      "    self._fit_folds(\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\bagged_ensemble_model.py\", line 724, in _fit_folds\n",
      "    fold_fitting_strategy.after_all_folds_scheduled()\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 690, in after_all_folds_scheduled\n",
      "    self._run_parallel(X, y, X_pseudo, y_pseudo, model_base_ref, time_limit_fold, head_node_id)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 631, in _run_parallel\n",
      "    self._process_fold_results(finished, unfinished, fold_ctx)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 587, in _process_fold_results\n",
      "    raise processed_exception\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 550, in _process_fold_results\n",
      "    fold_model, pred_proba, time_start_fit, time_end_fit, predict_time, predict_1_time, predict_n_size, fit_num_cpus, fit_num_gpus = self.ray.get(finished)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\worker.py\", line 2667, in get\n",
      "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\worker.py\", line 864, in get_objects\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(TypeError): \u001b[36mray::_ray_fit()\u001b[39m (pid=19436, ip=127.0.0.1)\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1889, in ray._raylet.execute_task\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 201, in _fit\n",
      "    train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "    dataset = self._process_train_data(\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "    self.processor = create_preprocessor(\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\utils\\data_preprocessor.py\", line 40, in create_preprocessor\n",
      "    return ColumnTransformer(\n",
      "TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "Fitting model: NeuralNetFastAI_r100_BAG_L1 ... Training model for up to 3040.31s of the 3040.30s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.06%)\n",
      "2025-01-30 01:08:27,224\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-30 01:08:27,227\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-30 01:08:32,267\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-30 01:08:32,274\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\t0.8526\t = Validation score   (roc_auc)\n",
      "\t11.32s\t = Training   runtime\n",
      "\t0.12s\t = Validation runtime\n",
      "Fitting model: CatBoost_r163_BAG_L1 ... Training model for up to 3026.38s of the 3026.36s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.56%)\n",
      "\t0.9291\t = Validation score   (roc_auc)\n",
      "\t21.92s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: CatBoost_r198_BAG_L1 ... Training model for up to 3001.68s of the 3001.67s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.80%)\n",
      "2025-01-30 01:09:49,277\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\t0.9309\t = Validation score   (roc_auc)\n",
      "\t57.14s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r187_BAG_L1 ... Training model for up to 2942.15s of the 2942.13s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.04%)\n",
      "\t0.8994\t = Validation score   (roc_auc)\n",
      "\t8.06s\t = Training   runtime\n",
      "\t0.09s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r19_BAG_L1 ... Training model for up to 2931.63s of the 2931.62s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.03%)\n",
      "\tWarning: Exception caused NeuralNetTorch_r19_BAG_L1 to fail during training... Skipping this model.\n",
      "\t\t\u001b[36mray::_ray_fit()\u001b[39m (pid=29300, ip=127.0.0.1)\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1889, in ray._raylet.execute_task\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 201, in _fit\n",
      "    train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "    dataset = self._process_train_data(\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "    self.processor = create_preprocessor(\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\utils\\data_preprocessor.py\", line 40, in create_preprocessor\n",
      "    return ColumnTransformer(\n",
      "TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 2106, in _train_and_save\n",
      "    model = self._train_single(**model_fit_kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 1993, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\stacker_ensemble_model.py\", line 270, in _fit\n",
      "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\bagged_ensemble_model.py\", line 298, in _fit\n",
      "    self._fit_folds(\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\bagged_ensemble_model.py\", line 724, in _fit_folds\n",
      "    fold_fitting_strategy.after_all_folds_scheduled()\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 690, in after_all_folds_scheduled\n",
      "    self._run_parallel(X, y, X_pseudo, y_pseudo, model_base_ref, time_limit_fold, head_node_id)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 631, in _run_parallel\n",
      "    self._process_fold_results(finished, unfinished, fold_ctx)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 587, in _process_fold_results\n",
      "    raise processed_exception\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 550, in _process_fold_results\n",
      "    fold_model, pred_proba, time_start_fit, time_end_fit, predict_time, predict_1_time, predict_n_size, fit_num_cpus, fit_num_gpus = self.ray.get(finished)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\worker.py\", line 2667, in get\n",
      "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\worker.py\", line 864, in get_objects\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(TypeError): \u001b[36mray::_ray_fit()\u001b[39m (pid=29300, ip=127.0.0.1)\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1889, in ray._raylet.execute_task\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 201, in _fit\n",
      "    train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "    dataset = self._process_train_data(\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "    self.processor = create_preprocessor(\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\utils\\data_preprocessor.py\", line 40, in create_preprocessor\n",
      "    return ColumnTransformer(\n",
      "TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "Fitting model: XGBoost_r95_BAG_L1 ... Training model for up to 2925.89s of the 2925.88s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=1.13%)\n",
      "\t0.9069\t = Validation score   (roc_auc)\n",
      "\t2.41s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: XGBoost_r34_BAG_L1 ... Training model for up to 2920.86s of the 2920.84s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=8.02%)\n",
      "2025-01-30 01:10:21,520\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-30 01:10:21,525\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-30 01:10:21,529\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-30 01:10:21,533\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-30 01:10:21,537\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-30 01:10:21,540\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\t0.9156\t = Validation score   (roc_auc)\n",
      "\t3.39s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: LightGBM_r42_BAG_L1 ... Training model for up to 2914.86s of the 2914.85s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=2.62%)\n",
      "\t0.9255\t = Validation score   (roc_auc)\n",
      "\t1.96s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r1_BAG_L1 ... Training model for up to 2910.44s of the 2910.42s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.03%)\n",
      "\tWarning: Exception caused NeuralNetTorch_r1_BAG_L1 to fail during training... Skipping this model.\n",
      "\t\t\u001b[36mray::_ray_fit()\u001b[39m (pid=11436, ip=127.0.0.1)\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1889, in ray._raylet.execute_task\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 201, in _fit\n",
      "    train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "    dataset = self._process_train_data(\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "    self.processor = create_preprocessor(\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\utils\\data_preprocessor.py\", line 40, in create_preprocessor\n",
      "    return ColumnTransformer(\n",
      "TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 2106, in _train_and_save\n",
      "    model = self._train_single(**model_fit_kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 1993, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\stacker_ensemble_model.py\", line 270, in _fit\n",
      "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\bagged_ensemble_model.py\", line 298, in _fit\n",
      "    self._fit_folds(\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\bagged_ensemble_model.py\", line 724, in _fit_folds\n",
      "    fold_fitting_strategy.after_all_folds_scheduled()\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 690, in after_all_folds_scheduled\n",
      "    self._run_parallel(X, y, X_pseudo, y_pseudo, model_base_ref, time_limit_fold, head_node_id)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 631, in _run_parallel\n",
      "    self._process_fold_results(finished, unfinished, fold_ctx)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 587, in _process_fold_results\n",
      "    raise processed_exception\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 550, in _process_fold_results\n",
      "    fold_model, pred_proba, time_start_fit, time_end_fit, predict_time, predict_1_time, predict_n_size, fit_num_cpus, fit_num_gpus = self.ray.get(finished)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\worker.py\", line 2667, in get\n",
      "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\worker.py\", line 864, in get_objects\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(TypeError): \u001b[36mray::_ray_fit()\u001b[39m (pid=11436, ip=127.0.0.1)\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1889, in ray._raylet.execute_task\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 201, in _fit\n",
      "    train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "    dataset = self._process_train_data(\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "    self.processor = create_preprocessor(\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\utils\\data_preprocessor.py\", line 40, in create_preprocessor\n",
      "    return ColumnTransformer(\n",
      "TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "Fitting model: NeuralNetTorch_r89_BAG_L1 ... Training model for up to 2904.67s of the 2904.65s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.03%)\n",
      "2025-01-30 01:10:42,768\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-30 01:10:42,770\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-30 01:10:42,773\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-30 01:10:42,777\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-30 01:10:42,780\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-30 01:10:42,782\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-30 01:10:42,785\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\tWarning: Exception caused NeuralNetTorch_r89_BAG_L1 to fail during training... Skipping this model.\n",
      "\t\t\u001b[36mray::_ray_fit()\u001b[39m (pid=32252, ip=127.0.0.1)\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1889, in ray._raylet.execute_task\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 201, in _fit\n",
      "    train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "    dataset = self._process_train_data(\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "    self.processor = create_preprocessor(\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\utils\\data_preprocessor.py\", line 40, in create_preprocessor\n",
      "    return ColumnTransformer(\n",
      "TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 2106, in _train_and_save\n",
      "    model = self._train_single(**model_fit_kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 1993, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\stacker_ensemble_model.py\", line 270, in _fit\n",
      "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\bagged_ensemble_model.py\", line 298, in _fit\n",
      "    self._fit_folds(\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\bagged_ensemble_model.py\", line 724, in _fit_folds\n",
      "    fold_fitting_strategy.after_all_folds_scheduled()\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 690, in after_all_folds_scheduled\n",
      "    self._run_parallel(X, y, X_pseudo, y_pseudo, model_base_ref, time_limit_fold, head_node_id)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 631, in _run_parallel\n",
      "    self._process_fold_results(finished, unfinished, fold_ctx)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 587, in _process_fold_results\n",
      "    raise processed_exception\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 550, in _process_fold_results\n",
      "    fold_model, pred_proba, time_start_fit, time_end_fit, predict_time, predict_1_time, predict_n_size, fit_num_cpus, fit_num_gpus = self.ray.get(finished)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\worker.py\", line 2667, in get\n",
      "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\worker.py\", line 864, in get_objects\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(TypeError): \u001b[36mray::_ray_fit()\u001b[39m (pid=32252, ip=127.0.0.1)\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1889, in ray._raylet.execute_task\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 201, in _fit\n",
      "    train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "    dataset = self._process_train_data(\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "    self.processor = create_preprocessor(\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\utils\\data_preprocessor.py\", line 40, in create_preprocessor\n",
      "    return ColumnTransformer(\n",
      "TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 520.40s of the 2898.64s of remaining time.\n",
      "\tEnsemble Weights: {'LightGBMXT_BAG_L1': 0.364, 'NeuralNetFastAI_r143_BAG_L1': 0.364, 'CatBoost_r6_BAG_L1': 0.273}\n",
      "\t0.9525\t = Validation score   (roc_auc)\n",
      "\t0.03s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 2305.69s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 169.8 rows/s (32 batch size)\n",
      "Automatically performing refit_full as a post-fit operation (due to `.fit(..., refit_full=True)`\n",
      "Refitting models via `predictor.refit_full` using all of the data (combined train and validation)...\n",
      "\tModels trained in this way will have the suffix \"_FULL\" and have NaN validation score.\n",
      "\tThis process is not bound by time_limit, but should take less time than the original `predictor.fit` call.\n",
      "\tTo learn more, refer to the `.refit_full` method docstring which explains how \"_FULL\" models differ from normal models.\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBMXT_BAG_L1_FULL ...\n",
      "2025-01-30 01:10:43,952\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-30 01:10:43,956\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-30 01:10:43,962\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-30 01:10:43,964\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-30 01:10:43,967\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-30 01:10:43,970\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\t0.41s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBM_BAG_L1_FULL ...\n",
      "\t0.12s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: CatBoost_BAG_L1_FULL ...\n",
      "\t6.26s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: NeuralNetFastAI_BAG_L1_FULL ...\n",
      "\tStopping at the best epoch learned earlier - 10.\n",
      "\t1.07s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: XGBoost_BAG_L1_FULL ...\n",
      "\t0.1s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBMLarge_BAG_L1_FULL ...\n",
      "\t0.17s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: CatBoost_r177_BAG_L1_FULL ...\n",
      "\t8.45s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBM_r131_BAG_L1_FULL ...\n",
      "\t0.18s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: NeuralNetFastAI_r191_BAG_L1_FULL ...\n",
      "\tStopping at the best epoch learned earlier - 7.\n",
      "\t0.91s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: CatBoost_r9_BAG_L1_FULL ...\n",
      "\t11.94s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBM_r96_BAG_L1_FULL ...\n",
      "\t0.2s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: XGBoost_r33_BAG_L1_FULL ...\n",
      "\t0.24s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: CatBoost_r137_BAG_L1_FULL ...\n",
      "\t8.12s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: NeuralNetFastAI_r102_BAG_L1_FULL ...\n",
      "\tStopping at the best epoch learned earlier - 9.\n",
      "\t0.87s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: CatBoost_r13_BAG_L1_FULL ...\n",
      "\t29.18s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBM_r188_BAG_L1_FULL ...\n",
      "\t0.17s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: NeuralNetFastAI_r145_BAG_L1_FULL ...\n",
      "\tStopping at the best epoch learned earlier - 10.\n",
      "\t0.42s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: XGBoost_r89_BAG_L1_FULL ...\n",
      "\t0.07s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBM_r130_BAG_L1_FULL ...\n",
      "\t0.13s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: CatBoost_r50_BAG_L1_FULL ...\n",
      "\t1.26s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: NeuralNetFastAI_r11_BAG_L1_FULL ...\n",
      "\tStopping at the best epoch learned earlier - 4.\n",
      "\t0.24s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: XGBoost_r194_BAG_L1_FULL ...\n",
      "\t0.1s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: CatBoost_r69_BAG_L1_FULL ...\n",
      "\t3.35s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: NeuralNetFastAI_r103_BAG_L1_FULL ...\n",
      "\tStopping at the best epoch learned earlier - 13.\n",
      "\t1.3s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBM_r161_BAG_L1_FULL ...\n",
      "\t0.25s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: NeuralNetFastAI_r143_BAG_L1_FULL ...\n",
      "\tStopping at the best epoch learned earlier - 13.\n",
      "\t1.38s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: CatBoost_r70_BAG_L1_FULL ...\n",
      "\t3.97s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: NeuralNetFastAI_r156_BAG_L1_FULL ...\n",
      "\tStopping at the best epoch learned earlier - 11.\n",
      "\t0.94s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBM_r196_BAG_L1_FULL ...\n",
      "\t0.59s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: CatBoost_r167_BAG_L1_FULL ...\n",
      "\t3.29s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: NeuralNetFastAI_r95_BAG_L1_FULL ...\n",
      "\tStopping at the best epoch learned earlier - 7.\n",
      "\t0.32s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: XGBoost_r98_BAG_L1_FULL ...\n",
      "\t0.72s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBM_r15_BAG_L1_FULL ...\n",
      "\t0.15s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: CatBoost_r86_BAG_L1_FULL ...\n",
      "2025-01-30 01:13:01,884\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\t58.4s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: NeuralNetFastAI_r37_BAG_L1_FULL ...\n",
      "\tStopping at the best epoch learned earlier - 14.\n",
      "\t1.6s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: CatBoost_r49_BAG_L1_FULL ...\n",
      "\t3.94s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBM_r143_BAG_L1_FULL ...\n",
      "\t0.18s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: NeuralNetFastAI_r134_BAG_L1_FULL ...\n",
      "\tStopping at the best epoch learned earlier - 8.\n",
      "\t0.99s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBM_r94_BAG_L1_FULL ...\n",
      "\t0.18s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: CatBoost_r128_BAG_L1_FULL ...\n",
      "\t10.84s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: NeuralNetFastAI_r111_BAG_L1_FULL ...\n",
      "\tStopping at the best epoch learned earlier - 10.\n",
      "\t1.06s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: NeuralNetFastAI_r65_BAG_L1_FULL ...\n",
      "\tStopping at the best epoch learned earlier - 24.\n",
      "\t1.91s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: NeuralNetFastAI_r88_BAG_L1_FULL ...\n",
      "\tStopping at the best epoch learned earlier - 5.\n",
      "\t0.54s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBM_r30_BAG_L1_FULL ...\n",
      "\t0.29s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: XGBoost_r49_BAG_L1_FULL ...\n",
      "\t0.09s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: CatBoost_r5_BAG_L1_FULL ...\n",
      "\t3.01s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: CatBoost_r143_BAG_L1_FULL ...\n",
      "\t7.07s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: XGBoost_r31_BAG_L1_FULL ...\n",
      "\t0.42s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: NeuralNetFastAI_r160_BAG_L1_FULL ...\n",
      "\tStopping at the best epoch learned earlier - 7.\n",
      "\t0.32s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: CatBoost_r60_BAG_L1_FULL ...\n",
      "\t4.53s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBM_r135_BAG_L1_FULL ...\n",
      "\t0.14s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: XGBoost_r22_BAG_L1_FULL ...\n",
      "\t0.06s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: NeuralNetFastAI_r69_BAG_L1_FULL ...\n",
      "\tStopping at the best epoch learned earlier - 8.\n",
      "\t0.33s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: CatBoost_r6_BAG_L1_FULL ...\n",
      "\t2.35s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: NeuralNetFastAI_r138_BAG_L1_FULL ...\n",
      "\tStopping at the best epoch learned earlier - 11.\n",
      "\t0.43s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBM_r121_BAG_L1_FULL ...\n",
      "\t0.25s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: NeuralNetFastAI_r172_BAG_L1_FULL ...\n",
      "\tStopping at the best epoch learned earlier - 6.\n",
      "\t0.59s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: CatBoost_r180_BAG_L1_FULL ...\n",
      "\t7.47s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: NeuralNetFastAI_r127_BAG_L1_FULL ...\n",
      "\tStopping at the best epoch learned earlier - 10.\n",
      "\t0.95s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: NeuralNetFastAI_r194_BAG_L1_FULL ...\n",
      "\tStopping at the best epoch learned earlier - 10.\n",
      "\t1.18s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: CatBoost_r12_BAG_L1_FULL ...\n",
      "\t12.2s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: NeuralNetFastAI_r4_BAG_L1_FULL ...\n",
      "\tStopping at the best epoch learned earlier - 12.\n",
      "\t0.93s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: NeuralNetFastAI_r100_BAG_L1_FULL ...\n",
      "\tStopping at the best epoch learned earlier - 8.\n",
      "\t1.01s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: CatBoost_r163_BAG_L1_FULL ...\n",
      "\t2.13s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: CatBoost_r198_BAG_L1_FULL ...\n",
      "\t7.5s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: NeuralNetFastAI_r187_BAG_L1_FULL ...\n",
      "\tStopping at the best epoch learned earlier - 12.\n",
      "\t1.29s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: XGBoost_r95_BAG_L1_FULL ...\n",
      "\t0.1s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: XGBoost_r34_BAG_L1_FULL ...\n",
      "\t0.17s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBM_r42_BAG_L1_FULL ...\n",
      "\t0.16s\t = Training   runtime\n",
      "Fitting model: WeightedEnsemble_L2_FULL | Skipping fit via cloning parent ...\n",
      "\tEnsemble Weights: {'LightGBMXT_BAG_L1': 0.364, 'NeuralNetFastAI_r143_BAG_L1': 0.364, 'CatBoost_r6_BAG_L1': 0.273}\n",
      "\t0.03s\t = Training   runtime\n",
      "Updated best model to \"WeightedEnsemble_L2_FULL\" (Previously \"WeightedEnsemble_L2\"). AutoGluon will default to using \"WeightedEnsemble_L2_FULL\" for predict() and predict_proba().\n",
      "Refit complete, total runtime = 230.28s ... Best model: \"WeightedEnsemble_L2_FULL\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\autogluon\\tlp\\AutogluonModels\\synthetic\\tvaes\\v2\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<autogluon.tabular.predictor.predictor.TabularPredictor at 0x1904bc2f2e0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.fit(\n",
    "    train_data = df_train,\n",
    "    presets = ['high_quality'],\n",
    "    time_limit = 2 * 3600,\n",
    "    auto_stack = True,\n",
    "    excluded_model_types=['KNN','RF','XT', 'LR'],\n",
    "    verbosity = 2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Summary of fit() ***\n",
      "Estimated performance of each model:\n",
      "                                model  score_val eval_metric  pred_time_val    fit_time  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
      "0                 WeightedEnsemble_L2   0.952550     roc_auc       0.188416   33.142842                0.000000           0.032883            2      False         70\n",
      "1                   LightGBMXT_BAG_L1   0.942165     roc_auc       0.039448    1.578243                0.039448           1.578243            1      False          1\n",
      "2                 LightGBM_r30_BAG_L1   0.939379     roc_auc       0.042316    3.672774                0.042316           3.672774            1      False         44\n",
      "3                 LightGBM_r94_BAG_L1   0.935917     roc_auc       0.035151    2.478766                0.035151           2.478766            1      False         39\n",
      "4                  CatBoost_r6_BAG_L1   0.934566     roc_auc       0.061259   23.672378                0.061259          23.672378            1      False         54\n",
      "5                LightGBM_r188_BAG_L1   0.934566     roc_auc       0.035149    2.066337                0.035149           2.066337            1      False         16\n",
      "6                 CatBoost_r50_BAG_L1   0.932624     roc_auc       0.066529   16.336649                0.066529          16.336649            1      False         20\n",
      "7                LightGBM_r196_BAG_L1   0.931611     roc_auc       0.049396    4.871945                0.049396           4.871945            1      False         29\n",
      "8                CatBoost_r180_BAG_L1   0.930935     roc_auc       0.059486   62.097018                0.059486          62.097018            1      False         58\n",
      "9                CatBoost_r198_BAG_L1   0.930851     roc_auc       0.064422   57.143691                0.064422          57.143691            1      False         65\n",
      "10               CatBoost_r163_BAG_L1   0.929078     roc_auc       0.057721   21.919345                0.057721          21.919345            1      False         64\n",
      "11                CatBoost_r49_BAG_L1   0.927389     roc_auc       0.056279   30.590431                0.056279          30.590431            1      False         36\n",
      "12               CatBoost_r177_BAG_L1   0.926630     roc_auc       0.056402   83.467856                0.056402          83.467856            1      False          7\n",
      "13                CatBoost_r70_BAG_L1   0.926292     roc_auc       0.065362   33.148754                0.065362          33.148754            1      False         27\n",
      "14                 CatBoost_r5_BAG_L1   0.926039     roc_auc       0.054334   19.470321                0.054334          19.470321            1      False         46\n",
      "15                LightGBM_r42_BAG_L1   0.925532     roc_auc       0.032320    1.957783                0.032320           1.957783            1      False         69\n",
      "16        NeuralNetFastAI_r143_BAG_L1   0.924603     roc_auc       0.087709    7.859338                0.087709           7.859338            1      False         26\n",
      "17               CatBoost_r137_BAG_L1   0.924012     roc_auc       0.053461   72.487751                0.053461          72.487751            1      False         13\n",
      "18                 CatBoost_r9_BAG_L1   0.923590     roc_auc       0.060614   80.558079                0.060614          80.558079            1      False         10\n",
      "19                CatBoost_r12_BAG_L1   0.923506     roc_auc       0.062084   94.341337                0.062084          94.341337            1      False         61\n",
      "20                CatBoost_r60_BAG_L1   0.923337     roc_auc       0.056488   34.281377                0.056488          34.281377            1      False         50\n",
      "21                CatBoost_r86_BAG_L1   0.923337     roc_auc       0.060136  643.359681                0.060136         643.359681            1      False         34\n",
      "22                    CatBoost_BAG_L1   0.923252     roc_auc       0.062618   42.844146                0.062618          42.844146            1      False          3\n",
      "23          NeuralNetFastAI_r4_BAG_L1   0.923252     roc_auc       0.089754    7.723455                0.089754           7.723455            1      False         62\n",
      "24                CatBoost_r13_BAG_L1   0.922239     roc_auc       0.062747  229.941207                0.062747         229.941207            1      False         15\n",
      "25               CatBoost_r128_BAG_L1   0.921648     roc_auc       0.063688   81.110201                0.063688          81.110201            1      False         40\n",
      "26               LightGBM_r121_BAG_L1   0.921395     roc_auc       0.040356    2.874527                0.040356           2.874527            1      False         56\n",
      "27                CatBoost_r69_BAG_L1   0.921310     roc_auc       0.062091   27.296521                0.062091          27.296521            1      False         23\n",
      "28               LightGBM_r135_BAG_L1   0.920635     roc_auc       0.035744    2.481856                0.035744           2.481856            1      False         51\n",
      "29               CatBoost_r167_BAG_L1   0.920213     roc_auc       0.055431   32.590602                0.055431          32.590602            1      False         30\n",
      "30                 XGBoost_r98_BAG_L1   0.918693     roc_auc       0.094027    6.512935                0.094027           6.512935            1      False         32\n",
      "31               LightGBM_r131_BAG_L1   0.916160     roc_auc       0.034111    2.134307                0.034111           2.134307            1      False          8\n",
      "32                 XGBoost_r34_BAG_L1   0.915569     roc_auc       0.049681    3.387580                0.049681           3.387580            1      False         68\n",
      "33                LightGBM_r96_BAG_L1   0.914978     roc_auc       0.038522    3.939717                0.038522           3.939717            1      False         11\n",
      "34                 XGBoost_r22_BAG_L1   0.914894     roc_auc       0.044387    1.925295                0.044387           1.925295            1      False         52\n",
      "35               LightGBM_r161_BAG_L1   0.913965     roc_auc       0.036878    3.021863                0.036878           3.021863            1      False         25\n",
      "36               LightGBM_r143_BAG_L1   0.912698     roc_auc       0.032612    2.550541                0.032612           2.550541            1      False         37\n",
      "37                XGBoost_r194_BAG_L1   0.912023     roc_auc       0.116689    2.214602                0.116689           2.214602            1      False         22\n",
      "38                    LightGBM_BAG_L1   0.911685     roc_auc       0.031247    1.968275                0.031247           1.968275            1      False          2\n",
      "39                 XGBoost_r33_BAG_L1   0.908815     roc_auc       0.046021    3.161743                0.046021           3.161743            1      False         12\n",
      "40                 XGBoost_r89_BAG_L1   0.908224     roc_auc       0.046598    1.840804                0.046598           1.840804            1      False         18\n",
      "41                LightGBM_r15_BAG_L1   0.907295     roc_auc       0.029558    2.182910                0.029558           2.182910            1      False         33\n",
      "42               CatBoost_r143_BAG_L1   0.907210     roc_auc       0.060422   59.950569                0.060422          59.950569            1      False         47\n",
      "43                 XGBoost_r31_BAG_L1   0.907042     roc_auc       0.048507    6.761811                0.048507           6.761811            1      False         48\n",
      "44                 XGBoost_r95_BAG_L1   0.906873     roc_auc       0.050745    2.412552                0.050745           2.412552            1      False         67\n",
      "45        NeuralNetFastAI_r103_BAG_L1   0.906619     roc_auc       0.089103    8.540509                0.089103           8.540509            1      False         24\n",
      "46        NeuralNetFastAI_r156_BAG_L1   0.906028     roc_auc       0.088786    7.914216                0.088786           7.914216            1      False         28\n",
      "47               LightGBM_r130_BAG_L1   0.904171     roc_auc       0.030014    1.996000                0.030014           1.996000            1      False         19\n",
      "48                     XGBoost_BAG_L1   0.903242     roc_auc       0.048339    2.607234                0.048339           2.607234            1      False          5\n",
      "49        NeuralNetFastAI_r111_BAG_L1   0.902989     roc_auc       0.090570    6.877579                0.090570           6.877579            1      False         41\n",
      "50         NeuralNetFastAI_r37_BAG_L1   0.902060     roc_auc       0.095145    8.507340                0.095145           8.507340            1      False         35\n",
      "51        NeuralNetFastAI_r102_BAG_L1   0.901385     roc_auc       0.080907    7.200621                0.080907           7.200621            1      False         14\n",
      "52        NeuralNetFastAI_r187_BAG_L1   0.899443     roc_auc       0.089868    8.061311                0.089868           8.061311            1      False         66\n",
      "53                 XGBoost_r49_BAG_L1   0.898007     roc_auc       0.046409    2.283182                0.046409           2.283182            1      False         45\n",
      "54        NeuralNetFastAI_r127_BAG_L1   0.890493     roc_auc       0.085249    7.369765                0.085249           7.369765            1      False         59\n",
      "55        NeuralNetFastAI_r191_BAG_L1   0.885089     roc_auc       0.106445   10.347082                0.106445          10.347082            1      False          9\n",
      "56        NeuralNetFastAI_r172_BAG_L1   0.884330     roc_auc       0.081522    7.674152                0.081522           7.674152            1      False         57\n",
      "57        NeuralNetFastAI_r134_BAG_L1   0.883063     roc_auc       0.099963   10.334364                0.099963          10.334364            1      False         38\n",
      "58         NeuralNetFastAI_r65_BAG_L1   0.882894     roc_auc       0.078833    7.989231                0.078833           7.989231            1      False         42\n",
      "59             NeuralNetFastAI_BAG_L1   0.879010     roc_auc       0.090203    7.839492                0.090203           7.839492            1      False          4\n",
      "60        NeuralNetFastAI_r194_BAG_L1   0.876900     roc_auc       0.100057    7.577571                0.100057           7.577571            1      False         60\n",
      "61               LightGBMLarge_BAG_L1   0.873607     roc_auc       0.031300    2.263635                0.031300           2.263635            1      False          6\n",
      "62         NeuralNetFastAI_r69_BAG_L1   0.867950     roc_auc       0.079326    5.946676                0.079326           5.946676            1      False         53\n",
      "63        NeuralNetFastAI_r138_BAG_L1   0.861702     roc_auc       0.097749    6.657528                0.097749           6.657528            1      False         55\n",
      "64         NeuralNetFastAI_r88_BAG_L1   0.856299     roc_auc       0.090169    7.454657                0.090169           7.454657            1      False         43\n",
      "65        NeuralNetFastAI_r160_BAG_L1   0.853259     roc_auc       0.092195    6.335960                0.092195           6.335960            1      False         49\n",
      "66        NeuralNetFastAI_r100_BAG_L1   0.852584     roc_auc       0.117449   11.320963                0.117449          11.320963            1      False         63\n",
      "67         NeuralNetFastAI_r11_BAG_L1   0.850811     roc_auc       0.105317    7.320618                0.105317           7.320618            1      False         21\n",
      "68        NeuralNetFastAI_r145_BAG_L1   0.849460     roc_auc       0.092242    5.975149                0.092242           5.975149            1      False         17\n",
      "69         NeuralNetFastAI_r95_BAG_L1   0.835782     roc_auc       0.090878    5.908298                0.090878           5.908298            1      False         31\n",
      "70            XGBoost_r98_BAG_L1_FULL        NaN     roc_auc            NaN    0.716771                     NaN           0.716771            1       True        102\n",
      "71            XGBoost_r95_BAG_L1_FULL        NaN     roc_auc            NaN    0.103941                     NaN           0.103941            1       True        137\n",
      "72            XGBoost_r89_BAG_L1_FULL        NaN     roc_auc            NaN    0.070457                     NaN           0.070457            1       True         88\n",
      "73            XGBoost_r49_BAG_L1_FULL        NaN     roc_auc            NaN    0.086495                     NaN           0.086495            1       True        115\n",
      "74            XGBoost_r34_BAG_L1_FULL        NaN     roc_auc            NaN    0.173366                     NaN           0.173366            1       True        138\n",
      "75            XGBoost_r33_BAG_L1_FULL        NaN     roc_auc            NaN    0.239748                     NaN           0.239748            1       True         82\n",
      "76            XGBoost_r31_BAG_L1_FULL        NaN     roc_auc            NaN    0.415009                     NaN           0.415009            1       True        118\n",
      "77            XGBoost_r22_BAG_L1_FULL        NaN     roc_auc            NaN    0.062241                     NaN           0.062241            1       True        122\n",
      "78           XGBoost_r194_BAG_L1_FULL        NaN     roc_auc            NaN    0.098566                     NaN           0.098566            1       True         92\n",
      "79                XGBoost_BAG_L1_FULL        NaN     roc_auc            NaN    0.104669                     NaN           0.104669            1       True         75\n",
      "80           WeightedEnsemble_L2_FULL        NaN     roc_auc            NaN    4.165213                     NaN           0.032883            2       True        140\n",
      "81    NeuralNetFastAI_r95_BAG_L1_FULL        NaN     roc_auc            NaN    0.316439                     NaN           0.316439            1       True        101\n",
      "82    NeuralNetFastAI_r88_BAG_L1_FULL        NaN     roc_auc            NaN    0.535585                     NaN           0.535585            1       True        113\n",
      "83    NeuralNetFastAI_r69_BAG_L1_FULL        NaN     roc_auc            NaN    0.326825                     NaN           0.326825            1       True        123\n",
      "84    NeuralNetFastAI_r65_BAG_L1_FULL        NaN     roc_auc            NaN    1.908405                     NaN           1.908405            1       True        112\n",
      "85     NeuralNetFastAI_r4_BAG_L1_FULL        NaN     roc_auc            NaN    0.934893                     NaN           0.934893            1       True        132\n",
      "86    NeuralNetFastAI_r37_BAG_L1_FULL        NaN     roc_auc            NaN    1.598661                     NaN           1.598661            1       True        105\n",
      "87   NeuralNetFastAI_r194_BAG_L1_FULL        NaN     roc_auc            NaN    1.182722                     NaN           1.182722            1       True        130\n",
      "88   NeuralNetFastAI_r191_BAG_L1_FULL        NaN     roc_auc            NaN    0.910841                     NaN           0.910841            1       True         79\n",
      "89   NeuralNetFastAI_r187_BAG_L1_FULL        NaN     roc_auc            NaN    1.288934                     NaN           1.288934            1       True        136\n",
      "90   NeuralNetFastAI_r172_BAG_L1_FULL        NaN     roc_auc            NaN    0.588124                     NaN           0.588124            1       True        127\n",
      "91   NeuralNetFastAI_r160_BAG_L1_FULL        NaN     roc_auc            NaN    0.324493                     NaN           0.324493            1       True        119\n",
      "92   NeuralNetFastAI_r156_BAG_L1_FULL        NaN     roc_auc            NaN    0.937201                     NaN           0.937201            1       True         98\n",
      "93   NeuralNetFastAI_r145_BAG_L1_FULL        NaN     roc_auc            NaN    0.423887                     NaN           0.423887            1       True         87\n",
      "94   NeuralNetFastAI_r143_BAG_L1_FULL        NaN     roc_auc            NaN    1.377918                     NaN           1.377918            1       True         96\n",
      "95   NeuralNetFastAI_r138_BAG_L1_FULL        NaN     roc_auc            NaN    0.433490                     NaN           0.433490            1       True        125\n",
      "96   NeuralNetFastAI_r134_BAG_L1_FULL        NaN     roc_auc            NaN    0.992996                     NaN           0.992996            1       True        108\n",
      "97   NeuralNetFastAI_r127_BAG_L1_FULL        NaN     roc_auc            NaN    0.953045                     NaN           0.953045            1       True        129\n",
      "98    NeuralNetFastAI_r11_BAG_L1_FULL        NaN     roc_auc            NaN    0.235724                     NaN           0.235724            1       True         91\n",
      "99   NeuralNetFastAI_r111_BAG_L1_FULL        NaN     roc_auc            NaN    1.056567                     NaN           1.056567            1       True        111\n",
      "100  NeuralNetFastAI_r103_BAG_L1_FULL        NaN     roc_auc            NaN    1.304190                     NaN           1.304190            1       True         94\n",
      "101  NeuralNetFastAI_r102_BAG_L1_FULL        NaN     roc_auc            NaN    0.869126                     NaN           0.869126            1       True         84\n",
      "102  NeuralNetFastAI_r100_BAG_L1_FULL        NaN     roc_auc            NaN    1.009329                     NaN           1.009329            1       True        133\n",
      "103       NeuralNetFastAI_BAG_L1_FULL        NaN     roc_auc            NaN    1.073821                     NaN           1.073821            1       True         74\n",
      "104          LightGBM_r96_BAG_L1_FULL        NaN     roc_auc            NaN    0.202678                     NaN           0.202678            1       True         81\n",
      "105          LightGBM_r94_BAG_L1_FULL        NaN     roc_auc            NaN    0.184334                     NaN           0.184334            1       True        109\n",
      "106          LightGBM_r42_BAG_L1_FULL        NaN     roc_auc            NaN    0.158222                     NaN           0.158222            1       True        139\n",
      "107          LightGBM_r30_BAG_L1_FULL        NaN     roc_auc            NaN    0.290362                     NaN           0.290362            1       True        114\n",
      "108         LightGBM_r196_BAG_L1_FULL        NaN     roc_auc            NaN    0.592877                     NaN           0.592877            1       True         99\n",
      "109         LightGBM_r188_BAG_L1_FULL        NaN     roc_auc            NaN    0.172183                     NaN           0.172183            1       True         86\n",
      "110         LightGBM_r161_BAG_L1_FULL        NaN     roc_auc            NaN    0.252748                     NaN           0.252748            1       True         95\n",
      "111          LightGBM_r15_BAG_L1_FULL        NaN     roc_auc            NaN    0.151339                     NaN           0.151339            1       True        103\n",
      "112         LightGBM_r143_BAG_L1_FULL        NaN     roc_auc            NaN    0.177956                     NaN           0.177956            1       True        107\n",
      "113         LightGBM_r135_BAG_L1_FULL        NaN     roc_auc            NaN    0.143306                     NaN           0.143306            1       True        121\n",
      "114         LightGBM_r131_BAG_L1_FULL        NaN     roc_auc            NaN    0.175676                     NaN           0.175676            1       True         78\n",
      "115         LightGBM_r130_BAG_L1_FULL        NaN     roc_auc            NaN    0.128245                     NaN           0.128245            1       True         89\n",
      "116         LightGBM_r121_BAG_L1_FULL        NaN     roc_auc            NaN    0.250834                     NaN           0.250834            1       True        126\n",
      "117              LightGBM_BAG_L1_FULL        NaN     roc_auc            NaN    0.116263                     NaN           0.116263            1       True         72\n",
      "118            LightGBMXT_BAG_L1_FULL        NaN     roc_auc            NaN    0.406470                     NaN           0.406470            1       True         71\n",
      "119         LightGBMLarge_BAG_L1_FULL        NaN     roc_auc            NaN    0.173439                     NaN           0.173439            1       True         76\n",
      "120           CatBoost_r9_BAG_L1_FULL        NaN     roc_auc            NaN   11.937403                     NaN          11.937403            1       True         80\n",
      "121          CatBoost_r86_BAG_L1_FULL        NaN     roc_auc            NaN   58.400040                     NaN          58.400040            1       True        104\n",
      "122          CatBoost_r70_BAG_L1_FULL        NaN     roc_auc            NaN    3.967215                     NaN           3.967215            1       True         97\n",
      "123           CatBoost_r6_BAG_L1_FULL        NaN     roc_auc            NaN    2.347942                     NaN           2.347942            1       True        124\n",
      "124          CatBoost_r69_BAG_L1_FULL        NaN     roc_auc            NaN    3.351288                     NaN           3.351288            1       True         93\n",
      "125          CatBoost_r60_BAG_L1_FULL        NaN     roc_auc            NaN    4.532232                     NaN           4.532232            1       True        120\n",
      "126           CatBoost_r5_BAG_L1_FULL        NaN     roc_auc            NaN    3.012797                     NaN           3.012797            1       True        116\n",
      "127          CatBoost_r50_BAG_L1_FULL        NaN     roc_auc            NaN    1.259650                     NaN           1.259650            1       True         90\n",
      "128          CatBoost_r49_BAG_L1_FULL        NaN     roc_auc            NaN    3.939841                     NaN           3.939841            1       True        106\n",
      "129         CatBoost_r198_BAG_L1_FULL        NaN     roc_auc            NaN    7.499654                     NaN           7.499654            1       True        135\n",
      "130         CatBoost_r180_BAG_L1_FULL        NaN     roc_auc            NaN    7.474488                     NaN           7.474488            1       True        128\n",
      "131         CatBoost_r177_BAG_L1_FULL        NaN     roc_auc            NaN    8.453065                     NaN           8.453065            1       True         77\n",
      "132         CatBoost_r167_BAG_L1_FULL        NaN     roc_auc            NaN    3.287416                     NaN           3.287416            1       True        100\n",
      "133         CatBoost_r163_BAG_L1_FULL        NaN     roc_auc            NaN    2.132948                     NaN           2.132948            1       True        134\n",
      "134         CatBoost_r143_BAG_L1_FULL        NaN     roc_auc            NaN    7.070833                     NaN           7.070833            1       True        117\n",
      "135          CatBoost_r13_BAG_L1_FULL        NaN     roc_auc            NaN   29.177051                     NaN          29.177051            1       True         85\n",
      "136         CatBoost_r137_BAG_L1_FULL        NaN     roc_auc            NaN    8.123681                     NaN           8.123681            1       True         83\n",
      "137          CatBoost_r12_BAG_L1_FULL        NaN     roc_auc            NaN   12.204523                     NaN          12.204523            1       True        131\n",
      "138         CatBoost_r128_BAG_L1_FULL        NaN     roc_auc            NaN   10.839817                     NaN          10.839817            1       True        110\n",
      "139              CatBoost_BAG_L1_FULL        NaN     roc_auc            NaN    6.258260                     NaN           6.258260            1       True         73\n",
      "Number of models trained: 140\n",
      "Types of models trained:\n",
      "{'WeightedEnsembleModel', 'StackerEnsembleModel_CatBoost', 'StackerEnsembleModel_NNFastAiTabular', 'StackerEnsembleModel_XGBoost', 'StackerEnsembleModel_LGB'}\n",
      "Bagging used: True  (with 8 folds)\n",
      "Multi-layer stack-ensembling used: False \n",
      "Feature Metadata (Processed):\n",
      "(raw dtype, special dtypes):\n",
      "('category', [])                    :  1 | ['demo-rangoEdad']\n",
      "('category', ['text_as_category'])  :  1 | ['clin-tipoAlcohol']\n",
      "('float', [])                       : 17 | ['clin-numCigarros', 'clin-aÃ±osSinFumar', 'ques-Sus-total-PD', 'eval-TLP-FigRey-totalCopia-PD', 'eval-TLP-FigRey-totalMemoria-PD', ...]\n",
      "('int', [])                         : 47 | ['demo-edad', 'clin-reservaCognitiva_total', 'clin-reservaCognitiva_idiomas', 'clin-reservaCognitiva_ocupacion', 'clin-reservaCognitiva_escolaridad', ...]\n",
      "('int', ['binned', 'text_special']) : 10 | ['clin-tipoAlcohol.char_count', 'clin-tipoAlcohol.word_count', 'clin-tipoAlcohol.capital_ratio', 'clin-tipoAlcohol.lower_ratio', 'clin-tipoAlcohol.digit_ratio', ...]\n",
      "('int', ['bool'])                   : 10 | ['demo-genero', 'clin-ansiedad', 'clin-depresion', 'clin-cardiopatiaIsquemica', 'clin-diabetes', ...]\n",
      "('int', ['datetime_as_int'])        :  9 | ['demo-fechaEvaluacion', 'demo-fechaEvaluacion.month', 'demo-fechaEvaluacion.day', 'demo-fechaEvaluacion.dayofweek', 'demo-fechaNacimiento', ...]\n",
      "Plot summary of models saved to file: c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\autogluon\\tlp\\AutogluonModels\\synthetic\\tvaes\\v2SummaryOfModels.html\n",
      "*** End of fit() summary ***\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'model_types': {'LightGBMXT_BAG_L1': 'StackerEnsembleModel_LGB',\n",
       "  'LightGBM_BAG_L1': 'StackerEnsembleModel_LGB',\n",
       "  'CatBoost_BAG_L1': 'StackerEnsembleModel_CatBoost',\n",
       "  'NeuralNetFastAI_BAG_L1': 'StackerEnsembleModel_NNFastAiTabular',\n",
       "  'XGBoost_BAG_L1': 'StackerEnsembleModel_XGBoost',\n",
       "  'LightGBMLarge_BAG_L1': 'StackerEnsembleModel_LGB',\n",
       "  'CatBoost_r177_BAG_L1': 'StackerEnsembleModel_CatBoost',\n",
       "  'LightGBM_r131_BAG_L1': 'StackerEnsembleModel_LGB',\n",
       "  'NeuralNetFastAI_r191_BAG_L1': 'StackerEnsembleModel_NNFastAiTabular',\n",
       "  'CatBoost_r9_BAG_L1': 'StackerEnsembleModel_CatBoost',\n",
       "  'LightGBM_r96_BAG_L1': 'StackerEnsembleModel_LGB',\n",
       "  'XGBoost_r33_BAG_L1': 'StackerEnsembleModel_XGBoost',\n",
       "  'CatBoost_r137_BAG_L1': 'StackerEnsembleModel_CatBoost',\n",
       "  'NeuralNetFastAI_r102_BAG_L1': 'StackerEnsembleModel_NNFastAiTabular',\n",
       "  'CatBoost_r13_BAG_L1': 'StackerEnsembleModel_CatBoost',\n",
       "  'LightGBM_r188_BAG_L1': 'StackerEnsembleModel_LGB',\n",
       "  'NeuralNetFastAI_r145_BAG_L1': 'StackerEnsembleModel_NNFastAiTabular',\n",
       "  'XGBoost_r89_BAG_L1': 'StackerEnsembleModel_XGBoost',\n",
       "  'LightGBM_r130_BAG_L1': 'StackerEnsembleModel_LGB',\n",
       "  'CatBoost_r50_BAG_L1': 'StackerEnsembleModel_CatBoost',\n",
       "  'NeuralNetFastAI_r11_BAG_L1': 'StackerEnsembleModel_NNFastAiTabular',\n",
       "  'XGBoost_r194_BAG_L1': 'StackerEnsembleModel_XGBoost',\n",
       "  'CatBoost_r69_BAG_L1': 'StackerEnsembleModel_CatBoost',\n",
       "  'NeuralNetFastAI_r103_BAG_L1': 'StackerEnsembleModel_NNFastAiTabular',\n",
       "  'LightGBM_r161_BAG_L1': 'StackerEnsembleModel_LGB',\n",
       "  'NeuralNetFastAI_r143_BAG_L1': 'StackerEnsembleModel_NNFastAiTabular',\n",
       "  'CatBoost_r70_BAG_L1': 'StackerEnsembleModel_CatBoost',\n",
       "  'NeuralNetFastAI_r156_BAG_L1': 'StackerEnsembleModel_NNFastAiTabular',\n",
       "  'LightGBM_r196_BAG_L1': 'StackerEnsembleModel_LGB',\n",
       "  'CatBoost_r167_BAG_L1': 'StackerEnsembleModel_CatBoost',\n",
       "  'NeuralNetFastAI_r95_BAG_L1': 'StackerEnsembleModel_NNFastAiTabular',\n",
       "  'XGBoost_r98_BAG_L1': 'StackerEnsembleModel_XGBoost',\n",
       "  'LightGBM_r15_BAG_L1': 'StackerEnsembleModel_LGB',\n",
       "  'CatBoost_r86_BAG_L1': 'StackerEnsembleModel_CatBoost',\n",
       "  'NeuralNetFastAI_r37_BAG_L1': 'StackerEnsembleModel_NNFastAiTabular',\n",
       "  'CatBoost_r49_BAG_L1': 'StackerEnsembleModel_CatBoost',\n",
       "  'LightGBM_r143_BAG_L1': 'StackerEnsembleModel_LGB',\n",
       "  'NeuralNetFastAI_r134_BAG_L1': 'StackerEnsembleModel_NNFastAiTabular',\n",
       "  'LightGBM_r94_BAG_L1': 'StackerEnsembleModel_LGB',\n",
       "  'CatBoost_r128_BAG_L1': 'StackerEnsembleModel_CatBoost',\n",
       "  'NeuralNetFastAI_r111_BAG_L1': 'StackerEnsembleModel_NNFastAiTabular',\n",
       "  'NeuralNetFastAI_r65_BAG_L1': 'StackerEnsembleModel_NNFastAiTabular',\n",
       "  'NeuralNetFastAI_r88_BAG_L1': 'StackerEnsembleModel_NNFastAiTabular',\n",
       "  'LightGBM_r30_BAG_L1': 'StackerEnsembleModel_LGB',\n",
       "  'XGBoost_r49_BAG_L1': 'StackerEnsembleModel_XGBoost',\n",
       "  'CatBoost_r5_BAG_L1': 'StackerEnsembleModel_CatBoost',\n",
       "  'CatBoost_r143_BAG_L1': 'StackerEnsembleModel_CatBoost',\n",
       "  'XGBoost_r31_BAG_L1': 'StackerEnsembleModel_XGBoost',\n",
       "  'NeuralNetFastAI_r160_BAG_L1': 'StackerEnsembleModel_NNFastAiTabular',\n",
       "  'CatBoost_r60_BAG_L1': 'StackerEnsembleModel_CatBoost',\n",
       "  'LightGBM_r135_BAG_L1': 'StackerEnsembleModel_LGB',\n",
       "  'XGBoost_r22_BAG_L1': 'StackerEnsembleModel_XGBoost',\n",
       "  'NeuralNetFastAI_r69_BAG_L1': 'StackerEnsembleModel_NNFastAiTabular',\n",
       "  'CatBoost_r6_BAG_L1': 'StackerEnsembleModel_CatBoost',\n",
       "  'NeuralNetFastAI_r138_BAG_L1': 'StackerEnsembleModel_NNFastAiTabular',\n",
       "  'LightGBM_r121_BAG_L1': 'StackerEnsembleModel_LGB',\n",
       "  'NeuralNetFastAI_r172_BAG_L1': 'StackerEnsembleModel_NNFastAiTabular',\n",
       "  'CatBoost_r180_BAG_L1': 'StackerEnsembleModel_CatBoost',\n",
       "  'NeuralNetFastAI_r127_BAG_L1': 'StackerEnsembleModel_NNFastAiTabular',\n",
       "  'NeuralNetFastAI_r194_BAG_L1': 'StackerEnsembleModel_NNFastAiTabular',\n",
       "  'CatBoost_r12_BAG_L1': 'StackerEnsembleModel_CatBoost',\n",
       "  'NeuralNetFastAI_r4_BAG_L1': 'StackerEnsembleModel_NNFastAiTabular',\n",
       "  'NeuralNetFastAI_r100_BAG_L1': 'StackerEnsembleModel_NNFastAiTabular',\n",
       "  'CatBoost_r163_BAG_L1': 'StackerEnsembleModel_CatBoost',\n",
       "  'CatBoost_r198_BAG_L1': 'StackerEnsembleModel_CatBoost',\n",
       "  'NeuralNetFastAI_r187_BAG_L1': 'StackerEnsembleModel_NNFastAiTabular',\n",
       "  'XGBoost_r95_BAG_L1': 'StackerEnsembleModel_XGBoost',\n",
       "  'XGBoost_r34_BAG_L1': 'StackerEnsembleModel_XGBoost',\n",
       "  'LightGBM_r42_BAG_L1': 'StackerEnsembleModel_LGB',\n",
       "  'WeightedEnsemble_L2': 'WeightedEnsembleModel',\n",
       "  'LightGBMXT_BAG_L1_FULL': 'StackerEnsembleModel_LGB',\n",
       "  'LightGBM_BAG_L1_FULL': 'StackerEnsembleModel_LGB',\n",
       "  'CatBoost_BAG_L1_FULL': 'StackerEnsembleModel_CatBoost',\n",
       "  'NeuralNetFastAI_BAG_L1_FULL': 'StackerEnsembleModel_NNFastAiTabular',\n",
       "  'XGBoost_BAG_L1_FULL': 'StackerEnsembleModel_XGBoost',\n",
       "  'LightGBMLarge_BAG_L1_FULL': 'StackerEnsembleModel_LGB',\n",
       "  'CatBoost_r177_BAG_L1_FULL': 'StackerEnsembleModel_CatBoost',\n",
       "  'LightGBM_r131_BAG_L1_FULL': 'StackerEnsembleModel_LGB',\n",
       "  'NeuralNetFastAI_r191_BAG_L1_FULL': 'StackerEnsembleModel_NNFastAiTabular',\n",
       "  'CatBoost_r9_BAG_L1_FULL': 'StackerEnsembleModel_CatBoost',\n",
       "  'LightGBM_r96_BAG_L1_FULL': 'StackerEnsembleModel_LGB',\n",
       "  'XGBoost_r33_BAG_L1_FULL': 'StackerEnsembleModel_XGBoost',\n",
       "  'CatBoost_r137_BAG_L1_FULL': 'StackerEnsembleModel_CatBoost',\n",
       "  'NeuralNetFastAI_r102_BAG_L1_FULL': 'StackerEnsembleModel_NNFastAiTabular',\n",
       "  'CatBoost_r13_BAG_L1_FULL': 'StackerEnsembleModel_CatBoost',\n",
       "  'LightGBM_r188_BAG_L1_FULL': 'StackerEnsembleModel_LGB',\n",
       "  'NeuralNetFastAI_r145_BAG_L1_FULL': 'StackerEnsembleModel_NNFastAiTabular',\n",
       "  'XGBoost_r89_BAG_L1_FULL': 'StackerEnsembleModel_XGBoost',\n",
       "  'LightGBM_r130_BAG_L1_FULL': 'StackerEnsembleModel_LGB',\n",
       "  'CatBoost_r50_BAG_L1_FULL': 'StackerEnsembleModel_CatBoost',\n",
       "  'NeuralNetFastAI_r11_BAG_L1_FULL': 'StackerEnsembleModel_NNFastAiTabular',\n",
       "  'XGBoost_r194_BAG_L1_FULL': 'StackerEnsembleModel_XGBoost',\n",
       "  'CatBoost_r69_BAG_L1_FULL': 'StackerEnsembleModel_CatBoost',\n",
       "  'NeuralNetFastAI_r103_BAG_L1_FULL': 'StackerEnsembleModel_NNFastAiTabular',\n",
       "  'LightGBM_r161_BAG_L1_FULL': 'StackerEnsembleModel_LGB',\n",
       "  'NeuralNetFastAI_r143_BAG_L1_FULL': 'StackerEnsembleModel_NNFastAiTabular',\n",
       "  'CatBoost_r70_BAG_L1_FULL': 'StackerEnsembleModel_CatBoost',\n",
       "  'NeuralNetFastAI_r156_BAG_L1_FULL': 'StackerEnsembleModel_NNFastAiTabular',\n",
       "  'LightGBM_r196_BAG_L1_FULL': 'StackerEnsembleModel_LGB',\n",
       "  'CatBoost_r167_BAG_L1_FULL': 'StackerEnsembleModel_CatBoost',\n",
       "  'NeuralNetFastAI_r95_BAG_L1_FULL': 'StackerEnsembleModel_NNFastAiTabular',\n",
       "  'XGBoost_r98_BAG_L1_FULL': 'StackerEnsembleModel_XGBoost',\n",
       "  'LightGBM_r15_BAG_L1_FULL': 'StackerEnsembleModel_LGB',\n",
       "  'CatBoost_r86_BAG_L1_FULL': 'StackerEnsembleModel_CatBoost',\n",
       "  'NeuralNetFastAI_r37_BAG_L1_FULL': 'StackerEnsembleModel_NNFastAiTabular',\n",
       "  'CatBoost_r49_BAG_L1_FULL': 'StackerEnsembleModel_CatBoost',\n",
       "  'LightGBM_r143_BAG_L1_FULL': 'StackerEnsembleModel_LGB',\n",
       "  'NeuralNetFastAI_r134_BAG_L1_FULL': 'StackerEnsembleModel_NNFastAiTabular',\n",
       "  'LightGBM_r94_BAG_L1_FULL': 'StackerEnsembleModel_LGB',\n",
       "  'CatBoost_r128_BAG_L1_FULL': 'StackerEnsembleModel_CatBoost',\n",
       "  'NeuralNetFastAI_r111_BAG_L1_FULL': 'StackerEnsembleModel_NNFastAiTabular',\n",
       "  'NeuralNetFastAI_r65_BAG_L1_FULL': 'StackerEnsembleModel_NNFastAiTabular',\n",
       "  'NeuralNetFastAI_r88_BAG_L1_FULL': 'StackerEnsembleModel_NNFastAiTabular',\n",
       "  'LightGBM_r30_BAG_L1_FULL': 'StackerEnsembleModel_LGB',\n",
       "  'XGBoost_r49_BAG_L1_FULL': 'StackerEnsembleModel_XGBoost',\n",
       "  'CatBoost_r5_BAG_L1_FULL': 'StackerEnsembleModel_CatBoost',\n",
       "  'CatBoost_r143_BAG_L1_FULL': 'StackerEnsembleModel_CatBoost',\n",
       "  'XGBoost_r31_BAG_L1_FULL': 'StackerEnsembleModel_XGBoost',\n",
       "  'NeuralNetFastAI_r160_BAG_L1_FULL': 'StackerEnsembleModel_NNFastAiTabular',\n",
       "  'CatBoost_r60_BAG_L1_FULL': 'StackerEnsembleModel_CatBoost',\n",
       "  'LightGBM_r135_BAG_L1_FULL': 'StackerEnsembleModel_LGB',\n",
       "  'XGBoost_r22_BAG_L1_FULL': 'StackerEnsembleModel_XGBoost',\n",
       "  'NeuralNetFastAI_r69_BAG_L1_FULL': 'StackerEnsembleModel_NNFastAiTabular',\n",
       "  'CatBoost_r6_BAG_L1_FULL': 'StackerEnsembleModel_CatBoost',\n",
       "  'NeuralNetFastAI_r138_BAG_L1_FULL': 'StackerEnsembleModel_NNFastAiTabular',\n",
       "  'LightGBM_r121_BAG_L1_FULL': 'StackerEnsembleModel_LGB',\n",
       "  'NeuralNetFastAI_r172_BAG_L1_FULL': 'StackerEnsembleModel_NNFastAiTabular',\n",
       "  'CatBoost_r180_BAG_L1_FULL': 'StackerEnsembleModel_CatBoost',\n",
       "  'NeuralNetFastAI_r127_BAG_L1_FULL': 'StackerEnsembleModel_NNFastAiTabular',\n",
       "  'NeuralNetFastAI_r194_BAG_L1_FULL': 'StackerEnsembleModel_NNFastAiTabular',\n",
       "  'CatBoost_r12_BAG_L1_FULL': 'StackerEnsembleModel_CatBoost',\n",
       "  'NeuralNetFastAI_r4_BAG_L1_FULL': 'StackerEnsembleModel_NNFastAiTabular',\n",
       "  'NeuralNetFastAI_r100_BAG_L1_FULL': 'StackerEnsembleModel_NNFastAiTabular',\n",
       "  'CatBoost_r163_BAG_L1_FULL': 'StackerEnsembleModel_CatBoost',\n",
       "  'CatBoost_r198_BAG_L1_FULL': 'StackerEnsembleModel_CatBoost',\n",
       "  'NeuralNetFastAI_r187_BAG_L1_FULL': 'StackerEnsembleModel_NNFastAiTabular',\n",
       "  'XGBoost_r95_BAG_L1_FULL': 'StackerEnsembleModel_XGBoost',\n",
       "  'XGBoost_r34_BAG_L1_FULL': 'StackerEnsembleModel_XGBoost',\n",
       "  'LightGBM_r42_BAG_L1_FULL': 'StackerEnsembleModel_LGB',\n",
       "  'WeightedEnsemble_L2_FULL': 'WeightedEnsembleModel'},\n",
       " 'model_performance': {'LightGBMXT_BAG_L1': 0.9421648091860858,\n",
       "  'LightGBM_BAG_L1': 0.9116852414724755,\n",
       "  'CatBoost_BAG_L1': 0.9232522796352585,\n",
       "  'NeuralNetFastAI_BAG_L1': 0.8790104694360013,\n",
       "  'XGBoost_BAG_L1': 0.9032421479229991,\n",
       "  'LightGBMLarge_BAG_L1': 0.8736068895643364,\n",
       "  'CatBoost_r177_BAG_L1': 0.9266295170550489,\n",
       "  'LightGBM_r131_BAG_L1': 0.9161600810536981,\n",
       "  'NeuralNetFastAI_r191_BAG_L1': 0.8850894967916245,\n",
       "  'CatBoost_r9_BAG_L1': 0.9235900033772373,\n",
       "  'LightGBM_r96_BAG_L1': 0.9149780479567713,\n",
       "  'XGBoost_r33_BAG_L1': 0.9088145896656534,\n",
       "  'CatBoost_r137_BAG_L1': 0.9240121580547112,\n",
       "  'NeuralNetFastAI_r102_BAG_L1': 0.9013846673421142,\n",
       "  'CatBoost_r13_BAG_L1': 0.9222391084093212,\n",
       "  'LightGBM_r188_BAG_L1': 0.9345660249915568,\n",
       "  'NeuralNetFastAI_r145_BAG_L1': 0.8494596420128335,\n",
       "  'XGBoost_r89_BAG_L1': 0.9082235731171902,\n",
       "  'LightGBM_r130_BAG_L1': 0.9041708882134414,\n",
       "  'CatBoost_r50_BAG_L1': 0.9326241134751774,\n",
       "  'NeuralNetFastAI_r11_BAG_L1': 0.8508105369807498,\n",
       "  'XGBoost_r194_BAG_L1': 0.9120229652144546,\n",
       "  'CatBoost_r69_BAG_L1': 0.9213103681188787,\n",
       "  'NeuralNetFastAI_r103_BAG_L1': 0.9066193853427895,\n",
       "  'LightGBM_r161_BAG_L1': 0.9139648767308342,\n",
       "  'NeuralNetFastAI_r143_BAG_L1': 0.9246031746031746,\n",
       "  'CatBoost_r70_BAG_L1': 0.9262917933130699,\n",
       "  'NeuralNetFastAI_r156_BAG_L1': 0.9060283687943262,\n",
       "  'LightGBM_r196_BAG_L1': 0.9316109422492401,\n",
       "  'CatBoost_r167_BAG_L1': 0.9202127659574468,\n",
       "  'NeuralNetFastAI_r95_BAG_L1': 0.8357818304626816,\n",
       "  'XGBoost_r98_BAG_L1': 0.918693009118541,\n",
       "  'LightGBM_r15_BAG_L1': 0.9072948328267477,\n",
       "  'CatBoost_r86_BAG_L1': 0.9233367105707531,\n",
       "  'NeuralNetFastAI_r37_BAG_L1': 0.9020601148260723,\n",
       "  'CatBoost_r49_BAG_L1': 0.9273893954745018,\n",
       "  'LightGBM_r143_BAG_L1': 0.9126984126984127,\n",
       "  'NeuralNetFastAI_r134_BAG_L1': 0.8830631543397501,\n",
       "  'LightGBM_r94_BAG_L1': 0.9359169199594731,\n",
       "  'CatBoost_r128_BAG_L1': 0.9216480918608578,\n",
       "  'NeuralNetFastAI_r111_BAG_L1': 0.9029888551165146,\n",
       "  'NeuralNetFastAI_r65_BAG_L1': 0.8828942924687605,\n",
       "  'NeuralNetFastAI_r88_BAG_L1': 0.8562985477879096,\n",
       "  'LightGBM_r30_BAG_L1': 0.9393785883147585,\n",
       "  'XGBoost_r49_BAG_L1': 0.8980074299223235,\n",
       "  'CatBoost_r5_BAG_L1': 0.9260385005065856,\n",
       "  'CatBoost_r143_BAG_L1': 0.9072104018912529,\n",
       "  'XGBoost_r31_BAG_L1': 0.9070415400202634,\n",
       "  'NeuralNetFastAI_r160_BAG_L1': 0.8532590341100978,\n",
       "  'CatBoost_r60_BAG_L1': 0.9233367105707532,\n",
       "  'LightGBM_r135_BAG_L1': 0.9206349206349207,\n",
       "  'XGBoost_r22_BAG_L1': 0.9148936170212765,\n",
       "  'NeuralNetFastAI_r69_BAG_L1': 0.8679500168861871,\n",
       "  'CatBoost_r6_BAG_L1': 0.9345660249915569,\n",
       "  'NeuralNetFastAI_r138_BAG_L1': 0.8617021276595747,\n",
       "  'LightGBM_r121_BAG_L1': 0.9213947990543735,\n",
       "  'NeuralNetFastAI_r172_BAG_L1': 0.8843296183721716,\n",
       "  'CatBoost_r180_BAG_L1': 0.9309354947652819,\n",
       "  'NeuralNetFastAI_r127_BAG_L1': 0.8904930766632895,\n",
       "  'NeuralNetFastAI_r194_BAG_L1': 0.8768996960486322,\n",
       "  'CatBoost_r12_BAG_L1': 0.9235055724417427,\n",
       "  'NeuralNetFastAI_r4_BAG_L1': 0.9232522796352584,\n",
       "  'NeuralNetFastAI_r100_BAG_L1': 0.8525835866261398,\n",
       "  'CatBoost_r163_BAG_L1': 0.9290780141843971,\n",
       "  'CatBoost_r198_BAG_L1': 0.9308510638297871,\n",
       "  'NeuralNetFastAI_r187_BAG_L1': 0.8994427558257346,\n",
       "  'XGBoost_r95_BAG_L1': 0.9068726781492739,\n",
       "  'XGBoost_r34_BAG_L1': 0.9155690645052348,\n",
       "  'LightGBM_r42_BAG_L1': 0.925531914893617,\n",
       "  'WeightedEnsemble_L2': 0.952549814251942,\n",
       "  'LightGBMXT_BAG_L1_FULL': None,\n",
       "  'LightGBM_BAG_L1_FULL': None,\n",
       "  'CatBoost_BAG_L1_FULL': None,\n",
       "  'NeuralNetFastAI_BAG_L1_FULL': None,\n",
       "  'XGBoost_BAG_L1_FULL': None,\n",
       "  'LightGBMLarge_BAG_L1_FULL': None,\n",
       "  'CatBoost_r177_BAG_L1_FULL': None,\n",
       "  'LightGBM_r131_BAG_L1_FULL': None,\n",
       "  'NeuralNetFastAI_r191_BAG_L1_FULL': None,\n",
       "  'CatBoost_r9_BAG_L1_FULL': None,\n",
       "  'LightGBM_r96_BAG_L1_FULL': None,\n",
       "  'XGBoost_r33_BAG_L1_FULL': None,\n",
       "  'CatBoost_r137_BAG_L1_FULL': None,\n",
       "  'NeuralNetFastAI_r102_BAG_L1_FULL': None,\n",
       "  'CatBoost_r13_BAG_L1_FULL': None,\n",
       "  'LightGBM_r188_BAG_L1_FULL': None,\n",
       "  'NeuralNetFastAI_r145_BAG_L1_FULL': None,\n",
       "  'XGBoost_r89_BAG_L1_FULL': None,\n",
       "  'LightGBM_r130_BAG_L1_FULL': None,\n",
       "  'CatBoost_r50_BAG_L1_FULL': None,\n",
       "  'NeuralNetFastAI_r11_BAG_L1_FULL': None,\n",
       "  'XGBoost_r194_BAG_L1_FULL': None,\n",
       "  'CatBoost_r69_BAG_L1_FULL': None,\n",
       "  'NeuralNetFastAI_r103_BAG_L1_FULL': None,\n",
       "  'LightGBM_r161_BAG_L1_FULL': None,\n",
       "  'NeuralNetFastAI_r143_BAG_L1_FULL': None,\n",
       "  'CatBoost_r70_BAG_L1_FULL': None,\n",
       "  'NeuralNetFastAI_r156_BAG_L1_FULL': None,\n",
       "  'LightGBM_r196_BAG_L1_FULL': None,\n",
       "  'CatBoost_r167_BAG_L1_FULL': None,\n",
       "  'NeuralNetFastAI_r95_BAG_L1_FULL': None,\n",
       "  'XGBoost_r98_BAG_L1_FULL': None,\n",
       "  'LightGBM_r15_BAG_L1_FULL': None,\n",
       "  'CatBoost_r86_BAG_L1_FULL': None,\n",
       "  'NeuralNetFastAI_r37_BAG_L1_FULL': None,\n",
       "  'CatBoost_r49_BAG_L1_FULL': None,\n",
       "  'LightGBM_r143_BAG_L1_FULL': None,\n",
       "  'NeuralNetFastAI_r134_BAG_L1_FULL': None,\n",
       "  'LightGBM_r94_BAG_L1_FULL': None,\n",
       "  'CatBoost_r128_BAG_L1_FULL': None,\n",
       "  'NeuralNetFastAI_r111_BAG_L1_FULL': None,\n",
       "  'NeuralNetFastAI_r65_BAG_L1_FULL': None,\n",
       "  'NeuralNetFastAI_r88_BAG_L1_FULL': None,\n",
       "  'LightGBM_r30_BAG_L1_FULL': None,\n",
       "  'XGBoost_r49_BAG_L1_FULL': None,\n",
       "  'CatBoost_r5_BAG_L1_FULL': None,\n",
       "  'CatBoost_r143_BAG_L1_FULL': None,\n",
       "  'XGBoost_r31_BAG_L1_FULL': None,\n",
       "  'NeuralNetFastAI_r160_BAG_L1_FULL': None,\n",
       "  'CatBoost_r60_BAG_L1_FULL': None,\n",
       "  'LightGBM_r135_BAG_L1_FULL': None,\n",
       "  'XGBoost_r22_BAG_L1_FULL': None,\n",
       "  'NeuralNetFastAI_r69_BAG_L1_FULL': None,\n",
       "  'CatBoost_r6_BAG_L1_FULL': None,\n",
       "  'NeuralNetFastAI_r138_BAG_L1_FULL': None,\n",
       "  'LightGBM_r121_BAG_L1_FULL': None,\n",
       "  'NeuralNetFastAI_r172_BAG_L1_FULL': None,\n",
       "  'CatBoost_r180_BAG_L1_FULL': None,\n",
       "  'NeuralNetFastAI_r127_BAG_L1_FULL': None,\n",
       "  'NeuralNetFastAI_r194_BAG_L1_FULL': None,\n",
       "  'CatBoost_r12_BAG_L1_FULL': None,\n",
       "  'NeuralNetFastAI_r4_BAG_L1_FULL': None,\n",
       "  'NeuralNetFastAI_r100_BAG_L1_FULL': None,\n",
       "  'CatBoost_r163_BAG_L1_FULL': None,\n",
       "  'CatBoost_r198_BAG_L1_FULL': None,\n",
       "  'NeuralNetFastAI_r187_BAG_L1_FULL': None,\n",
       "  'XGBoost_r95_BAG_L1_FULL': None,\n",
       "  'XGBoost_r34_BAG_L1_FULL': None,\n",
       "  'LightGBM_r42_BAG_L1_FULL': None,\n",
       "  'WeightedEnsemble_L2_FULL': None},\n",
       " 'model_best': 'WeightedEnsemble_L2_FULL',\n",
       " 'model_paths': {'LightGBMXT_BAG_L1': ['LightGBMXT_BAG_L1'],\n",
       "  'LightGBM_BAG_L1': ['LightGBM_BAG_L1'],\n",
       "  'CatBoost_BAG_L1': ['CatBoost_BAG_L1'],\n",
       "  'NeuralNetFastAI_BAG_L1': ['NeuralNetFastAI_BAG_L1'],\n",
       "  'XGBoost_BAG_L1': ['XGBoost_BAG_L1'],\n",
       "  'LightGBMLarge_BAG_L1': ['LightGBMLarge_BAG_L1'],\n",
       "  'CatBoost_r177_BAG_L1': ['CatBoost_r177_BAG_L1'],\n",
       "  'LightGBM_r131_BAG_L1': ['LightGBM_r131_BAG_L1'],\n",
       "  'NeuralNetFastAI_r191_BAG_L1': ['NeuralNetFastAI_r191_BAG_L1'],\n",
       "  'CatBoost_r9_BAG_L1': ['CatBoost_r9_BAG_L1'],\n",
       "  'LightGBM_r96_BAG_L1': ['LightGBM_r96_BAG_L1'],\n",
       "  'XGBoost_r33_BAG_L1': ['XGBoost_r33_BAG_L1'],\n",
       "  'CatBoost_r137_BAG_L1': ['CatBoost_r137_BAG_L1'],\n",
       "  'NeuralNetFastAI_r102_BAG_L1': ['NeuralNetFastAI_r102_BAG_L1'],\n",
       "  'CatBoost_r13_BAG_L1': ['CatBoost_r13_BAG_L1'],\n",
       "  'LightGBM_r188_BAG_L1': ['LightGBM_r188_BAG_L1'],\n",
       "  'NeuralNetFastAI_r145_BAG_L1': ['NeuralNetFastAI_r145_BAG_L1'],\n",
       "  'XGBoost_r89_BAG_L1': ['XGBoost_r89_BAG_L1'],\n",
       "  'LightGBM_r130_BAG_L1': ['LightGBM_r130_BAG_L1'],\n",
       "  'CatBoost_r50_BAG_L1': ['CatBoost_r50_BAG_L1'],\n",
       "  'NeuralNetFastAI_r11_BAG_L1': ['NeuralNetFastAI_r11_BAG_L1'],\n",
       "  'XGBoost_r194_BAG_L1': ['XGBoost_r194_BAG_L1'],\n",
       "  'CatBoost_r69_BAG_L1': ['CatBoost_r69_BAG_L1'],\n",
       "  'NeuralNetFastAI_r103_BAG_L1': ['NeuralNetFastAI_r103_BAG_L1'],\n",
       "  'LightGBM_r161_BAG_L1': ['LightGBM_r161_BAG_L1'],\n",
       "  'NeuralNetFastAI_r143_BAG_L1': ['NeuralNetFastAI_r143_BAG_L1'],\n",
       "  'CatBoost_r70_BAG_L1': ['CatBoost_r70_BAG_L1'],\n",
       "  'NeuralNetFastAI_r156_BAG_L1': ['NeuralNetFastAI_r156_BAG_L1'],\n",
       "  'LightGBM_r196_BAG_L1': ['LightGBM_r196_BAG_L1'],\n",
       "  'CatBoost_r167_BAG_L1': ['CatBoost_r167_BAG_L1'],\n",
       "  'NeuralNetFastAI_r95_BAG_L1': ['NeuralNetFastAI_r95_BAG_L1'],\n",
       "  'XGBoost_r98_BAG_L1': ['XGBoost_r98_BAG_L1'],\n",
       "  'LightGBM_r15_BAG_L1': ['LightGBM_r15_BAG_L1'],\n",
       "  'CatBoost_r86_BAG_L1': ['CatBoost_r86_BAG_L1'],\n",
       "  'NeuralNetFastAI_r37_BAG_L1': ['NeuralNetFastAI_r37_BAG_L1'],\n",
       "  'CatBoost_r49_BAG_L1': ['CatBoost_r49_BAG_L1'],\n",
       "  'LightGBM_r143_BAG_L1': ['LightGBM_r143_BAG_L1'],\n",
       "  'NeuralNetFastAI_r134_BAG_L1': ['NeuralNetFastAI_r134_BAG_L1'],\n",
       "  'LightGBM_r94_BAG_L1': ['LightGBM_r94_BAG_L1'],\n",
       "  'CatBoost_r128_BAG_L1': ['CatBoost_r128_BAG_L1'],\n",
       "  'NeuralNetFastAI_r111_BAG_L1': ['NeuralNetFastAI_r111_BAG_L1'],\n",
       "  'NeuralNetFastAI_r65_BAG_L1': ['NeuralNetFastAI_r65_BAG_L1'],\n",
       "  'NeuralNetFastAI_r88_BAG_L1': ['NeuralNetFastAI_r88_BAG_L1'],\n",
       "  'LightGBM_r30_BAG_L1': ['LightGBM_r30_BAG_L1'],\n",
       "  'XGBoost_r49_BAG_L1': ['XGBoost_r49_BAG_L1'],\n",
       "  'CatBoost_r5_BAG_L1': ['CatBoost_r5_BAG_L1'],\n",
       "  'CatBoost_r143_BAG_L1': ['CatBoost_r143_BAG_L1'],\n",
       "  'XGBoost_r31_BAG_L1': ['XGBoost_r31_BAG_L1'],\n",
       "  'NeuralNetFastAI_r160_BAG_L1': ['NeuralNetFastAI_r160_BAG_L1'],\n",
       "  'CatBoost_r60_BAG_L1': ['CatBoost_r60_BAG_L1'],\n",
       "  'LightGBM_r135_BAG_L1': ['LightGBM_r135_BAG_L1'],\n",
       "  'XGBoost_r22_BAG_L1': ['XGBoost_r22_BAG_L1'],\n",
       "  'NeuralNetFastAI_r69_BAG_L1': ['NeuralNetFastAI_r69_BAG_L1'],\n",
       "  'CatBoost_r6_BAG_L1': ['CatBoost_r6_BAG_L1'],\n",
       "  'NeuralNetFastAI_r138_BAG_L1': ['NeuralNetFastAI_r138_BAG_L1'],\n",
       "  'LightGBM_r121_BAG_L1': ['LightGBM_r121_BAG_L1'],\n",
       "  'NeuralNetFastAI_r172_BAG_L1': ['NeuralNetFastAI_r172_BAG_L1'],\n",
       "  'CatBoost_r180_BAG_L1': ['CatBoost_r180_BAG_L1'],\n",
       "  'NeuralNetFastAI_r127_BAG_L1': ['NeuralNetFastAI_r127_BAG_L1'],\n",
       "  'NeuralNetFastAI_r194_BAG_L1': ['NeuralNetFastAI_r194_BAG_L1'],\n",
       "  'CatBoost_r12_BAG_L1': ['CatBoost_r12_BAG_L1'],\n",
       "  'NeuralNetFastAI_r4_BAG_L1': ['NeuralNetFastAI_r4_BAG_L1'],\n",
       "  'NeuralNetFastAI_r100_BAG_L1': ['NeuralNetFastAI_r100_BAG_L1'],\n",
       "  'CatBoost_r163_BAG_L1': ['CatBoost_r163_BAG_L1'],\n",
       "  'CatBoost_r198_BAG_L1': ['CatBoost_r198_BAG_L1'],\n",
       "  'NeuralNetFastAI_r187_BAG_L1': ['NeuralNetFastAI_r187_BAG_L1'],\n",
       "  'XGBoost_r95_BAG_L1': ['XGBoost_r95_BAG_L1'],\n",
       "  'XGBoost_r34_BAG_L1': ['XGBoost_r34_BAG_L1'],\n",
       "  'LightGBM_r42_BAG_L1': ['LightGBM_r42_BAG_L1'],\n",
       "  'WeightedEnsemble_L2': ['WeightedEnsemble_L2'],\n",
       "  'LightGBMXT_BAG_L1_FULL': ['LightGBMXT_BAG_L1_FULL'],\n",
       "  'LightGBM_BAG_L1_FULL': ['LightGBM_BAG_L1_FULL'],\n",
       "  'CatBoost_BAG_L1_FULL': ['CatBoost_BAG_L1_FULL'],\n",
       "  'NeuralNetFastAI_BAG_L1_FULL': ['NeuralNetFastAI_BAG_L1_FULL'],\n",
       "  'XGBoost_BAG_L1_FULL': ['XGBoost_BAG_L1_FULL'],\n",
       "  'LightGBMLarge_BAG_L1_FULL': ['LightGBMLarge_BAG_L1_FULL'],\n",
       "  'CatBoost_r177_BAG_L1_FULL': ['CatBoost_r177_BAG_L1_FULL'],\n",
       "  'LightGBM_r131_BAG_L1_FULL': ['LightGBM_r131_BAG_L1_FULL'],\n",
       "  'NeuralNetFastAI_r191_BAG_L1_FULL': ['NeuralNetFastAI_r191_BAG_L1_FULL'],\n",
       "  'CatBoost_r9_BAG_L1_FULL': ['CatBoost_r9_BAG_L1_FULL'],\n",
       "  'LightGBM_r96_BAG_L1_FULL': ['LightGBM_r96_BAG_L1_FULL'],\n",
       "  'XGBoost_r33_BAG_L1_FULL': ['XGBoost_r33_BAG_L1_FULL'],\n",
       "  'CatBoost_r137_BAG_L1_FULL': ['CatBoost_r137_BAG_L1_FULL'],\n",
       "  'NeuralNetFastAI_r102_BAG_L1_FULL': ['NeuralNetFastAI_r102_BAG_L1_FULL'],\n",
       "  'CatBoost_r13_BAG_L1_FULL': ['CatBoost_r13_BAG_L1_FULL'],\n",
       "  'LightGBM_r188_BAG_L1_FULL': ['LightGBM_r188_BAG_L1_FULL'],\n",
       "  'NeuralNetFastAI_r145_BAG_L1_FULL': ['NeuralNetFastAI_r145_BAG_L1_FULL'],\n",
       "  'XGBoost_r89_BAG_L1_FULL': ['XGBoost_r89_BAG_L1_FULL'],\n",
       "  'LightGBM_r130_BAG_L1_FULL': ['LightGBM_r130_BAG_L1_FULL'],\n",
       "  'CatBoost_r50_BAG_L1_FULL': ['CatBoost_r50_BAG_L1_FULL'],\n",
       "  'NeuralNetFastAI_r11_BAG_L1_FULL': ['NeuralNetFastAI_r11_BAG_L1_FULL'],\n",
       "  'XGBoost_r194_BAG_L1_FULL': ['XGBoost_r194_BAG_L1_FULL'],\n",
       "  'CatBoost_r69_BAG_L1_FULL': ['CatBoost_r69_BAG_L1_FULL'],\n",
       "  'NeuralNetFastAI_r103_BAG_L1_FULL': ['NeuralNetFastAI_r103_BAG_L1_FULL'],\n",
       "  'LightGBM_r161_BAG_L1_FULL': ['LightGBM_r161_BAG_L1_FULL'],\n",
       "  'NeuralNetFastAI_r143_BAG_L1_FULL': ['NeuralNetFastAI_r143_BAG_L1_FULL'],\n",
       "  'CatBoost_r70_BAG_L1_FULL': ['CatBoost_r70_BAG_L1_FULL'],\n",
       "  'NeuralNetFastAI_r156_BAG_L1_FULL': ['NeuralNetFastAI_r156_BAG_L1_FULL'],\n",
       "  'LightGBM_r196_BAG_L1_FULL': ['LightGBM_r196_BAG_L1_FULL'],\n",
       "  'CatBoost_r167_BAG_L1_FULL': ['CatBoost_r167_BAG_L1_FULL'],\n",
       "  'NeuralNetFastAI_r95_BAG_L1_FULL': ['NeuralNetFastAI_r95_BAG_L1_FULL'],\n",
       "  'XGBoost_r98_BAG_L1_FULL': ['XGBoost_r98_BAG_L1_FULL'],\n",
       "  'LightGBM_r15_BAG_L1_FULL': ['LightGBM_r15_BAG_L1_FULL'],\n",
       "  'CatBoost_r86_BAG_L1_FULL': ['CatBoost_r86_BAG_L1_FULL'],\n",
       "  'NeuralNetFastAI_r37_BAG_L1_FULL': ['NeuralNetFastAI_r37_BAG_L1_FULL'],\n",
       "  'CatBoost_r49_BAG_L1_FULL': ['CatBoost_r49_BAG_L1_FULL'],\n",
       "  'LightGBM_r143_BAG_L1_FULL': ['LightGBM_r143_BAG_L1_FULL'],\n",
       "  'NeuralNetFastAI_r134_BAG_L1_FULL': ['NeuralNetFastAI_r134_BAG_L1_FULL'],\n",
       "  'LightGBM_r94_BAG_L1_FULL': ['LightGBM_r94_BAG_L1_FULL'],\n",
       "  'CatBoost_r128_BAG_L1_FULL': ['CatBoost_r128_BAG_L1_FULL'],\n",
       "  'NeuralNetFastAI_r111_BAG_L1_FULL': ['NeuralNetFastAI_r111_BAG_L1_FULL'],\n",
       "  'NeuralNetFastAI_r65_BAG_L1_FULL': ['NeuralNetFastAI_r65_BAG_L1_FULL'],\n",
       "  'NeuralNetFastAI_r88_BAG_L1_FULL': ['NeuralNetFastAI_r88_BAG_L1_FULL'],\n",
       "  'LightGBM_r30_BAG_L1_FULL': ['LightGBM_r30_BAG_L1_FULL'],\n",
       "  'XGBoost_r49_BAG_L1_FULL': ['XGBoost_r49_BAG_L1_FULL'],\n",
       "  'CatBoost_r5_BAG_L1_FULL': ['CatBoost_r5_BAG_L1_FULL'],\n",
       "  'CatBoost_r143_BAG_L1_FULL': ['CatBoost_r143_BAG_L1_FULL'],\n",
       "  'XGBoost_r31_BAG_L1_FULL': ['XGBoost_r31_BAG_L1_FULL'],\n",
       "  'NeuralNetFastAI_r160_BAG_L1_FULL': ['NeuralNetFastAI_r160_BAG_L1_FULL'],\n",
       "  'CatBoost_r60_BAG_L1_FULL': ['CatBoost_r60_BAG_L1_FULL'],\n",
       "  'LightGBM_r135_BAG_L1_FULL': ['LightGBM_r135_BAG_L1_FULL'],\n",
       "  'XGBoost_r22_BAG_L1_FULL': ['XGBoost_r22_BAG_L1_FULL'],\n",
       "  'NeuralNetFastAI_r69_BAG_L1_FULL': ['NeuralNetFastAI_r69_BAG_L1_FULL'],\n",
       "  'CatBoost_r6_BAG_L1_FULL': ['CatBoost_r6_BAG_L1_FULL'],\n",
       "  'NeuralNetFastAI_r138_BAG_L1_FULL': ['NeuralNetFastAI_r138_BAG_L1_FULL'],\n",
       "  'LightGBM_r121_BAG_L1_FULL': ['LightGBM_r121_BAG_L1_FULL'],\n",
       "  'NeuralNetFastAI_r172_BAG_L1_FULL': ['NeuralNetFastAI_r172_BAG_L1_FULL'],\n",
       "  'CatBoost_r180_BAG_L1_FULL': ['CatBoost_r180_BAG_L1_FULL'],\n",
       "  'NeuralNetFastAI_r127_BAG_L1_FULL': ['NeuralNetFastAI_r127_BAG_L1_FULL'],\n",
       "  'NeuralNetFastAI_r194_BAG_L1_FULL': ['NeuralNetFastAI_r194_BAG_L1_FULL'],\n",
       "  'CatBoost_r12_BAG_L1_FULL': ['CatBoost_r12_BAG_L1_FULL'],\n",
       "  'NeuralNetFastAI_r4_BAG_L1_FULL': ['NeuralNetFastAI_r4_BAG_L1_FULL'],\n",
       "  'NeuralNetFastAI_r100_BAG_L1_FULL': ['NeuralNetFastAI_r100_BAG_L1_FULL'],\n",
       "  'CatBoost_r163_BAG_L1_FULL': ['CatBoost_r163_BAG_L1_FULL'],\n",
       "  'CatBoost_r198_BAG_L1_FULL': ['CatBoost_r198_BAG_L1_FULL'],\n",
       "  'NeuralNetFastAI_r187_BAG_L1_FULL': ['NeuralNetFastAI_r187_BAG_L1_FULL'],\n",
       "  'XGBoost_r95_BAG_L1_FULL': ['XGBoost_r95_BAG_L1_FULL'],\n",
       "  'XGBoost_r34_BAG_L1_FULL': ['XGBoost_r34_BAG_L1_FULL'],\n",
       "  'LightGBM_r42_BAG_L1_FULL': ['LightGBM_r42_BAG_L1_FULL'],\n",
       "  'WeightedEnsemble_L2_FULL': ['WeightedEnsemble_L2_FULL']},\n",
       " 'model_fit_times': {'LightGBMXT_BAG_L1': 1.5782434940338135,\n",
       "  'LightGBM_BAG_L1': 1.9682748317718506,\n",
       "  'CatBoost_BAG_L1': 42.84414577484131,\n",
       "  'NeuralNetFastAI_BAG_L1': 7.839491844177246,\n",
       "  'XGBoost_BAG_L1': 2.607234001159668,\n",
       "  'LightGBMLarge_BAG_L1': 2.2636353969573975,\n",
       "  'CatBoost_r177_BAG_L1': 83.46785616874695,\n",
       "  'LightGBM_r131_BAG_L1': 2.1343069076538086,\n",
       "  'NeuralNetFastAI_r191_BAG_L1': 10.347082138061523,\n",
       "  'CatBoost_r9_BAG_L1': 80.55807876586914,\n",
       "  'LightGBM_r96_BAG_L1': 3.9397170543670654,\n",
       "  'XGBoost_r33_BAG_L1': 3.161743402481079,\n",
       "  'CatBoost_r137_BAG_L1': 72.48775053024292,\n",
       "  'NeuralNetFastAI_r102_BAG_L1': 7.200621128082275,\n",
       "  'CatBoost_r13_BAG_L1': 229.9412066936493,\n",
       "  'LightGBM_r188_BAG_L1': 2.0663373470306396,\n",
       "  'NeuralNetFastAI_r145_BAG_L1': 5.975148677825928,\n",
       "  'XGBoost_r89_BAG_L1': 1.840804100036621,\n",
       "  'LightGBM_r130_BAG_L1': 1.9960002899169922,\n",
       "  'CatBoost_r50_BAG_L1': 16.33664870262146,\n",
       "  'NeuralNetFastAI_r11_BAG_L1': 7.320618152618408,\n",
       "  'XGBoost_r194_BAG_L1': 2.214602470397949,\n",
       "  'CatBoost_r69_BAG_L1': 27.296520948410034,\n",
       "  'NeuralNetFastAI_r103_BAG_L1': 8.540509223937988,\n",
       "  'LightGBM_r161_BAG_L1': 3.0218634605407715,\n",
       "  'NeuralNetFastAI_r143_BAG_L1': 7.859337568283081,\n",
       "  'CatBoost_r70_BAG_L1': 33.14875411987305,\n",
       "  'NeuralNetFastAI_r156_BAG_L1': 7.9142162799835205,\n",
       "  'LightGBM_r196_BAG_L1': 4.871945381164551,\n",
       "  'CatBoost_r167_BAG_L1': 32.5906023979187,\n",
       "  'NeuralNetFastAI_r95_BAG_L1': 5.908298492431641,\n",
       "  'XGBoost_r98_BAG_L1': 6.512934923171997,\n",
       "  'LightGBM_r15_BAG_L1': 2.182910203933716,\n",
       "  'CatBoost_r86_BAG_L1': 643.359680891037,\n",
       "  'NeuralNetFastAI_r37_BAG_L1': 8.507339715957642,\n",
       "  'CatBoost_r49_BAG_L1': 30.590431451797485,\n",
       "  'LightGBM_r143_BAG_L1': 2.550541400909424,\n",
       "  'NeuralNetFastAI_r134_BAG_L1': 10.33436369895935,\n",
       "  'LightGBM_r94_BAG_L1': 2.478766441345215,\n",
       "  'CatBoost_r128_BAG_L1': 81.11020112037659,\n",
       "  'NeuralNetFastAI_r111_BAG_L1': 6.8775794506073,\n",
       "  'NeuralNetFastAI_r65_BAG_L1': 7.9892308712005615,\n",
       "  'NeuralNetFastAI_r88_BAG_L1': 7.454656600952148,\n",
       "  'LightGBM_r30_BAG_L1': 3.672773838043213,\n",
       "  'XGBoost_r49_BAG_L1': 2.283181667327881,\n",
       "  'CatBoost_r5_BAG_L1': 19.4703209400177,\n",
       "  'CatBoost_r143_BAG_L1': 59.95056891441345,\n",
       "  'XGBoost_r31_BAG_L1': 6.761810779571533,\n",
       "  'NeuralNetFastAI_r160_BAG_L1': 6.335960149765015,\n",
       "  'CatBoost_r60_BAG_L1': 34.28137683868408,\n",
       "  'LightGBM_r135_BAG_L1': 2.481856107711792,\n",
       "  'XGBoost_r22_BAG_L1': 1.925295352935791,\n",
       "  'NeuralNetFastAI_r69_BAG_L1': 5.946675777435303,\n",
       "  'CatBoost_r6_BAG_L1': 23.672377586364746,\n",
       "  'NeuralNetFastAI_r138_BAG_L1': 6.6575281620025635,\n",
       "  'LightGBM_r121_BAG_L1': 2.8745274543762207,\n",
       "  'NeuralNetFastAI_r172_BAG_L1': 7.67415189743042,\n",
       "  'CatBoost_r180_BAG_L1': 62.0970184803009,\n",
       "  'NeuralNetFastAI_r127_BAG_L1': 7.369765043258667,\n",
       "  'NeuralNetFastAI_r194_BAG_L1': 7.577571153640747,\n",
       "  'CatBoost_r12_BAG_L1': 94.34133744239807,\n",
       "  'NeuralNetFastAI_r4_BAG_L1': 7.723455429077148,\n",
       "  'NeuralNetFastAI_r100_BAG_L1': 11.320963382720947,\n",
       "  'CatBoost_r163_BAG_L1': 21.919345140457153,\n",
       "  'CatBoost_r198_BAG_L1': 57.14369058609009,\n",
       "  'NeuralNetFastAI_r187_BAG_L1': 8.06131100654602,\n",
       "  'XGBoost_r95_BAG_L1': 2.4125518798828125,\n",
       "  'XGBoost_r34_BAG_L1': 3.387580394744873,\n",
       "  'LightGBM_r42_BAG_L1': 1.9577832221984863,\n",
       "  'WeightedEnsemble_L2': 0.0328831672668457,\n",
       "  'LightGBMXT_BAG_L1_FULL': 0.40646958351135254,\n",
       "  'LightGBM_BAG_L1_FULL': 0.11626315116882324,\n",
       "  'CatBoost_BAG_L1_FULL': 6.258259534835815,\n",
       "  'NeuralNetFastAI_BAG_L1_FULL': 1.0738208293914795,\n",
       "  'XGBoost_BAG_L1_FULL': 0.10466933250427246,\n",
       "  'LightGBMLarge_BAG_L1_FULL': 0.17343902587890625,\n",
       "  'CatBoost_r177_BAG_L1_FULL': 8.453064680099487,\n",
       "  'LightGBM_r131_BAG_L1_FULL': 0.1756758689880371,\n",
       "  'NeuralNetFastAI_r191_BAG_L1_FULL': 0.9108409881591797,\n",
       "  'CatBoost_r9_BAG_L1_FULL': 11.937402963638306,\n",
       "  'LightGBM_r96_BAG_L1_FULL': 0.20267844200134277,\n",
       "  'XGBoost_r33_BAG_L1_FULL': 0.2397480010986328,\n",
       "  'CatBoost_r137_BAG_L1_FULL': 8.123680830001831,\n",
       "  'NeuralNetFastAI_r102_BAG_L1_FULL': 0.8691258430480957,\n",
       "  'CatBoost_r13_BAG_L1_FULL': 29.177050590515137,\n",
       "  'LightGBM_r188_BAG_L1_FULL': 0.17218279838562012,\n",
       "  'NeuralNetFastAI_r145_BAG_L1_FULL': 0.423886775970459,\n",
       "  'XGBoost_r89_BAG_L1_FULL': 0.07045745849609375,\n",
       "  'LightGBM_r130_BAG_L1_FULL': 0.12824463844299316,\n",
       "  'CatBoost_r50_BAG_L1_FULL': 1.259650468826294,\n",
       "  'NeuralNetFastAI_r11_BAG_L1_FULL': 0.23572444915771484,\n",
       "  'XGBoost_r194_BAG_L1_FULL': 0.09856605529785156,\n",
       "  'CatBoost_r69_BAG_L1_FULL': 3.351287603378296,\n",
       "  'NeuralNetFastAI_r103_BAG_L1_FULL': 1.304189682006836,\n",
       "  'LightGBM_r161_BAG_L1_FULL': 0.2527480125427246,\n",
       "  'NeuralNetFastAI_r143_BAG_L1_FULL': 1.3779184818267822,\n",
       "  'CatBoost_r70_BAG_L1_FULL': 3.967215061187744,\n",
       "  'NeuralNetFastAI_r156_BAG_L1_FULL': 0.9372010231018066,\n",
       "  'LightGBM_r196_BAG_L1_FULL': 0.5928771495819092,\n",
       "  'CatBoost_r167_BAG_L1_FULL': 3.2874155044555664,\n",
       "  'NeuralNetFastAI_r95_BAG_L1_FULL': 0.316439151763916,\n",
       "  'XGBoost_r98_BAG_L1_FULL': 0.716771125793457,\n",
       "  'LightGBM_r15_BAG_L1_FULL': 0.15133881568908691,\n",
       "  'CatBoost_r86_BAG_L1_FULL': 58.40003991127014,\n",
       "  'NeuralNetFastAI_r37_BAG_L1_FULL': 1.598660945892334,\n",
       "  'CatBoost_r49_BAG_L1_FULL': 3.939840793609619,\n",
       "  'LightGBM_r143_BAG_L1_FULL': 0.17795562744140625,\n",
       "  'NeuralNetFastAI_r134_BAG_L1_FULL': 0.9929964542388916,\n",
       "  'LightGBM_r94_BAG_L1_FULL': 0.18433427810668945,\n",
       "  'CatBoost_r128_BAG_L1_FULL': 10.83981728553772,\n",
       "  'NeuralNetFastAI_r111_BAG_L1_FULL': 1.0565671920776367,\n",
       "  'NeuralNetFastAI_r65_BAG_L1_FULL': 1.9084053039550781,\n",
       "  'NeuralNetFastAI_r88_BAG_L1_FULL': 0.5355854034423828,\n",
       "  'LightGBM_r30_BAG_L1_FULL': 0.2903623580932617,\n",
       "  'XGBoost_r49_BAG_L1_FULL': 0.08649468421936035,\n",
       "  'CatBoost_r5_BAG_L1_FULL': 3.0127973556518555,\n",
       "  'CatBoost_r143_BAG_L1_FULL': 7.070833206176758,\n",
       "  'XGBoost_r31_BAG_L1_FULL': 0.4150087833404541,\n",
       "  'NeuralNetFastAI_r160_BAG_L1_FULL': 0.3244929313659668,\n",
       "  'CatBoost_r60_BAG_L1_FULL': 4.53223180770874,\n",
       "  'LightGBM_r135_BAG_L1_FULL': 0.14330554008483887,\n",
       "  'XGBoost_r22_BAG_L1_FULL': 0.0622408390045166,\n",
       "  'NeuralNetFastAI_r69_BAG_L1_FULL': 0.3268246650695801,\n",
       "  'CatBoost_r6_BAG_L1_FULL': 2.3479418754577637,\n",
       "  'NeuralNetFastAI_r138_BAG_L1_FULL': 0.4334902763366699,\n",
       "  'LightGBM_r121_BAG_L1_FULL': 0.25083398818969727,\n",
       "  'NeuralNetFastAI_r172_BAG_L1_FULL': 0.5881240367889404,\n",
       "  'CatBoost_r180_BAG_L1_FULL': 7.4744884967803955,\n",
       "  'NeuralNetFastAI_r127_BAG_L1_FULL': 0.9530446529388428,\n",
       "  'NeuralNetFastAI_r194_BAG_L1_FULL': 1.1827223300933838,\n",
       "  'CatBoost_r12_BAG_L1_FULL': 12.204522609710693,\n",
       "  'NeuralNetFastAI_r4_BAG_L1_FULL': 0.9348933696746826,\n",
       "  'NeuralNetFastAI_r100_BAG_L1_FULL': 1.0093286037445068,\n",
       "  'CatBoost_r163_BAG_L1_FULL': 2.132948160171509,\n",
       "  'CatBoost_r198_BAG_L1_FULL': 7.4996538162231445,\n",
       "  'NeuralNetFastAI_r187_BAG_L1_FULL': 1.2889344692230225,\n",
       "  'XGBoost_r95_BAG_L1_FULL': 0.10394072532653809,\n",
       "  'XGBoost_r34_BAG_L1_FULL': 0.17336606979370117,\n",
       "  'LightGBM_r42_BAG_L1_FULL': 0.15822196006774902,\n",
       "  'WeightedEnsemble_L2_FULL': 0.0328831672668457},\n",
       " 'model_pred_times': {'LightGBMXT_BAG_L1': 0.03944849967956543,\n",
       "  'LightGBM_BAG_L1': 0.031246662139892578,\n",
       "  'CatBoost_BAG_L1': 0.06261801719665527,\n",
       "  'NeuralNetFastAI_BAG_L1': 0.09020328521728516,\n",
       "  'XGBoost_BAG_L1': 0.048339128494262695,\n",
       "  'LightGBMLarge_BAG_L1': 0.03129982948303223,\n",
       "  'CatBoost_r177_BAG_L1': 0.056401729583740234,\n",
       "  'LightGBM_r131_BAG_L1': 0.03411054611206055,\n",
       "  'NeuralNetFastAI_r191_BAG_L1': 0.1064453125,\n",
       "  'CatBoost_r9_BAG_L1': 0.06061387062072754,\n",
       "  'LightGBM_r96_BAG_L1': 0.03852248191833496,\n",
       "  'XGBoost_r33_BAG_L1': 0.0460205078125,\n",
       "  'CatBoost_r137_BAG_L1': 0.05346083641052246,\n",
       "  'NeuralNetFastAI_r102_BAG_L1': 0.08090686798095703,\n",
       "  'CatBoost_r13_BAG_L1': 0.06274747848510742,\n",
       "  'LightGBM_r188_BAG_L1': 0.035149335861206055,\n",
       "  'NeuralNetFastAI_r145_BAG_L1': 0.09224247932434082,\n",
       "  'XGBoost_r89_BAG_L1': 0.046597957611083984,\n",
       "  'LightGBM_r130_BAG_L1': 0.0300142765045166,\n",
       "  'CatBoost_r50_BAG_L1': 0.0665285587310791,\n",
       "  'NeuralNetFastAI_r11_BAG_L1': 0.1053171157836914,\n",
       "  'XGBoost_r194_BAG_L1': 0.11668872833251953,\n",
       "  'CatBoost_r69_BAG_L1': 0.06209087371826172,\n",
       "  'NeuralNetFastAI_r103_BAG_L1': 0.08910298347473145,\n",
       "  'LightGBM_r161_BAG_L1': 0.03687787055969238,\n",
       "  'NeuralNetFastAI_r143_BAG_L1': 0.08770895004272461,\n",
       "  'CatBoost_r70_BAG_L1': 0.06536221504211426,\n",
       "  'NeuralNetFastAI_r156_BAG_L1': 0.08878636360168457,\n",
       "  'LightGBM_r196_BAG_L1': 0.04939556121826172,\n",
       "  'CatBoost_r167_BAG_L1': 0.055431365966796875,\n",
       "  'NeuralNetFastAI_r95_BAG_L1': 0.09087848663330078,\n",
       "  'XGBoost_r98_BAG_L1': 0.09402656555175781,\n",
       "  'LightGBM_r15_BAG_L1': 0.02955770492553711,\n",
       "  'CatBoost_r86_BAG_L1': 0.060135602951049805,\n",
       "  'NeuralNetFastAI_r37_BAG_L1': 0.09514474868774414,\n",
       "  'CatBoost_r49_BAG_L1': 0.05627894401550293,\n",
       "  'LightGBM_r143_BAG_L1': 0.03261208534240723,\n",
       "  'NeuralNetFastAI_r134_BAG_L1': 0.09996342658996582,\n",
       "  'LightGBM_r94_BAG_L1': 0.03515148162841797,\n",
       "  'CatBoost_r128_BAG_L1': 0.06368756294250488,\n",
       "  'NeuralNetFastAI_r111_BAG_L1': 0.09056973457336426,\n",
       "  'NeuralNetFastAI_r65_BAG_L1': 0.07883286476135254,\n",
       "  'NeuralNetFastAI_r88_BAG_L1': 0.09016871452331543,\n",
       "  'LightGBM_r30_BAG_L1': 0.042316436767578125,\n",
       "  'XGBoost_r49_BAG_L1': 0.046408653259277344,\n",
       "  'CatBoost_r5_BAG_L1': 0.054334163665771484,\n",
       "  'CatBoost_r143_BAG_L1': 0.06042170524597168,\n",
       "  'XGBoost_r31_BAG_L1': 0.048506736755371094,\n",
       "  'NeuralNetFastAI_r160_BAG_L1': 0.09219503402709961,\n",
       "  'CatBoost_r60_BAG_L1': 0.0564882755279541,\n",
       "  'LightGBM_r135_BAG_L1': 0.03574419021606445,\n",
       "  'XGBoost_r22_BAG_L1': 0.0443873405456543,\n",
       "  'NeuralNetFastAI_r69_BAG_L1': 0.07932639122009277,\n",
       "  'CatBoost_r6_BAG_L1': 0.061258792877197266,\n",
       "  'NeuralNetFastAI_r138_BAG_L1': 0.09774947166442871,\n",
       "  'LightGBM_r121_BAG_L1': 0.040355682373046875,\n",
       "  'NeuralNetFastAI_r172_BAG_L1': 0.08152174949645996,\n",
       "  'CatBoost_r180_BAG_L1': 0.05948591232299805,\n",
       "  'NeuralNetFastAI_r127_BAG_L1': 0.08524918556213379,\n",
       "  'NeuralNetFastAI_r194_BAG_L1': 0.10005688667297363,\n",
       "  'CatBoost_r12_BAG_L1': 0.06208443641662598,\n",
       "  'NeuralNetFastAI_r4_BAG_L1': 0.08975434303283691,\n",
       "  'NeuralNetFastAI_r100_BAG_L1': 0.11744928359985352,\n",
       "  'CatBoost_r163_BAG_L1': 0.05772089958190918,\n",
       "  'CatBoost_r198_BAG_L1': 0.0644223690032959,\n",
       "  'NeuralNetFastAI_r187_BAG_L1': 0.08986783027648926,\n",
       "  'XGBoost_r95_BAG_L1': 0.05074501037597656,\n",
       "  'XGBoost_r34_BAG_L1': 0.04968142509460449,\n",
       "  'LightGBM_r42_BAG_L1': 0.03232002258300781,\n",
       "  'WeightedEnsemble_L2': 0.0,\n",
       "  'LightGBMXT_BAG_L1_FULL': None,\n",
       "  'LightGBM_BAG_L1_FULL': None,\n",
       "  'CatBoost_BAG_L1_FULL': None,\n",
       "  'NeuralNetFastAI_BAG_L1_FULL': None,\n",
       "  'XGBoost_BAG_L1_FULL': None,\n",
       "  'LightGBMLarge_BAG_L1_FULL': None,\n",
       "  'CatBoost_r177_BAG_L1_FULL': None,\n",
       "  'LightGBM_r131_BAG_L1_FULL': None,\n",
       "  'NeuralNetFastAI_r191_BAG_L1_FULL': None,\n",
       "  'CatBoost_r9_BAG_L1_FULL': None,\n",
       "  'LightGBM_r96_BAG_L1_FULL': None,\n",
       "  'XGBoost_r33_BAG_L1_FULL': None,\n",
       "  'CatBoost_r137_BAG_L1_FULL': None,\n",
       "  'NeuralNetFastAI_r102_BAG_L1_FULL': None,\n",
       "  'CatBoost_r13_BAG_L1_FULL': None,\n",
       "  'LightGBM_r188_BAG_L1_FULL': None,\n",
       "  'NeuralNetFastAI_r145_BAG_L1_FULL': None,\n",
       "  'XGBoost_r89_BAG_L1_FULL': None,\n",
       "  'LightGBM_r130_BAG_L1_FULL': None,\n",
       "  'CatBoost_r50_BAG_L1_FULL': None,\n",
       "  'NeuralNetFastAI_r11_BAG_L1_FULL': None,\n",
       "  'XGBoost_r194_BAG_L1_FULL': None,\n",
       "  'CatBoost_r69_BAG_L1_FULL': None,\n",
       "  'NeuralNetFastAI_r103_BAG_L1_FULL': None,\n",
       "  'LightGBM_r161_BAG_L1_FULL': None,\n",
       "  'NeuralNetFastAI_r143_BAG_L1_FULL': None,\n",
       "  'CatBoost_r70_BAG_L1_FULL': None,\n",
       "  'NeuralNetFastAI_r156_BAG_L1_FULL': None,\n",
       "  'LightGBM_r196_BAG_L1_FULL': None,\n",
       "  'CatBoost_r167_BAG_L1_FULL': None,\n",
       "  'NeuralNetFastAI_r95_BAG_L1_FULL': None,\n",
       "  'XGBoost_r98_BAG_L1_FULL': None,\n",
       "  'LightGBM_r15_BAG_L1_FULL': None,\n",
       "  'CatBoost_r86_BAG_L1_FULL': None,\n",
       "  'NeuralNetFastAI_r37_BAG_L1_FULL': None,\n",
       "  'CatBoost_r49_BAG_L1_FULL': None,\n",
       "  'LightGBM_r143_BAG_L1_FULL': None,\n",
       "  'NeuralNetFastAI_r134_BAG_L1_FULL': None,\n",
       "  'LightGBM_r94_BAG_L1_FULL': None,\n",
       "  'CatBoost_r128_BAG_L1_FULL': None,\n",
       "  'NeuralNetFastAI_r111_BAG_L1_FULL': None,\n",
       "  'NeuralNetFastAI_r65_BAG_L1_FULL': None,\n",
       "  'NeuralNetFastAI_r88_BAG_L1_FULL': None,\n",
       "  'LightGBM_r30_BAG_L1_FULL': None,\n",
       "  'XGBoost_r49_BAG_L1_FULL': None,\n",
       "  'CatBoost_r5_BAG_L1_FULL': None,\n",
       "  'CatBoost_r143_BAG_L1_FULL': None,\n",
       "  'XGBoost_r31_BAG_L1_FULL': None,\n",
       "  'NeuralNetFastAI_r160_BAG_L1_FULL': None,\n",
       "  'CatBoost_r60_BAG_L1_FULL': None,\n",
       "  'LightGBM_r135_BAG_L1_FULL': None,\n",
       "  'XGBoost_r22_BAG_L1_FULL': None,\n",
       "  'NeuralNetFastAI_r69_BAG_L1_FULL': None,\n",
       "  'CatBoost_r6_BAG_L1_FULL': None,\n",
       "  'NeuralNetFastAI_r138_BAG_L1_FULL': None,\n",
       "  'LightGBM_r121_BAG_L1_FULL': None,\n",
       "  'NeuralNetFastAI_r172_BAG_L1_FULL': None,\n",
       "  'CatBoost_r180_BAG_L1_FULL': None,\n",
       "  'NeuralNetFastAI_r127_BAG_L1_FULL': None,\n",
       "  'NeuralNetFastAI_r194_BAG_L1_FULL': None,\n",
       "  'CatBoost_r12_BAG_L1_FULL': None,\n",
       "  'NeuralNetFastAI_r4_BAG_L1_FULL': None,\n",
       "  'NeuralNetFastAI_r100_BAG_L1_FULL': None,\n",
       "  'CatBoost_r163_BAG_L1_FULL': None,\n",
       "  'CatBoost_r198_BAG_L1_FULL': None,\n",
       "  'NeuralNetFastAI_r187_BAG_L1_FULL': None,\n",
       "  'XGBoost_r95_BAG_L1_FULL': None,\n",
       "  'XGBoost_r34_BAG_L1_FULL': None,\n",
       "  'LightGBM_r42_BAG_L1_FULL': None,\n",
       "  'WeightedEnsemble_L2_FULL': None},\n",
       " 'num_bag_folds': 8,\n",
       " 'max_stack_level': 2,\n",
       " 'num_classes': 2,\n",
       " 'model_hyperparams': {'LightGBMXT_BAG_L1': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': False},\n",
       "  'LightGBM_BAG_L1': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': False},\n",
       "  'CatBoost_BAG_L1': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': False},\n",
       "  'NeuralNetFastAI_BAG_L1': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': False},\n",
       "  'XGBoost_BAG_L1': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': False},\n",
       "  'LightGBMLarge_BAG_L1': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': False},\n",
       "  'CatBoost_r177_BAG_L1': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': False},\n",
       "  'LightGBM_r131_BAG_L1': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': False},\n",
       "  'NeuralNetFastAI_r191_BAG_L1': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': False},\n",
       "  'CatBoost_r9_BAG_L1': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': False},\n",
       "  'LightGBM_r96_BAG_L1': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': False},\n",
       "  'XGBoost_r33_BAG_L1': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': False},\n",
       "  'CatBoost_r137_BAG_L1': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': False},\n",
       "  'NeuralNetFastAI_r102_BAG_L1': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': False},\n",
       "  'CatBoost_r13_BAG_L1': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': False},\n",
       "  'LightGBM_r188_BAG_L1': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': False},\n",
       "  'NeuralNetFastAI_r145_BAG_L1': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': False},\n",
       "  'XGBoost_r89_BAG_L1': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': False},\n",
       "  'LightGBM_r130_BAG_L1': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': False},\n",
       "  'CatBoost_r50_BAG_L1': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': False},\n",
       "  'NeuralNetFastAI_r11_BAG_L1': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': False},\n",
       "  'XGBoost_r194_BAG_L1': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': False},\n",
       "  'CatBoost_r69_BAG_L1': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': False},\n",
       "  'NeuralNetFastAI_r103_BAG_L1': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': False},\n",
       "  'LightGBM_r161_BAG_L1': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': False},\n",
       "  'NeuralNetFastAI_r143_BAG_L1': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': False},\n",
       "  'CatBoost_r70_BAG_L1': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': False},\n",
       "  'NeuralNetFastAI_r156_BAG_L1': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': False},\n",
       "  'LightGBM_r196_BAG_L1': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': False},\n",
       "  'CatBoost_r167_BAG_L1': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': False},\n",
       "  'NeuralNetFastAI_r95_BAG_L1': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': False},\n",
       "  'XGBoost_r98_BAG_L1': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': False},\n",
       "  'LightGBM_r15_BAG_L1': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': False},\n",
       "  'CatBoost_r86_BAG_L1': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': False},\n",
       "  'NeuralNetFastAI_r37_BAG_L1': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': False},\n",
       "  'CatBoost_r49_BAG_L1': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': False},\n",
       "  'LightGBM_r143_BAG_L1': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': False},\n",
       "  'NeuralNetFastAI_r134_BAG_L1': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': False},\n",
       "  'LightGBM_r94_BAG_L1': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': False},\n",
       "  'CatBoost_r128_BAG_L1': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': False},\n",
       "  'NeuralNetFastAI_r111_BAG_L1': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': False},\n",
       "  'NeuralNetFastAI_r65_BAG_L1': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': False},\n",
       "  'NeuralNetFastAI_r88_BAG_L1': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': False},\n",
       "  'LightGBM_r30_BAG_L1': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': False},\n",
       "  'XGBoost_r49_BAG_L1': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': False},\n",
       "  'CatBoost_r5_BAG_L1': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': False},\n",
       "  'CatBoost_r143_BAG_L1': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': False},\n",
       "  'XGBoost_r31_BAG_L1': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': False},\n",
       "  'NeuralNetFastAI_r160_BAG_L1': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': False},\n",
       "  'CatBoost_r60_BAG_L1': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': False},\n",
       "  'LightGBM_r135_BAG_L1': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': False},\n",
       "  'XGBoost_r22_BAG_L1': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': False},\n",
       "  'NeuralNetFastAI_r69_BAG_L1': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': False},\n",
       "  'CatBoost_r6_BAG_L1': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': False},\n",
       "  'NeuralNetFastAI_r138_BAG_L1': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': False},\n",
       "  'LightGBM_r121_BAG_L1': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': False},\n",
       "  'NeuralNetFastAI_r172_BAG_L1': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': False},\n",
       "  'CatBoost_r180_BAG_L1': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': False},\n",
       "  'NeuralNetFastAI_r127_BAG_L1': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': False},\n",
       "  'NeuralNetFastAI_r194_BAG_L1': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': False},\n",
       "  'CatBoost_r12_BAG_L1': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': False},\n",
       "  'NeuralNetFastAI_r4_BAG_L1': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': False},\n",
       "  'NeuralNetFastAI_r100_BAG_L1': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': False},\n",
       "  'CatBoost_r163_BAG_L1': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': False},\n",
       "  'CatBoost_r198_BAG_L1': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': False},\n",
       "  'NeuralNetFastAI_r187_BAG_L1': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': False},\n",
       "  'XGBoost_r95_BAG_L1': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': False},\n",
       "  'XGBoost_r34_BAG_L1': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': False},\n",
       "  'LightGBM_r42_BAG_L1': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': False},\n",
       "  'WeightedEnsemble_L2': {'use_orig_features': False,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True},\n",
       "  'LightGBMXT_BAG_L1_FULL': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True},\n",
       "  'LightGBM_BAG_L1_FULL': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True},\n",
       "  'CatBoost_BAG_L1_FULL': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True},\n",
       "  'NeuralNetFastAI_BAG_L1_FULL': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True},\n",
       "  'XGBoost_BAG_L1_FULL': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True},\n",
       "  'LightGBMLarge_BAG_L1_FULL': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True},\n",
       "  'CatBoost_r177_BAG_L1_FULL': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True},\n",
       "  'LightGBM_r131_BAG_L1_FULL': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True},\n",
       "  'NeuralNetFastAI_r191_BAG_L1_FULL': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True},\n",
       "  'CatBoost_r9_BAG_L1_FULL': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True},\n",
       "  'LightGBM_r96_BAG_L1_FULL': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True},\n",
       "  'XGBoost_r33_BAG_L1_FULL': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True},\n",
       "  'CatBoost_r137_BAG_L1_FULL': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True},\n",
       "  'NeuralNetFastAI_r102_BAG_L1_FULL': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True},\n",
       "  'CatBoost_r13_BAG_L1_FULL': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True},\n",
       "  'LightGBM_r188_BAG_L1_FULL': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True},\n",
       "  'NeuralNetFastAI_r145_BAG_L1_FULL': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True},\n",
       "  'XGBoost_r89_BAG_L1_FULL': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True},\n",
       "  'LightGBM_r130_BAG_L1_FULL': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True},\n",
       "  'CatBoost_r50_BAG_L1_FULL': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True},\n",
       "  'NeuralNetFastAI_r11_BAG_L1_FULL': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True},\n",
       "  'XGBoost_r194_BAG_L1_FULL': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True},\n",
       "  'CatBoost_r69_BAG_L1_FULL': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True},\n",
       "  'NeuralNetFastAI_r103_BAG_L1_FULL': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True},\n",
       "  'LightGBM_r161_BAG_L1_FULL': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True},\n",
       "  'NeuralNetFastAI_r143_BAG_L1_FULL': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True},\n",
       "  'CatBoost_r70_BAG_L1_FULL': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True},\n",
       "  'NeuralNetFastAI_r156_BAG_L1_FULL': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True},\n",
       "  'LightGBM_r196_BAG_L1_FULL': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True},\n",
       "  'CatBoost_r167_BAG_L1_FULL': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True},\n",
       "  'NeuralNetFastAI_r95_BAG_L1_FULL': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True},\n",
       "  'XGBoost_r98_BAG_L1_FULL': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True},\n",
       "  'LightGBM_r15_BAG_L1_FULL': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True},\n",
       "  'CatBoost_r86_BAG_L1_FULL': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True},\n",
       "  'NeuralNetFastAI_r37_BAG_L1_FULL': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True},\n",
       "  'CatBoost_r49_BAG_L1_FULL': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True},\n",
       "  'LightGBM_r143_BAG_L1_FULL': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True},\n",
       "  'NeuralNetFastAI_r134_BAG_L1_FULL': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True},\n",
       "  'LightGBM_r94_BAG_L1_FULL': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True},\n",
       "  'CatBoost_r128_BAG_L1_FULL': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True},\n",
       "  'NeuralNetFastAI_r111_BAG_L1_FULL': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True},\n",
       "  'NeuralNetFastAI_r65_BAG_L1_FULL': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True},\n",
       "  'NeuralNetFastAI_r88_BAG_L1_FULL': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True},\n",
       "  'LightGBM_r30_BAG_L1_FULL': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True},\n",
       "  'XGBoost_r49_BAG_L1_FULL': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True},\n",
       "  'CatBoost_r5_BAG_L1_FULL': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True},\n",
       "  'CatBoost_r143_BAG_L1_FULL': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True},\n",
       "  'XGBoost_r31_BAG_L1_FULL': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True},\n",
       "  'NeuralNetFastAI_r160_BAG_L1_FULL': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True},\n",
       "  'CatBoost_r60_BAG_L1_FULL': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True},\n",
       "  'LightGBM_r135_BAG_L1_FULL': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True},\n",
       "  'XGBoost_r22_BAG_L1_FULL': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True},\n",
       "  'NeuralNetFastAI_r69_BAG_L1_FULL': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True},\n",
       "  'CatBoost_r6_BAG_L1_FULL': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True},\n",
       "  'NeuralNetFastAI_r138_BAG_L1_FULL': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True},\n",
       "  'LightGBM_r121_BAG_L1_FULL': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True},\n",
       "  'NeuralNetFastAI_r172_BAG_L1_FULL': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True},\n",
       "  'CatBoost_r180_BAG_L1_FULL': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True},\n",
       "  'NeuralNetFastAI_r127_BAG_L1_FULL': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True},\n",
       "  'NeuralNetFastAI_r194_BAG_L1_FULL': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True},\n",
       "  'CatBoost_r12_BAG_L1_FULL': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True},\n",
       "  'NeuralNetFastAI_r4_BAG_L1_FULL': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True},\n",
       "  'NeuralNetFastAI_r100_BAG_L1_FULL': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True},\n",
       "  'CatBoost_r163_BAG_L1_FULL': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True},\n",
       "  'CatBoost_r198_BAG_L1_FULL': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True},\n",
       "  'NeuralNetFastAI_r187_BAG_L1_FULL': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True},\n",
       "  'XGBoost_r95_BAG_L1_FULL': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True},\n",
       "  'XGBoost_r34_BAG_L1_FULL': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True},\n",
       "  'LightGBM_r42_BAG_L1_FULL': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True},\n",
       "  'WeightedEnsemble_L2_FULL': {'use_orig_features': False,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True}},\n",
       " 'leaderboard':                          model  score_val eval_metric  pred_time_val  \\\n",
       " 0          WeightedEnsemble_L2   0.952550     roc_auc       0.188416   \n",
       " 1            LightGBMXT_BAG_L1   0.942165     roc_auc       0.039448   \n",
       " 2          LightGBM_r30_BAG_L1   0.939379     roc_auc       0.042316   \n",
       " 3          LightGBM_r94_BAG_L1   0.935917     roc_auc       0.035151   \n",
       " 4           CatBoost_r6_BAG_L1   0.934566     roc_auc       0.061259   \n",
       " ..                         ...        ...         ...            ...   \n",
       " 135   CatBoost_r13_BAG_L1_FULL        NaN     roc_auc            NaN   \n",
       " 136  CatBoost_r137_BAG_L1_FULL        NaN     roc_auc            NaN   \n",
       " 137   CatBoost_r12_BAG_L1_FULL        NaN     roc_auc            NaN   \n",
       " 138  CatBoost_r128_BAG_L1_FULL        NaN     roc_auc            NaN   \n",
       " 139       CatBoost_BAG_L1_FULL        NaN     roc_auc            NaN   \n",
       " \n",
       "       fit_time  pred_time_val_marginal  fit_time_marginal  stack_level  \\\n",
       " 0    33.142842                0.000000           0.032883            2   \n",
       " 1     1.578243                0.039448           1.578243            1   \n",
       " 2     3.672774                0.042316           3.672774            1   \n",
       " 3     2.478766                0.035151           2.478766            1   \n",
       " 4    23.672378                0.061259          23.672378            1   \n",
       " ..         ...                     ...                ...          ...   \n",
       " 135  29.177051                     NaN          29.177051            1   \n",
       " 136   8.123681                     NaN           8.123681            1   \n",
       " 137  12.204523                     NaN          12.204523            1   \n",
       " 138  10.839817                     NaN          10.839817            1   \n",
       " 139   6.258260                     NaN           6.258260            1   \n",
       " \n",
       "      can_infer  fit_order  \n",
       " 0        False         70  \n",
       " 1        False          1  \n",
       " 2        False         44  \n",
       " 3        False         39  \n",
       " 4        False         54  \n",
       " ..         ...        ...  \n",
       " 135       True         85  \n",
       " 136       True         83  \n",
       " 137       True        131  \n",
       " 138       True        110  \n",
       " 139       True         73  \n",
       " \n",
       " [140 rows x 10 columns]}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.fit_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "auxiliary_metrics = ['balanced_accuracy', 'f1', 'f1_macro', 'f1_micro', 'roc_auc', 'average_precision', 'precision', 'recall', 'log_loss', 'pac_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluation: roc_auc on test data: 0.8839869281045751\n",
      "Evaluations on test data:\n",
      "{\n",
      "    \"roc_auc\": 0.8839869281045751,\n",
      "    \"accuracy\": 0.8412698412698413,\n",
      "    \"balanced_accuracy\": 0.7745098039215685,\n",
      "    \"mcc\": 0.5185629788417315,\n",
      "    \"f1\": 0.6153846153846154,\n",
      "    \"precision\": 0.5714285714285714,\n",
      "    \"recall\": 0.6666666666666666\n",
      "}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'roc_auc': 0.8839869281045751,\n",
       " 'accuracy': 0.8412698412698413,\n",
       " 'balanced_accuracy': 0.7745098039215685,\n",
       " 'mcc': 0.5185629788417315,\n",
       " 'f1': 0.6153846153846154,\n",
       " 'precision': 0.5714285714285714,\n",
       " 'recall': 0.6666666666666666}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.evaluate(\n",
    "    df_test,\n",
    "    silent = False,\n",
    "    auxiliary_metrics = auxiliary_metrics\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'predictor' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m predictors \u001b[38;5;241m=\u001b[39m \u001b[43mpredictor\u001b[49m\u001b[38;5;241m.\u001b[39mleaderboard(\n\u001b[0;32m      2\u001b[0m     df_test,\n\u001b[0;32m      3\u001b[0m     extra_metrics \u001b[38;5;241m=\u001b[39m auxiliary_metrics,\n\u001b[0;32m      4\u001b[0m     extra_info\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m      5\u001b[0m     silent\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m      6\u001b[0m )\n",
      "\u001b[1;31mNameError\u001b[0m: name 'predictor' is not defined"
     ]
    }
   ],
   "source": [
    "predictors = predictor.leaderboard(\n",
    "    df_test,\n",
    "    extra_metrics = auxiliary_metrics,\n",
    "    extra_info=True,\n",
    "    silent=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>score_test</th>\n",
       "      <th>balanced_accuracy</th>\n",
       "      <th>f1</th>\n",
       "      <th>f1_macro</th>\n",
       "      <th>f1_micro</th>\n",
       "      <th>roc_auc</th>\n",
       "      <th>average_precision</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>...</th>\n",
       "      <th>hyperparameters</th>\n",
       "      <th>hyperparameters_fit</th>\n",
       "      <th>ag_args_fit</th>\n",
       "      <th>features</th>\n",
       "      <th>compile_time</th>\n",
       "      <th>child_hyperparameters</th>\n",
       "      <th>child_hyperparameters_fit</th>\n",
       "      <th>child_ag_args_fit</th>\n",
       "      <th>ancestors</th>\n",
       "      <th>descendants</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LightGBM_BAG_L1_FULL</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.984043</td>\n",
       "      <td>0.954545</td>\n",
       "      <td>0.969165</td>\n",
       "      <td>0.976096</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.913043</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>{'use_orig_features': True, 'valid_stacker': True, 'max_base_models': 0, 'max_base_models_per_type': 'auto', 'save_bag_folds': True}</td>\n",
       "      <td>{}</td>\n",
       "      <td>{'max_memory_usage_ratio': 1.15, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': None, 'valid_special_types': None, 'ignored_type_group_special': None, 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'temperature_scalar': None, 'drop_unique': False}</td>\n",
       "      <td>[clin-tipoAlcohol.symbol_ratio. , clin-numCigarros, clin-tipoAlcohol, eval-TLP-Tavec-33_Recon_Ac_frente_RCl_LP-PD, demo-fechaNacimiento.dayofweek, eval-TLP-CubCorsi-totalinversos-PD, clin-reservaCognitiva_ocupacion, eval-TLP-FigRey-Duracion-PD, eval-TLP-Tavec-4_RI_B-PD, eval-TLP-Tavec-12_ESem_RI_A-PD, eval-TLP-Tavec-29_RCl_Cp_frente_RCl_LP-PD, ques-Sus-totalImpar-PD, clin-alcohol, ques-MMSE-memoria-PD, eval-TLP-Tavec-26_Sesgo-PD, demo-fechaNacimiento.year, eval-TLP-Tavec-1_RI_A1-PD, eval-TLP-Stroop-color-PD, eval-TLP-Tavec-11_RCl_LP-PD, demo-fechaEvaluacion.dayofweek, clin-tipoAlcohol.lowe...</td>\n",
       "      <td>None</td>\n",
       "      <td>{'learning_rate': 0.05, 'num_boost_round': 72}</td>\n",
       "      <td>{'num_boost_round': 72}</td>\n",
       "      <td>{'max_memory_usage_ratio': 1.0, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': ['bool', 'int', 'float', 'category'], 'valid_special_types': None, 'ignored_type_group_special': None, 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'temperature_scalar': None}</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LightGBMXT_BAG_L1_FULL</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>{'use_orig_features': True, 'valid_stacker': True, 'max_base_models': 0, 'max_base_models_per_type': 'auto', 'save_bag_folds': True}</td>\n",
       "      <td>{}</td>\n",
       "      <td>{'max_memory_usage_ratio': 1.15, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': None, 'valid_special_types': None, 'ignored_type_group_special': None, 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'temperature_scalar': None, 'drop_unique': False}</td>\n",
       "      <td>[clin-tipoAlcohol.symbol_ratio. , clin-numCigarros, clin-tipoAlcohol, eval-TLP-Tavec-33_Recon_Ac_frente_RCl_LP-PD, demo-fechaNacimiento.dayofweek, eval-TLP-CubCorsi-totalinversos-PD, clin-reservaCognitiva_ocupacion, eval-TLP-FigRey-Duracion-PD, eval-TLP-Tavec-4_RI_B-PD, eval-TLP-Tavec-12_ESem_RI_A-PD, eval-TLP-Tavec-29_RCl_Cp_frente_RCl_LP-PD, ques-Sus-totalImpar-PD, clin-alcohol, ques-MMSE-memoria-PD, eval-TLP-Tavec-26_Sesgo-PD, demo-fechaNacimiento.year, eval-TLP-Tavec-1_RI_A1-PD, eval-TLP-Stroop-color-PD, eval-TLP-Tavec-11_RCl_LP-PD, demo-fechaEvaluacion.dayofweek, clin-tipoAlcohol.lowe...</td>\n",
       "      <td>None</td>\n",
       "      <td>{'learning_rate': 0.05, 'extra_trees': True, 'num_boost_round': 212}</td>\n",
       "      <td>{'num_boost_round': 212}</td>\n",
       "      <td>{'max_memory_usage_ratio': 1.0, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': ['bool', 'int', 'float', 'category'], 'valid_special_types': None, 'ignored_type_group_special': None, 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'temperature_scalar': None}</td>\n",
       "      <td>[]</td>\n",
       "      <td>[WeightedEnsemble_L2_FULL]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>XGBoost_r95_BAG_L1_FULL</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>{'use_orig_features': True, 'valid_stacker': True, 'max_base_models': 0, 'max_base_models_per_type': 'auto', 'save_bag_folds': True}</td>\n",
       "      <td>{}</td>\n",
       "      <td>{'max_memory_usage_ratio': 1.15, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': None, 'valid_special_types': None, 'ignored_type_group_special': None, 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'temperature_scalar': None, 'drop_unique': False}</td>\n",
       "      <td>[clin-tipoAlcohol.symbol_ratio. , clin-numCigarros, clin-tipoAlcohol, eval-TLP-Tavec-33_Recon_Ac_frente_RCl_LP-PD, demo-fechaNacimiento.dayofweek, eval-TLP-CubCorsi-totalinversos-PD, clin-reservaCognitiva_ocupacion, eval-TLP-FigRey-Duracion-PD, eval-TLP-Tavec-4_RI_B-PD, eval-TLP-Tavec-12_ESem_RI_A-PD, eval-TLP-Tavec-29_RCl_Cp_frente_RCl_LP-PD, ques-Sus-totalImpar-PD, clin-alcohol, ques-MMSE-memoria-PD, eval-TLP-Tavec-26_Sesgo-PD, demo-fechaNacimiento.year, eval-TLP-Tavec-1_RI_A1-PD, eval-TLP-Stroop-color-PD, eval-TLP-Tavec-11_RCl_LP-PD, demo-fechaEvaluacion.dayofweek, clin-tipoAlcohol.lowe...</td>\n",
       "      <td>None</td>\n",
       "      <td>{'n_estimators': 180, 'learning_rate': 0.06634196266155237, 'n_jobs': -1, 'proc.max_category_levels': 100, 'objective': 'binary:logistic', 'booster': 'gbtree', 'colsample_bytree': 0.975937238416368, 'enable_categorical': False, 'max_depth': 5, 'min_child_weight': 1.4088437184127383}</td>\n",
       "      <td>{}</td>\n",
       "      <td>{'max_memory_usage_ratio': 1.0, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': ['bool', 'int', 'float', 'category'], 'valid_special_types': None, 'ignored_type_group_special': None, 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'temperature_scalar': None}</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LightGBMLarge_BAG_L1_FULL</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>{'use_orig_features': True, 'valid_stacker': True, 'max_base_models': 0, 'max_base_models_per_type': 'auto', 'save_bag_folds': True}</td>\n",
       "      <td>{}</td>\n",
       "      <td>{'max_memory_usage_ratio': 1.15, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': None, 'valid_special_types': None, 'ignored_type_group_special': None, 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'temperature_scalar': None, 'drop_unique': False}</td>\n",
       "      <td>[clin-tipoAlcohol.symbol_ratio. , clin-numCigarros, clin-tipoAlcohol, eval-TLP-Tavec-33_Recon_Ac_frente_RCl_LP-PD, demo-fechaNacimiento.dayofweek, eval-TLP-CubCorsi-totalinversos-PD, clin-reservaCognitiva_ocupacion, eval-TLP-FigRey-Duracion-PD, eval-TLP-Tavec-4_RI_B-PD, eval-TLP-Tavec-12_ESem_RI_A-PD, eval-TLP-Tavec-29_RCl_Cp_frente_RCl_LP-PD, ques-Sus-totalImpar-PD, clin-alcohol, ques-MMSE-memoria-PD, eval-TLP-Tavec-26_Sesgo-PD, demo-fechaNacimiento.year, eval-TLP-Tavec-1_RI_A1-PD, eval-TLP-Stroop-color-PD, eval-TLP-Tavec-11_RCl_LP-PD, demo-fechaEvaluacion.dayofweek, clin-tipoAlcohol.lowe...</td>\n",
       "      <td>None</td>\n",
       "      <td>{'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'num_boost_round': 68}</td>\n",
       "      <td>{'num_boost_round': 68}</td>\n",
       "      <td>{'max_memory_usage_ratio': 1.0, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': ['bool', 'int', 'float', 'category'], 'valid_special_types': None, 'ignored_type_group_special': None, 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'temperature_scalar': None}</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LightGBM_r135_BAG_L1_FULL</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.994681</td>\n",
       "      <td>0.984375</td>\n",
       "      <td>0.989514</td>\n",
       "      <td>0.992032</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.969231</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>{'use_orig_features': True, 'valid_stacker': True, 'max_base_models': 0, 'max_base_models_per_type': 'auto', 'save_bag_folds': True}</td>\n",
       "      <td>{}</td>\n",
       "      <td>{'max_memory_usage_ratio': 1.15, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': None, 'valid_special_types': None, 'ignored_type_group_special': None, 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'temperature_scalar': None, 'drop_unique': False}</td>\n",
       "      <td>[clin-tipoAlcohol.symbol_ratio. , clin-numCigarros, clin-tipoAlcohol, eval-TLP-Tavec-33_Recon_Ac_frente_RCl_LP-PD, demo-fechaNacimiento.dayofweek, eval-TLP-CubCorsi-totalinversos-PD, clin-reservaCognitiva_ocupacion, eval-TLP-FigRey-Duracion-PD, eval-TLP-Tavec-4_RI_B-PD, eval-TLP-Tavec-12_ESem_RI_A-PD, eval-TLP-Tavec-29_RCl_Cp_frente_RCl_LP-PD, ques-Sus-totalImpar-PD, clin-alcohol, ques-MMSE-memoria-PD, eval-TLP-Tavec-26_Sesgo-PD, demo-fechaNacimiento.year, eval-TLP-Tavec-1_RI_A1-PD, eval-TLP-Stroop-color-PD, eval-TLP-Tavec-11_RCl_LP-PD, demo-fechaEvaluacion.dayofweek, clin-tipoAlcohol.lowe...</td>\n",
       "      <td>None</td>\n",
       "      <td>{'learning_rate': 0.031251656439648626, 'extra_trees': False, 'feature_fraction': 0.8254432681390782, 'min_data_in_leaf': 50, 'num_leaves': 210, 'num_boost_round': 422}</td>\n",
       "      <td>{'num_boost_round': 422}</td>\n",
       "      <td>{'max_memory_usage_ratio': 1.0, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': ['bool', 'int', 'float', 'category'], 'valid_special_types': None, 'ignored_type_group_special': None, 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'temperature_scalar': None}</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>NeuralNetFastAI_r160_BAG_L1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>{'use_orig_features': True, 'valid_stacker': True, 'max_base_models': 0, 'max_base_models_per_type': 'auto', 'save_bag_folds': False}</td>\n",
       "      <td>{}</td>\n",
       "      <td>{'max_memory_usage_ratio': 1.0, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': None, 'valid_special_types': None, 'ignored_type_group_special': None, 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'temperature_scalar': None, 'drop_unique': False}</td>\n",
       "      <td>[clin-tipoAlcohol.symbol_ratio. , clin-numCigarros, eval-TLP-Tavec-33_Recon_Ac_frente_RCl_LP-PD, demo-fechaNacimiento.dayofweek, eval-TLP-CubCorsi-totalinversos-PD, clin-reservaCognitiva_ocupacion, eval-TLP-FigRey-Duracion-PD, eval-TLP-Tavec-4_RI_B-PD, eval-TLP-Tavec-12_ESem_RI_A-PD, eval-TLP-Tavec-29_RCl_Cp_frente_RCl_LP-PD, ques-Sus-totalImpar-PD, clin-alcohol, ques-MMSE-memoria-PD, eval-TLP-Tavec-26_Sesgo-PD, demo-fechaNacimiento.year, eval-TLP-Tavec-1_RI_A1-PD, eval-TLP-Stroop-color-PD, eval-TLP-Tavec-11_RCl_LP-PD, demo-fechaEvaluacion.dayofweek, clin-tipoAlcohol.lower_ratio, eval-TLP-...</td>\n",
       "      <td>None</td>\n",
       "      <td>{'layers': [400, 200, 100], 'emb_drop': 0.3171659718142149, 'ps': 0.5909644730871169, 'bs': 128, 'lr': 0.03087210106068273, 'epochs': 20, 'early.stopping.min_delta': 0.0001, 'early.stopping.patience': 20, 'smoothing': 0.0}</td>\n",
       "      <td>{'epochs': 20, 'best_epoch': 7}</td>\n",
       "      <td>{'max_memory_usage_ratio': 1.0, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': ['bool', 'int', 'float', 'category'], 'valid_special_types': None, 'ignored_type_group_special': ['text_ngram', 'text_as_category'], 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'temperature_scalar': None}</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>NeuralNetFastAI_r100_BAG_L1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>{'use_orig_features': True, 'valid_stacker': True, 'max_base_models': 0, 'max_base_models_per_type': 'auto', 'save_bag_folds': False}</td>\n",
       "      <td>{}</td>\n",
       "      <td>{'max_memory_usage_ratio': 1.0, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': None, 'valid_special_types': None, 'ignored_type_group_special': None, 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'temperature_scalar': None, 'drop_unique': False}</td>\n",
       "      <td>[clin-tipoAlcohol.symbol_ratio. , clin-numCigarros, eval-TLP-Tavec-33_Recon_Ac_frente_RCl_LP-PD, demo-fechaNacimiento.dayofweek, eval-TLP-CubCorsi-totalinversos-PD, clin-reservaCognitiva_ocupacion, eval-TLP-FigRey-Duracion-PD, eval-TLP-Tavec-4_RI_B-PD, eval-TLP-Tavec-12_ESem_RI_A-PD, eval-TLP-Tavec-29_RCl_Cp_frente_RCl_LP-PD, ques-Sus-totalImpar-PD, clin-alcohol, ques-MMSE-memoria-PD, eval-TLP-Tavec-26_Sesgo-PD, demo-fechaNacimiento.year, eval-TLP-Tavec-1_RI_A1-PD, eval-TLP-Stroop-color-PD, eval-TLP-Tavec-11_RCl_LP-PD, demo-fechaEvaluacion.dayofweek, clin-tipoAlcohol.lower_ratio, eval-TLP-...</td>\n",
       "      <td>None</td>\n",
       "      <td>{'layers': [800, 400], 'emb_drop': 0.6960805527533755, 'ps': 0.20495582200836318, 'bs': 2048, 'lr': 0.0007278526871749883, 'epochs': 38, 'early.stopping.min_delta': 0.0001, 'early.stopping.patience': 20, 'smoothing': 0.0}</td>\n",
       "      <td>{'epochs': 38, 'best_epoch': 8}</td>\n",
       "      <td>{'max_memory_usage_ratio': 1.0, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': ['bool', 'int', 'float', 'category'], 'valid_special_types': None, 'ignored_type_group_special': ['text_ngram', 'text_as_category'], 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'temperature_scalar': None}</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>NeuralNetFastAI_r11_BAG_L1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>{'use_orig_features': True, 'valid_stacker': True, 'max_base_models': 0, 'max_base_models_per_type': 'auto', 'save_bag_folds': False}</td>\n",
       "      <td>{}</td>\n",
       "      <td>{'max_memory_usage_ratio': 1.0, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': None, 'valid_special_types': None, 'ignored_type_group_special': None, 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'temperature_scalar': None, 'drop_unique': False}</td>\n",
       "      <td>[clin-tipoAlcohol.symbol_ratio. , clin-numCigarros, eval-TLP-Tavec-33_Recon_Ac_frente_RCl_LP-PD, demo-fechaNacimiento.dayofweek, eval-TLP-CubCorsi-totalinversos-PD, clin-reservaCognitiva_ocupacion, eval-TLP-FigRey-Duracion-PD, eval-TLP-Tavec-4_RI_B-PD, eval-TLP-Tavec-12_ESem_RI_A-PD, eval-TLP-Tavec-29_RCl_Cp_frente_RCl_LP-PD, ques-Sus-totalImpar-PD, clin-alcohol, ques-MMSE-memoria-PD, eval-TLP-Tavec-26_Sesgo-PD, demo-fechaNacimiento.year, eval-TLP-Tavec-1_RI_A1-PD, eval-TLP-Stroop-color-PD, eval-TLP-Tavec-11_RCl_LP-PD, demo-fechaEvaluacion.dayofweek, clin-tipoAlcohol.lower_ratio, eval-TLP-...</td>\n",
       "      <td>None</td>\n",
       "      <td>{'layers': [800, 400], 'emb_drop': 0.026897798530914306, 'ps': 0.4569532219038436, 'bs': 128, 'lr': 0.08045277634470181, 'epochs': 31, 'early.stopping.min_delta': 0.0001, 'early.stopping.patience': 20, 'smoothing': 0.0}</td>\n",
       "      <td>{'epochs': 31, 'best_epoch': 4}</td>\n",
       "      <td>{'max_memory_usage_ratio': 1.0, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': ['bool', 'int', 'float', 'category'], 'valid_special_types': None, 'ignored_type_group_special': ['text_ngram', 'text_as_category'], 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'temperature_scalar': None}</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>NeuralNetFastAI_r145_BAG_L1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>{'use_orig_features': True, 'valid_stacker': True, 'max_base_models': 0, 'max_base_models_per_type': 'auto', 'save_bag_folds': False}</td>\n",
       "      <td>{}</td>\n",
       "      <td>{'max_memory_usage_ratio': 1.0, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': None, 'valid_special_types': None, 'ignored_type_group_special': None, 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'temperature_scalar': None, 'drop_unique': False}</td>\n",
       "      <td>[clin-tipoAlcohol.symbol_ratio. , clin-numCigarros, eval-TLP-Tavec-33_Recon_Ac_frente_RCl_LP-PD, demo-fechaNacimiento.dayofweek, eval-TLP-CubCorsi-totalinversos-PD, clin-reservaCognitiva_ocupacion, eval-TLP-FigRey-Duracion-PD, eval-TLP-Tavec-4_RI_B-PD, eval-TLP-Tavec-12_ESem_RI_A-PD, eval-TLP-Tavec-29_RCl_Cp_frente_RCl_LP-PD, ques-Sus-totalImpar-PD, clin-alcohol, ques-MMSE-memoria-PD, eval-TLP-Tavec-26_Sesgo-PD, demo-fechaNacimiento.year, eval-TLP-Tavec-1_RI_A1-PD, eval-TLP-Stroop-color-PD, eval-TLP-Tavec-11_RCl_LP-PD, demo-fechaEvaluacion.dayofweek, clin-tipoAlcohol.lower_ratio, eval-TLP-...</td>\n",
       "      <td>None</td>\n",
       "      <td>{'layers': [400, 200, 100], 'emb_drop': 0.44339037504795686, 'ps': 0.19220253419114286, 'bs': 128, 'lr': 0.008615195908919904, 'epochs': 31, 'early.stopping.min_delta': 0.0001, 'early.stopping.patience': 20, 'smoothing': 0.0}</td>\n",
       "      <td>{'epochs': 31, 'best_epoch': 10}</td>\n",
       "      <td>{'max_memory_usage_ratio': 1.0, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': ['bool', 'int', 'float', 'category'], 'valid_special_types': None, 'ignored_type_group_special': ['text_ngram', 'text_as_category'], 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'temperature_scalar': None}</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>NeuralNetFastAI_r95_BAG_L1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>{'use_orig_features': True, 'valid_stacker': True, 'max_base_models': 0, 'max_base_models_per_type': 'auto', 'save_bag_folds': False}</td>\n",
       "      <td>{}</td>\n",
       "      <td>{'max_memory_usage_ratio': 1.0, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': None, 'valid_special_types': None, 'ignored_type_group_special': None, 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'temperature_scalar': None, 'drop_unique': False}</td>\n",
       "      <td>[clin-tipoAlcohol.symbol_ratio. , clin-numCigarros, eval-TLP-Tavec-33_Recon_Ac_frente_RCl_LP-PD, demo-fechaNacimiento.dayofweek, eval-TLP-CubCorsi-totalinversos-PD, clin-reservaCognitiva_ocupacion, eval-TLP-FigRey-Duracion-PD, eval-TLP-Tavec-4_RI_B-PD, eval-TLP-Tavec-12_ESem_RI_A-PD, eval-TLP-Tavec-29_RCl_Cp_frente_RCl_LP-PD, ques-Sus-totalImpar-PD, clin-alcohol, ques-MMSE-memoria-PD, eval-TLP-Tavec-26_Sesgo-PD, demo-fechaNacimiento.year, eval-TLP-Tavec-1_RI_A1-PD, eval-TLP-Stroop-color-PD, eval-TLP-Tavec-11_RCl_LP-PD, demo-fechaEvaluacion.dayofweek, clin-tipoAlcohol.lower_ratio, eval-TLP-...</td>\n",
       "      <td>None</td>\n",
       "      <td>{'layers': [400, 200, 100], 'emb_drop': 0.6656668277387758, 'ps': 0.04084945128641206, 'bs': 128, 'lr': 0.019326244622675428, 'epochs': 32, 'early.stopping.min_delta': 0.0001, 'early.stopping.patience': 20, 'smoothing': 0.0}</td>\n",
       "      <td>{'epochs': 32, 'best_epoch': 7}</td>\n",
       "      <td>{'max_memory_usage_ratio': 1.0, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': ['bool', 'int', 'float', 'category'], 'valid_special_types': None, 'ignored_type_group_special': ['text_ngram', 'text_as_category'], 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'temperature_scalar': None}</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>140 rows Ã— 45 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           model  score_test  balanced_accuracy        f1  \\\n",
       "0           LightGBM_BAG_L1_FULL         1.0           0.984043  0.954545   \n",
       "1         LightGBMXT_BAG_L1_FULL         1.0           1.000000  1.000000   \n",
       "2        XGBoost_r95_BAG_L1_FULL         1.0           1.000000  1.000000   \n",
       "3      LightGBMLarge_BAG_L1_FULL         1.0           1.000000  1.000000   \n",
       "4      LightGBM_r135_BAG_L1_FULL         1.0           0.994681  0.984375   \n",
       "..                           ...         ...                ...       ...   \n",
       "135  NeuralNetFastAI_r160_BAG_L1         NaN                NaN       NaN   \n",
       "136  NeuralNetFastAI_r100_BAG_L1         NaN                NaN       NaN   \n",
       "137   NeuralNetFastAI_r11_BAG_L1         NaN                NaN       NaN   \n",
       "138  NeuralNetFastAI_r145_BAG_L1         NaN                NaN       NaN   \n",
       "139   NeuralNetFastAI_r95_BAG_L1         NaN                NaN       NaN   \n",
       "\n",
       "     f1_macro  f1_micro  roc_auc  average_precision  precision  recall  ...  \\\n",
       "0    0.969165  0.976096      1.0                1.0   0.913043     1.0  ...   \n",
       "1    1.000000  1.000000      1.0                1.0   1.000000     1.0  ...   \n",
       "2    1.000000  1.000000      1.0                1.0   1.000000     1.0  ...   \n",
       "3    1.000000  1.000000      1.0                1.0   1.000000     1.0  ...   \n",
       "4    0.989514  0.992032      1.0                1.0   0.969231     1.0  ...   \n",
       "..        ...       ...      ...                ...        ...     ...  ...   \n",
       "135       NaN       NaN      NaN                NaN        NaN     NaN  ...   \n",
       "136       NaN       NaN      NaN                NaN        NaN     NaN  ...   \n",
       "137       NaN       NaN      NaN                NaN        NaN     NaN  ...   \n",
       "138       NaN       NaN      NaN                NaN        NaN     NaN  ...   \n",
       "139       NaN       NaN      NaN                NaN        NaN     NaN  ...   \n",
       "\n",
       "                                                                                                                           hyperparameters  \\\n",
       "0     {'use_orig_features': True, 'valid_stacker': True, 'max_base_models': 0, 'max_base_models_per_type': 'auto', 'save_bag_folds': True}   \n",
       "1     {'use_orig_features': True, 'valid_stacker': True, 'max_base_models': 0, 'max_base_models_per_type': 'auto', 'save_bag_folds': True}   \n",
       "2     {'use_orig_features': True, 'valid_stacker': True, 'max_base_models': 0, 'max_base_models_per_type': 'auto', 'save_bag_folds': True}   \n",
       "3     {'use_orig_features': True, 'valid_stacker': True, 'max_base_models': 0, 'max_base_models_per_type': 'auto', 'save_bag_folds': True}   \n",
       "4     {'use_orig_features': True, 'valid_stacker': True, 'max_base_models': 0, 'max_base_models_per_type': 'auto', 'save_bag_folds': True}   \n",
       "..                                                                                                                                     ...   \n",
       "135  {'use_orig_features': True, 'valid_stacker': True, 'max_base_models': 0, 'max_base_models_per_type': 'auto', 'save_bag_folds': False}   \n",
       "136  {'use_orig_features': True, 'valid_stacker': True, 'max_base_models': 0, 'max_base_models_per_type': 'auto', 'save_bag_folds': False}   \n",
       "137  {'use_orig_features': True, 'valid_stacker': True, 'max_base_models': 0, 'max_base_models_per_type': 'auto', 'save_bag_folds': False}   \n",
       "138  {'use_orig_features': True, 'valid_stacker': True, 'max_base_models': 0, 'max_base_models_per_type': 'auto', 'save_bag_folds': False}   \n",
       "139  {'use_orig_features': True, 'valid_stacker': True, 'max_base_models': 0, 'max_base_models_per_type': 'auto', 'save_bag_folds': False}   \n",
       "\n",
       "     hyperparameters_fit  \\\n",
       "0                     {}   \n",
       "1                     {}   \n",
       "2                     {}   \n",
       "3                     {}   \n",
       "4                     {}   \n",
       "..                   ...   \n",
       "135                   {}   \n",
       "136                   {}   \n",
       "137                   {}   \n",
       "138                   {}   \n",
       "139                   {}   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                              ag_args_fit  \\\n",
       "0    {'max_memory_usage_ratio': 1.15, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': None, 'valid_special_types': None, 'ignored_type_group_special': None, 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'temperature_scalar': None, 'drop_unique': False}   \n",
       "1    {'max_memory_usage_ratio': 1.15, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': None, 'valid_special_types': None, 'ignored_type_group_special': None, 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'temperature_scalar': None, 'drop_unique': False}   \n",
       "2    {'max_memory_usage_ratio': 1.15, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': None, 'valid_special_types': None, 'ignored_type_group_special': None, 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'temperature_scalar': None, 'drop_unique': False}   \n",
       "3    {'max_memory_usage_ratio': 1.15, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': None, 'valid_special_types': None, 'ignored_type_group_special': None, 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'temperature_scalar': None, 'drop_unique': False}   \n",
       "4    {'max_memory_usage_ratio': 1.15, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': None, 'valid_special_types': None, 'ignored_type_group_special': None, 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'temperature_scalar': None, 'drop_unique': False}   \n",
       "..                                                                                                                                                                                                                                                                                                                                                                                    ...   \n",
       "135   {'max_memory_usage_ratio': 1.0, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': None, 'valid_special_types': None, 'ignored_type_group_special': None, 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'temperature_scalar': None, 'drop_unique': False}   \n",
       "136   {'max_memory_usage_ratio': 1.0, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': None, 'valid_special_types': None, 'ignored_type_group_special': None, 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'temperature_scalar': None, 'drop_unique': False}   \n",
       "137   {'max_memory_usage_ratio': 1.0, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': None, 'valid_special_types': None, 'ignored_type_group_special': None, 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'temperature_scalar': None, 'drop_unique': False}   \n",
       "138   {'max_memory_usage_ratio': 1.0, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': None, 'valid_special_types': None, 'ignored_type_group_special': None, 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'temperature_scalar': None, 'drop_unique': False}   \n",
       "139   {'max_memory_usage_ratio': 1.0, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': None, 'valid_special_types': None, 'ignored_type_group_special': None, 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'temperature_scalar': None, 'drop_unique': False}   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    features  \\\n",
       "0    [clin-tipoAlcohol.symbol_ratio. , clin-numCigarros, clin-tipoAlcohol, eval-TLP-Tavec-33_Recon_Ac_frente_RCl_LP-PD, demo-fechaNacimiento.dayofweek, eval-TLP-CubCorsi-totalinversos-PD, clin-reservaCognitiva_ocupacion, eval-TLP-FigRey-Duracion-PD, eval-TLP-Tavec-4_RI_B-PD, eval-TLP-Tavec-12_ESem_RI_A-PD, eval-TLP-Tavec-29_RCl_Cp_frente_RCl_LP-PD, ques-Sus-totalImpar-PD, clin-alcohol, ques-MMSE-memoria-PD, eval-TLP-Tavec-26_Sesgo-PD, demo-fechaNacimiento.year, eval-TLP-Tavec-1_RI_A1-PD, eval-TLP-Stroop-color-PD, eval-TLP-Tavec-11_RCl_LP-PD, demo-fechaEvaluacion.dayofweek, clin-tipoAlcohol.lowe...   \n",
       "1    [clin-tipoAlcohol.symbol_ratio. , clin-numCigarros, clin-tipoAlcohol, eval-TLP-Tavec-33_Recon_Ac_frente_RCl_LP-PD, demo-fechaNacimiento.dayofweek, eval-TLP-CubCorsi-totalinversos-PD, clin-reservaCognitiva_ocupacion, eval-TLP-FigRey-Duracion-PD, eval-TLP-Tavec-4_RI_B-PD, eval-TLP-Tavec-12_ESem_RI_A-PD, eval-TLP-Tavec-29_RCl_Cp_frente_RCl_LP-PD, ques-Sus-totalImpar-PD, clin-alcohol, ques-MMSE-memoria-PD, eval-TLP-Tavec-26_Sesgo-PD, demo-fechaNacimiento.year, eval-TLP-Tavec-1_RI_A1-PD, eval-TLP-Stroop-color-PD, eval-TLP-Tavec-11_RCl_LP-PD, demo-fechaEvaluacion.dayofweek, clin-tipoAlcohol.lowe...   \n",
       "2    [clin-tipoAlcohol.symbol_ratio. , clin-numCigarros, clin-tipoAlcohol, eval-TLP-Tavec-33_Recon_Ac_frente_RCl_LP-PD, demo-fechaNacimiento.dayofweek, eval-TLP-CubCorsi-totalinversos-PD, clin-reservaCognitiva_ocupacion, eval-TLP-FigRey-Duracion-PD, eval-TLP-Tavec-4_RI_B-PD, eval-TLP-Tavec-12_ESem_RI_A-PD, eval-TLP-Tavec-29_RCl_Cp_frente_RCl_LP-PD, ques-Sus-totalImpar-PD, clin-alcohol, ques-MMSE-memoria-PD, eval-TLP-Tavec-26_Sesgo-PD, demo-fechaNacimiento.year, eval-TLP-Tavec-1_RI_A1-PD, eval-TLP-Stroop-color-PD, eval-TLP-Tavec-11_RCl_LP-PD, demo-fechaEvaluacion.dayofweek, clin-tipoAlcohol.lowe...   \n",
       "3    [clin-tipoAlcohol.symbol_ratio. , clin-numCigarros, clin-tipoAlcohol, eval-TLP-Tavec-33_Recon_Ac_frente_RCl_LP-PD, demo-fechaNacimiento.dayofweek, eval-TLP-CubCorsi-totalinversos-PD, clin-reservaCognitiva_ocupacion, eval-TLP-FigRey-Duracion-PD, eval-TLP-Tavec-4_RI_B-PD, eval-TLP-Tavec-12_ESem_RI_A-PD, eval-TLP-Tavec-29_RCl_Cp_frente_RCl_LP-PD, ques-Sus-totalImpar-PD, clin-alcohol, ques-MMSE-memoria-PD, eval-TLP-Tavec-26_Sesgo-PD, demo-fechaNacimiento.year, eval-TLP-Tavec-1_RI_A1-PD, eval-TLP-Stroop-color-PD, eval-TLP-Tavec-11_RCl_LP-PD, demo-fechaEvaluacion.dayofweek, clin-tipoAlcohol.lowe...   \n",
       "4    [clin-tipoAlcohol.symbol_ratio. , clin-numCigarros, clin-tipoAlcohol, eval-TLP-Tavec-33_Recon_Ac_frente_RCl_LP-PD, demo-fechaNacimiento.dayofweek, eval-TLP-CubCorsi-totalinversos-PD, clin-reservaCognitiva_ocupacion, eval-TLP-FigRey-Duracion-PD, eval-TLP-Tavec-4_RI_B-PD, eval-TLP-Tavec-12_ESem_RI_A-PD, eval-TLP-Tavec-29_RCl_Cp_frente_RCl_LP-PD, ques-Sus-totalImpar-PD, clin-alcohol, ques-MMSE-memoria-PD, eval-TLP-Tavec-26_Sesgo-PD, demo-fechaNacimiento.year, eval-TLP-Tavec-1_RI_A1-PD, eval-TLP-Stroop-color-PD, eval-TLP-Tavec-11_RCl_LP-PD, demo-fechaEvaluacion.dayofweek, clin-tipoAlcohol.lowe...   \n",
       "..                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       ...   \n",
       "135  [clin-tipoAlcohol.symbol_ratio. , clin-numCigarros, eval-TLP-Tavec-33_Recon_Ac_frente_RCl_LP-PD, demo-fechaNacimiento.dayofweek, eval-TLP-CubCorsi-totalinversos-PD, clin-reservaCognitiva_ocupacion, eval-TLP-FigRey-Duracion-PD, eval-TLP-Tavec-4_RI_B-PD, eval-TLP-Tavec-12_ESem_RI_A-PD, eval-TLP-Tavec-29_RCl_Cp_frente_RCl_LP-PD, ques-Sus-totalImpar-PD, clin-alcohol, ques-MMSE-memoria-PD, eval-TLP-Tavec-26_Sesgo-PD, demo-fechaNacimiento.year, eval-TLP-Tavec-1_RI_A1-PD, eval-TLP-Stroop-color-PD, eval-TLP-Tavec-11_RCl_LP-PD, demo-fechaEvaluacion.dayofweek, clin-tipoAlcohol.lower_ratio, eval-TLP-...   \n",
       "136  [clin-tipoAlcohol.symbol_ratio. , clin-numCigarros, eval-TLP-Tavec-33_Recon_Ac_frente_RCl_LP-PD, demo-fechaNacimiento.dayofweek, eval-TLP-CubCorsi-totalinversos-PD, clin-reservaCognitiva_ocupacion, eval-TLP-FigRey-Duracion-PD, eval-TLP-Tavec-4_RI_B-PD, eval-TLP-Tavec-12_ESem_RI_A-PD, eval-TLP-Tavec-29_RCl_Cp_frente_RCl_LP-PD, ques-Sus-totalImpar-PD, clin-alcohol, ques-MMSE-memoria-PD, eval-TLP-Tavec-26_Sesgo-PD, demo-fechaNacimiento.year, eval-TLP-Tavec-1_RI_A1-PD, eval-TLP-Stroop-color-PD, eval-TLP-Tavec-11_RCl_LP-PD, demo-fechaEvaluacion.dayofweek, clin-tipoAlcohol.lower_ratio, eval-TLP-...   \n",
       "137  [clin-tipoAlcohol.symbol_ratio. , clin-numCigarros, eval-TLP-Tavec-33_Recon_Ac_frente_RCl_LP-PD, demo-fechaNacimiento.dayofweek, eval-TLP-CubCorsi-totalinversos-PD, clin-reservaCognitiva_ocupacion, eval-TLP-FigRey-Duracion-PD, eval-TLP-Tavec-4_RI_B-PD, eval-TLP-Tavec-12_ESem_RI_A-PD, eval-TLP-Tavec-29_RCl_Cp_frente_RCl_LP-PD, ques-Sus-totalImpar-PD, clin-alcohol, ques-MMSE-memoria-PD, eval-TLP-Tavec-26_Sesgo-PD, demo-fechaNacimiento.year, eval-TLP-Tavec-1_RI_A1-PD, eval-TLP-Stroop-color-PD, eval-TLP-Tavec-11_RCl_LP-PD, demo-fechaEvaluacion.dayofweek, clin-tipoAlcohol.lower_ratio, eval-TLP-...   \n",
       "138  [clin-tipoAlcohol.symbol_ratio. , clin-numCigarros, eval-TLP-Tavec-33_Recon_Ac_frente_RCl_LP-PD, demo-fechaNacimiento.dayofweek, eval-TLP-CubCorsi-totalinversos-PD, clin-reservaCognitiva_ocupacion, eval-TLP-FigRey-Duracion-PD, eval-TLP-Tavec-4_RI_B-PD, eval-TLP-Tavec-12_ESem_RI_A-PD, eval-TLP-Tavec-29_RCl_Cp_frente_RCl_LP-PD, ques-Sus-totalImpar-PD, clin-alcohol, ques-MMSE-memoria-PD, eval-TLP-Tavec-26_Sesgo-PD, demo-fechaNacimiento.year, eval-TLP-Tavec-1_RI_A1-PD, eval-TLP-Stroop-color-PD, eval-TLP-Tavec-11_RCl_LP-PD, demo-fechaEvaluacion.dayofweek, clin-tipoAlcohol.lower_ratio, eval-TLP-...   \n",
       "139  [clin-tipoAlcohol.symbol_ratio. , clin-numCigarros, eval-TLP-Tavec-33_Recon_Ac_frente_RCl_LP-PD, demo-fechaNacimiento.dayofweek, eval-TLP-CubCorsi-totalinversos-PD, clin-reservaCognitiva_ocupacion, eval-TLP-FigRey-Duracion-PD, eval-TLP-Tavec-4_RI_B-PD, eval-TLP-Tavec-12_ESem_RI_A-PD, eval-TLP-Tavec-29_RCl_Cp_frente_RCl_LP-PD, ques-Sus-totalImpar-PD, clin-alcohol, ques-MMSE-memoria-PD, eval-TLP-Tavec-26_Sesgo-PD, demo-fechaNacimiento.year, eval-TLP-Tavec-1_RI_A1-PD, eval-TLP-Stroop-color-PD, eval-TLP-Tavec-11_RCl_LP-PD, demo-fechaEvaluacion.dayofweek, clin-tipoAlcohol.lower_ratio, eval-TLP-...   \n",
       "\n",
       "     compile_time  \\\n",
       "0            None   \n",
       "1            None   \n",
       "2            None   \n",
       "3            None   \n",
       "4            None   \n",
       "..            ...   \n",
       "135          None   \n",
       "136          None   \n",
       "137          None   \n",
       "138          None   \n",
       "139          None   \n",
       "\n",
       "                                                                                                                                                                                                                                                                           child_hyperparameters  \\\n",
       "0                                                                                                                                                                                                                                                 {'learning_rate': 0.05, 'num_boost_round': 72}   \n",
       "1                                                                                                                                                                                                                           {'learning_rate': 0.05, 'extra_trees': True, 'num_boost_round': 212}   \n",
       "2    {'n_estimators': 180, 'learning_rate': 0.06634196266155237, 'n_jobs': -1, 'proc.max_category_levels': 100, 'objective': 'binary:logistic', 'booster': 'gbtree', 'colsample_bytree': 0.975937238416368, 'enable_categorical': False, 'max_depth': 5, 'min_child_weight': 1.4088437184127383}   \n",
       "3                                                                                                                                                                              {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'num_boost_round': 68}   \n",
       "4                                                                                                                       {'learning_rate': 0.031251656439648626, 'extra_trees': False, 'feature_fraction': 0.8254432681390782, 'min_data_in_leaf': 50, 'num_leaves': 210, 'num_boost_round': 422}   \n",
       "..                                                                                                                                                                                                                                                                                           ...   \n",
       "135                                                               {'layers': [400, 200, 100], 'emb_drop': 0.3171659718142149, 'ps': 0.5909644730871169, 'bs': 128, 'lr': 0.03087210106068273, 'epochs': 20, 'early.stopping.min_delta': 0.0001, 'early.stopping.patience': 20, 'smoothing': 0.0}   \n",
       "136                                                                {'layers': [800, 400], 'emb_drop': 0.6960805527533755, 'ps': 0.20495582200836318, 'bs': 2048, 'lr': 0.0007278526871749883, 'epochs': 38, 'early.stopping.min_delta': 0.0001, 'early.stopping.patience': 20, 'smoothing': 0.0}   \n",
       "137                                                                  {'layers': [800, 400], 'emb_drop': 0.026897798530914306, 'ps': 0.4569532219038436, 'bs': 128, 'lr': 0.08045277634470181, 'epochs': 31, 'early.stopping.min_delta': 0.0001, 'early.stopping.patience': 20, 'smoothing': 0.0}   \n",
       "138                                                            {'layers': [400, 200, 100], 'emb_drop': 0.44339037504795686, 'ps': 0.19220253419114286, 'bs': 128, 'lr': 0.008615195908919904, 'epochs': 31, 'early.stopping.min_delta': 0.0001, 'early.stopping.patience': 20, 'smoothing': 0.0}   \n",
       "139                                                             {'layers': [400, 200, 100], 'emb_drop': 0.6656668277387758, 'ps': 0.04084945128641206, 'bs': 128, 'lr': 0.019326244622675428, 'epochs': 32, 'early.stopping.min_delta': 0.0001, 'early.stopping.patience': 20, 'smoothing': 0.0}   \n",
       "\n",
       "            child_hyperparameters_fit  \\\n",
       "0             {'num_boost_round': 72}   \n",
       "1            {'num_boost_round': 212}   \n",
       "2                                  {}   \n",
       "3             {'num_boost_round': 68}   \n",
       "4            {'num_boost_round': 422}   \n",
       "..                                ...   \n",
       "135   {'epochs': 20, 'best_epoch': 7}   \n",
       "136   {'epochs': 38, 'best_epoch': 8}   \n",
       "137   {'epochs': 31, 'best_epoch': 4}   \n",
       "138  {'epochs': 31, 'best_epoch': 10}   \n",
       "139   {'epochs': 32, 'best_epoch': 7}   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                               child_ag_args_fit  \\\n",
       "0                                  {'max_memory_usage_ratio': 1.0, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': ['bool', 'int', 'float', 'category'], 'valid_special_types': None, 'ignored_type_group_special': None, 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'temperature_scalar': None}   \n",
       "1                                  {'max_memory_usage_ratio': 1.0, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': ['bool', 'int', 'float', 'category'], 'valid_special_types': None, 'ignored_type_group_special': None, 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'temperature_scalar': None}   \n",
       "2                                  {'max_memory_usage_ratio': 1.0, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': ['bool', 'int', 'float', 'category'], 'valid_special_types': None, 'ignored_type_group_special': None, 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'temperature_scalar': None}   \n",
       "3                                  {'max_memory_usage_ratio': 1.0, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': ['bool', 'int', 'float', 'category'], 'valid_special_types': None, 'ignored_type_group_special': None, 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'temperature_scalar': None}   \n",
       "4                                  {'max_memory_usage_ratio': 1.0, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': ['bool', 'int', 'float', 'category'], 'valid_special_types': None, 'ignored_type_group_special': None, 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'temperature_scalar': None}   \n",
       "..                                                                                                                                                                                                                                                                                                                                                                                                                           ...   \n",
       "135  {'max_memory_usage_ratio': 1.0, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': ['bool', 'int', 'float', 'category'], 'valid_special_types': None, 'ignored_type_group_special': ['text_ngram', 'text_as_category'], 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'temperature_scalar': None}   \n",
       "136  {'max_memory_usage_ratio': 1.0, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': ['bool', 'int', 'float', 'category'], 'valid_special_types': None, 'ignored_type_group_special': ['text_ngram', 'text_as_category'], 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'temperature_scalar': None}   \n",
       "137  {'max_memory_usage_ratio': 1.0, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': ['bool', 'int', 'float', 'category'], 'valid_special_types': None, 'ignored_type_group_special': ['text_ngram', 'text_as_category'], 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'temperature_scalar': None}   \n",
       "138  {'max_memory_usage_ratio': 1.0, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': ['bool', 'int', 'float', 'category'], 'valid_special_types': None, 'ignored_type_group_special': ['text_ngram', 'text_as_category'], 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'temperature_scalar': None}   \n",
       "139  {'max_memory_usage_ratio': 1.0, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': ['bool', 'int', 'float', 'category'], 'valid_special_types': None, 'ignored_type_group_special': ['text_ngram', 'text_as_category'], 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'temperature_scalar': None}   \n",
       "\n",
       "     ancestors                 descendants  \n",
       "0           []                          []  \n",
       "1           []  [WeightedEnsemble_L2_FULL]  \n",
       "2           []                          []  \n",
       "3           []                          []  \n",
       "4           []                          []  \n",
       "..         ...                         ...  \n",
       "135         []                          []  \n",
       "136         []                          []  \n",
       "137         []                          []  \n",
       "138         []                          []  \n",
       "139         []                          []  \n",
       "\n",
       "[140 rows x 45 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictors.to_csv(\n",
    "    '../../data/tlp/predictors.csv',\n",
    "    index=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>score_test</th>\n",
       "      <th>balanced_accuracy</th>\n",
       "      <th>f1</th>\n",
       "      <th>f1_macro</th>\n",
       "      <th>f1_micro</th>\n",
       "      <th>roc_auc</th>\n",
       "      <th>average_precision</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>...</th>\n",
       "      <th>hyperparameters</th>\n",
       "      <th>hyperparameters_fit</th>\n",
       "      <th>ag_args_fit</th>\n",
       "      <th>features</th>\n",
       "      <th>compile_time</th>\n",
       "      <th>child_hyperparameters</th>\n",
       "      <th>child_hyperparameters_fit</th>\n",
       "      <th>child_ag_args_fit</th>\n",
       "      <th>ancestors</th>\n",
       "      <th>descendants</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LightGBM_BAG_L1_FULL</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.984043</td>\n",
       "      <td>0.954545</td>\n",
       "      <td>0.969165</td>\n",
       "      <td>0.976096</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.913043</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>{'use_orig_features': True, 'valid_stacker': True, 'max_base_models': 0, 'max_base_models_per_type': 'auto', 'save_bag_folds': True}</td>\n",
       "      <td>{}</td>\n",
       "      <td>{'max_memory_usage_ratio': 1.15, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': None, 'valid_special_types': None, 'ignored_type_group_special': None, 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'temperature_scalar': None, 'drop_unique': False}</td>\n",
       "      <td>[clin-tipoAlcohol.symbol_ratio. , clin-numCigarros, clin-tipoAlcohol, eval-TLP-Tavec-33_Recon_Ac_frente_RCl_LP-PD, demo-fechaNacimiento.dayofweek, eval-TLP-CubCorsi-totalinversos-PD, clin-reservaCognitiva_ocupacion, eval-TLP-FigRey-Duracion-PD, eval-TLP-Tavec-4_RI_B-PD, eval-TLP-Tavec-12_ESem_RI_A-PD, eval-TLP-Tavec-29_RCl_Cp_frente_RCl_LP-PD, ques-Sus-totalImpar-PD, clin-alcohol, ques-MMSE-memoria-PD, eval-TLP-Tavec-26_Sesgo-PD, demo-fechaNacimiento.year, eval-TLP-Tavec-1_RI_A1-PD, eval-TLP-Stroop-color-PD, eval-TLP-Tavec-11_RCl_LP-PD, demo-fechaEvaluacion.dayofweek, clin-tipoAlcohol.lowe...</td>\n",
       "      <td>None</td>\n",
       "      <td>{'learning_rate': 0.05, 'num_boost_round': 72}</td>\n",
       "      <td>{'num_boost_round': 72}</td>\n",
       "      <td>{'max_memory_usage_ratio': 1.0, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': ['bool', 'int', 'float', 'category'], 'valid_special_types': None, 'ignored_type_group_special': None, 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'temperature_scalar': None}</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 45 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  model  score_test  balanced_accuracy        f1  f1_macro  \\\n",
       "0  LightGBM_BAG_L1_FULL         1.0           0.984043  0.954545  0.969165   \n",
       "\n",
       "   f1_micro  roc_auc  average_precision  precision  recall  ...  \\\n",
       "0  0.976096      1.0                1.0   0.913043     1.0  ...   \n",
       "\n",
       "                                                                                                                        hyperparameters  \\\n",
       "0  {'use_orig_features': True, 'valid_stacker': True, 'max_base_models': 0, 'max_base_models_per_type': 'auto', 'save_bag_folds': True}   \n",
       "\n",
       "   hyperparameters_fit  \\\n",
       "0                   {}   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                            ag_args_fit  \\\n",
       "0  {'max_memory_usage_ratio': 1.15, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': None, 'valid_special_types': None, 'ignored_type_group_special': None, 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'temperature_scalar': None, 'drop_unique': False}   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  features  \\\n",
       "0  [clin-tipoAlcohol.symbol_ratio. , clin-numCigarros, clin-tipoAlcohol, eval-TLP-Tavec-33_Recon_Ac_frente_RCl_LP-PD, demo-fechaNacimiento.dayofweek, eval-TLP-CubCorsi-totalinversos-PD, clin-reservaCognitiva_ocupacion, eval-TLP-FigRey-Duracion-PD, eval-TLP-Tavec-4_RI_B-PD, eval-TLP-Tavec-12_ESem_RI_A-PD, eval-TLP-Tavec-29_RCl_Cp_frente_RCl_LP-PD, ques-Sus-totalImpar-PD, clin-alcohol, ques-MMSE-memoria-PD, eval-TLP-Tavec-26_Sesgo-PD, demo-fechaNacimiento.year, eval-TLP-Tavec-1_RI_A1-PD, eval-TLP-Stroop-color-PD, eval-TLP-Tavec-11_RCl_LP-PD, demo-fechaEvaluacion.dayofweek, clin-tipoAlcohol.lowe...   \n",
       "\n",
       "   compile_time                           child_hyperparameters  \\\n",
       "0          None  {'learning_rate': 0.05, 'num_boost_round': 72}   \n",
       "\n",
       "   child_hyperparameters_fit  \\\n",
       "0    {'num_boost_round': 72}   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                               child_ag_args_fit  \\\n",
       "0  {'max_memory_usage_ratio': 1.0, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': ['bool', 'int', 'float', 'category'], 'valid_special_types': None, 'ignored_type_group_special': None, 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'temperature_scalar': None}   \n",
       "\n",
       "   ancestors  descendants  \n",
       "0         []           []  \n",
       "\n",
       "[1 rows x 45 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictors[predictors['model']=='LightGBM_BAG_L1_FULL']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "These features in provided data are not utilized by the predictor and will be ignored: ['clin-Covid_sintomaSarpullido']\n",
      "Computing feature importance via permutation shuffling for 78 features using 251 rows with 5 shuffle sets...\n",
      "\t28.22s\t= Expected runtime (5.64s per shuffle set)\n",
      "\t10.37s\t= Actual runtime (Completed 5 of 5 shuffle sets)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>importance</th>\n",
       "      <th>stddev</th>\n",
       "      <th>p_value</th>\n",
       "      <th>n</th>\n",
       "      <th>p99_high</th>\n",
       "      <th>p99_low</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>eval-TLP-Stroop-color-PD</th>\n",
       "      <td>0.044073</td>\n",
       "      <td>0.009099</td>\n",
       "      <td>0.000206</td>\n",
       "      <td>5</td>\n",
       "      <td>0.062808</td>\n",
       "      <td>0.025338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eval-TLP-CubCorsi-totalDirectos-PD</th>\n",
       "      <td>0.004813</td>\n",
       "      <td>0.001751</td>\n",
       "      <td>0.001777</td>\n",
       "      <td>5</td>\n",
       "      <td>0.008417</td>\n",
       "      <td>0.001208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>demo-fechaNacimiento</th>\n",
       "      <td>0.002280</td>\n",
       "      <td>0.000612</td>\n",
       "      <td>0.000567</td>\n",
       "      <td>5</td>\n",
       "      <td>0.003539</td>\n",
       "      <td>0.001020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eval-TLP-FigRey-totalCopia-PD</th>\n",
       "      <td>0.000338</td>\n",
       "      <td>0.000189</td>\n",
       "      <td>0.008065</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000726</td>\n",
       "      <td>-0.000051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>clin-reservaCognitiva_escolaridad</th>\n",
       "      <td>0.000051</td>\n",
       "      <td>0.000046</td>\n",
       "      <td>0.035242</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000146</td>\n",
       "      <td>-0.000045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ques-Sus-totalImpar-PD</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ques-Sus-totalPar-PD</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ques-NavEspacial-resultadosWFQ_DE-PD</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ques-NavEspacial-resultadosWFQ_SA-PD</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eval-TLP-Tavec-33_Recon_Ac_frente_RCl_LP-PD</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>78 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             importance    stddev   p_value  \\\n",
       "eval-TLP-Stroop-color-PD                       0.044073  0.009099  0.000206   \n",
       "eval-TLP-CubCorsi-totalDirectos-PD             0.004813  0.001751  0.001777   \n",
       "demo-fechaNacimiento                           0.002280  0.000612  0.000567   \n",
       "eval-TLP-FigRey-totalCopia-PD                  0.000338  0.000189  0.008065   \n",
       "clin-reservaCognitiva_escolaridad              0.000051  0.000046  0.035242   \n",
       "...                                                 ...       ...       ...   \n",
       "ques-Sus-totalImpar-PD                         0.000000  0.000000  0.500000   \n",
       "ques-Sus-totalPar-PD                           0.000000  0.000000  0.500000   \n",
       "ques-NavEspacial-resultadosWFQ_DE-PD           0.000000  0.000000  0.500000   \n",
       "ques-NavEspacial-resultadosWFQ_SA-PD           0.000000  0.000000  0.500000   \n",
       "eval-TLP-Tavec-33_Recon_Ac_frente_RCl_LP-PD    0.000000  0.000000  0.500000   \n",
       "\n",
       "                                             n  p99_high   p99_low  \n",
       "eval-TLP-Stroop-color-PD                     5  0.062808  0.025338  \n",
       "eval-TLP-CubCorsi-totalDirectos-PD           5  0.008417  0.001208  \n",
       "demo-fechaNacimiento                         5  0.003539  0.001020  \n",
       "eval-TLP-FigRey-totalCopia-PD                5  0.000726 -0.000051  \n",
       "clin-reservaCognitiva_escolaridad            5  0.000146 -0.000045  \n",
       "...                                         ..       ...       ...  \n",
       "ques-Sus-totalImpar-PD                       5  0.000000  0.000000  \n",
       "ques-Sus-totalPar-PD                         5  0.000000  0.000000  \n",
       "ques-NavEspacial-resultadosWFQ_DE-PD         5  0.000000  0.000000  \n",
       "ques-NavEspacial-resultadosWFQ_SA-PD         5  0.000000  0.000000  \n",
       "eval-TLP-Tavec-33_Recon_Ac_frente_RCl_LP-PD  5  0.000000  0.000000  \n",
       "\n",
       "[78 rows x 6 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.feature_importance(data=df_train)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
