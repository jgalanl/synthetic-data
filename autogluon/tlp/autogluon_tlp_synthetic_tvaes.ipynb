{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from autogluon.tabular import TabularPredictor\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../../data/tlp/synthetic-tvaes.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>etiq-diagExpTLPtext</th>\n",
       "      <th>etiq-diagExpTLPcode</th>\n",
       "      <th>etiq-diagExpTLPtext_R2</th>\n",
       "      <th>etiq-diagExpTLPcode_R2</th>\n",
       "      <th>demo-genero</th>\n",
       "      <th>demo-fechaEvaluacion</th>\n",
       "      <th>demo-fechaNacimiento</th>\n",
       "      <th>demo-rangoEdad</th>\n",
       "      <th>demo-edad</th>\n",
       "      <th>clin-reservaCognitiva_total</th>\n",
       "      <th>...</th>\n",
       "      <th>eval-TLP-Tavec-25_Discriminabilidad-PD</th>\n",
       "      <th>eval-TLP-Tavec-26_Sesgo-PD</th>\n",
       "      <th>eval-TLP-Tavec-27_RI_B_frente_RI_A1-PD</th>\n",
       "      <th>eval-TLP-Tavec-28_RL_CP_frente_RI_A5-PD</th>\n",
       "      <th>eval-TLP-Tavec-29_RCl_Cp_frente_RCl_LP-PD</th>\n",
       "      <th>eval-TLP-Tavec-30_RL_LP_frente_RL_CP-PD</th>\n",
       "      <th>eval-TLP-Tavec-31_RCl_LP_frente_RL_LP-PD</th>\n",
       "      <th>eval-TLP-Tavec-32_Recon_Ac_frente_RL_LP-PD</th>\n",
       "      <th>eval-TLP-Tavec-33_Recon_Ac_frente_RCl_LP-PD</th>\n",
       "      <th>ED_2Clases</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DC MUY LEVE, ejecutivo - atencional</td>\n",
       "      <td>2.07</td>\n",
       "      <td>DC MUY LEVE, ejecutivo - atencional</td>\n",
       "      <td>2.07</td>\n",
       "      <td>2</td>\n",
       "      <td>2024-02-22T00:00:00</td>\n",
       "      <td>1942-05-08T00:00:00</td>\n",
       "      <td>Rango3</td>\n",
       "      <td>81</td>\n",
       "      <td>12</td>\n",
       "      <td>...</td>\n",
       "      <td>84.09</td>\n",
       "      <td>0.14</td>\n",
       "      <td>-20.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>33.33</td>\n",
       "      <td>37.50</td>\n",
       "      <td>-33.33</td>\n",
       "      <td>-38.46</td>\n",
       "      <td>-7.69</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DC LEVE, ejecutivo - atencional</td>\n",
       "      <td>3.07</td>\n",
       "      <td>DC LEVE, multidominio amnésico</td>\n",
       "      <td>3.06</td>\n",
       "      <td>2</td>\n",
       "      <td>2024-06-26T00:00:00</td>\n",
       "      <td>1948-10-07T00:00:00</td>\n",
       "      <td>Rango3</td>\n",
       "      <td>75</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>79.55</td>\n",
       "      <td>-0.33</td>\n",
       "      <td>-71.43</td>\n",
       "      <td>12.50</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-20.00</td>\n",
       "      <td>-20.00</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NORMAL</td>\n",
       "      <td>1.00</td>\n",
       "      <td>DC MUY LEVE, multidominio amnésico</td>\n",
       "      <td>2.06</td>\n",
       "      <td>2</td>\n",
       "      <td>2024-05-14T00:00:00</td>\n",
       "      <td>1952-05-08T00:00:00</td>\n",
       "      <td>Rango2</td>\n",
       "      <td>72</td>\n",
       "      <td>11</td>\n",
       "      <td>...</td>\n",
       "      <td>88.64</td>\n",
       "      <td>-0.60</td>\n",
       "      <td>-14.29</td>\n",
       "      <td>75.00</td>\n",
       "      <td>25.00</td>\n",
       "      <td>-20.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-16.67</td>\n",
       "      <td>-16.67</td>\n",
       "      <td>H</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DC MUY LEVE, amnésico</td>\n",
       "      <td>2.01</td>\n",
       "      <td>DC MUY LEVE, amnésico</td>\n",
       "      <td>2.01</td>\n",
       "      <td>2</td>\n",
       "      <td>2024-04-10T00:00:00</td>\n",
       "      <td>1964-01-27T00:00:00</td>\n",
       "      <td>Rango1</td>\n",
       "      <td>60</td>\n",
       "      <td>18</td>\n",
       "      <td>...</td>\n",
       "      <td>90.91</td>\n",
       "      <td>0.60</td>\n",
       "      <td>60.00</td>\n",
       "      <td>16.67</td>\n",
       "      <td>0.00</td>\n",
       "      <td>50.00</td>\n",
       "      <td>-20.00</td>\n",
       "      <td>-50.00</td>\n",
       "      <td>-37.50</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DC MUY LEVE, multidominio amnésico</td>\n",
       "      <td>2.06</td>\n",
       "      <td>DC LEVE, multidominio amnésico</td>\n",
       "      <td>3.06</td>\n",
       "      <td>2</td>\n",
       "      <td>2024-05-14T00:00:00</td>\n",
       "      <td>1959-09-16T00:00:00</td>\n",
       "      <td>Rango1</td>\n",
       "      <td>64</td>\n",
       "      <td>13</td>\n",
       "      <td>...</td>\n",
       "      <td>86.36</td>\n",
       "      <td>-0.71</td>\n",
       "      <td>0.00</td>\n",
       "      <td>66.67</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-33.33</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-10.00</td>\n",
       "      <td>-10.00</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 84 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   etiq-diagExpTLPtext  etiq-diagExpTLPcode  \\\n",
       "0  DC MUY LEVE, ejecutivo - atencional                 2.07   \n",
       "1      DC LEVE, ejecutivo - atencional                 3.07   \n",
       "2                               NORMAL                 1.00   \n",
       "3                DC MUY LEVE, amnésico                 2.01   \n",
       "4   DC MUY LEVE, multidominio amnésico                 2.06   \n",
       "\n",
       "                etiq-diagExpTLPtext_R2  etiq-diagExpTLPcode_R2  demo-genero  \\\n",
       "0  DC MUY LEVE, ejecutivo - atencional                    2.07            2   \n",
       "1       DC LEVE, multidominio amnésico                    3.06            2   \n",
       "2   DC MUY LEVE, multidominio amnésico                    2.06            2   \n",
       "3                DC MUY LEVE, amnésico                    2.01            2   \n",
       "4       DC LEVE, multidominio amnésico                    3.06            2   \n",
       "\n",
       "  demo-fechaEvaluacion demo-fechaNacimiento demo-rangoEdad  demo-edad  \\\n",
       "0  2024-02-22T00:00:00  1942-05-08T00:00:00         Rango3         81   \n",
       "1  2024-06-26T00:00:00  1948-10-07T00:00:00         Rango3         75   \n",
       "2  2024-05-14T00:00:00  1952-05-08T00:00:00         Rango2         72   \n",
       "3  2024-04-10T00:00:00  1964-01-27T00:00:00         Rango1         60   \n",
       "4  2024-05-14T00:00:00  1959-09-16T00:00:00         Rango1         64   \n",
       "\n",
       "   clin-reservaCognitiva_total  ...  eval-TLP-Tavec-25_Discriminabilidad-PD  \\\n",
       "0                           12  ...                                   84.09   \n",
       "1                            8  ...                                   79.55   \n",
       "2                           11  ...                                   88.64   \n",
       "3                           18  ...                                   90.91   \n",
       "4                           13  ...                                   86.36   \n",
       "\n",
       "   eval-TLP-Tavec-26_Sesgo-PD  eval-TLP-Tavec-27_RI_B_frente_RI_A1-PD  \\\n",
       "0                        0.14                                  -20.00   \n",
       "1                       -0.33                                  -71.43   \n",
       "2                       -0.60                                  -14.29   \n",
       "3                        0.60                                   60.00   \n",
       "4                       -0.71                                    0.00   \n",
       "\n",
       "   eval-TLP-Tavec-28_RL_CP_frente_RI_A5-PD  \\\n",
       "0                                     0.00   \n",
       "1                                    12.50   \n",
       "2                                    75.00   \n",
       "3                                    16.67   \n",
       "4                                    66.67   \n",
       "\n",
       "   eval-TLP-Tavec-29_RCl_Cp_frente_RCl_LP-PD  \\\n",
       "0                                      33.33   \n",
       "1                                       0.00   \n",
       "2                                      25.00   \n",
       "3                                       0.00   \n",
       "4                                       0.00   \n",
       "\n",
       "   eval-TLP-Tavec-30_RL_LP_frente_RL_CP-PD  \\\n",
       "0                                    37.50   \n",
       "1                                     0.00   \n",
       "2                                   -20.00   \n",
       "3                                    50.00   \n",
       "4                                   -33.33   \n",
       "\n",
       "   eval-TLP-Tavec-31_RCl_LP_frente_RL_LP-PD  \\\n",
       "0                                    -33.33   \n",
       "1                                      0.00   \n",
       "2                                      0.00   \n",
       "3                                    -20.00   \n",
       "4                                      0.00   \n",
       "\n",
       "   eval-TLP-Tavec-32_Recon_Ac_frente_RL_LP-PD  \\\n",
       "0                                      -38.46   \n",
       "1                                      -20.00   \n",
       "2                                      -16.67   \n",
       "3                                      -50.00   \n",
       "4                                      -10.00   \n",
       "\n",
       "   eval-TLP-Tavec-33_Recon_Ac_frente_RCl_LP-PD  ED_2Clases  \n",
       "0                                        -7.69           D  \n",
       "1                                       -20.00           D  \n",
       "2                                       -16.67           H  \n",
       "3                                       -37.50           D  \n",
       "4                                       -10.00           D  \n",
       "\n",
       "[5 rows x 84 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((382, 84), (96, 84))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train, df_test = train_test_split(df, test_size=0.2, random_state=42)\n",
    "df_train.shape, df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"AutogluonModels/synthetic/tvaes/v1\"\n"
     ]
    }
   ],
   "source": [
    "predictor= TabularPredictor(\n",
    "    label='ED_2Clases',\n",
    "    problem_type='binary',\n",
    "    eval_metric='roc_auc',\n",
    "    sample_weight='balance_weight',\n",
    "    path='AutogluonModels/synthetic/tvaes/v1'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.2\n",
      "Python Version:     3.10.2\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.26100\n",
      "CPU Count:          12\n",
      "Memory Avail:       7.66 GB / 15.94 GB (48.1%)\n",
      "Disk Space Avail:   118.78 GB / 446.36 GB (26.6%)\n",
      "===================================================\n",
      "Presets specified: ['high_quality']\n",
      "Setting dynamic_stacking from 'auto' to True. Reason: Enable dynamic_stacking when use_bag_holdout is disabled. (use_bag_holdout=False)\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=1\n",
      "Note: `save_bag_folds=False`! This will greatly reduce peak disk usage during fit (by ~8x), but runs the risk of an out-of-memory error during model refit if memory is small relative to the data size.\n",
      "\tYou can avoid this risk by setting `save_bag_folds=True`.\n",
      "DyStack is enabled (dynamic_stacking=True). AutoGluon will try to determine whether the input data is affected by stacked overfitting and enable or disable stacking as a consequence.\n",
      "\tThis is used to identify the optimal `num_stack_levels` value. Copies of AutoGluon will be fit on subsets of the data. Then holdout validation data is used to detect stacked overfitting.\n",
      "\tRunning DyStack for up to 1800s of the 7200s of remaining time (25%).\n",
      "\tRunning DyStack sub-fit in a ray process to avoid memory leakage. Enabling ray logging (enable_ray_logging=True). Specify `ds_args={'enable_ray_logging': False}` if you experience logging issues.\n",
      "2025-01-29 18:30:49,008\tINFO worker.py:1743 -- Started a local Ray instance. View the dashboard at \u001b[1m\u001b[32m127.0.0.1:8265 \u001b[39m\u001b[22m\n",
      "\t\tContext path: \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\autogluon\\tlp\\AutogluonModels\\synthetic\\tvaes\\v1\\ds_sub_fit\\sub_fit_ho\"\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m Running DyStack sub-fit ...\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m Using predefined sample weighting strategy: balance_weight. Evaluation metrics will ignore sample weights, specify weight_evaluation=True to instead report weighted metrics.\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m Beginning AutoGluon training ... Time limit = 1795s\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m AutoGluon will save models to \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\autogluon\\tlp\\AutogluonModels\\synthetic\\tvaes\\v1\\ds_sub_fit\\sub_fit_ho\"\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m Train Data Rows:    339\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m Train Data Columns: 83\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m Label Column:       ED_2Clases\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m Problem Type:       binary\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m Preprocessing data ...\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m Selected class <--> label mapping:  class 1 = H, class 0 = D\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m \tNote: For your binary classification, AutoGluon arbitrarily selected which label-value represents positive (H) vs negative (D) class.\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m \tTo explicitly set the positive_class, either rename classes to 1 and 0, or specify positive_class in Predictor init.\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m Assigning sample weights to balance differences in frequency of classes.\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m Using Feature Generators to preprocess the data ...\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m Fitting AutoMLPipelineFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m \tAvailable Memory:                    7247.16 MB\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m \tTrain Data (Original)  Memory Usage: 0.32 MB (0.0% of available memory)\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m \tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m \tStage 1 Generators:\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m \t\tFitting AsTypeFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m \t\t\tNote: Converting 9 features to boolean dtype as they only contain 2 unique values.\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m \tStage 2 Generators:\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m \t\tFitting FillNaFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m \tStage 3 Generators:\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m \t\tFitting IdentityFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m \t\tFitting CategoryFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m \t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m \t\tFitting DatetimeFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m \t\tFitting TextSpecialFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m \t\t\tFitting BinnedFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m \t\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m \t\tFitting TextNgramFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m \t\t\tFitting CountVectorizer for text features: ['etiq-diagExpTLPtext', 'etiq-diagExpTLPtext_R2', 'clin-tipoAlcohol']\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m \t\t\tCountVectorizer fit with vocabulary size = 16\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m \tStage 4 Generators:\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m \t\tFitting DropUniqueFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m \tStage 5 Generators:\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m \t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m \tUseless Original Features (Count: 2): ['clin-Covid_sintomaSarpullido', 'ques-MMSE-fijacion-PD']\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m \t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m \t\tThis is typically a feature which has the same value for all rows.\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m \t\tThese features do not need to be present at inference time.\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m \tTypes of features in original data (raw dtype, special dtypes):\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m \t\t('bool', [])                       :  8 | ['clin-ansiedad', 'clin-depresion', 'clin-cardiopatiaIsquemica', 'clin-diabetes', 'clin-Hipercolesterolemia', ...]\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m \t\t('float', [])                      : 19 | ['etiq-diagExpTLPcode', 'etiq-diagExpTLPcode_R2', 'clin-numCigarros', 'clin-añosSinFumar', 'ques-Sus-total-PD', ...]\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m \t\t('int', [])                        : 48 | ['demo-genero', 'demo-edad', 'clin-reservaCognitiva_total', 'clin-reservaCognitiva_idiomas', 'clin-reservaCognitiva_ocupacion', ...]\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m \t\t('object', [])                     :  1 | ['demo-rangoEdad']\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m \t\t('object', ['datetime_as_object']) :  2 | ['demo-fechaEvaluacion', 'demo-fechaNacimiento']\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m \t\t('object', ['text'])               :  3 | ['etiq-diagExpTLPtext', 'etiq-diagExpTLPtext_R2', 'clin-tipoAlcohol']\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m \tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m \t\t('category', [])                    :  1 | ['demo-rangoEdad']\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m \t\t('category', ['text_as_category'])  :  3 | ['etiq-diagExpTLPtext', 'etiq-diagExpTLPtext_R2', 'clin-tipoAlcohol']\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m \t\t('float', [])                       : 19 | ['etiq-diagExpTLPcode', 'etiq-diagExpTLPcode_R2', 'clin-numCigarros', 'clin-añosSinFumar', 'ques-Sus-total-PD', ...]\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m \t\t('int', [])                         : 47 | ['demo-edad', 'clin-reservaCognitiva_total', 'clin-reservaCognitiva_idiomas', 'clin-reservaCognitiva_ocupacion', 'clin-reservaCognitiva_escolaridad', ...]\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m \t\t('int', ['binned', 'text_special']) : 30 | ['etiq-diagExpTLPtext.char_count', 'etiq-diagExpTLPtext.word_count', 'etiq-diagExpTLPtext.capital_ratio', 'etiq-diagExpTLPtext.lower_ratio', 'etiq-diagExpTLPtext.special_ratio', ...]\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m \t\t('int', ['bool'])                   :  9 | ['demo-genero', 'clin-ansiedad', 'clin-depresion', 'clin-cardiopatiaIsquemica', 'clin-diabetes', ...]\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m \t\t('int', ['datetime_as_int'])        :  9 | ['demo-fechaEvaluacion', 'demo-fechaEvaluacion.month', 'demo-fechaEvaluacion.day', 'demo-fechaEvaluacion.dayofweek', 'demo-fechaNacimiento', ...]\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m \t\t('int', ['text_ngram'])             : 10 | ['__nlp__.amnésico', '__nlp__.amnésico dc', '__nlp__.atencional', '__nlp__.atencional dc', '__nlp__.dc', ...]\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m \t0.6s = Fit runtime\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m \t81 features in original data used to generate 128 features in processed data.\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m \tTrain Data (Processed) Memory Usage: 0.22 MB (0.0% of available memory)\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m Data preprocessing and feature engineering runtime = 0.56s ...\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m AutoGluon will gauge predictive performance using evaluation metric: 'roc_auc'\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m \tThis metric expects predicted probabilities rather than predicted class labels, so you'll need to use predict_proba() instead of predict()\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m \tTo change this, specify the eval_metric parameter of Predictor()\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m Large model count detected (112 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m User-specified model hyperparameters to be fit:\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m {\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m \t'NN_TORCH': [{}, {'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2}}, {'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7}}],\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m \t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m \t'CAT': [{}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5}}],\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m \t'XGB': [{}, {'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'name_suffix': '_r33', 'priority': -8}}, {'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'name_suffix': '_r89', 'priority': -16}}],\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m \t'FASTAI': [{}, {'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4}}, {'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11}}],\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m \t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m \t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m \t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m }\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m Excluded models: ['RF', 'XT', 'KNN'] (Specified by `excluded_model_types`)\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m Fitting 90 L1 models, fit_strategy=\"sequential\" ...\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 1196.24s of the 1794.80s of remaining time.\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.35%)\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m \t1.0\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m \t1.4s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m \t0.04s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m Fitting model: LightGBM_BAG_L1 ... Training model for up to 1189.69s of the 1788.25s of remaining time.\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.41%)\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m \t1.0\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m \t1.1s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m \t0.04s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m Fitting model: CatBoost_BAG_L1 ... Training model for up to 1185.11s of the 1783.68s of remaining time.\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.83%)\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m \t1.0\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m \t584.88s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m \t0.1s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 596.75s of the 1195.31s of remaining time.\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.03%)\n",
      "\u001b[36m(_ray_fit pid=17032)\u001b[0m No improvement since epoch 6: early stopping\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m \t1.0\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m \t6.94s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m \t0.15s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m Fitting model: XGBoost_BAG_L1 ... Training model for up to 586.63s of the 1185.19s of remaining time.\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=1.00%)\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m \t1.0\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m \t1.44s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m \t0.13s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m Fitting model: NeuralNetTorch_BAG_L1 ... Training model for up to 581.38s of the 1179.94s of remaining time.\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.02%)\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m \tWarning: Exception caused NeuralNetTorch_BAG_L1 to fail during training... Skipping this model.\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m \t\t\u001b[36mray::_ray_fit()\u001b[39m (pid=7560, ip=127.0.0.1)\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m   File \"python\\ray\\_raylet.pyx\", line 1889, in ray._raylet.execute_task\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m     fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m     out = self._fit(**kwargs)\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 201, in _fit\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m     train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m     dataset = self._process_train_data(\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m     self.processor = create_preprocessor(\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\utils\\data_preprocessor.py\", line 40, in create_preprocessor\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m     return ColumnTransformer(\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m Detailed Traceback:\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 2106, in _train_and_save\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m     model = self._train_single(**model_fit_kwargs)\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 1993, in _train_single\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m     model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m     out = self._fit(**kwargs)\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\stacker_ensemble_model.py\", line 270, in _fit\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m     return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\bagged_ensemble_model.py\", line 298, in _fit\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m     self._fit_folds(\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\bagged_ensemble_model.py\", line 724, in _fit_folds\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m     fold_fitting_strategy.after_all_folds_scheduled()\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 690, in after_all_folds_scheduled\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m     self._run_parallel(X, y, X_pseudo, y_pseudo, model_base_ref, time_limit_fold, head_node_id)\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 631, in _run_parallel\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m     self._process_fold_results(finished, unfinished, fold_ctx)\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 587, in _process_fold_results\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m     raise processed_exception\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 550, in _process_fold_results\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m     fold_model, pred_proba, time_start_fit, time_end_fit, predict_time, predict_1_time, predict_n_size, fit_num_cpus, fit_num_gpus = self.ray.get(finished)\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m     return fn(*args, **kwargs)\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\client_mode_hook.py\", line 103, in wrapper\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m     return func(*args, **kwargs)\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\worker.py\", line 2667, in get\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m     values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\worker.py\", line 864, in get_objects\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m     raise value.as_instanceof_cause()\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m ray.exceptions.RayTaskError(TypeError): \u001b[36mray::_ray_fit()\u001b[39m (pid=7560, ip=127.0.0.1)\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m   File \"python\\ray\\_raylet.pyx\", line 1889, in ray._raylet.execute_task\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m     fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m     out = self._fit(**kwargs)\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 201, in _fit\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m     train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m     dataset = self._process_train_data(\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m     self.processor = create_preprocessor(\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\utils\\data_preprocessor.py\", line 40, in create_preprocessor\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m     return ColumnTransformer(\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m Fitting model: LightGBMLarge_BAG_L1 ... Training model for up to 574.35s of the 1172.91s of remaining time.\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=1.65%)\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m \t1.0\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m \t1.52s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m \t0.05s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m Fitting model: CatBoost_r177_BAG_L1 ... Training model for up to 569.41s of the 1167.98s of remaining time.\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.87%)\n",
      "\u001b[36m(_ray_fit pid=18884)\u001b[0m \tRan out of time, early stopping on iteration 8756.\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m \t1.0\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m \t455.69s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m \t0.12s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m Fitting model: NeuralNetTorch_r79_BAG_L1 ... Training model for up to 110.11s of the 708.68s of remaining time.\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.02%)\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m \tWarning: Exception caused NeuralNetTorch_r79_BAG_L1 to fail during training... Skipping this model.\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m \t\t\u001b[36mray::_ray_fit()\u001b[39m (pid=16552, ip=127.0.0.1)\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m   File \"python\\ray\\_raylet.pyx\", line 1889, in ray._raylet.execute_task\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m     fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m     out = self._fit(**kwargs)\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 201, in _fit\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m     train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m     dataset = self._process_train_data(\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m     self.processor = create_preprocessor(\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\utils\\data_preprocessor.py\", line 40, in create_preprocessor\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m     return ColumnTransformer(\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m Detailed Traceback:\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 2106, in _train_and_save\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m     model = self._train_single(**model_fit_kwargs)\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 1993, in _train_single\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m     model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m     out = self._fit(**kwargs)\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\stacker_ensemble_model.py\", line 270, in _fit\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m     return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\bagged_ensemble_model.py\", line 298, in _fit\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m     self._fit_folds(\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\bagged_ensemble_model.py\", line 724, in _fit_folds\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m     fold_fitting_strategy.after_all_folds_scheduled()\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 690, in after_all_folds_scheduled\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m     self._run_parallel(X, y, X_pseudo, y_pseudo, model_base_ref, time_limit_fold, head_node_id)\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 631, in _run_parallel\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m     self._process_fold_results(finished, unfinished, fold_ctx)\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 587, in _process_fold_results\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m     raise processed_exception\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 550, in _process_fold_results\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m     fold_model, pred_proba, time_start_fit, time_end_fit, predict_time, predict_1_time, predict_n_size, fit_num_cpus, fit_num_gpus = self.ray.get(finished)\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m     return fn(*args, **kwargs)\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\client_mode_hook.py\", line 103, in wrapper\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m     return func(*args, **kwargs)\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\worker.py\", line 2667, in get\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m     values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\worker.py\", line 864, in get_objects\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m     raise value.as_instanceof_cause()\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m ray.exceptions.RayTaskError(TypeError): \u001b[36mray::_ray_fit()\u001b[39m (pid=16552, ip=127.0.0.1)\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m   File \"python\\ray\\_raylet.pyx\", line 1889, in ray._raylet.execute_task\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m     fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m     out = self._fit(**kwargs)\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 201, in _fit\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m     train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m     dataset = self._process_train_data(\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m     self.processor = create_preprocessor(\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\utils\\data_preprocessor.py\", line 40, in create_preprocessor\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m     return ColumnTransformer(\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m Fitting model: LightGBM_r131_BAG_L1 ... Training model for up to 103.54s of the 702.10s of remaining time.\n",
      "\u001b[36m(_ray_fit pid=14496)\u001b[0m \tRan out of time, early stopping on iteration 8707.\u001b[32m [repeated 4x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/ray-logging.html#log-deduplication for more options.)\u001b[0m\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.93%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=8592)\u001b[0m [1000]\tvalid_set's binary_logloss: 3.69095e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_dystack pid=7812)\u001b[0m \t1.0\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m \t2.24s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m \t0.07s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m Fitting model: NeuralNetFastAI_r191_BAG_L1 ... Training model for up to 97.81s of the 696.38s of remaining time.\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.06%)\n",
      "\u001b[36m(_ray_fit pid=13996)\u001b[0m No improvement since epoch 4: early stopping\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m \t1.0\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m \t7.32s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m \t0.13s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m Fitting model: CatBoost_r9_BAG_L1 ... Training model for up to 86.89s of the 685.45s of remaining time.\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=7.52%)\n",
      "\u001b[36m(_ray_fit pid=2704)\u001b[0m \tRan out of time, early stopping on iteration 445.\n",
      "\u001b[36m(_ray_fit pid=16768)\u001b[0m No improvement since epoch 19: early stopping\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m \t1.0\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m \t69.57s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m \t0.1s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m Fitting model: LightGBM_r96_BAG_L1 ... Training model for up to 13.47s of the 612.03s of remaining time.\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.35%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=13396)\u001b[0m [1000]\tvalid_set's binary_logloss: 0.0043799\u001b[32m [repeated 8x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_dystack pid=7812)\u001b[0m \t1.0\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m \t4.18s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m \t0.04s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m Fitting model: NeuralNetTorch_r22_BAG_L1 ... Training model for up to 5.60s of the 604.16s of remaining time.\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.03%)\n",
      "\u001b[36m(_ray_fit pid=6760)\u001b[0m \tRan out of time, early stopping on iteration 436.\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m \tWarning: Exception caused NeuralNetTorch_r22_BAG_L1 to fail during training... Skipping this model.\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m \t\t\u001b[36mray::_ray_fit()\u001b[39m (pid=1352, ip=127.0.0.1)\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m   File \"python\\ray\\_raylet.pyx\", line 1889, in ray._raylet.execute_task\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m     fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m     out = self._fit(**kwargs)\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 201, in _fit\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m     train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m     dataset = self._process_train_data(\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m     self.processor = create_preprocessor(\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\utils\\data_preprocessor.py\", line 40, in create_preprocessor\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m     return ColumnTransformer(\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m Detailed Traceback:\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 2106, in _train_and_save\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m     model = self._train_single(**model_fit_kwargs)\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 1993, in _train_single\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m     model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m     out = self._fit(**kwargs)\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\stacker_ensemble_model.py\", line 270, in _fit\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m     return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\bagged_ensemble_model.py\", line 298, in _fit\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m     self._fit_folds(\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\bagged_ensemble_model.py\", line 724, in _fit_folds\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m     fold_fitting_strategy.after_all_folds_scheduled()\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 690, in after_all_folds_scheduled\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m     self._run_parallel(X, y, X_pseudo, y_pseudo, model_base_ref, time_limit_fold, head_node_id)\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 631, in _run_parallel\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m     self._process_fold_results(finished, unfinished, fold_ctx)\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 587, in _process_fold_results\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m     raise processed_exception\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 550, in _process_fold_results\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m     fold_model, pred_proba, time_start_fit, time_end_fit, predict_time, predict_1_time, predict_n_size, fit_num_cpus, fit_num_gpus = self.ray.get(finished)\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m     return fn(*args, **kwargs)\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\client_mode_hook.py\", line 103, in wrapper\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m     return func(*args, **kwargs)\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\worker.py\", line 2667, in get\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m     values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\worker.py\", line 864, in get_objects\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m     raise value.as_instanceof_cause()\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m ray.exceptions.RayTaskError(TypeError): \u001b[36mray::_ray_fit()\u001b[39m (pid=1352, ip=127.0.0.1)\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m   File \"python\\ray\\_raylet.pyx\", line 1889, in ray._raylet.execute_task\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m     fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m     out = self._fit(**kwargs)\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 201, in _fit\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m     train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m     dataset = self._process_train_data(\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m     self.processor = create_preprocessor(\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\utils\\data_preprocessor.py\", line 40, in create_preprocessor\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m     return ColumnTransformer(\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m Fitting model: WeightedEnsemble_L2 ... Training model for up to 360.00s of the 597.63s of remaining time.\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m \tEnsemble Weights: {'LightGBMXT_BAG_L1': 1.0}\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m \t1.0\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m \t0.02s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m \t0.0s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m Excluded models: ['RF', 'XT', 'KNN'] (Specified by `excluded_model_types`)\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m Fitting 90 L2 models, fit_strategy=\"sequential\" ...\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m Fitting model: LightGBMXT_BAG_L2 ... Training model for up to 597.59s of the 597.54s of remaining time.\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.92%)\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m \t1.0\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m \t1.1s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m \t0.05s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m Fitting model: LightGBM_BAG_L2 ... Training model for up to 593.17s of the 593.12s of remaining time.\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=1.28%)\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m \t1.0\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m \t1.14s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m \t0.05s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m Fitting model: CatBoost_BAG_L2 ... Training model for up to 588.46s of the 588.40s of remaining time.\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=2.58%)\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_ray_fit pid=13200)\u001b[0m \tRan out of time, early stopping on iteration 8269.\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m \t1.0\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m \t470.98s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m \t0.11s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m Fitting model: NeuralNetFastAI_BAG_L2 ... Training model for up to 113.86s of the 113.81s of remaining time.\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.10%)\n",
      "\u001b[36m(_ray_fit pid=13344)\u001b[0m No improvement since epoch 5: early stopping\n",
      "\u001b[36m(_ray_fit pid=13984)\u001b[0m \tRan out of time, early stopping on iteration 8303.\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m \t1.0\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m \t6.12s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m \t0.14s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m Fitting model: XGBoost_BAG_L2 ... Training model for up to 104.01s of the 103.95s of remaining time.\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=5.31%)\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m \t0.9996\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m \t1.85s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m \t0.06s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m Fitting model: NeuralNetTorch_BAG_L2 ... Training model for up to 97.46s of the 97.41s of remaining time.\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.04%)\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m \tWarning: Exception caused NeuralNetTorch_BAG_L2 to fail during training... Skipping this model.\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m \t\t\u001b[36mray::_ray_fit()\u001b[39m (pid=17512, ip=127.0.0.1)\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m   File \"python\\ray\\_raylet.pyx\", line 1889, in ray._raylet.execute_task\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m     fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m     out = self._fit(**kwargs)\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 201, in _fit\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m     train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m     dataset = self._process_train_data(\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m     self.processor = create_preprocessor(\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\utils\\data_preprocessor.py\", line 40, in create_preprocessor\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m     return ColumnTransformer(\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m Detailed Traceback:\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 2106, in _train_and_save\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m     model = self._train_single(**model_fit_kwargs)\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 1993, in _train_single\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m     model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m     out = self._fit(**kwargs)\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\stacker_ensemble_model.py\", line 270, in _fit\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m     return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\bagged_ensemble_model.py\", line 298, in _fit\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m     self._fit_folds(\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\bagged_ensemble_model.py\", line 724, in _fit_folds\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m     fold_fitting_strategy.after_all_folds_scheduled()\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 690, in after_all_folds_scheduled\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m     self._run_parallel(X, y, X_pseudo, y_pseudo, model_base_ref, time_limit_fold, head_node_id)\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 631, in _run_parallel\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m     self._process_fold_results(finished, unfinished, fold_ctx)\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 587, in _process_fold_results\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m     raise processed_exception\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 550, in _process_fold_results\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m     fold_model, pred_proba, time_start_fit, time_end_fit, predict_time, predict_1_time, predict_n_size, fit_num_cpus, fit_num_gpus = self.ray.get(finished)\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m     return fn(*args, **kwargs)\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\client_mode_hook.py\", line 103, in wrapper\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m     return func(*args, **kwargs)\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\worker.py\", line 2667, in get\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m     values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\worker.py\", line 864, in get_objects\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m     raise value.as_instanceof_cause()\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m ray.exceptions.RayTaskError(TypeError): \u001b[36mray::_ray_fit()\u001b[39m (pid=17512, ip=127.0.0.1)\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m   File \"python\\ray\\_raylet.pyx\", line 1889, in ray._raylet.execute_task\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m     fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m     out = self._fit(**kwargs)\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 201, in _fit\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m     train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m     dataset = self._process_train_data(\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m     self.processor = create_preprocessor(\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\utils\\data_preprocessor.py\", line 40, in create_preprocessor\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m     return ColumnTransformer(\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m Fitting model: LightGBMLarge_BAG_L2 ... Training model for up to 90.99s of the 90.94s of remaining time.\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=8.18%)\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m \t1.0\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m \t2.2s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m \t0.05s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m Fitting model: CatBoost_r177_BAG_L2 ... Training model for up to 85.43s of the 85.37s of remaining time.\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=6.70%)\n",
      "\u001b[36m(_ray_fit pid=11176)\u001b[0m \tRan out of time, early stopping on iteration 1358.\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m \t1.0\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m \t68.38s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m \t0.11s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m Fitting model: NeuralNetTorch_r79_BAG_L2 ... Training model for up to 13.32s of the 13.27s of remaining time.\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.13%)\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m \tWarning: Exception caused NeuralNetTorch_r79_BAG_L2 to fail during training... Skipping this model.\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m \t\t\u001b[36mray::_ray_fit()\u001b[39m (pid=7144, ip=127.0.0.1)\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m   File \"python\\ray\\_raylet.pyx\", line 1889, in ray._raylet.execute_task\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m     fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m     out = self._fit(**kwargs)\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 201, in _fit\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m     train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m     dataset = self._process_train_data(\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m     self.processor = create_preprocessor(\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\utils\\data_preprocessor.py\", line 40, in create_preprocessor\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m     return ColumnTransformer(\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m Detailed Traceback:\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 2106, in _train_and_save\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m     model = self._train_single(**model_fit_kwargs)\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 1993, in _train_single\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m     model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m     out = self._fit(**kwargs)\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\stacker_ensemble_model.py\", line 270, in _fit\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m     return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\bagged_ensemble_model.py\", line 298, in _fit\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m     self._fit_folds(\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\bagged_ensemble_model.py\", line 724, in _fit_folds\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m     fold_fitting_strategy.after_all_folds_scheduled()\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 690, in after_all_folds_scheduled\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m     self._run_parallel(X, y, X_pseudo, y_pseudo, model_base_ref, time_limit_fold, head_node_id)\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 631, in _run_parallel\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m     self._process_fold_results(finished, unfinished, fold_ctx)\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 587, in _process_fold_results\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m     raise processed_exception\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 550, in _process_fold_results\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m     fold_model, pred_proba, time_start_fit, time_end_fit, predict_time, predict_1_time, predict_n_size, fit_num_cpus, fit_num_gpus = self.ray.get(finished)\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m     return fn(*args, **kwargs)\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\client_mode_hook.py\", line 103, in wrapper\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m     return func(*args, **kwargs)\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\worker.py\", line 2667, in get\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m     values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\worker.py\", line 864, in get_objects\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m     raise value.as_instanceof_cause()\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m ray.exceptions.RayTaskError(TypeError): \u001b[36mray::_ray_fit()\u001b[39m (pid=7144, ip=127.0.0.1)\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m   File \"python\\ray\\_raylet.pyx\", line 1889, in ray._raylet.execute_task\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m     fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m     out = self._fit(**kwargs)\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 201, in _fit\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m     train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m     dataset = self._process_train_data(\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m     self.processor = create_preprocessor(\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\utils\\data_preprocessor.py\", line 40, in create_preprocessor\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m     return ColumnTransformer(\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "\u001b[36m(_ray_fit pid=9724)\u001b[0m \tRan out of time, early stopping on iteration 1362.\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m Fitting model: WeightedEnsemble_L3 ... Training model for up to 360.00s of the 4.99s of remaining time.\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m \tEnsemble Weights: {'LightGBMXT_BAG_L1': 1.0}\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m \t1.0\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m \t0.04s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m \t0.0s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m AutoGluon training complete, total runtime = 1790.44s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 972.2 rows/s (43 batch size)\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m Automatically performing refit_full as a post-fit operation (due to `.fit(..., refit_full=True)`\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m Refitting models via `predictor.refit_full` using all of the data (combined train and validation)...\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m \tModels trained in this way will have the suffix \"_FULL\" and have NaN validation score.\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m \tThis process is not bound by time_limit, but should take less time than the original `predictor.fit` call.\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m \tTo learn more, refer to the `.refit_full` method docstring which explains how \"_FULL\" models differ from normal models.\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m Fitting model: LightGBMXT_BAG_L1_FULL ...\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): \u001b[36mray::_ray_fit()\u001b[39m (pid=22948, ip=127.0.0.1)\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m   File \"python\\ray\\_raylet.pyx\", line 1889, in ray._raylet.execute_task\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m     fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m     out = self._fit(**kwargs)\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 201, in _fit\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m     train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m     dataset = self._process_train_data(\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m     self.processor = create_preprocessor(\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\utils\\data_preprocessor.py\", line 40, in create_preprocessor\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m     return ColumnTransformer(\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m \t0.53s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m Fitting model: LightGBM_BAG_L1_FULL ...\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m \t0.16s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m Fitting model: CatBoost_BAG_L1_FULL ...\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m \t271.28s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m Fitting model: NeuralNetFastAI_BAG_L1_FULL ...\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m \tStopping at the best epoch learned earlier - 22.\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m \t1.06s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m Fitting model: XGBoost_BAG_L1_FULL ...\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m \t0.09s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m Fitting model: LightGBMLarge_BAG_L1_FULL ...\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m \t0.3s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m Fitting model: CatBoost_r177_BAG_L1_FULL ...\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m \t193.75s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m Fitting model: LightGBM_r131_BAG_L1_FULL ...\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m \t0.5s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m Fitting model: NeuralNetFastAI_r191_BAG_L1_FULL ...\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m \tStopping at the best epoch learned earlier - 22.\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m \t0.8s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m Fitting model: CatBoost_r9_BAG_L1_FULL ...\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m \t27.78s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m Fitting model: LightGBM_r96_BAG_L1_FULL ...\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m \t0.36s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m Fitting model: WeightedEnsemble_L2_FULL | Skipping fit via cloning parent ...\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m \tEnsemble Weights: {'LightGBMXT_BAG_L1': 1.0}\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m \t0.02s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m Fitting 1 L2 models, fit_strategy=\"sequential\" ...\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m Fitting model: LightGBMXT_BAG_L2_FULL ...\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m \t0.16s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m Fitting 1 L2 models, fit_strategy=\"sequential\" ...\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m Fitting model: LightGBM_BAG_L2_FULL ...\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m \t0.18s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m Fitting 1 L2 models, fit_strategy=\"sequential\" ...\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m Fitting model: CatBoost_BAG_L2_FULL ...\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m \t185.18s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m Fitting 1 L2 models, fit_strategy=\"sequential\" ...\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m Fitting model: NeuralNetFastAI_BAG_L2_FULL ...\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m \tStopping at the best epoch learned earlier - 24.\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m \t0.68s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m Fitting 1 L2 models, fit_strategy=\"sequential\" ...\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m Fitting model: XGBoost_BAG_L2_FULL ...\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m \t0.06s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m Fitting 1 L2 models, fit_strategy=\"sequential\" ...\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m Fitting model: LightGBMLarge_BAG_L2_FULL ...\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m \t0.61s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m Fitting 1 L2 models, fit_strategy=\"sequential\" ...\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m Fitting model: CatBoost_r177_BAG_L2_FULL ...\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m \t31.55s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m Fitting model: WeightedEnsemble_L3_FULL | Skipping fit via cloning parent ...\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m \tEnsemble Weights: {'LightGBMXT_BAG_L1': 1.0}\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m \t0.04s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m Updated best model to \"LightGBM_r96_BAG_L1_FULL\" (Previously \"WeightedEnsemble_L2\"). AutoGluon will default to using \"LightGBM_r96_BAG_L1_FULL\" for predict() and predict_proba().\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m Refit complete, total runtime = 717.8s ... Best model: \"LightGBM_r96_BAG_L1_FULL\"\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\autogluon\\tlp\\AutogluonModels\\synthetic\\tvaes\\v1\\ds_sub_fit\\sub_fit_ho\")\n",
      "\u001b[36m(_dystack pid=7812)\u001b[0m Deleting DyStack predictor artifacts (clean_up_fits=True) ...\n",
      "Leaderboard on holdout data (DyStack):\n",
      "                               model  score_holdout  score_val eval_metric  pred_time_test pred_time_val    fit_time  pred_time_test_marginal pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
      "0             LightGBMXT_BAG_L1_FULL       1.000000   1.000000     roc_auc        0.023190          None    0.525208                 0.023190                   None           0.525208            1       True          1\n",
      "1               LightGBM_BAG_L1_FULL       1.000000   1.000000     roc_auc        0.025656          None    0.161829                 0.025656                   None           0.161829            1       True          2\n",
      "2                XGBoost_BAG_L1_FULL       1.000000   1.000000     roc_auc        0.030973          None    0.089669                 0.030973                   None           0.089669            1       True          5\n",
      "3          LightGBMLarge_BAG_L1_FULL       1.000000   1.000000     roc_auc        0.032219          None    0.299499                 0.032219                   None           0.299499            1       True          6\n",
      "4            CatBoost_r9_BAG_L1_FULL       1.000000   1.000000     roc_auc        0.035194          None   27.775917                 0.035194                   None          27.775917            1       True         10\n",
      "5           WeightedEnsemble_L2_FULL       1.000000   1.000000     roc_auc        0.037417          None    0.548429                 0.014227                   None           0.023222            2       True         12\n",
      "6          LightGBM_r131_BAG_L1_FULL       1.000000   1.000000     roc_auc        0.039402          None    0.499241                 0.039402                   None           0.499241            1       True          8\n",
      "7           LightGBM_r96_BAG_L1_FULL       1.000000   1.000000     roc_auc        0.039407          None    0.364507                 0.039407                   None           0.364507            1       True         11\n",
      "8           WeightedEnsemble_L3_FULL       1.000000   1.000000     roc_auc        0.043064          None    0.563961                 0.019874                   None           0.038753            3       True         20\n",
      "9          CatBoost_r177_BAG_L1_FULL       1.000000   1.000000     roc_auc        0.045119          None  193.754097                 0.045119                   None         193.754097            1       True          7\n",
      "10              CatBoost_BAG_L1_FULL       1.000000   1.000000     roc_auc        0.050967          None  271.284984                 0.050967                   None         271.284984            1       True          3\n",
      "11         CatBoost_r177_BAG_L2_FULL       1.000000   1.000000     roc_auc        0.174680          None  304.507979                 0.021301                   None          31.548081            2       True         19\n",
      "12            LightGBMXT_BAG_L2_FULL       1.000000   1.000000     roc_auc        0.184817          None  273.122345                 0.031437                   None           0.162447            2       True         13\n",
      "13              LightGBM_BAG_L2_FULL       1.000000   1.000000     roc_auc        0.186616          None  273.138459                 0.033237                   None           0.178561            2       True         14\n",
      "14         LightGBMLarge_BAG_L2_FULL       1.000000   1.000000     roc_auc        0.190270          None  273.574668                 0.036890                   None           0.614770            2       True         18\n",
      "15              CatBoost_BAG_L2_FULL       1.000000   1.000000     roc_auc        0.199092          None  458.140095                 0.045713                   None         185.180197            2       True         15\n",
      "16               XGBoost_BAG_L2_FULL       0.977273   0.999635     roc_auc        0.197145          None  273.021027                 0.043765                   None           0.061129            2       True         17\n",
      "17  NeuralNetFastAI_r191_BAG_L1_FULL       0.963203   1.000000     roc_auc        0.042216          None    0.795713                 0.042216                   None           0.795713            1       True          9\n",
      "18       NeuralNetFastAI_BAG_L1_FULL       0.952381   1.000000     roc_auc        0.048249          None    1.060037                 0.048249                   None           1.060037            1       True          4\n",
      "19       NeuralNetFastAI_BAG_L2_FULL       0.952381   1.000000     roc_auc        0.182690          None  273.637012                 0.029310                   None           0.677114            2       True         16\n",
      "\t1\t = Optimal   num_stack_levels (Stacked Overfitting Occurred: False)\n",
      "\t2516s\t = DyStack   runtime |\t4684s\t = Remaining runtime\n",
      "Starting main fit with num_stack_levels=1.\n",
      "\tFor future fit calls on this dataset, you can skip DyStack to save time: `predictor.fit(..., dynamic_stacking=False, num_stack_levels=1)`\n",
      "Using predefined sample weighting strategy: balance_weight. Evaluation metrics will ignore sample weights, specify weight_evaluation=True to instead report weighted metrics.\n",
      "Beginning AutoGluon training ... Time limit = 4684s\n",
      "AutoGluon will save models to \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\autogluon\\tlp\\AutogluonModels\\synthetic\\tvaes\\v1\"\n",
      "Train Data Rows:    382\n",
      "Train Data Columns: 83\n",
      "Label Column:       ED_2Clases\n",
      "Problem Type:       binary\n",
      "Preprocessing data ...\n",
      "Selected class <--> label mapping:  class 1 = H, class 0 = D\n",
      "\tNote: For your binary classification, AutoGluon arbitrarily selected which label-value represents positive (H) vs negative (D) class.\n",
      "\tTo explicitly set the positive_class, either rename classes to 1 and 0, or specify positive_class in Predictor init.\n",
      "Assigning sample weights to balance differences in frequency of classes.\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    6235.17 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.36 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 9 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\t\tFitting DatetimeFeatureGenerator...\n",
      "\t\tFitting TextSpecialFeatureGenerator...\n",
      "\t\t\tFitting BinnedFeatureGenerator...\n",
      "\t\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\t\tFitting TextNgramFeatureGenerator...\n",
      "\t\t\tFitting CountVectorizer for text features: ['etiq-diagExpTLPtext', 'etiq-diagExpTLPtext_R2', 'clin-tipoAlcohol']\n",
      "\t\t\tCountVectorizer fit with vocabulary size = 17\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUseless Original Features (Count: 2): ['clin-Covid_sintomaSarpullido', 'ques-MMSE-fijacion-PD']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('bool', [])                       :  8 | ['clin-ansiedad', 'clin-depresion', 'clin-cardiopatiaIsquemica', 'clin-diabetes', 'clin-Hipercolesterolemia', ...]\n",
      "\t\t('float', [])                      : 19 | ['etiq-diagExpTLPcode', 'etiq-diagExpTLPcode_R2', 'clin-numCigarros', 'clin-añosSinFumar', 'ques-Sus-total-PD', ...]\n",
      "\t\t('int', [])                        : 48 | ['demo-genero', 'demo-edad', 'clin-reservaCognitiva_total', 'clin-reservaCognitiva_idiomas', 'clin-reservaCognitiva_ocupacion', ...]\n",
      "\t\t('object', [])                     :  1 | ['demo-rangoEdad']\n",
      "\t\t('object', ['datetime_as_object']) :  2 | ['demo-fechaEvaluacion', 'demo-fechaNacimiento']\n",
      "\t\t('object', ['text'])               :  3 | ['etiq-diagExpTLPtext', 'etiq-diagExpTLPtext_R2', 'clin-tipoAlcohol']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', [])                    :  1 | ['demo-rangoEdad']\n",
      "\t\t('category', ['text_as_category'])  :  3 | ['etiq-diagExpTLPtext', 'etiq-diagExpTLPtext_R2', 'clin-tipoAlcohol']\n",
      "\t\t('float', [])                       : 19 | ['etiq-diagExpTLPcode', 'etiq-diagExpTLPcode_R2', 'clin-numCigarros', 'clin-añosSinFumar', 'ques-Sus-total-PD', ...]\n",
      "\t\t('int', [])                         : 47 | ['demo-edad', 'clin-reservaCognitiva_total', 'clin-reservaCognitiva_idiomas', 'clin-reservaCognitiva_ocupacion', 'clin-reservaCognitiva_escolaridad', ...]\n",
      "\t\t('int', ['binned', 'text_special']) : 30 | ['etiq-diagExpTLPtext.char_count', 'etiq-diagExpTLPtext.word_count', 'etiq-diagExpTLPtext.capital_ratio', 'etiq-diagExpTLPtext.lower_ratio', 'etiq-diagExpTLPtext.special_ratio', ...]\n",
      "\t\t('int', ['bool'])                   :  9 | ['demo-genero', 'clin-ansiedad', 'clin-depresion', 'clin-cardiopatiaIsquemica', 'clin-diabetes', ...]\n",
      "\t\t('int', ['datetime_as_int'])        :  9 | ['demo-fechaEvaluacion', 'demo-fechaEvaluacion.month', 'demo-fechaEvaluacion.day', 'demo-fechaEvaluacion.dayofweek', 'demo-fechaNacimiento', ...]\n",
      "\t\t('int', ['text_ngram'])             : 11 | ['__nlp__.amnésico', '__nlp__.amnésico dc', '__nlp__.atencional', '__nlp__.atencional dc', '__nlp__.dc', ...]\n",
      "\t0.5s = Fit runtime\n",
      "\t81 features in original data used to generate 129 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.24 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.52s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'roc_auc'\n",
      "\tThis metric expects predicted probabilities rather than predicted class labels, so you'll need to use predict_proba() instead of predict()\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Large model count detected (112 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': [{}, {'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2}}, {'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7}}],\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\n",
      "\t'CAT': [{}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5}}],\n",
      "\t'XGB': [{}, {'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'name_suffix': '_r33', 'priority': -8}}, {'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'name_suffix': '_r89', 'priority': -16}}],\n",
      "\t'FASTAI': [{}, {'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4}}, {'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11}}],\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Excluded models: ['RF', 'KNN', 'XT'] (Specified by `excluded_model_types`)\n",
      "Fitting 90 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 3121.67s of the 4683.66s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.40%)\n",
      "\t1.0\t = Validation score   (roc_auc)\n",
      "\t1.07s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 3113.09s of the 4675.09s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.49%)\n",
      "\t1.0\t = Validation score   (roc_auc)\n",
      "\t1.8s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L1 ... Training model for up to 3108.48s of the 4670.48s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.94%)\n",
      "\t1.0\t = Validation score   (roc_auc)\n",
      "\t555.32s\t = Training   runtime\n",
      "\t0.09s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 2550.46s of the 4112.45s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.04%)\n",
      "\t0.997\t = Validation score   (roc_auc)\n",
      "\t6.33s\t = Training   runtime\n",
      "\t0.1s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L1 ... Training model for up to 2541.71s of the 4103.71s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=1.28%)\n",
      "\t1.0\t = Validation score   (roc_auc)\n",
      "\t2.22s\t = Training   runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_BAG_L1 ... Training model for up to 2536.30s of the 4098.30s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.03%)\n",
      "\tWarning: Exception caused NeuralNetTorch_BAG_L1 to fail during training... Skipping this model.\n",
      "\t\t\u001b[36mray::_ray_fit()\u001b[39m (pid=6976, ip=127.0.0.1)\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1889, in ray._raylet.execute_task\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 201, in _fit\n",
      "    train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "    dataset = self._process_train_data(\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "    self.processor = create_preprocessor(\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\utils\\data_preprocessor.py\", line 40, in create_preprocessor\n",
      "    return ColumnTransformer(\n",
      "TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 2106, in _train_and_save\n",
      "    model = self._train_single(**model_fit_kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 1993, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\stacker_ensemble_model.py\", line 270, in _fit\n",
      "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\bagged_ensemble_model.py\", line 298, in _fit\n",
      "    self._fit_folds(\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\bagged_ensemble_model.py\", line 724, in _fit_folds\n",
      "    fold_fitting_strategy.after_all_folds_scheduled()\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 690, in after_all_folds_scheduled\n",
      "    self._run_parallel(X, y, X_pseudo, y_pseudo, model_base_ref, time_limit_fold, head_node_id)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 631, in _run_parallel\n",
      "    self._process_fold_results(finished, unfinished, fold_ctx)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 587, in _process_fold_results\n",
      "    raise processed_exception\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 550, in _process_fold_results\n",
      "    fold_model, pred_proba, time_start_fit, time_end_fit, predict_time, predict_1_time, predict_n_size, fit_num_cpus, fit_num_gpus = self.ray.get(finished)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\worker.py\", line 2667, in get\n",
      "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\worker.py\", line 864, in get_objects\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(TypeError): \u001b[36mray::_ray_fit()\u001b[39m (pid=6976, ip=127.0.0.1)\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1889, in ray._raylet.execute_task\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 201, in _fit\n",
      "    train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "    dataset = self._process_train_data(\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "    self.processor = create_preprocessor(\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\utils\\data_preprocessor.py\", line 40, in create_preprocessor\n",
      "    return ColumnTransformer(\n",
      "TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "Fitting model: LightGBMLarge_BAG_L1 ... Training model for up to 2530.54s of the 4092.53s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=1.68%)\n",
      "2025-01-29 19:22:38,927\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-29 19:22:38,927\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-29 19:22:38,927\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-29 19:22:38,927\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-29 19:22:38,927\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-29 19:22:38,943\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-29 19:22:38,944\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\t1.0\t = Validation score   (roc_auc)\n",
      "\t2.54s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: CatBoost_r177_BAG_L1 ... Training model for up to 2525.42s of the 4087.41s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.92%)\n",
      "\t1.0\t = Validation score   (roc_auc)\n",
      "\t623.57s\t = Training   runtime\n",
      "\t0.09s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r79_BAG_L1 ... Training model for up to 1899.06s of the 3461.05s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.02%)\n",
      "\tWarning: Exception caused NeuralNetTorch_r79_BAG_L1 to fail during training... Skipping this model.\n",
      "\t\t\u001b[36mray::_ray_fit()\u001b[39m (pid=10588, ip=127.0.0.1)\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1889, in ray._raylet.execute_task\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 201, in _fit\n",
      "    train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "    dataset = self._process_train_data(\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "    self.processor = create_preprocessor(\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\utils\\data_preprocessor.py\", line 40, in create_preprocessor\n",
      "    return ColumnTransformer(\n",
      "TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 2106, in _train_and_save\n",
      "    model = self._train_single(**model_fit_kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 1993, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\stacker_ensemble_model.py\", line 270, in _fit\n",
      "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\bagged_ensemble_model.py\", line 298, in _fit\n",
      "    self._fit_folds(\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\bagged_ensemble_model.py\", line 724, in _fit_folds\n",
      "    fold_fitting_strategy.after_all_folds_scheduled()\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 690, in after_all_folds_scheduled\n",
      "    self._run_parallel(X, y, X_pseudo, y_pseudo, model_base_ref, time_limit_fold, head_node_id)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 631, in _run_parallel\n",
      "    self._process_fold_results(finished, unfinished, fold_ctx)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 587, in _process_fold_results\n",
      "    raise processed_exception\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 550, in _process_fold_results\n",
      "    fold_model, pred_proba, time_start_fit, time_end_fit, predict_time, predict_1_time, predict_n_size, fit_num_cpus, fit_num_gpus = self.ray.get(finished)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\worker.py\", line 2667, in get\n",
      "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\worker.py\", line 864, in get_objects\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(TypeError): \u001b[36mray::_ray_fit()\u001b[39m (pid=10588, ip=127.0.0.1)\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1889, in ray._raylet.execute_task\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 201, in _fit\n",
      "    train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "    dataset = self._process_train_data(\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "    self.processor = create_preprocessor(\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\utils\\data_preprocessor.py\", line 40, in create_preprocessor\n",
      "    return ColumnTransformer(\n",
      "TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "Fitting model: LightGBM_r131_BAG_L1 ... Training model for up to 1893.78s of the 3455.78s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.77%)\n",
      "2025-01-29 19:33:15,986\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-29 19:33:15,990\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-29 19:33:15,993\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-29 19:33:15,996\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-29 19:33:15,998\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-29 19:33:16,003\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-29 19:33:16,006\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\t1.0\t = Validation score   (roc_auc)\n",
      "\t3.47s\t = Training   runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r191_BAG_L1 ... Training model for up to 1887.58s of the 3449.57s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.05%)\n",
      "\t0.9999\t = Validation score   (roc_auc)\n",
      "\t7.51s\t = Training   runtime\n",
      "\t0.1s\t = Validation runtime\n",
      "Fitting model: CatBoost_r9_BAG_L1 ... Training model for up to 1877.38s of the 3439.37s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=5.15%)\n",
      "\t1.0\t = Validation score   (roc_auc)\n",
      "\t1505.4s\t = Training   runtime\n",
      "\t0.18s\t = Validation runtime\n",
      "Fitting model: LightGBM_r96_BAG_L1 ... Training model for up to 368.83s of the 1930.83s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.25%)\n",
      "\t1.0\t = Validation score   (roc_auc)\n",
      "\t4.92s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r22_BAG_L1 ... Training model for up to 361.18s of the 1923.18s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.02%)\n",
      "\tWarning: Exception caused NeuralNetTorch_r22_BAG_L1 to fail during training... Skipping this model.\n",
      "\t\t\u001b[36mray::_ray_fit()\u001b[39m (pid=10444, ip=127.0.0.1)\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1889, in ray._raylet.execute_task\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 201, in _fit\n",
      "    train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "    dataset = self._process_train_data(\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "    self.processor = create_preprocessor(\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\utils\\data_preprocessor.py\", line 40, in create_preprocessor\n",
      "    return ColumnTransformer(\n",
      "TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 2106, in _train_and_save\n",
      "    model = self._train_single(**model_fit_kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 1993, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\stacker_ensemble_model.py\", line 270, in _fit\n",
      "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\bagged_ensemble_model.py\", line 298, in _fit\n",
      "    self._fit_folds(\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\bagged_ensemble_model.py\", line 724, in _fit_folds\n",
      "    fold_fitting_strategy.after_all_folds_scheduled()\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 690, in after_all_folds_scheduled\n",
      "    self._run_parallel(X, y, X_pseudo, y_pseudo, model_base_ref, time_limit_fold, head_node_id)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 631, in _run_parallel\n",
      "    self._process_fold_results(finished, unfinished, fold_ctx)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 587, in _process_fold_results\n",
      "    raise processed_exception\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 550, in _process_fold_results\n",
      "    fold_model, pred_proba, time_start_fit, time_end_fit, predict_time, predict_1_time, predict_n_size, fit_num_cpus, fit_num_gpus = self.ray.get(finished)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\worker.py\", line 2667, in get\n",
      "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\worker.py\", line 864, in get_objects\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(TypeError): \u001b[36mray::_ray_fit()\u001b[39m (pid=10444, ip=127.0.0.1)\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1889, in ray._raylet.execute_task\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 201, in _fit\n",
      "    train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "    dataset = self._process_train_data(\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "    self.processor = create_preprocessor(\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\utils\\data_preprocessor.py\", line 40, in create_preprocessor\n",
      "    return ColumnTransformer(\n",
      "TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "Fitting model: XGBoost_r33_BAG_L1 ... Training model for up to 355.84s of the 1917.84s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=7.30%)\n",
      "2025-01-29 19:58:53,961\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-29 19:58:53,964\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-29 19:58:53,978\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-29 19:58:53,981\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-29 19:58:53,984\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-29 19:58:53,987\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-29 19:58:53,990\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\t1.0\t = Validation score   (roc_auc)\n",
      "\t3.26s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: CatBoost_r137_BAG_L1 ... Training model for up to 350.03s of the 1912.03s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.23%)\n",
      "\t1.0\t = Validation score   (roc_auc)\n",
      "\t281.17s\t = Training   runtime\n",
      "\t0.1s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r102_BAG_L1 ... Training model for up to 66.37s of the 1628.37s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.05%)\n",
      "\t0.9926\t = Validation score   (roc_auc)\n",
      "\t8.37s\t = Training   runtime\n",
      "\t0.11s\t = Validation runtime\n",
      "Fitting model: CatBoost_r13_BAG_L1 ... Training model for up to 55.15s of the 1617.15s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=5.07%)\n",
      "\t1.0\t = Validation score   (roc_auc)\n",
      "\t44.78s\t = Training   runtime\n",
      "\t0.09s\t = Validation runtime\n",
      "Fitting model: LightGBM_r188_BAG_L1 ... Training model for up to 7.19s of the 1569.19s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=1.90%)\n",
      "\t1.0\t = Validation score   (roc_auc)\n",
      "\t2.34s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r145_BAG_L1 ... Training model for up to 1.96s of the 1563.95s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.05%)\n",
      "\t0.9998\t = Validation score   (roc_auc)\n",
      "\t6.9s\t = Training   runtime\n",
      "\t0.09s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 360.00s of the 1553.98s of remaining time.\n",
      "\tEnsemble Weights: {'LightGBMXT_BAG_L1': 1.0}\n",
      "\t1.0\t = Validation score   (roc_auc)\n",
      "\t0.05s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Excluded models: ['RF', 'KNN', 'XT'] (Specified by `excluded_model_types`)\n",
      "Fitting 90 L2 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBMXT_BAG_L2 ... Training model for up to 1553.89s of the 1553.78s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.68%)\n",
      "\t1.0\t = Validation score   (roc_auc)\n",
      "\t1.94s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L2 ... Training model for up to 1549.05s of the 1548.94s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.54%)\n",
      "\t1.0\t = Validation score   (roc_auc)\n",
      "\t1.84s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L2 ... Training model for up to 1544.39s of the 1544.28s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=1.07%)\n",
      "\t1.0\t = Validation score   (roc_auc)\n",
      "\t543.06s\t = Training   runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L2 ... Training model for up to 998.53s of the 998.42s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.05%)\n",
      "\t0.9947\t = Validation score   (roc_auc)\n",
      "\t5.99s\t = Training   runtime\n",
      "\t0.09s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L2 ... Training model for up to 990.22s of the 990.10s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=1.52%)\n",
      "\t0.9997\t = Validation score   (roc_auc)\n",
      "\t2.12s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_BAG_L2 ... Training model for up to 984.82s of the 984.71s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.03%)\n",
      "\tWarning: Exception caused NeuralNetTorch_BAG_L2 to fail during training... Skipping this model.\n",
      "\t\t\u001b[36mray::_ray_fit()\u001b[39m (pid=12568, ip=127.0.0.1)\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1889, in ray._raylet.execute_task\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 201, in _fit\n",
      "    train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "    dataset = self._process_train_data(\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "    self.processor = create_preprocessor(\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\utils\\data_preprocessor.py\", line 40, in create_preprocessor\n",
      "    return ColumnTransformer(\n",
      "TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 2106, in _train_and_save\n",
      "    model = self._train_single(**model_fit_kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 1993, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\stacker_ensemble_model.py\", line 270, in _fit\n",
      "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\bagged_ensemble_model.py\", line 298, in _fit\n",
      "    self._fit_folds(\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\bagged_ensemble_model.py\", line 724, in _fit_folds\n",
      "    fold_fitting_strategy.after_all_folds_scheduled()\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 690, in after_all_folds_scheduled\n",
      "    self._run_parallel(X, y, X_pseudo, y_pseudo, model_base_ref, time_limit_fold, head_node_id)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 631, in _run_parallel\n",
      "    self._process_fold_results(finished, unfinished, fold_ctx)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 587, in _process_fold_results\n",
      "    raise processed_exception\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 550, in _process_fold_results\n",
      "    fold_model, pred_proba, time_start_fit, time_end_fit, predict_time, predict_1_time, predict_n_size, fit_num_cpus, fit_num_gpus = self.ray.get(finished)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\worker.py\", line 2667, in get\n",
      "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\worker.py\", line 864, in get_objects\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(TypeError): \u001b[36mray::_ray_fit()\u001b[39m (pid=12568, ip=127.0.0.1)\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1889, in ray._raylet.execute_task\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 201, in _fit\n",
      "    train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "    dataset = self._process_train_data(\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "    self.processor = create_preprocessor(\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\utils\\data_preprocessor.py\", line 40, in create_preprocessor\n",
      "    return ColumnTransformer(\n",
      "TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "Fitting model: LightGBMLarge_BAG_L2 ... Training model for up to 979.30s of the 979.19s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=2.37%)\n",
      "\t1.0\t = Validation score   (roc_auc)\n",
      "\t2.53s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: CatBoost_r177_BAG_L2 ... Training model for up to 974.21s of the 974.09s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=1.18%)\n",
      "2025-01-29 20:14:33,006\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-29 20:14:33,010\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-29 20:14:33,013\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-29 20:14:33,016\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-29 20:14:33,019\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-29 20:21:32,668\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-29 20:21:32,672\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\t1.0\t = Validation score   (roc_auc)\n",
      "\t546.23s\t = Training   runtime\n",
      "\t0.09s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r79_BAG_L2 ... Training model for up to 425.16s of the 425.04s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.03%)\n",
      "\tWarning: Exception caused NeuralNetTorch_r79_BAG_L2 to fail during training... Skipping this model.\n",
      "\t\t\u001b[36mray::_ray_fit()\u001b[39m (pid=7032, ip=127.0.0.1)\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1889, in ray._raylet.execute_task\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 201, in _fit\n",
      "    train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "    dataset = self._process_train_data(\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "    self.processor = create_preprocessor(\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\utils\\data_preprocessor.py\", line 40, in create_preprocessor\n",
      "    return ColumnTransformer(\n",
      "TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 2106, in _train_and_save\n",
      "    model = self._train_single(**model_fit_kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 1993, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\stacker_ensemble_model.py\", line 270, in _fit\n",
      "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\bagged_ensemble_model.py\", line 298, in _fit\n",
      "    self._fit_folds(\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\bagged_ensemble_model.py\", line 724, in _fit_folds\n",
      "    fold_fitting_strategy.after_all_folds_scheduled()\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 690, in after_all_folds_scheduled\n",
      "    self._run_parallel(X, y, X_pseudo, y_pseudo, model_base_ref, time_limit_fold, head_node_id)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 631, in _run_parallel\n",
      "    self._process_fold_results(finished, unfinished, fold_ctx)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 587, in _process_fold_results\n",
      "    raise processed_exception\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 550, in _process_fold_results\n",
      "    fold_model, pred_proba, time_start_fit, time_end_fit, predict_time, predict_1_time, predict_n_size, fit_num_cpus, fit_num_gpus = self.ray.get(finished)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\worker.py\", line 2667, in get\n",
      "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\worker.py\", line 864, in get_objects\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(TypeError): \u001b[36mray::_ray_fit()\u001b[39m (pid=7032, ip=127.0.0.1)\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1889, in ray._raylet.execute_task\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 201, in _fit\n",
      "    train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "    dataset = self._process_train_data(\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "    self.processor = create_preprocessor(\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\utils\\data_preprocessor.py\", line 40, in create_preprocessor\n",
      "    return ColumnTransformer(\n",
      "TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "Fitting model: LightGBM_r131_BAG_L2 ... Training model for up to 419.84s of the 419.72s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=1.13%)\n",
      "2025-01-29 20:23:52,049\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-29 20:23:52,052\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-29 20:23:52,055\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-29 20:23:52,060\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-29 20:23:52,063\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\t1.0\t = Validation score   (roc_auc)\n",
      "\t3.07s\t = Training   runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r191_BAG_L2 ... Training model for up to 414.34s of the 414.23s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.07%)\n",
      "\t0.9999\t = Validation score   (roc_auc)\n",
      "\t7.41s\t = Training   runtime\n",
      "\t0.12s\t = Validation runtime\n",
      "Fitting model: CatBoost_r9_BAG_L2 ... Training model for up to 404.11s of the 404.00s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=8.96%)\n",
      "\t1.0\t = Validation score   (roc_auc)\n",
      "\t324.39s\t = Training   runtime\n",
      "\t0.11s\t = Validation runtime\n",
      "Fitting model: LightGBM_r96_BAG_L2 ... Training model for up to 76.51s of the 76.40s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.38%)\n",
      "\t1.0\t = Validation score   (roc_auc)\n",
      "\t3.45s\t = Training   runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r22_BAG_L2 ... Training model for up to 70.00s of the 69.88s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.03%)\n",
      "\tWarning: Exception caused NeuralNetTorch_r22_BAG_L2 to fail during training... Skipping this model.\n",
      "\t\t\u001b[36mray::_ray_fit()\u001b[39m (pid=23516, ip=127.0.0.1)\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1889, in ray._raylet.execute_task\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 201, in _fit\n",
      "    train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "    dataset = self._process_train_data(\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "    self.processor = create_preprocessor(\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\utils\\data_preprocessor.py\", line 40, in create_preprocessor\n",
      "    return ColumnTransformer(\n",
      "TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 2106, in _train_and_save\n",
      "    model = self._train_single(**model_fit_kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 1993, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\stacker_ensemble_model.py\", line 270, in _fit\n",
      "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\bagged_ensemble_model.py\", line 298, in _fit\n",
      "    self._fit_folds(\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\bagged_ensemble_model.py\", line 724, in _fit_folds\n",
      "    fold_fitting_strategy.after_all_folds_scheduled()\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 690, in after_all_folds_scheduled\n",
      "    self._run_parallel(X, y, X_pseudo, y_pseudo, model_base_ref, time_limit_fold, head_node_id)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 631, in _run_parallel\n",
      "    self._process_fold_results(finished, unfinished, fold_ctx)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 587, in _process_fold_results\n",
      "    raise processed_exception\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 550, in _process_fold_results\n",
      "    fold_model, pred_proba, time_start_fit, time_end_fit, predict_time, predict_1_time, predict_n_size, fit_num_cpus, fit_num_gpus = self.ray.get(finished)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\worker.py\", line 2667, in get\n",
      "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\worker.py\", line 864, in get_objects\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(TypeError): \u001b[36mray::_ray_fit()\u001b[39m (pid=23516, ip=127.0.0.1)\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1889, in ray._raylet.execute_task\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 201, in _fit\n",
      "    train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "    dataset = self._process_train_data(\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "    self.processor = create_preprocessor(\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\utils\\data_preprocessor.py\", line 40, in create_preprocessor\n",
      "    return ColumnTransformer(\n",
      "TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "Fitting model: XGBoost_r33_BAG_L2 ... Training model for up to 64.54s of the 64.43s of remaining time.\n",
      "\tMemory not enough to fit 8 folds in parallel. Will train 4 folds in parallel instead (Estimated 11.12% memory usage per fold, 44.50%/80.00% total).\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=3, gpus=0, memory=11.12%)\n",
      "2025-01-29 20:29:47,104\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-29 20:29:47,107\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-29 20:29:47,111\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-29 20:29:47,114\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-29 20:29:47,117\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\t1.0\t = Validation score   (roc_auc)\n",
      "\t5.56s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: CatBoost_r137_BAG_L2 ... Training model for up to 57.14s of the 57.03s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.37%)\n",
      "\t1.0\t = Validation score   (roc_auc)\n",
      "\t45.65s\t = Training   runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ... Training model for up to 360.00s of the 7.73s of remaining time.\n",
      "\tEnsemble Weights: {'LightGBMXT_BAG_L1': 1.0}\n",
      "\t1.0\t = Validation score   (roc_auc)\n",
      "\t0.03s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 4676.52s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 910.9 rows/s (48 batch size)\n",
      "Automatically performing refit_full as a post-fit operation (due to `.fit(..., refit_full=True)`\n",
      "Refitting models via `predictor.refit_full` using all of the data (combined train and validation)...\n",
      "\tModels trained in this way will have the suffix \"_FULL\" and have NaN validation score.\n",
      "\tThis process is not bound by time_limit, but should take less time than the original `predictor.fit` call.\n",
      "\tTo learn more, refer to the `.refit_full` method docstring which explains how \"_FULL\" models differ from normal models.\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBMXT_BAG_L1_FULL ...\n",
      "\t0.41s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBM_BAG_L1_FULL ...\n",
      "\t0.19s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: CatBoost_BAG_L1_FULL ...\n",
      "2025-01-29 20:30:46,540\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-29 20:30:46,542\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\t211.04s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: NeuralNetFastAI_BAG_L1_FULL ...\n",
      "\tStopping at the best epoch learned earlier - 19.\n",
      "\t0.68s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: XGBoost_BAG_L1_FULL ...\n",
      "\t0.09s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBMLarge_BAG_L1_FULL ...\n",
      "\t0.29s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: CatBoost_r177_BAG_L1_FULL ...\n",
      "2025-01-29 20:36:41,814\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-29 20:36:41,816\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\t286.62s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBM_r131_BAG_L1_FULL ...\n",
      "\t0.51s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: NeuralNetFastAI_r191_BAG_L1_FULL ...\n",
      "\tStopping at the best epoch learned earlier - 17.\n",
      "\t0.67s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: CatBoost_r9_BAG_L1_FULL ...\n",
      "\t558.33s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBM_r96_BAG_L1_FULL ...\n",
      "\t0.36s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: XGBoost_r33_BAG_L1_FULL ...\n",
      "\t0.24s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: CatBoost_r137_BAG_L1_FULL ...\n",
      "\t122.48s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: NeuralNetFastAI_r102_BAG_L1_FULL ...\n",
      "\tStopping at the best epoch learned earlier - 8.\n",
      "\t1.16s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: CatBoost_r13_BAG_L1_FULL ...\n",
      "\t18.16s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBM_r188_BAG_L1_FULL ...\n",
      "\t0.32s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: NeuralNetFastAI_r145_BAG_L1_FULL ...\n",
      "\tStopping at the best epoch learned earlier - 12.\n",
      "\t0.65s\t = Training   runtime\n",
      "Fitting model: WeightedEnsemble_L2_FULL | Skipping fit via cloning parent ...\n",
      "\tEnsemble Weights: {'LightGBMXT_BAG_L1': 1.0}\n",
      "\t0.05s\t = Training   runtime\n",
      "Fitting 1 L2 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBMXT_BAG_L2_FULL ...\n",
      "\t0.19s\t = Training   runtime\n",
      "Fitting 1 L2 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBM_BAG_L2_FULL ...\n",
      "\t0.15s\t = Training   runtime\n",
      "Fitting 1 L2 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: CatBoost_BAG_L2_FULL ...\n",
      "\t157.4s\t = Training   runtime\n",
      "Fitting 1 L2 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: NeuralNetFastAI_BAG_L2_FULL ...\n",
      "\tStopping at the best epoch learned earlier - 20.\n",
      "\t0.61s\t = Training   runtime\n",
      "Fitting 1 L2 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: XGBoost_BAG_L2_FULL ...\n",
      "\t0.06s\t = Training   runtime\n",
      "Fitting 1 L2 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBMLarge_BAG_L2_FULL ...\n",
      "\t0.38s\t = Training   runtime\n",
      "Fitting 1 L2 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: CatBoost_r177_BAG_L2_FULL ...\n",
      "\t192.51s\t = Training   runtime\n",
      "Fitting 1 L2 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBM_r131_BAG_L2_FULL ...\n",
      "\t0.49s\t = Training   runtime\n",
      "Fitting 1 L2 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: NeuralNetFastAI_r191_BAG_L2_FULL ...\n",
      "\tStopping at the best epoch learned earlier - 18.\n",
      "\t0.68s\t = Training   runtime\n",
      "Fitting 1 L2 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: CatBoost_r9_BAG_L2_FULL ...\n",
      "\t122.52s\t = Training   runtime\n",
      "Fitting 1 L2 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBM_r96_BAG_L2_FULL ...\n",
      "\t0.32s\t = Training   runtime\n",
      "Fitting 1 L2 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: XGBoost_r33_BAG_L2_FULL ...\n",
      "\t0.13s\t = Training   runtime\n",
      "Fitting 1 L2 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: CatBoost_r137_BAG_L2_FULL ...\n",
      "\t13.97s\t = Training   runtime\n",
      "Fitting model: WeightedEnsemble_L3_FULL | Skipping fit via cloning parent ...\n",
      "\tEnsemble Weights: {'LightGBMXT_BAG_L1': 1.0}\n",
      "\t0.03s\t = Training   runtime\n",
      "Updated best model to \"LightGBM_BAG_L1_FULL\" (Previously \"WeightedEnsemble_L2\"). AutoGluon will default to using \"LightGBM_BAG_L1_FULL\" for predict() and predict_proba().\n",
      "Refit complete, total runtime = 1695.69s ... Best model: \"LightGBM_BAG_L1_FULL\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\autogluon\\tlp\\AutogluonModels\\synthetic\\tvaes\\v1\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<autogluon.tabular.predictor.predictor.TabularPredictor at 0x1ec7b0d2ef0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.fit(\n",
    "    train_data = df_train,\n",
    "    presets = ['high_quality'],\n",
    "    time_limit = 2 * 3600,\n",
    "    auto_stack = True,\n",
    "    excluded_model_types=['KNN','RF','XT', 'LR'],\n",
    "    verbosity = 2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Summary of fit() ***\n",
      "Estimated performance of each model:\n",
      "                               model  score_val eval_metric  pred_time_val     fit_time  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
      "0                    LightGBM_BAG_L1   1.000000     roc_auc       0.029233     1.798387                0.029233           1.798387            1      False          2\n",
      "1                WeightedEnsemble_L3   1.000000     roc_auc       0.052571     1.097105                0.000000           0.027211            3      False         32\n",
      "2                  LightGBMXT_BAG_L1   1.000000     roc_auc       0.052571     1.069894                0.052571           1.069894            1      False          1\n",
      "3                LightGBM_r96_BAG_L1   1.000000     roc_auc       0.053207     4.919226                0.053207           4.919226            1      False         11\n",
      "4                WeightedEnsemble_L2   1.000000     roc_auc       0.053573     1.118017                0.001002           0.048123            2      False         18\n",
      "5               LightGBM_r188_BAG_L1   1.000000     roc_auc       0.055348     2.341816                0.055348           2.341816            1      False         16\n",
      "6                 XGBoost_r33_BAG_L1   1.000000     roc_auc       0.055805     3.255008                0.055805           3.255008            1      False         12\n",
      "7               LightGBMLarge_BAG_L1   1.000000     roc_auc       0.059453     2.543848                0.059453           2.543848            1      False          6\n",
      "8               LightGBM_r131_BAG_L1   1.000000     roc_auc       0.068793     3.469293                0.068793           3.469293            1      False          8\n",
      "9                     XGBoost_BAG_L1   1.000000     roc_auc       0.071305     2.223928                0.071305           2.223928            1      False          5\n",
      "10                   CatBoost_BAG_L1   1.000000     roc_auc       0.089320   555.322087                0.089320         555.322087            1      False          3\n",
      "11              CatBoost_r177_BAG_L1   1.000000     roc_auc       0.089691   623.568069                0.089691         623.568069            1      False          7\n",
      "12               CatBoost_r13_BAG_L1   1.000000     roc_auc       0.091895    44.783701                0.091895          44.783701            1      False         15\n",
      "13              CatBoost_r137_BAG_L1   1.000000     roc_auc       0.095549   281.167299                0.095549         281.167299            1      False         13\n",
      "14                CatBoost_r9_BAG_L1   1.000000     roc_auc       0.175981  1505.401868                0.175981        1505.401868            1      False         10\n",
      "15                   LightGBM_BAG_L2   1.000000     roc_auc       0.351454   567.962930                0.039569           1.841838            2      False         20\n",
      "16                 LightGBMXT_BAG_L2   1.000000     roc_auc       0.358020   568.061553                0.046134           1.940461            2      False         19\n",
      "17              LightGBMLarge_BAG_L2   1.000000     roc_auc       0.365995   568.654549                0.054110           2.533457            2      False         24\n",
      "18                XGBoost_r33_BAG_L2   1.000000     roc_auc       0.368300   571.681631                0.056414           5.560539            2      False         30\n",
      "19              LightGBM_r131_BAG_L2   1.000000     roc_auc       0.379672   569.194442                0.067786           3.073350            2      False         26\n",
      "20               LightGBM_r96_BAG_L2   1.000000     roc_auc       0.380193   569.572296                0.068307           3.451204            2      False         29\n",
      "21              CatBoost_r137_BAG_L2   1.000000     roc_auc       0.385474   611.773456                0.073588          45.652364            2      False         31\n",
      "22                   CatBoost_BAG_L2   1.000000     roc_auc       0.392435  1109.180971                0.080549         543.059879            2      False         21\n",
      "23              CatBoost_r177_BAG_L2   1.000000     roc_auc       0.400044  1112.352317                0.088158         546.231225            2      False         25\n",
      "24                CatBoost_r9_BAG_L2   1.000000     roc_auc       0.423272   890.512027                0.111386         324.390935            2      False         28\n",
      "25       NeuralNetFastAI_r191_BAG_L1   0.999945     roc_auc       0.098690     7.505183                0.098690           7.505183            1      False          9\n",
      "26       NeuralNetFastAI_r191_BAG_L2   0.999890     roc_auc       0.433616   573.531560                0.121730           7.410468            2      False         27\n",
      "27       NeuralNetFastAI_r145_BAG_L1   0.999808     roc_auc       0.085709     6.895908                0.085709           6.895908            1      False         17\n",
      "28                    XGBoost_BAG_L2   0.999685     roc_auc       0.363952   568.242771                0.052066           2.121679            2      False         23\n",
      "29            NeuralNetFastAI_BAG_L1   0.997012     roc_auc       0.102542     6.330047                0.102542           6.330047            1      False          4\n",
      "30            NeuralNetFastAI_BAG_L2   0.994709     roc_auc       0.399824   572.115461                0.087938           5.994369            2      False         22\n",
      "31       NeuralNetFastAI_r102_BAG_L1   0.992626     roc_auc       0.105563     8.373437                0.105563           8.373437            1      False         14\n",
      "32           XGBoost_r33_BAG_L2_FULL        NaN     roc_auc            NaN   212.333422                     NaN           0.131471            2       True         62\n",
      "33           XGBoost_r33_BAG_L1_FULL        NaN     roc_auc            NaN     0.239535                     NaN           0.239535            1       True         44\n",
      "34               XGBoost_BAG_L2_FULL        NaN     roc_auc            NaN   212.263283                     NaN           0.061332            2       True         55\n",
      "35               XGBoost_BAG_L1_FULL        NaN     roc_auc            NaN     0.086179                     NaN           0.086179            1       True         37\n",
      "36          WeightedEnsemble_L3_FULL        NaN     roc_auc            NaN     0.433497                     NaN           0.027211            3       True         64\n",
      "37          WeightedEnsemble_L2_FULL        NaN     roc_auc            NaN     0.454410                     NaN           0.048123            2       True         50\n",
      "38  NeuralNetFastAI_r191_BAG_L2_FULL        NaN     roc_auc            NaN   212.881431                     NaN           0.679480            2       True         59\n",
      "39  NeuralNetFastAI_r191_BAG_L1_FULL        NaN     roc_auc            NaN     0.672307                     NaN           0.672307            1       True         41\n",
      "40  NeuralNetFastAI_r145_BAG_L1_FULL        NaN     roc_auc            NaN     0.650921                     NaN           0.650921            1       True         49\n",
      "41  NeuralNetFastAI_r102_BAG_L1_FULL        NaN     roc_auc            NaN     1.160682                     NaN           1.160682            1       True         46\n",
      "42       NeuralNetFastAI_BAG_L2_FULL        NaN     roc_auc            NaN   212.807018                     NaN           0.605067            2       True         54\n",
      "43       NeuralNetFastAI_BAG_L1_FULL        NaN     roc_auc            NaN     0.676754                     NaN           0.676754            1       True         36\n",
      "44          LightGBM_r96_BAG_L2_FULL        NaN     roc_auc            NaN   212.526585                     NaN           0.324634            2       True         61\n",
      "45          LightGBM_r96_BAG_L1_FULL        NaN     roc_auc            NaN     0.362663                     NaN           0.362663            1       True         43\n",
      "46         LightGBM_r188_BAG_L1_FULL        NaN     roc_auc            NaN     0.317057                     NaN           0.317057            1       True         48\n",
      "47         LightGBM_r131_BAG_L2_FULL        NaN     roc_auc            NaN   212.694545                     NaN           0.492594            2       True         58\n",
      "48         LightGBM_r131_BAG_L1_FULL        NaN     roc_auc            NaN     0.510390                     NaN           0.510390            1       True         40\n",
      "49              LightGBM_BAG_L2_FULL        NaN     roc_auc            NaN   212.349244                     NaN           0.147293            2       True         52\n",
      "50              LightGBM_BAG_L1_FULL        NaN     roc_auc            NaN     0.188587                     NaN           0.188587            1       True         34\n",
      "51            LightGBMXT_BAG_L2_FULL        NaN     roc_auc            NaN   212.388138                     NaN           0.186187            2       True         51\n",
      "52            LightGBMXT_BAG_L1_FULL        NaN     roc_auc            NaN     0.406286                     NaN           0.406286            1       True         33\n",
      "53         LightGBMLarge_BAG_L2_FULL        NaN     roc_auc            NaN   212.582219                     NaN           0.380269            2       True         56\n",
      "54         LightGBMLarge_BAG_L1_FULL        NaN     roc_auc            NaN     0.288805                     NaN           0.288805            1       True         38\n",
      "55           CatBoost_r9_BAG_L2_FULL        NaN     roc_auc            NaN   334.718309                     NaN         122.516358            2       True         60\n",
      "56           CatBoost_r9_BAG_L1_FULL        NaN     roc_auc            NaN   558.328223                     NaN         558.328223            1       True         42\n",
      "57         CatBoost_r177_BAG_L2_FULL        NaN     roc_auc            NaN   404.712420                     NaN         192.510470            2       True         57\n",
      "58         CatBoost_r177_BAG_L1_FULL        NaN     roc_auc            NaN   286.619542                     NaN         286.619542            1       True         39\n",
      "59          CatBoost_r13_BAG_L1_FULL        NaN     roc_auc            NaN    18.156106                     NaN          18.156106            1       True         47\n",
      "60         CatBoost_r137_BAG_L2_FULL        NaN     roc_auc            NaN   226.167875                     NaN          13.965925            2       True         63\n",
      "61         CatBoost_r137_BAG_L1_FULL        NaN     roc_auc            NaN   122.484934                     NaN         122.484934            1       True         45\n",
      "62              CatBoost_BAG_L2_FULL        NaN     roc_auc            NaN   369.598421                     NaN         157.396470            2       True         53\n",
      "63              CatBoost_BAG_L1_FULL        NaN     roc_auc            NaN   211.037178                     NaN         211.037178            1       True         35\n",
      "Number of models trained: 64\n",
      "Types of models trained:\n",
      "{'StackerEnsembleModel_LGB', 'StackerEnsembleModel_NNFastAiTabular', 'StackerEnsembleModel_CatBoost', 'StackerEnsembleModel_XGBoost', 'WeightedEnsembleModel'}\n",
      "Bagging used: True  (with 8 folds)\n",
      "Multi-layer stack-ensembling used: True  (with 3 levels)\n",
      "Feature Metadata (Processed):\n",
      "(raw dtype, special dtypes):\n",
      "('category', [])                    :  1 | ['demo-rangoEdad']\n",
      "('category', ['text_as_category'])  :  3 | ['etiq-diagExpTLPtext', 'etiq-diagExpTLPtext_R2', 'clin-tipoAlcohol']\n",
      "('float', [])                       : 19 | ['etiq-diagExpTLPcode', 'etiq-diagExpTLPcode_R2', 'clin-numCigarros', 'clin-añosSinFumar', 'ques-Sus-total-PD', ...]\n",
      "('int', [])                         : 47 | ['demo-edad', 'clin-reservaCognitiva_total', 'clin-reservaCognitiva_idiomas', 'clin-reservaCognitiva_ocupacion', 'clin-reservaCognitiva_escolaridad', ...]\n",
      "('int', ['binned', 'text_special']) : 30 | ['etiq-diagExpTLPtext.char_count', 'etiq-diagExpTLPtext.word_count', 'etiq-diagExpTLPtext.capital_ratio', 'etiq-diagExpTLPtext.lower_ratio', 'etiq-diagExpTLPtext.special_ratio', ...]\n",
      "('int', ['bool'])                   :  9 | ['demo-genero', 'clin-ansiedad', 'clin-depresion', 'clin-cardiopatiaIsquemica', 'clin-diabetes', ...]\n",
      "('int', ['datetime_as_int'])        :  9 | ['demo-fechaEvaluacion', 'demo-fechaEvaluacion.month', 'demo-fechaEvaluacion.day', 'demo-fechaEvaluacion.dayofweek', 'demo-fechaNacimiento', ...]\n",
      "('int', ['text_ngram'])             : 11 | ['__nlp__.amnésico', '__nlp__.amnésico dc', '__nlp__.atencional', '__nlp__.atencional dc', '__nlp__.dc', ...]\n",
      "Plot summary of models saved to file: c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\autogluon\\tlp\\AutogluonModels\\synthetic\\tvaes\\v1SummaryOfModels.html\n",
      "*** End of fit() summary ***\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'model_types': {'LightGBMXT_BAG_L1': 'StackerEnsembleModel_LGB',\n",
       "  'LightGBM_BAG_L1': 'StackerEnsembleModel_LGB',\n",
       "  'CatBoost_BAG_L1': 'StackerEnsembleModel_CatBoost',\n",
       "  'NeuralNetFastAI_BAG_L1': 'StackerEnsembleModel_NNFastAiTabular',\n",
       "  'XGBoost_BAG_L1': 'StackerEnsembleModel_XGBoost',\n",
       "  'LightGBMLarge_BAG_L1': 'StackerEnsembleModel_LGB',\n",
       "  'CatBoost_r177_BAG_L1': 'StackerEnsembleModel_CatBoost',\n",
       "  'LightGBM_r131_BAG_L1': 'StackerEnsembleModel_LGB',\n",
       "  'NeuralNetFastAI_r191_BAG_L1': 'StackerEnsembleModel_NNFastAiTabular',\n",
       "  'CatBoost_r9_BAG_L1': 'StackerEnsembleModel_CatBoost',\n",
       "  'LightGBM_r96_BAG_L1': 'StackerEnsembleModel_LGB',\n",
       "  'XGBoost_r33_BAG_L1': 'StackerEnsembleModel_XGBoost',\n",
       "  'CatBoost_r137_BAG_L1': 'StackerEnsembleModel_CatBoost',\n",
       "  'NeuralNetFastAI_r102_BAG_L1': 'StackerEnsembleModel_NNFastAiTabular',\n",
       "  'CatBoost_r13_BAG_L1': 'StackerEnsembleModel_CatBoost',\n",
       "  'LightGBM_r188_BAG_L1': 'StackerEnsembleModel_LGB',\n",
       "  'NeuralNetFastAI_r145_BAG_L1': 'StackerEnsembleModel_NNFastAiTabular',\n",
       "  'WeightedEnsemble_L2': 'WeightedEnsembleModel',\n",
       "  'LightGBMXT_BAG_L2': 'StackerEnsembleModel_LGB',\n",
       "  'LightGBM_BAG_L2': 'StackerEnsembleModel_LGB',\n",
       "  'CatBoost_BAG_L2': 'StackerEnsembleModel_CatBoost',\n",
       "  'NeuralNetFastAI_BAG_L2': 'StackerEnsembleModel_NNFastAiTabular',\n",
       "  'XGBoost_BAG_L2': 'StackerEnsembleModel_XGBoost',\n",
       "  'LightGBMLarge_BAG_L2': 'StackerEnsembleModel_LGB',\n",
       "  'CatBoost_r177_BAG_L2': 'StackerEnsembleModel_CatBoost',\n",
       "  'LightGBM_r131_BAG_L2': 'StackerEnsembleModel_LGB',\n",
       "  'NeuralNetFastAI_r191_BAG_L2': 'StackerEnsembleModel_NNFastAiTabular',\n",
       "  'CatBoost_r9_BAG_L2': 'StackerEnsembleModel_CatBoost',\n",
       "  'LightGBM_r96_BAG_L2': 'StackerEnsembleModel_LGB',\n",
       "  'XGBoost_r33_BAG_L2': 'StackerEnsembleModel_XGBoost',\n",
       "  'CatBoost_r137_BAG_L2': 'StackerEnsembleModel_CatBoost',\n",
       "  'WeightedEnsemble_L3': 'WeightedEnsembleModel',\n",
       "  'LightGBMXT_BAG_L1_FULL': 'StackerEnsembleModel_LGB',\n",
       "  'LightGBM_BAG_L1_FULL': 'StackerEnsembleModel_LGB',\n",
       "  'CatBoost_BAG_L1_FULL': 'StackerEnsembleModel_CatBoost',\n",
       "  'NeuralNetFastAI_BAG_L1_FULL': 'StackerEnsembleModel_NNFastAiTabular',\n",
       "  'XGBoost_BAG_L1_FULL': 'StackerEnsembleModel_XGBoost',\n",
       "  'LightGBMLarge_BAG_L1_FULL': 'StackerEnsembleModel_LGB',\n",
       "  'CatBoost_r177_BAG_L1_FULL': 'StackerEnsembleModel_CatBoost',\n",
       "  'LightGBM_r131_BAG_L1_FULL': 'StackerEnsembleModel_LGB',\n",
       "  'NeuralNetFastAI_r191_BAG_L1_FULL': 'StackerEnsembleModel_NNFastAiTabular',\n",
       "  'CatBoost_r9_BAG_L1_FULL': 'StackerEnsembleModel_CatBoost',\n",
       "  'LightGBM_r96_BAG_L1_FULL': 'StackerEnsembleModel_LGB',\n",
       "  'XGBoost_r33_BAG_L1_FULL': 'StackerEnsembleModel_XGBoost',\n",
       "  'CatBoost_r137_BAG_L1_FULL': 'StackerEnsembleModel_CatBoost',\n",
       "  'NeuralNetFastAI_r102_BAG_L1_FULL': 'StackerEnsembleModel_NNFastAiTabular',\n",
       "  'CatBoost_r13_BAG_L1_FULL': 'StackerEnsembleModel_CatBoost',\n",
       "  'LightGBM_r188_BAG_L1_FULL': 'StackerEnsembleModel_LGB',\n",
       "  'NeuralNetFastAI_r145_BAG_L1_FULL': 'StackerEnsembleModel_NNFastAiTabular',\n",
       "  'WeightedEnsemble_L2_FULL': 'WeightedEnsembleModel',\n",
       "  'LightGBMXT_BAG_L2_FULL': 'StackerEnsembleModel_LGB',\n",
       "  'LightGBM_BAG_L2_FULL': 'StackerEnsembleModel_LGB',\n",
       "  'CatBoost_BAG_L2_FULL': 'StackerEnsembleModel_CatBoost',\n",
       "  'NeuralNetFastAI_BAG_L2_FULL': 'StackerEnsembleModel_NNFastAiTabular',\n",
       "  'XGBoost_BAG_L2_FULL': 'StackerEnsembleModel_XGBoost',\n",
       "  'LightGBMLarge_BAG_L2_FULL': 'StackerEnsembleModel_LGB',\n",
       "  'CatBoost_r177_BAG_L2_FULL': 'StackerEnsembleModel_CatBoost',\n",
       "  'LightGBM_r131_BAG_L2_FULL': 'StackerEnsembleModel_LGB',\n",
       "  'NeuralNetFastAI_r191_BAG_L2_FULL': 'StackerEnsembleModel_NNFastAiTabular',\n",
       "  'CatBoost_r9_BAG_L2_FULL': 'StackerEnsembleModel_CatBoost',\n",
       "  'LightGBM_r96_BAG_L2_FULL': 'StackerEnsembleModel_LGB',\n",
       "  'XGBoost_r33_BAG_L2_FULL': 'StackerEnsembleModel_XGBoost',\n",
       "  'CatBoost_r137_BAG_L2_FULL': 'StackerEnsembleModel_CatBoost',\n",
       "  'WeightedEnsemble_L3_FULL': 'WeightedEnsembleModel'},\n",
       " 'model_performance': {'LightGBMXT_BAG_L1': 1.0,\n",
       "  'LightGBM_BAG_L1': 1.0,\n",
       "  'CatBoost_BAG_L1': 1.0,\n",
       "  'NeuralNetFastAI_BAG_L1': 0.9970120614035088,\n",
       "  'XGBoost_BAG_L1': 1.0,\n",
       "  'LightGBMLarge_BAG_L1': 1.0,\n",
       "  'CatBoost_r177_BAG_L1': 1.0,\n",
       "  'LightGBM_r131_BAG_L1': 1.0,\n",
       "  'NeuralNetFastAI_r191_BAG_L1': 0.9999451754385965,\n",
       "  'CatBoost_r9_BAG_L1': 1.0,\n",
       "  'LightGBM_r96_BAG_L1': 1.0,\n",
       "  'XGBoost_r33_BAG_L1': 1.0,\n",
       "  'CatBoost_r137_BAG_L1': 1.0,\n",
       "  'NeuralNetFastAI_r102_BAG_L1': 0.992626096491228,\n",
       "  'CatBoost_r13_BAG_L1': 1.0,\n",
       "  'LightGBM_r188_BAG_L1': 1.0,\n",
       "  'NeuralNetFastAI_r145_BAG_L1': 0.9998081140350878,\n",
       "  'WeightedEnsemble_L2': 1.0,\n",
       "  'LightGBMXT_BAG_L2': 1.0,\n",
       "  'LightGBM_BAG_L2': 1.0,\n",
       "  'CatBoost_BAG_L2': 1.0,\n",
       "  'NeuralNetFastAI_BAG_L2': 0.9947094298245613,\n",
       "  'XGBoost_BAG_L2': 0.9996847587719297,\n",
       "  'LightGBMLarge_BAG_L2': 1.0,\n",
       "  'CatBoost_r177_BAG_L2': 1.0,\n",
       "  'LightGBM_r131_BAG_L2': 1.0,\n",
       "  'NeuralNetFastAI_r191_BAG_L2': 0.999890350877193,\n",
       "  'CatBoost_r9_BAG_L2': 1.0,\n",
       "  'LightGBM_r96_BAG_L2': 1.0,\n",
       "  'XGBoost_r33_BAG_L2': 1.0,\n",
       "  'CatBoost_r137_BAG_L2': 1.0,\n",
       "  'WeightedEnsemble_L3': 1.0,\n",
       "  'LightGBMXT_BAG_L1_FULL': None,\n",
       "  'LightGBM_BAG_L1_FULL': None,\n",
       "  'CatBoost_BAG_L1_FULL': None,\n",
       "  'NeuralNetFastAI_BAG_L1_FULL': None,\n",
       "  'XGBoost_BAG_L1_FULL': None,\n",
       "  'LightGBMLarge_BAG_L1_FULL': None,\n",
       "  'CatBoost_r177_BAG_L1_FULL': None,\n",
       "  'LightGBM_r131_BAG_L1_FULL': None,\n",
       "  'NeuralNetFastAI_r191_BAG_L1_FULL': None,\n",
       "  'CatBoost_r9_BAG_L1_FULL': None,\n",
       "  'LightGBM_r96_BAG_L1_FULL': None,\n",
       "  'XGBoost_r33_BAG_L1_FULL': None,\n",
       "  'CatBoost_r137_BAG_L1_FULL': None,\n",
       "  'NeuralNetFastAI_r102_BAG_L1_FULL': None,\n",
       "  'CatBoost_r13_BAG_L1_FULL': None,\n",
       "  'LightGBM_r188_BAG_L1_FULL': None,\n",
       "  'NeuralNetFastAI_r145_BAG_L1_FULL': None,\n",
       "  'WeightedEnsemble_L2_FULL': None,\n",
       "  'LightGBMXT_BAG_L2_FULL': None,\n",
       "  'LightGBM_BAG_L2_FULL': None,\n",
       "  'CatBoost_BAG_L2_FULL': None,\n",
       "  'NeuralNetFastAI_BAG_L2_FULL': None,\n",
       "  'XGBoost_BAG_L2_FULL': None,\n",
       "  'LightGBMLarge_BAG_L2_FULL': None,\n",
       "  'CatBoost_r177_BAG_L2_FULL': None,\n",
       "  'LightGBM_r131_BAG_L2_FULL': None,\n",
       "  'NeuralNetFastAI_r191_BAG_L2_FULL': None,\n",
       "  'CatBoost_r9_BAG_L2_FULL': None,\n",
       "  'LightGBM_r96_BAG_L2_FULL': None,\n",
       "  'XGBoost_r33_BAG_L2_FULL': None,\n",
       "  'CatBoost_r137_BAG_L2_FULL': None,\n",
       "  'WeightedEnsemble_L3_FULL': None},\n",
       " 'model_best': 'LightGBM_BAG_L1_FULL',\n",
       " 'model_paths': {'LightGBMXT_BAG_L1': ['LightGBMXT_BAG_L1'],\n",
       "  'LightGBM_BAG_L1': ['LightGBM_BAG_L1'],\n",
       "  'CatBoost_BAG_L1': ['CatBoost_BAG_L1'],\n",
       "  'NeuralNetFastAI_BAG_L1': ['NeuralNetFastAI_BAG_L1'],\n",
       "  'XGBoost_BAG_L1': ['XGBoost_BAG_L1'],\n",
       "  'LightGBMLarge_BAG_L1': ['LightGBMLarge_BAG_L1'],\n",
       "  'CatBoost_r177_BAG_L1': ['CatBoost_r177_BAG_L1'],\n",
       "  'LightGBM_r131_BAG_L1': ['LightGBM_r131_BAG_L1'],\n",
       "  'NeuralNetFastAI_r191_BAG_L1': ['NeuralNetFastAI_r191_BAG_L1'],\n",
       "  'CatBoost_r9_BAG_L1': ['CatBoost_r9_BAG_L1'],\n",
       "  'LightGBM_r96_BAG_L1': ['LightGBM_r96_BAG_L1'],\n",
       "  'XGBoost_r33_BAG_L1': ['XGBoost_r33_BAG_L1'],\n",
       "  'CatBoost_r137_BAG_L1': ['CatBoost_r137_BAG_L1'],\n",
       "  'NeuralNetFastAI_r102_BAG_L1': ['NeuralNetFastAI_r102_BAG_L1'],\n",
       "  'CatBoost_r13_BAG_L1': ['CatBoost_r13_BAG_L1'],\n",
       "  'LightGBM_r188_BAG_L1': ['LightGBM_r188_BAG_L1'],\n",
       "  'NeuralNetFastAI_r145_BAG_L1': ['NeuralNetFastAI_r145_BAG_L1'],\n",
       "  'WeightedEnsemble_L2': ['WeightedEnsemble_L2'],\n",
       "  'LightGBMXT_BAG_L2': ['LightGBMXT_BAG_L2'],\n",
       "  'LightGBM_BAG_L2': ['LightGBM_BAG_L2'],\n",
       "  'CatBoost_BAG_L2': ['CatBoost_BAG_L2'],\n",
       "  'NeuralNetFastAI_BAG_L2': ['NeuralNetFastAI_BAG_L2'],\n",
       "  'XGBoost_BAG_L2': ['XGBoost_BAG_L2'],\n",
       "  'LightGBMLarge_BAG_L2': ['LightGBMLarge_BAG_L2'],\n",
       "  'CatBoost_r177_BAG_L2': ['CatBoost_r177_BAG_L2'],\n",
       "  'LightGBM_r131_BAG_L2': ['LightGBM_r131_BAG_L2'],\n",
       "  'NeuralNetFastAI_r191_BAG_L2': ['NeuralNetFastAI_r191_BAG_L2'],\n",
       "  'CatBoost_r9_BAG_L2': ['CatBoost_r9_BAG_L2'],\n",
       "  'LightGBM_r96_BAG_L2': ['LightGBM_r96_BAG_L2'],\n",
       "  'XGBoost_r33_BAG_L2': ['XGBoost_r33_BAG_L2'],\n",
       "  'CatBoost_r137_BAG_L2': ['CatBoost_r137_BAG_L2'],\n",
       "  'WeightedEnsemble_L3': ['WeightedEnsemble_L3'],\n",
       "  'LightGBMXT_BAG_L1_FULL': ['LightGBMXT_BAG_L1_FULL'],\n",
       "  'LightGBM_BAG_L1_FULL': ['LightGBM_BAG_L1_FULL'],\n",
       "  'CatBoost_BAG_L1_FULL': ['CatBoost_BAG_L1_FULL'],\n",
       "  'NeuralNetFastAI_BAG_L1_FULL': ['NeuralNetFastAI_BAG_L1_FULL'],\n",
       "  'XGBoost_BAG_L1_FULL': ['XGBoost_BAG_L1_FULL'],\n",
       "  'LightGBMLarge_BAG_L1_FULL': ['LightGBMLarge_BAG_L1_FULL'],\n",
       "  'CatBoost_r177_BAG_L1_FULL': ['CatBoost_r177_BAG_L1_FULL'],\n",
       "  'LightGBM_r131_BAG_L1_FULL': ['LightGBM_r131_BAG_L1_FULL'],\n",
       "  'NeuralNetFastAI_r191_BAG_L1_FULL': ['NeuralNetFastAI_r191_BAG_L1_FULL'],\n",
       "  'CatBoost_r9_BAG_L1_FULL': ['CatBoost_r9_BAG_L1_FULL'],\n",
       "  'LightGBM_r96_BAG_L1_FULL': ['LightGBM_r96_BAG_L1_FULL'],\n",
       "  'XGBoost_r33_BAG_L1_FULL': ['XGBoost_r33_BAG_L1_FULL'],\n",
       "  'CatBoost_r137_BAG_L1_FULL': ['CatBoost_r137_BAG_L1_FULL'],\n",
       "  'NeuralNetFastAI_r102_BAG_L1_FULL': ['NeuralNetFastAI_r102_BAG_L1_FULL'],\n",
       "  'CatBoost_r13_BAG_L1_FULL': ['CatBoost_r13_BAG_L1_FULL'],\n",
       "  'LightGBM_r188_BAG_L1_FULL': ['LightGBM_r188_BAG_L1_FULL'],\n",
       "  'NeuralNetFastAI_r145_BAG_L1_FULL': ['NeuralNetFastAI_r145_BAG_L1_FULL'],\n",
       "  'WeightedEnsemble_L2_FULL': ['WeightedEnsemble_L2_FULL'],\n",
       "  'LightGBMXT_BAG_L2_FULL': ['LightGBMXT_BAG_L2_FULL'],\n",
       "  'LightGBM_BAG_L2_FULL': ['LightGBM_BAG_L2_FULL'],\n",
       "  'CatBoost_BAG_L2_FULL': ['CatBoost_BAG_L2_FULL'],\n",
       "  'NeuralNetFastAI_BAG_L2_FULL': ['NeuralNetFastAI_BAG_L2_FULL'],\n",
       "  'XGBoost_BAG_L2_FULL': ['XGBoost_BAG_L2_FULL'],\n",
       "  'LightGBMLarge_BAG_L2_FULL': ['LightGBMLarge_BAG_L2_FULL'],\n",
       "  'CatBoost_r177_BAG_L2_FULL': ['CatBoost_r177_BAG_L2_FULL'],\n",
       "  'LightGBM_r131_BAG_L2_FULL': ['LightGBM_r131_BAG_L2_FULL'],\n",
       "  'NeuralNetFastAI_r191_BAG_L2_FULL': ['NeuralNetFastAI_r191_BAG_L2_FULL'],\n",
       "  'CatBoost_r9_BAG_L2_FULL': ['CatBoost_r9_BAG_L2_FULL'],\n",
       "  'LightGBM_r96_BAG_L2_FULL': ['LightGBM_r96_BAG_L2_FULL'],\n",
       "  'XGBoost_r33_BAG_L2_FULL': ['XGBoost_r33_BAG_L2_FULL'],\n",
       "  'CatBoost_r137_BAG_L2_FULL': ['CatBoost_r137_BAG_L2_FULL'],\n",
       "  'WeightedEnsemble_L3_FULL': ['WeightedEnsemble_L3_FULL']},\n",
       " 'model_fit_times': {'LightGBMXT_BAG_L1': 1.0698935985565186,\n",
       "  'LightGBM_BAG_L1': 1.7983872890472412,\n",
       "  'CatBoost_BAG_L1': 555.3220868110657,\n",
       "  'NeuralNetFastAI_BAG_L1': 6.330047130584717,\n",
       "  'XGBoost_BAG_L1': 2.223928213119507,\n",
       "  'LightGBMLarge_BAG_L1': 2.5438477993011475,\n",
       "  'CatBoost_r177_BAG_L1': 623.5680692195892,\n",
       "  'LightGBM_r131_BAG_L1': 3.4692931175231934,\n",
       "  'NeuralNetFastAI_r191_BAG_L1': 7.505183219909668,\n",
       "  'CatBoost_r9_BAG_L1': 1505.4018676280975,\n",
       "  'LightGBM_r96_BAG_L1': 4.919226408004761,\n",
       "  'XGBoost_r33_BAG_L1': 3.2550082206726074,\n",
       "  'CatBoost_r137_BAG_L1': 281.1672987937927,\n",
       "  'NeuralNetFastAI_r102_BAG_L1': 8.37343692779541,\n",
       "  'CatBoost_r13_BAG_L1': 44.783700942993164,\n",
       "  'LightGBM_r188_BAG_L1': 2.341815710067749,\n",
       "  'NeuralNetFastAI_r145_BAG_L1': 6.895907640457153,\n",
       "  'WeightedEnsemble_L2': 0.04812312126159668,\n",
       "  'LightGBMXT_BAG_L2': 1.9404606819152832,\n",
       "  'LightGBM_BAG_L2': 1.8418378829956055,\n",
       "  'CatBoost_BAG_L2': 543.0598793029785,\n",
       "  'NeuralNetFastAI_BAG_L2': 5.9943687915802,\n",
       "  'XGBoost_BAG_L2': 2.1216788291931152,\n",
       "  'LightGBMLarge_BAG_L2': 2.5334572792053223,\n",
       "  'CatBoost_r177_BAG_L2': 546.2312252521515,\n",
       "  'LightGBM_r131_BAG_L2': 3.073349714279175,\n",
       "  'NeuralNetFastAI_r191_BAG_L2': 7.410468101501465,\n",
       "  'CatBoost_r9_BAG_L2': 324.39093542099,\n",
       "  'LightGBM_r96_BAG_L2': 3.451204299926758,\n",
       "  'XGBoost_r33_BAG_L2': 5.560539245605469,\n",
       "  'CatBoost_r137_BAG_L2': 45.6523642539978,\n",
       "  'WeightedEnsemble_L3': 0.02721095085144043,\n",
       "  'LightGBMXT_BAG_L1_FULL': 0.40628647804260254,\n",
       "  'LightGBM_BAG_L1_FULL': 0.18858695030212402,\n",
       "  'CatBoost_BAG_L1_FULL': 211.0371778011322,\n",
       "  'NeuralNetFastAI_BAG_L1_FULL': 0.6767544746398926,\n",
       "  'XGBoost_BAG_L1_FULL': 0.08617925643920898,\n",
       "  'LightGBMLarge_BAG_L1_FULL': 0.2888054847717285,\n",
       "  'CatBoost_r177_BAG_L1_FULL': 286.6195418834686,\n",
       "  'LightGBM_r131_BAG_L1_FULL': 0.5103902816772461,\n",
       "  'NeuralNetFastAI_r191_BAG_L1_FULL': 0.6723072528839111,\n",
       "  'CatBoost_r9_BAG_L1_FULL': 558.3282232284546,\n",
       "  'LightGBM_r96_BAG_L1_FULL': 0.36266326904296875,\n",
       "  'XGBoost_r33_BAG_L1_FULL': 0.23953461647033691,\n",
       "  'CatBoost_r137_BAG_L1_FULL': 122.484934091568,\n",
       "  'NeuralNetFastAI_r102_BAG_L1_FULL': 1.160682201385498,\n",
       "  'CatBoost_r13_BAG_L1_FULL': 18.1561062335968,\n",
       "  'LightGBM_r188_BAG_L1_FULL': 0.31705713272094727,\n",
       "  'NeuralNetFastAI_r145_BAG_L1_FULL': 0.6509206295013428,\n",
       "  'WeightedEnsemble_L2_FULL': 0.04812312126159668,\n",
       "  'LightGBMXT_BAG_L2_FULL': 0.1861872673034668,\n",
       "  'LightGBM_BAG_L2_FULL': 0.1472930908203125,\n",
       "  'CatBoost_BAG_L2_FULL': 157.39646983146667,\n",
       "  'NeuralNetFastAI_BAG_L2_FULL': 0.6050674915313721,\n",
       "  'XGBoost_BAG_L2_FULL': 0.061331748962402344,\n",
       "  'LightGBMLarge_BAG_L2_FULL': 0.38026857376098633,\n",
       "  'CatBoost_r177_BAG_L2_FULL': 192.5104696750641,\n",
       "  'LightGBM_r131_BAG_L2_FULL': 0.49259376525878906,\n",
       "  'NeuralNetFastAI_r191_BAG_L2_FULL': 0.6794798374176025,\n",
       "  'CatBoost_r9_BAG_L2_FULL': 122.51635813713074,\n",
       "  'LightGBM_r96_BAG_L2_FULL': 0.3246338367462158,\n",
       "  'XGBoost_r33_BAG_L2_FULL': 0.1314709186553955,\n",
       "  'CatBoost_r137_BAG_L2_FULL': 13.965924501419067,\n",
       "  'WeightedEnsemble_L3_FULL': 0.02721095085144043},\n",
       " 'model_pred_times': {'LightGBMXT_BAG_L1': 0.05257129669189453,\n",
       "  'LightGBM_BAG_L1': 0.02923297882080078,\n",
       "  'CatBoost_BAG_L1': 0.08931970596313477,\n",
       "  'NeuralNetFastAI_BAG_L1': 0.10254240036010742,\n",
       "  'XGBoost_BAG_L1': 0.0713052749633789,\n",
       "  'LightGBMLarge_BAG_L1': 0.05945253372192383,\n",
       "  'CatBoost_r177_BAG_L1': 0.089691162109375,\n",
       "  'LightGBM_r131_BAG_L1': 0.06879281997680664,\n",
       "  'NeuralNetFastAI_r191_BAG_L1': 0.09868955612182617,\n",
       "  'CatBoost_r9_BAG_L1': 0.1759812831878662,\n",
       "  'LightGBM_r96_BAG_L1': 0.0532069206237793,\n",
       "  'XGBoost_r33_BAG_L1': 0.055805206298828125,\n",
       "  'CatBoost_r137_BAG_L1': 0.09554934501647949,\n",
       "  'NeuralNetFastAI_r102_BAG_L1': 0.10556340217590332,\n",
       "  'CatBoost_r13_BAG_L1': 0.09189462661743164,\n",
       "  'LightGBM_r188_BAG_L1': 0.05534791946411133,\n",
       "  'NeuralNetFastAI_r145_BAG_L1': 0.0857088565826416,\n",
       "  'WeightedEnsemble_L2': 0.0010018348693847656,\n",
       "  'LightGBMXT_BAG_L2': 0.04613447189331055,\n",
       "  'LightGBM_BAG_L2': 0.03956866264343262,\n",
       "  'CatBoost_BAG_L2': 0.08054947853088379,\n",
       "  'NeuralNetFastAI_BAG_L2': 0.08793830871582031,\n",
       "  'XGBoost_BAG_L2': 0.05206584930419922,\n",
       "  'LightGBMLarge_BAG_L2': 0.05410957336425781,\n",
       "  'CatBoost_r177_BAG_L2': 0.08815813064575195,\n",
       "  'LightGBM_r131_BAG_L2': 0.06778621673583984,\n",
       "  'NeuralNetFastAI_r191_BAG_L2': 0.12172985076904297,\n",
       "  'CatBoost_r9_BAG_L2': 0.11138629913330078,\n",
       "  'LightGBM_r96_BAG_L2': 0.06830692291259766,\n",
       "  'XGBoost_r33_BAG_L2': 0.056413888931274414,\n",
       "  'CatBoost_r137_BAG_L2': 0.07358837127685547,\n",
       "  'WeightedEnsemble_L3': 0.0,\n",
       "  'LightGBMXT_BAG_L1_FULL': None,\n",
       "  'LightGBM_BAG_L1_FULL': None,\n",
       "  'CatBoost_BAG_L1_FULL': None,\n",
       "  'NeuralNetFastAI_BAG_L1_FULL': None,\n",
       "  'XGBoost_BAG_L1_FULL': None,\n",
       "  'LightGBMLarge_BAG_L1_FULL': None,\n",
       "  'CatBoost_r177_BAG_L1_FULL': None,\n",
       "  'LightGBM_r131_BAG_L1_FULL': None,\n",
       "  'NeuralNetFastAI_r191_BAG_L1_FULL': None,\n",
       "  'CatBoost_r9_BAG_L1_FULL': None,\n",
       "  'LightGBM_r96_BAG_L1_FULL': None,\n",
       "  'XGBoost_r33_BAG_L1_FULL': None,\n",
       "  'CatBoost_r137_BAG_L1_FULL': None,\n",
       "  'NeuralNetFastAI_r102_BAG_L1_FULL': None,\n",
       "  'CatBoost_r13_BAG_L1_FULL': None,\n",
       "  'LightGBM_r188_BAG_L1_FULL': None,\n",
       "  'NeuralNetFastAI_r145_BAG_L1_FULL': None,\n",
       "  'WeightedEnsemble_L2_FULL': None,\n",
       "  'LightGBMXT_BAG_L2_FULL': None,\n",
       "  'LightGBM_BAG_L2_FULL': None,\n",
       "  'CatBoost_BAG_L2_FULL': None,\n",
       "  'NeuralNetFastAI_BAG_L2_FULL': None,\n",
       "  'XGBoost_BAG_L2_FULL': None,\n",
       "  'LightGBMLarge_BAG_L2_FULL': None,\n",
       "  'CatBoost_r177_BAG_L2_FULL': None,\n",
       "  'LightGBM_r131_BAG_L2_FULL': None,\n",
       "  'NeuralNetFastAI_r191_BAG_L2_FULL': None,\n",
       "  'CatBoost_r9_BAG_L2_FULL': None,\n",
       "  'LightGBM_r96_BAG_L2_FULL': None,\n",
       "  'XGBoost_r33_BAG_L2_FULL': None,\n",
       "  'CatBoost_r137_BAG_L2_FULL': None,\n",
       "  'WeightedEnsemble_L3_FULL': None},\n",
       " 'num_bag_folds': 8,\n",
       " 'max_stack_level': 3,\n",
       " 'num_classes': 2,\n",
       " 'model_hyperparams': {'LightGBMXT_BAG_L1': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': False},\n",
       "  'LightGBM_BAG_L1': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': False},\n",
       "  'CatBoost_BAG_L1': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': False},\n",
       "  'NeuralNetFastAI_BAG_L1': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': False},\n",
       "  'XGBoost_BAG_L1': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': False},\n",
       "  'LightGBMLarge_BAG_L1': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': False},\n",
       "  'CatBoost_r177_BAG_L1': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': False},\n",
       "  'LightGBM_r131_BAG_L1': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': False},\n",
       "  'NeuralNetFastAI_r191_BAG_L1': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': False},\n",
       "  'CatBoost_r9_BAG_L1': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': False},\n",
       "  'LightGBM_r96_BAG_L1': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': False},\n",
       "  'XGBoost_r33_BAG_L1': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': False},\n",
       "  'CatBoost_r137_BAG_L1': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': False},\n",
       "  'NeuralNetFastAI_r102_BAG_L1': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': False},\n",
       "  'CatBoost_r13_BAG_L1': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': False},\n",
       "  'LightGBM_r188_BAG_L1': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': False},\n",
       "  'NeuralNetFastAI_r145_BAG_L1': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': False},\n",
       "  'WeightedEnsemble_L2': {'use_orig_features': False,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True},\n",
       "  'LightGBMXT_BAG_L2': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': False},\n",
       "  'LightGBM_BAG_L2': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': False},\n",
       "  'CatBoost_BAG_L2': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': False},\n",
       "  'NeuralNetFastAI_BAG_L2': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': False},\n",
       "  'XGBoost_BAG_L2': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': False},\n",
       "  'LightGBMLarge_BAG_L2': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': False},\n",
       "  'CatBoost_r177_BAG_L2': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': False},\n",
       "  'LightGBM_r131_BAG_L2': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': False},\n",
       "  'NeuralNetFastAI_r191_BAG_L2': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': False},\n",
       "  'CatBoost_r9_BAG_L2': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': False},\n",
       "  'LightGBM_r96_BAG_L2': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': False},\n",
       "  'XGBoost_r33_BAG_L2': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': False},\n",
       "  'CatBoost_r137_BAG_L2': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': False},\n",
       "  'WeightedEnsemble_L3': {'use_orig_features': False,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True},\n",
       "  'LightGBMXT_BAG_L1_FULL': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True},\n",
       "  'LightGBM_BAG_L1_FULL': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True},\n",
       "  'CatBoost_BAG_L1_FULL': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True},\n",
       "  'NeuralNetFastAI_BAG_L1_FULL': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True},\n",
       "  'XGBoost_BAG_L1_FULL': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True},\n",
       "  'LightGBMLarge_BAG_L1_FULL': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True},\n",
       "  'CatBoost_r177_BAG_L1_FULL': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True},\n",
       "  'LightGBM_r131_BAG_L1_FULL': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True},\n",
       "  'NeuralNetFastAI_r191_BAG_L1_FULL': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True},\n",
       "  'CatBoost_r9_BAG_L1_FULL': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True},\n",
       "  'LightGBM_r96_BAG_L1_FULL': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True},\n",
       "  'XGBoost_r33_BAG_L1_FULL': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True},\n",
       "  'CatBoost_r137_BAG_L1_FULL': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True},\n",
       "  'NeuralNetFastAI_r102_BAG_L1_FULL': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True},\n",
       "  'CatBoost_r13_BAG_L1_FULL': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True},\n",
       "  'LightGBM_r188_BAG_L1_FULL': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True},\n",
       "  'NeuralNetFastAI_r145_BAG_L1_FULL': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True},\n",
       "  'WeightedEnsemble_L2_FULL': {'use_orig_features': False,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True},\n",
       "  'LightGBMXT_BAG_L2_FULL': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True},\n",
       "  'LightGBM_BAG_L2_FULL': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True},\n",
       "  'CatBoost_BAG_L2_FULL': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True},\n",
       "  'NeuralNetFastAI_BAG_L2_FULL': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True},\n",
       "  'XGBoost_BAG_L2_FULL': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True},\n",
       "  'LightGBMLarge_BAG_L2_FULL': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True},\n",
       "  'CatBoost_r177_BAG_L2_FULL': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True},\n",
       "  'LightGBM_r131_BAG_L2_FULL': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True},\n",
       "  'NeuralNetFastAI_r191_BAG_L2_FULL': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True},\n",
       "  'CatBoost_r9_BAG_L2_FULL': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True},\n",
       "  'LightGBM_r96_BAG_L2_FULL': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True},\n",
       "  'XGBoost_r33_BAG_L2_FULL': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True},\n",
       "  'CatBoost_r137_BAG_L2_FULL': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True},\n",
       "  'WeightedEnsemble_L3_FULL': {'use_orig_features': False,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True}},\n",
       " 'leaderboard':                         model  score_val eval_metric  pred_time_val  \\\n",
       " 0             LightGBM_BAG_L1        1.0     roc_auc       0.029233   \n",
       " 1         WeightedEnsemble_L3        1.0     roc_auc       0.052571   \n",
       " 2           LightGBMXT_BAG_L1        1.0     roc_auc       0.052571   \n",
       " 3         LightGBM_r96_BAG_L1        1.0     roc_auc       0.053207   \n",
       " 4         WeightedEnsemble_L2        1.0     roc_auc       0.053573   \n",
       " ..                        ...        ...         ...            ...   \n",
       " 59   CatBoost_r13_BAG_L1_FULL        NaN     roc_auc            NaN   \n",
       " 60  CatBoost_r137_BAG_L2_FULL        NaN     roc_auc            NaN   \n",
       " 61  CatBoost_r137_BAG_L1_FULL        NaN     roc_auc            NaN   \n",
       " 62       CatBoost_BAG_L2_FULL        NaN     roc_auc            NaN   \n",
       " 63       CatBoost_BAG_L1_FULL        NaN     roc_auc            NaN   \n",
       " \n",
       "       fit_time  pred_time_val_marginal  fit_time_marginal  stack_level  \\\n",
       " 0     1.798387                0.029233           1.798387            1   \n",
       " 1     1.097105                0.000000           0.027211            3   \n",
       " 2     1.069894                0.052571           1.069894            1   \n",
       " 3     4.919226                0.053207           4.919226            1   \n",
       " 4     1.118017                0.001002           0.048123            2   \n",
       " ..         ...                     ...                ...          ...   \n",
       " 59   18.156106                     NaN          18.156106            1   \n",
       " 60  226.167875                     NaN          13.965925            2   \n",
       " 61  122.484934                     NaN         122.484934            1   \n",
       " 62  369.598421                     NaN         157.396470            2   \n",
       " 63  211.037178                     NaN         211.037178            1   \n",
       " \n",
       "     can_infer  fit_order  \n",
       " 0       False          2  \n",
       " 1       False         32  \n",
       " 2       False          1  \n",
       " 3       False         11  \n",
       " 4       False         18  \n",
       " ..        ...        ...  \n",
       " 59       True         47  \n",
       " 60       True         63  \n",
       " 61       True         45  \n",
       " 62       True         53  \n",
       " 63       True         35  \n",
       " \n",
       " [64 rows x 10 columns]}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.fit_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "auxiliary_metrics = ['balanced_accuracy', 'f1', 'f1_macro', 'f1_micro', 'roc_auc', 'average_precision', 'precision', 'recall', 'log_loss', 'pac_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluation: roc_auc on test data: 0.9999999999999999\n",
      "Evaluations on test data:\n",
      "{\n",
      "    \"roc_auc\": 0.9999999999999999,\n",
      "    \"accuracy\": 1.0,\n",
      "    \"balanced_accuracy\": 1.0,\n",
      "    \"mcc\": 1.0,\n",
      "    \"f1\": 1.0,\n",
      "    \"precision\": 1.0,\n",
      "    \"recall\": 1.0\n",
      "}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'roc_auc': 0.9999999999999999,\n",
       " 'accuracy': 1.0,\n",
       " 'balanced_accuracy': 1.0,\n",
       " 'mcc': 1.0,\n",
       " 'f1': 1.0,\n",
       " 'precision': 1.0,\n",
       " 'recall': 1.0}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.evaluate(\n",
    "    df_test,\n",
    "    silent = False,\n",
    "    auxiliary_metrics = auxiliary_metrics\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictors = predictor.leaderboard(\n",
    "    df_train,\n",
    "    extra_metrics = auxiliary_metrics,\n",
    "    extra_info=True,\n",
    "    silent=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>score_test</th>\n",
       "      <th>balanced_accuracy</th>\n",
       "      <th>f1</th>\n",
       "      <th>f1_macro</th>\n",
       "      <th>f1_micro</th>\n",
       "      <th>roc_auc</th>\n",
       "      <th>average_precision</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>...</th>\n",
       "      <th>hyperparameters</th>\n",
       "      <th>hyperparameters_fit</th>\n",
       "      <th>ag_args_fit</th>\n",
       "      <th>features</th>\n",
       "      <th>compile_time</th>\n",
       "      <th>child_hyperparameters</th>\n",
       "      <th>child_hyperparameters_fit</th>\n",
       "      <th>child_ag_args_fit</th>\n",
       "      <th>ancestors</th>\n",
       "      <th>descendants</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LightGBM_BAG_L1_FULL</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>{'use_orig_features': True, 'valid_stacker': True, 'max_base_models': 0, 'max_base_models_per_type': 'auto', 'save_bag_folds': True}</td>\n",
       "      <td>{}</td>\n",
       "      <td>{'max_memory_usage_ratio': 1.15, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': None, 'valid_special_types': None, 'ignored_type_group_special': None, 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'temperature_scalar': None, 'drop_unique': False}</td>\n",
       "      <td>[eval-TLP-Tavec-24_FP-PD, clin-ansiedad, eval-TLP-Tavec-31_RCl_LP_frente_RL_LP-PD, clin-cardiopatiaIsquemica, __nlp__.atencional dc, eval-TLP-FigRey-totalCopia-PD, eval-TLP-Stroop-palabrasColor-PD, eval-TLP-Tavec-1_RI_A1-PD, etiq-diagExpTLPtext.char_count, __nlp__._total_, clin-tipoAlcohol.capital_ratio, clin-Hipercolesterolemia, clin-tipoAlcohol.lower_ratio, eval-TLP-FigRey-totalMemoria-PD, ques-Sus-total-PD, __nlp__.amnésico dc, eval-TLP-Tavec-4_RI_B-PD, clin-tipoAlcohol.word_count, demo-genero, etiq-diagExpTLPtext.symbol_ratio.-, eval-TLP-FigRey-Duracion-PD, etiq-diagExpTLPtext.word_cou...</td>\n",
       "      <td>None</td>\n",
       "      <td>{'learning_rate': 0.05, 'num_boost_round': 221}</td>\n",
       "      <td>{'num_boost_round': 221}</td>\n",
       "      <td>{'max_memory_usage_ratio': 1.0, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': ['bool', 'int', 'float', 'category'], 'valid_special_types': None, 'ignored_type_group_special': None, 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'temperature_scalar': None}</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>XGBoost_BAG_L1_FULL</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>{'use_orig_features': True, 'valid_stacker': True, 'max_base_models': 0, 'max_base_models_per_type': 'auto', 'save_bag_folds': True}</td>\n",
       "      <td>{}</td>\n",
       "      <td>{'max_memory_usage_ratio': 1.15, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': None, 'valid_special_types': None, 'ignored_type_group_special': None, 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'temperature_scalar': None, 'drop_unique': False}</td>\n",
       "      <td>[eval-TLP-Tavec-24_FP-PD, clin-ansiedad, eval-TLP-Tavec-31_RCl_LP_frente_RL_LP-PD, clin-cardiopatiaIsquemica, __nlp__.atencional dc, eval-TLP-FigRey-totalCopia-PD, eval-TLP-Stroop-palabrasColor-PD, eval-TLP-Tavec-1_RI_A1-PD, etiq-diagExpTLPtext.char_count, __nlp__._total_, clin-tipoAlcohol.capital_ratio, clin-Hipercolesterolemia, clin-tipoAlcohol.lower_ratio, eval-TLP-FigRey-totalMemoria-PD, ques-Sus-total-PD, __nlp__.amnésico dc, eval-TLP-Tavec-4_RI_B-PD, clin-tipoAlcohol.word_count, demo-genero, etiq-diagExpTLPtext.symbol_ratio.-, eval-TLP-FigRey-Duracion-PD, etiq-diagExpTLPtext.word_cou...</td>\n",
       "      <td>None</td>\n",
       "      <td>{'n_estimators': 105, 'learning_rate': 0.1, 'n_jobs': -1, 'proc.max_category_levels': 100, 'objective': 'binary:logistic', 'booster': 'gbtree'}</td>\n",
       "      <td>{}</td>\n",
       "      <td>{'max_memory_usage_ratio': 1.0, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': ['bool', 'int', 'float', 'category'], 'valid_special_types': None, 'ignored_type_group_special': None, 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'temperature_scalar': None}</td>\n",
       "      <td>[]</td>\n",
       "      <td>[CatBoost_r9_BAG_L2_FULL, LightGBMXT_BAG_L2_FULL, CatBoost_r177_BAG_L2_FULL, LightGBM_r131_BAG_L2_FULL, CatBoost_BAG_L2_FULL, XGBoost_BAG_L2_FULL, LightGBMLarge_BAG_L2_FULL, LightGBM_r96_BAG_L2_FULL, CatBoost_r137_BAG_L2_FULL, NeuralNetFastAI_BAG_L2_FULL, NeuralNetFastAI_r191_BAG_L2_FULL, XGBoost_r33_BAG_L2_FULL, LightGBM_BAG_L2_FULL]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LightGBMXT_BAG_L1_FULL</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>{'use_orig_features': True, 'valid_stacker': True, 'max_base_models': 0, 'max_base_models_per_type': 'auto', 'save_bag_folds': True}</td>\n",
       "      <td>{}</td>\n",
       "      <td>{'max_memory_usage_ratio': 1.15, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': None, 'valid_special_types': None, 'ignored_type_group_special': None, 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'temperature_scalar': None, 'drop_unique': False}</td>\n",
       "      <td>[eval-TLP-Tavec-24_FP-PD, clin-ansiedad, eval-TLP-Tavec-31_RCl_LP_frente_RL_LP-PD, clin-cardiopatiaIsquemica, __nlp__.atencional dc, eval-TLP-FigRey-totalCopia-PD, eval-TLP-Stroop-palabrasColor-PD, eval-TLP-Tavec-1_RI_A1-PD, etiq-diagExpTLPtext.char_count, __nlp__._total_, clin-tipoAlcohol.capital_ratio, clin-Hipercolesterolemia, clin-tipoAlcohol.lower_ratio, eval-TLP-FigRey-totalMemoria-PD, ques-Sus-total-PD, __nlp__.amnésico dc, eval-TLP-Tavec-4_RI_B-PD, clin-tipoAlcohol.word_count, demo-genero, etiq-diagExpTLPtext.symbol_ratio.-, eval-TLP-FigRey-Duracion-PD, etiq-diagExpTLPtext.word_cou...</td>\n",
       "      <td>None</td>\n",
       "      <td>{'learning_rate': 0.05, 'extra_trees': True, 'num_boost_round': 328}</td>\n",
       "      <td>{'num_boost_round': 328}</td>\n",
       "      <td>{'max_memory_usage_ratio': 1.0, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': ['bool', 'int', 'float', 'category'], 'valid_special_types': None, 'ignored_type_group_special': None, 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'temperature_scalar': None}</td>\n",
       "      <td>[]</td>\n",
       "      <td>[CatBoost_r9_BAG_L2_FULL, WeightedEnsemble_L2_FULL, LightGBMXT_BAG_L2_FULL, CatBoost_r177_BAG_L2_FULL, LightGBM_r131_BAG_L2_FULL, CatBoost_BAG_L2_FULL, XGBoost_BAG_L2_FULL, LightGBMLarge_BAG_L2_FULL, WeightedEnsemble_L3_FULL, LightGBM_r96_BAG_L2_FULL, CatBoost_r137_BAG_L2_FULL, NeuralNetFastAI_BAG_L2_FULL, NeuralNetFastAI_r191_BAG_L2_FULL, XGBoost_r33_BAG_L2_FULL, LightGBM_BAG_L2_FULL]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>WeightedEnsemble_L2_FULL</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>{'use_orig_features': False, 'valid_stacker': True, 'max_base_models': 0, 'max_base_models_per_type': 'auto', 'save_bag_folds': True}</td>\n",
       "      <td>{}</td>\n",
       "      <td>{'max_memory_usage_ratio': 1.0, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': None, 'valid_special_types': None, 'ignored_type_group_special': None, 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'temperature_scalar': None, 'drop_unique': False}</td>\n",
       "      <td>[LightGBMXT_BAG_L1]</td>\n",
       "      <td>None</td>\n",
       "      <td>{'ensemble_size': 25, 'subsample_size': 1000000}</td>\n",
       "      <td>{'ensemble_size': 1}</td>\n",
       "      <td>{'max_memory_usage_ratio': 1.0, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': None, 'valid_special_types': None, 'ignored_type_group_special': None, 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'temperature_scalar': None, 'drop_unique': False}</td>\n",
       "      <td>[LightGBMXT_BAG_L1_FULL]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LightGBMLarge_BAG_L1_FULL</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>{'use_orig_features': True, 'valid_stacker': True, 'max_base_models': 0, 'max_base_models_per_type': 'auto', 'save_bag_folds': True}</td>\n",
       "      <td>{}</td>\n",
       "      <td>{'max_memory_usage_ratio': 1.15, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': None, 'valid_special_types': None, 'ignored_type_group_special': None, 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'temperature_scalar': None, 'drop_unique': False}</td>\n",
       "      <td>[eval-TLP-Tavec-24_FP-PD, clin-ansiedad, eval-TLP-Tavec-31_RCl_LP_frente_RL_LP-PD, clin-cardiopatiaIsquemica, __nlp__.atencional dc, eval-TLP-FigRey-totalCopia-PD, eval-TLP-Stroop-palabrasColor-PD, eval-TLP-Tavec-1_RI_A1-PD, etiq-diagExpTLPtext.char_count, __nlp__._total_, clin-tipoAlcohol.capital_ratio, clin-Hipercolesterolemia, clin-tipoAlcohol.lower_ratio, eval-TLP-FigRey-totalMemoria-PD, ques-Sus-total-PD, __nlp__.amnésico dc, eval-TLP-Tavec-4_RI_B-PD, clin-tipoAlcohol.word_count, demo-genero, etiq-diagExpTLPtext.symbol_ratio.-, eval-TLP-FigRey-Duracion-PD, etiq-diagExpTLPtext.word_cou...</td>\n",
       "      <td>None</td>\n",
       "      <td>{'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'num_boost_round': 342}</td>\n",
       "      <td>{'num_boost_round': 342}</td>\n",
       "      <td>{'max_memory_usage_ratio': 1.0, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': ['bool', 'int', 'float', 'category'], 'valid_special_types': None, 'ignored_type_group_special': None, 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'temperature_scalar': None}</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>NeuralNetFastAI_r145_BAG_L1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>{'use_orig_features': True, 'valid_stacker': True, 'max_base_models': 0, 'max_base_models_per_type': 'auto', 'save_bag_folds': False}</td>\n",
       "      <td>{}</td>\n",
       "      <td>{'max_memory_usage_ratio': 1.0, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': None, 'valid_special_types': None, 'ignored_type_group_special': None, 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'temperature_scalar': None, 'drop_unique': False}</td>\n",
       "      <td>[eval-TLP-Tavec-24_FP-PD, clin-ansiedad, eval-TLP-Tavec-31_RCl_LP_frente_RL_LP-PD, clin-cardiopatiaIsquemica, eval-TLP-FigRey-totalCopia-PD, eval-TLP-Stroop-palabrasColor-PD, eval-TLP-Tavec-1_RI_A1-PD, etiq-diagExpTLPtext.char_count, clin-tipoAlcohol.capital_ratio, clin-Hipercolesterolemia, clin-tipoAlcohol.lower_ratio, eval-TLP-FigRey-totalMemoria-PD, ques-Sus-total-PD, eval-TLP-Tavec-4_RI_B-PD, clin-tipoAlcohol.word_count, demo-genero, etiq-diagExpTLPtext.symbol_ratio.-, eval-TLP-FigRey-Duracion-PD, etiq-diagExpTLPtext.word_count, etiq-diagExpTLPtext_R2.char_count, demo-fechaNacimiento.m...</td>\n",
       "      <td>None</td>\n",
       "      <td>{'layers': [400, 200, 100], 'emb_drop': 0.44339037504795686, 'ps': 0.19220253419114286, 'bs': 128, 'lr': 0.008615195908919904, 'epochs': 31, 'early.stopping.min_delta': 0.0001, 'early.stopping.patience': 20, 'smoothing': 0.0}</td>\n",
       "      <td>{'epochs': 31, 'best_epoch': 12}</td>\n",
       "      <td>{'max_memory_usage_ratio': 1.0, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': ['bool', 'int', 'float', 'category'], 'valid_special_types': None, 'ignored_type_group_special': ['text_ngram', 'text_as_category'], 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'temperature_scalar': None}</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>XGBoost_BAG_L2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>{'use_orig_features': True, 'valid_stacker': True, 'max_base_models': 0, 'max_base_models_per_type': 'auto', 'save_bag_folds': False}</td>\n",
       "      <td>{}</td>\n",
       "      <td>{'max_memory_usage_ratio': 1.0, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': None, 'valid_special_types': None, 'ignored_type_group_special': None, 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'temperature_scalar': None, 'drop_unique': False}</td>\n",
       "      <td>[eval-TLP-Tavec-24_FP-PD, LightGBMXT_BAG_L1, clin-ansiedad, eval-TLP-Tavec-31_RCl_LP_frente_RL_LP-PD, clin-cardiopatiaIsquemica, __nlp__.atencional dc, eval-TLP-FigRey-totalCopia-PD, eval-TLP-Stroop-palabrasColor-PD, eval-TLP-Tavec-1_RI_A1-PD, etiq-diagExpTLPtext.char_count, __nlp__._total_, clin-tipoAlcohol.capital_ratio, clin-Hipercolesterolemia, clin-tipoAlcohol.lower_ratio, eval-TLP-FigRey-totalMemoria-PD, ques-Sus-total-PD, __nlp__.amnésico dc, eval-TLP-Tavec-4_RI_B-PD, clin-tipoAlcohol.word_count, demo-genero, etiq-diagExpTLPtext.symbol_ratio.-, eval-TLP-FigRey-Duracion-PD, etiq-diag...</td>\n",
       "      <td>None</td>\n",
       "      <td>{'n_estimators': 10000, 'learning_rate': 0.1, 'n_jobs': -1, 'proc.max_category_levels': 100, 'objective': 'binary:logistic', 'booster': 'gbtree'}</td>\n",
       "      <td>{'n_estimators': 52}</td>\n",
       "      <td>{'max_memory_usage_ratio': 1.0, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': ['bool', 'int', 'float', 'category'], 'valid_special_types': None, 'ignored_type_group_special': None, 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'temperature_scalar': None}</td>\n",
       "      <td>[NeuralNetFastAI_r191_BAG_L1, CatBoost_BAG_L1, XGBoost_BAG_L1, LightGBMXT_BAG_L1]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>NeuralNetFastAI_BAG_L1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>{'use_orig_features': True, 'valid_stacker': True, 'max_base_models': 0, 'max_base_models_per_type': 'auto', 'save_bag_folds': False}</td>\n",
       "      <td>{}</td>\n",
       "      <td>{'max_memory_usage_ratio': 1.0, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': None, 'valid_special_types': None, 'ignored_type_group_special': None, 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'temperature_scalar': None, 'drop_unique': False}</td>\n",
       "      <td>[eval-TLP-Tavec-24_FP-PD, clin-ansiedad, eval-TLP-Tavec-31_RCl_LP_frente_RL_LP-PD, clin-cardiopatiaIsquemica, eval-TLP-FigRey-totalCopia-PD, eval-TLP-Stroop-palabrasColor-PD, eval-TLP-Tavec-1_RI_A1-PD, etiq-diagExpTLPtext.char_count, clin-tipoAlcohol.capital_ratio, clin-Hipercolesterolemia, clin-tipoAlcohol.lower_ratio, eval-TLP-FigRey-totalMemoria-PD, ques-Sus-total-PD, eval-TLP-Tavec-4_RI_B-PD, clin-tipoAlcohol.word_count, demo-genero, etiq-diagExpTLPtext.symbol_ratio.-, eval-TLP-FigRey-Duracion-PD, etiq-diagExpTLPtext.word_count, etiq-diagExpTLPtext_R2.char_count, demo-fechaNacimiento.m...</td>\n",
       "      <td>None</td>\n",
       "      <td>{'layers': None, 'emb_drop': 0.1, 'ps': 0.1, 'bs': 'auto', 'lr': 0.01, 'epochs': 'auto', 'early.stopping.min_delta': 0.0001, 'early.stopping.patience': 20, 'smoothing': 0.0}</td>\n",
       "      <td>{'epochs': 30, 'best_epoch': 19}</td>\n",
       "      <td>{'max_memory_usage_ratio': 1.0, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': ['bool', 'int', 'float', 'category'], 'valid_special_types': None, 'ignored_type_group_special': ['text_ngram', 'text_as_category'], 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'temperature_scalar': None}</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>NeuralNetFastAI_BAG_L2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>{'use_orig_features': True, 'valid_stacker': True, 'max_base_models': 0, 'max_base_models_per_type': 'auto', 'save_bag_folds': False}</td>\n",
       "      <td>{}</td>\n",
       "      <td>{'max_memory_usage_ratio': 1.0, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': None, 'valid_special_types': None, 'ignored_type_group_special': None, 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'temperature_scalar': None, 'drop_unique': False}</td>\n",
       "      <td>[eval-TLP-Tavec-24_FP-PD, LightGBMXT_BAG_L1, clin-ansiedad, eval-TLP-Tavec-31_RCl_LP_frente_RL_LP-PD, clin-cardiopatiaIsquemica, eval-TLP-FigRey-totalCopia-PD, eval-TLP-Stroop-palabrasColor-PD, eval-TLP-Tavec-1_RI_A1-PD, etiq-diagExpTLPtext.char_count, clin-tipoAlcohol.capital_ratio, clin-Hipercolesterolemia, clin-tipoAlcohol.lower_ratio, eval-TLP-FigRey-totalMemoria-PD, ques-Sus-total-PD, eval-TLP-Tavec-4_RI_B-PD, clin-tipoAlcohol.word_count, demo-genero, etiq-diagExpTLPtext.symbol_ratio.-, eval-TLP-FigRey-Duracion-PD, etiq-diagExpTLPtext.word_count, etiq-diagExpTLPtext_R2.char_count, dem...</td>\n",
       "      <td>None</td>\n",
       "      <td>{'layers': None, 'emb_drop': 0.1, 'ps': 0.1, 'bs': 'auto', 'lr': 0.01, 'epochs': 'auto', 'early.stopping.min_delta': 0.0001, 'early.stopping.patience': 20, 'smoothing': 0.0}</td>\n",
       "      <td>{'epochs': 30, 'best_epoch': 20}</td>\n",
       "      <td>{'max_memory_usage_ratio': 1.0, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': ['bool', 'int', 'float', 'category'], 'valid_special_types': None, 'ignored_type_group_special': ['text_ngram', 'text_as_category'], 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'temperature_scalar': None}</td>\n",
       "      <td>[NeuralNetFastAI_r191_BAG_L1, CatBoost_BAG_L1, XGBoost_BAG_L1, LightGBMXT_BAG_L1]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>NeuralNetFastAI_r102_BAG_L1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>{'use_orig_features': True, 'valid_stacker': True, 'max_base_models': 0, 'max_base_models_per_type': 'auto', 'save_bag_folds': False}</td>\n",
       "      <td>{}</td>\n",
       "      <td>{'max_memory_usage_ratio': 1.0, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': None, 'valid_special_types': None, 'ignored_type_group_special': None, 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'temperature_scalar': None, 'drop_unique': False}</td>\n",
       "      <td>[eval-TLP-Tavec-24_FP-PD, clin-ansiedad, eval-TLP-Tavec-31_RCl_LP_frente_RL_LP-PD, clin-cardiopatiaIsquemica, eval-TLP-FigRey-totalCopia-PD, eval-TLP-Stroop-palabrasColor-PD, eval-TLP-Tavec-1_RI_A1-PD, etiq-diagExpTLPtext.char_count, clin-tipoAlcohol.capital_ratio, clin-Hipercolesterolemia, clin-tipoAlcohol.lower_ratio, eval-TLP-FigRey-totalMemoria-PD, ques-Sus-total-PD, eval-TLP-Tavec-4_RI_B-PD, clin-tipoAlcohol.word_count, demo-genero, etiq-diagExpTLPtext.symbol_ratio.-, eval-TLP-FigRey-Duracion-PD, etiq-diagExpTLPtext.word_count, etiq-diagExpTLPtext_R2.char_count, demo-fechaNacimiento.m...</td>\n",
       "      <td>None</td>\n",
       "      <td>{'layers': [200, 100], 'emb_drop': 0.05070411322605811, 'ps': 0.10393466140748028, 'bs': 2048, 'lr': 0.08974235041576624, 'epochs': 29, 'early.stopping.min_delta': 0.0001, 'early.stopping.patience': 20, 'smoothing': 0.0}</td>\n",
       "      <td>{'epochs': 29, 'best_epoch': 8}</td>\n",
       "      <td>{'max_memory_usage_ratio': 1.0, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': ['bool', 'int', 'float', 'category'], 'valid_special_types': None, 'ignored_type_group_special': ['text_ngram', 'text_as_category'], 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'temperature_scalar': None}</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>64 rows × 45 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          model  score_test  balanced_accuracy   f1  f1_macro  \\\n",
       "0          LightGBM_BAG_L1_FULL         1.0                1.0  1.0       1.0   \n",
       "1           XGBoost_BAG_L1_FULL         1.0                1.0  1.0       1.0   \n",
       "2        LightGBMXT_BAG_L1_FULL         1.0                1.0  1.0       1.0   \n",
       "3      WeightedEnsemble_L2_FULL         1.0                1.0  1.0       1.0   \n",
       "4     LightGBMLarge_BAG_L1_FULL         1.0                1.0  1.0       1.0   \n",
       "..                          ...         ...                ...  ...       ...   \n",
       "59  NeuralNetFastAI_r145_BAG_L1         NaN                NaN  NaN       NaN   \n",
       "60               XGBoost_BAG_L2         NaN                NaN  NaN       NaN   \n",
       "61       NeuralNetFastAI_BAG_L1         NaN                NaN  NaN       NaN   \n",
       "62       NeuralNetFastAI_BAG_L2         NaN                NaN  NaN       NaN   \n",
       "63  NeuralNetFastAI_r102_BAG_L1         NaN                NaN  NaN       NaN   \n",
       "\n",
       "    f1_micro  roc_auc  average_precision  precision  recall  ...  \\\n",
       "0        1.0      1.0                1.0        1.0     1.0  ...   \n",
       "1        1.0      1.0                1.0        1.0     1.0  ...   \n",
       "2        1.0      1.0                1.0        1.0     1.0  ...   \n",
       "3        1.0      1.0                1.0        1.0     1.0  ...   \n",
       "4        1.0      1.0                1.0        1.0     1.0  ...   \n",
       "..       ...      ...                ...        ...     ...  ...   \n",
       "59       NaN      NaN                NaN        NaN     NaN  ...   \n",
       "60       NaN      NaN                NaN        NaN     NaN  ...   \n",
       "61       NaN      NaN                NaN        NaN     NaN  ...   \n",
       "62       NaN      NaN                NaN        NaN     NaN  ...   \n",
       "63       NaN      NaN                NaN        NaN     NaN  ...   \n",
       "\n",
       "                                                                                                                          hyperparameters  \\\n",
       "0    {'use_orig_features': True, 'valid_stacker': True, 'max_base_models': 0, 'max_base_models_per_type': 'auto', 'save_bag_folds': True}   \n",
       "1    {'use_orig_features': True, 'valid_stacker': True, 'max_base_models': 0, 'max_base_models_per_type': 'auto', 'save_bag_folds': True}   \n",
       "2    {'use_orig_features': True, 'valid_stacker': True, 'max_base_models': 0, 'max_base_models_per_type': 'auto', 'save_bag_folds': True}   \n",
       "3   {'use_orig_features': False, 'valid_stacker': True, 'max_base_models': 0, 'max_base_models_per_type': 'auto', 'save_bag_folds': True}   \n",
       "4    {'use_orig_features': True, 'valid_stacker': True, 'max_base_models': 0, 'max_base_models_per_type': 'auto', 'save_bag_folds': True}   \n",
       "..                                                                                                                                    ...   \n",
       "59  {'use_orig_features': True, 'valid_stacker': True, 'max_base_models': 0, 'max_base_models_per_type': 'auto', 'save_bag_folds': False}   \n",
       "60  {'use_orig_features': True, 'valid_stacker': True, 'max_base_models': 0, 'max_base_models_per_type': 'auto', 'save_bag_folds': False}   \n",
       "61  {'use_orig_features': True, 'valid_stacker': True, 'max_base_models': 0, 'max_base_models_per_type': 'auto', 'save_bag_folds': False}   \n",
       "62  {'use_orig_features': True, 'valid_stacker': True, 'max_base_models': 0, 'max_base_models_per_type': 'auto', 'save_bag_folds': False}   \n",
       "63  {'use_orig_features': True, 'valid_stacker': True, 'max_base_models': 0, 'max_base_models_per_type': 'auto', 'save_bag_folds': False}   \n",
       "\n",
       "    hyperparameters_fit  \\\n",
       "0                    {}   \n",
       "1                    {}   \n",
       "2                    {}   \n",
       "3                    {}   \n",
       "4                    {}   \n",
       "..                  ...   \n",
       "59                   {}   \n",
       "60                   {}   \n",
       "61                   {}   \n",
       "62                   {}   \n",
       "63                   {}   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                             ag_args_fit  \\\n",
       "0   {'max_memory_usage_ratio': 1.15, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': None, 'valid_special_types': None, 'ignored_type_group_special': None, 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'temperature_scalar': None, 'drop_unique': False}   \n",
       "1   {'max_memory_usage_ratio': 1.15, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': None, 'valid_special_types': None, 'ignored_type_group_special': None, 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'temperature_scalar': None, 'drop_unique': False}   \n",
       "2   {'max_memory_usage_ratio': 1.15, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': None, 'valid_special_types': None, 'ignored_type_group_special': None, 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'temperature_scalar': None, 'drop_unique': False}   \n",
       "3    {'max_memory_usage_ratio': 1.0, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': None, 'valid_special_types': None, 'ignored_type_group_special': None, 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'temperature_scalar': None, 'drop_unique': False}   \n",
       "4   {'max_memory_usage_ratio': 1.15, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': None, 'valid_special_types': None, 'ignored_type_group_special': None, 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'temperature_scalar': None, 'drop_unique': False}   \n",
       "..                                                                                                                                                                                                                                                                                                                                                                                   ...   \n",
       "59   {'max_memory_usage_ratio': 1.0, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': None, 'valid_special_types': None, 'ignored_type_group_special': None, 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'temperature_scalar': None, 'drop_unique': False}   \n",
       "60   {'max_memory_usage_ratio': 1.0, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': None, 'valid_special_types': None, 'ignored_type_group_special': None, 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'temperature_scalar': None, 'drop_unique': False}   \n",
       "61   {'max_memory_usage_ratio': 1.0, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': None, 'valid_special_types': None, 'ignored_type_group_special': None, 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'temperature_scalar': None, 'drop_unique': False}   \n",
       "62   {'max_memory_usage_ratio': 1.0, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': None, 'valid_special_types': None, 'ignored_type_group_special': None, 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'temperature_scalar': None, 'drop_unique': False}   \n",
       "63   {'max_memory_usage_ratio': 1.0, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': None, 'valid_special_types': None, 'ignored_type_group_special': None, 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'temperature_scalar': None, 'drop_unique': False}   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   features  \\\n",
       "0   [eval-TLP-Tavec-24_FP-PD, clin-ansiedad, eval-TLP-Tavec-31_RCl_LP_frente_RL_LP-PD, clin-cardiopatiaIsquemica, __nlp__.atencional dc, eval-TLP-FigRey-totalCopia-PD, eval-TLP-Stroop-palabrasColor-PD, eval-TLP-Tavec-1_RI_A1-PD, etiq-diagExpTLPtext.char_count, __nlp__._total_, clin-tipoAlcohol.capital_ratio, clin-Hipercolesterolemia, clin-tipoAlcohol.lower_ratio, eval-TLP-FigRey-totalMemoria-PD, ques-Sus-total-PD, __nlp__.amnésico dc, eval-TLP-Tavec-4_RI_B-PD, clin-tipoAlcohol.word_count, demo-genero, etiq-diagExpTLPtext.symbol_ratio.-, eval-TLP-FigRey-Duracion-PD, etiq-diagExpTLPtext.word_cou...   \n",
       "1   [eval-TLP-Tavec-24_FP-PD, clin-ansiedad, eval-TLP-Tavec-31_RCl_LP_frente_RL_LP-PD, clin-cardiopatiaIsquemica, __nlp__.atencional dc, eval-TLP-FigRey-totalCopia-PD, eval-TLP-Stroop-palabrasColor-PD, eval-TLP-Tavec-1_RI_A1-PD, etiq-diagExpTLPtext.char_count, __nlp__._total_, clin-tipoAlcohol.capital_ratio, clin-Hipercolesterolemia, clin-tipoAlcohol.lower_ratio, eval-TLP-FigRey-totalMemoria-PD, ques-Sus-total-PD, __nlp__.amnésico dc, eval-TLP-Tavec-4_RI_B-PD, clin-tipoAlcohol.word_count, demo-genero, etiq-diagExpTLPtext.symbol_ratio.-, eval-TLP-FigRey-Duracion-PD, etiq-diagExpTLPtext.word_cou...   \n",
       "2   [eval-TLP-Tavec-24_FP-PD, clin-ansiedad, eval-TLP-Tavec-31_RCl_LP_frente_RL_LP-PD, clin-cardiopatiaIsquemica, __nlp__.atencional dc, eval-TLP-FigRey-totalCopia-PD, eval-TLP-Stroop-palabrasColor-PD, eval-TLP-Tavec-1_RI_A1-PD, etiq-diagExpTLPtext.char_count, __nlp__._total_, clin-tipoAlcohol.capital_ratio, clin-Hipercolesterolemia, clin-tipoAlcohol.lower_ratio, eval-TLP-FigRey-totalMemoria-PD, ques-Sus-total-PD, __nlp__.amnésico dc, eval-TLP-Tavec-4_RI_B-PD, clin-tipoAlcohol.word_count, demo-genero, etiq-diagExpTLPtext.symbol_ratio.-, eval-TLP-FigRey-Duracion-PD, etiq-diagExpTLPtext.word_cou...   \n",
       "3                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       [LightGBMXT_BAG_L1]   \n",
       "4   [eval-TLP-Tavec-24_FP-PD, clin-ansiedad, eval-TLP-Tavec-31_RCl_LP_frente_RL_LP-PD, clin-cardiopatiaIsquemica, __nlp__.atencional dc, eval-TLP-FigRey-totalCopia-PD, eval-TLP-Stroop-palabrasColor-PD, eval-TLP-Tavec-1_RI_A1-PD, etiq-diagExpTLPtext.char_count, __nlp__._total_, clin-tipoAlcohol.capital_ratio, clin-Hipercolesterolemia, clin-tipoAlcohol.lower_ratio, eval-TLP-FigRey-totalMemoria-PD, ques-Sus-total-PD, __nlp__.amnésico dc, eval-TLP-Tavec-4_RI_B-PD, clin-tipoAlcohol.word_count, demo-genero, etiq-diagExpTLPtext.symbol_ratio.-, eval-TLP-FigRey-Duracion-PD, etiq-diagExpTLPtext.word_cou...   \n",
       "..                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      ...   \n",
       "59  [eval-TLP-Tavec-24_FP-PD, clin-ansiedad, eval-TLP-Tavec-31_RCl_LP_frente_RL_LP-PD, clin-cardiopatiaIsquemica, eval-TLP-FigRey-totalCopia-PD, eval-TLP-Stroop-palabrasColor-PD, eval-TLP-Tavec-1_RI_A1-PD, etiq-diagExpTLPtext.char_count, clin-tipoAlcohol.capital_ratio, clin-Hipercolesterolemia, clin-tipoAlcohol.lower_ratio, eval-TLP-FigRey-totalMemoria-PD, ques-Sus-total-PD, eval-TLP-Tavec-4_RI_B-PD, clin-tipoAlcohol.word_count, demo-genero, etiq-diagExpTLPtext.symbol_ratio.-, eval-TLP-FigRey-Duracion-PD, etiq-diagExpTLPtext.word_count, etiq-diagExpTLPtext_R2.char_count, demo-fechaNacimiento.m...   \n",
       "60  [eval-TLP-Tavec-24_FP-PD, LightGBMXT_BAG_L1, clin-ansiedad, eval-TLP-Tavec-31_RCl_LP_frente_RL_LP-PD, clin-cardiopatiaIsquemica, __nlp__.atencional dc, eval-TLP-FigRey-totalCopia-PD, eval-TLP-Stroop-palabrasColor-PD, eval-TLP-Tavec-1_RI_A1-PD, etiq-diagExpTLPtext.char_count, __nlp__._total_, clin-tipoAlcohol.capital_ratio, clin-Hipercolesterolemia, clin-tipoAlcohol.lower_ratio, eval-TLP-FigRey-totalMemoria-PD, ques-Sus-total-PD, __nlp__.amnésico dc, eval-TLP-Tavec-4_RI_B-PD, clin-tipoAlcohol.word_count, demo-genero, etiq-diagExpTLPtext.symbol_ratio.-, eval-TLP-FigRey-Duracion-PD, etiq-diag...   \n",
       "61  [eval-TLP-Tavec-24_FP-PD, clin-ansiedad, eval-TLP-Tavec-31_RCl_LP_frente_RL_LP-PD, clin-cardiopatiaIsquemica, eval-TLP-FigRey-totalCopia-PD, eval-TLP-Stroop-palabrasColor-PD, eval-TLP-Tavec-1_RI_A1-PD, etiq-diagExpTLPtext.char_count, clin-tipoAlcohol.capital_ratio, clin-Hipercolesterolemia, clin-tipoAlcohol.lower_ratio, eval-TLP-FigRey-totalMemoria-PD, ques-Sus-total-PD, eval-TLP-Tavec-4_RI_B-PD, clin-tipoAlcohol.word_count, demo-genero, etiq-diagExpTLPtext.symbol_ratio.-, eval-TLP-FigRey-Duracion-PD, etiq-diagExpTLPtext.word_count, etiq-diagExpTLPtext_R2.char_count, demo-fechaNacimiento.m...   \n",
       "62  [eval-TLP-Tavec-24_FP-PD, LightGBMXT_BAG_L1, clin-ansiedad, eval-TLP-Tavec-31_RCl_LP_frente_RL_LP-PD, clin-cardiopatiaIsquemica, eval-TLP-FigRey-totalCopia-PD, eval-TLP-Stroop-palabrasColor-PD, eval-TLP-Tavec-1_RI_A1-PD, etiq-diagExpTLPtext.char_count, clin-tipoAlcohol.capital_ratio, clin-Hipercolesterolemia, clin-tipoAlcohol.lower_ratio, eval-TLP-FigRey-totalMemoria-PD, ques-Sus-total-PD, eval-TLP-Tavec-4_RI_B-PD, clin-tipoAlcohol.word_count, demo-genero, etiq-diagExpTLPtext.symbol_ratio.-, eval-TLP-FigRey-Duracion-PD, etiq-diagExpTLPtext.word_count, etiq-diagExpTLPtext_R2.char_count, dem...   \n",
       "63  [eval-TLP-Tavec-24_FP-PD, clin-ansiedad, eval-TLP-Tavec-31_RCl_LP_frente_RL_LP-PD, clin-cardiopatiaIsquemica, eval-TLP-FigRey-totalCopia-PD, eval-TLP-Stroop-palabrasColor-PD, eval-TLP-Tavec-1_RI_A1-PD, etiq-diagExpTLPtext.char_count, clin-tipoAlcohol.capital_ratio, clin-Hipercolesterolemia, clin-tipoAlcohol.lower_ratio, eval-TLP-FigRey-totalMemoria-PD, ques-Sus-total-PD, eval-TLP-Tavec-4_RI_B-PD, clin-tipoAlcohol.word_count, demo-genero, etiq-diagExpTLPtext.symbol_ratio.-, eval-TLP-FigRey-Duracion-PD, etiq-diagExpTLPtext.word_count, etiq-diagExpTLPtext_R2.char_count, demo-fechaNacimiento.m...   \n",
       "\n",
       "    compile_time  \\\n",
       "0           None   \n",
       "1           None   \n",
       "2           None   \n",
       "3           None   \n",
       "4           None   \n",
       "..           ...   \n",
       "59          None   \n",
       "60          None   \n",
       "61          None   \n",
       "62          None   \n",
       "63          None   \n",
       "\n",
       "                                                                                                                                                                                                                child_hyperparameters  \\\n",
       "0                                                                                                                                                                                     {'learning_rate': 0.05, 'num_boost_round': 221}   \n",
       "1                                                                                     {'n_estimators': 105, 'learning_rate': 0.1, 'n_jobs': -1, 'proc.max_category_levels': 100, 'objective': 'binary:logistic', 'booster': 'gbtree'}   \n",
       "2                                                                                                                                                                {'learning_rate': 0.05, 'extra_trees': True, 'num_boost_round': 328}   \n",
       "3                                                                                                                                                                                    {'ensemble_size': 25, 'subsample_size': 1000000}   \n",
       "4                                                                                                                  {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'num_boost_round': 342}   \n",
       "..                                                                                                                                                                                                                                ...   \n",
       "59  {'layers': [400, 200, 100], 'emb_drop': 0.44339037504795686, 'ps': 0.19220253419114286, 'bs': 128, 'lr': 0.008615195908919904, 'epochs': 31, 'early.stopping.min_delta': 0.0001, 'early.stopping.patience': 20, 'smoothing': 0.0}   \n",
       "60                                                                                  {'n_estimators': 10000, 'learning_rate': 0.1, 'n_jobs': -1, 'proc.max_category_levels': 100, 'objective': 'binary:logistic', 'booster': 'gbtree'}   \n",
       "61                                                      {'layers': None, 'emb_drop': 0.1, 'ps': 0.1, 'bs': 'auto', 'lr': 0.01, 'epochs': 'auto', 'early.stopping.min_delta': 0.0001, 'early.stopping.patience': 20, 'smoothing': 0.0}   \n",
       "62                                                      {'layers': None, 'emb_drop': 0.1, 'ps': 0.1, 'bs': 'auto', 'lr': 0.01, 'epochs': 'auto', 'early.stopping.min_delta': 0.0001, 'early.stopping.patience': 20, 'smoothing': 0.0}   \n",
       "63       {'layers': [200, 100], 'emb_drop': 0.05070411322605811, 'ps': 0.10393466140748028, 'bs': 2048, 'lr': 0.08974235041576624, 'epochs': 29, 'early.stopping.min_delta': 0.0001, 'early.stopping.patience': 20, 'smoothing': 0.0}   \n",
       "\n",
       "           child_hyperparameters_fit  \\\n",
       "0           {'num_boost_round': 221}   \n",
       "1                                 {}   \n",
       "2           {'num_boost_round': 328}   \n",
       "3               {'ensemble_size': 1}   \n",
       "4           {'num_boost_round': 342}   \n",
       "..                               ...   \n",
       "59  {'epochs': 31, 'best_epoch': 12}   \n",
       "60              {'n_estimators': 52}   \n",
       "61  {'epochs': 30, 'best_epoch': 19}   \n",
       "62  {'epochs': 30, 'best_epoch': 20}   \n",
       "63   {'epochs': 29, 'best_epoch': 8}   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                              child_ag_args_fit  \\\n",
       "0                                 {'max_memory_usage_ratio': 1.0, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': ['bool', 'int', 'float', 'category'], 'valid_special_types': None, 'ignored_type_group_special': None, 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'temperature_scalar': None}   \n",
       "1                                 {'max_memory_usage_ratio': 1.0, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': ['bool', 'int', 'float', 'category'], 'valid_special_types': None, 'ignored_type_group_special': None, 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'temperature_scalar': None}   \n",
       "2                                 {'max_memory_usage_ratio': 1.0, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': ['bool', 'int', 'float', 'category'], 'valid_special_types': None, 'ignored_type_group_special': None, 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'temperature_scalar': None}   \n",
       "3                                           {'max_memory_usage_ratio': 1.0, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': None, 'valid_special_types': None, 'ignored_type_group_special': None, 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'temperature_scalar': None, 'drop_unique': False}   \n",
       "4                                 {'max_memory_usage_ratio': 1.0, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': ['bool', 'int', 'float', 'category'], 'valid_special_types': None, 'ignored_type_group_special': None, 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'temperature_scalar': None}   \n",
       "..                                                                                                                                                                                                                                                                                                                                                                                                                          ...   \n",
       "59  {'max_memory_usage_ratio': 1.0, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': ['bool', 'int', 'float', 'category'], 'valid_special_types': None, 'ignored_type_group_special': ['text_ngram', 'text_as_category'], 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'temperature_scalar': None}   \n",
       "60                                {'max_memory_usage_ratio': 1.0, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': ['bool', 'int', 'float', 'category'], 'valid_special_types': None, 'ignored_type_group_special': None, 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'temperature_scalar': None}   \n",
       "61  {'max_memory_usage_ratio': 1.0, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': ['bool', 'int', 'float', 'category'], 'valid_special_types': None, 'ignored_type_group_special': ['text_ngram', 'text_as_category'], 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'temperature_scalar': None}   \n",
       "62  {'max_memory_usage_ratio': 1.0, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': ['bool', 'int', 'float', 'category'], 'valid_special_types': None, 'ignored_type_group_special': ['text_ngram', 'text_as_category'], 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'temperature_scalar': None}   \n",
       "63  {'max_memory_usage_ratio': 1.0, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': ['bool', 'int', 'float', 'category'], 'valid_special_types': None, 'ignored_type_group_special': ['text_ngram', 'text_as_category'], 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'temperature_scalar': None}   \n",
       "\n",
       "                                                                            ancestors  \\\n",
       "0                                                                                  []   \n",
       "1                                                                                  []   \n",
       "2                                                                                  []   \n",
       "3                                                            [LightGBMXT_BAG_L1_FULL]   \n",
       "4                                                                                  []   \n",
       "..                                                                                ...   \n",
       "59                                                                                 []   \n",
       "60  [NeuralNetFastAI_r191_BAG_L1, CatBoost_BAG_L1, XGBoost_BAG_L1, LightGBMXT_BAG_L1]   \n",
       "61                                                                                 []   \n",
       "62  [NeuralNetFastAI_r191_BAG_L1, CatBoost_BAG_L1, XGBoost_BAG_L1, LightGBMXT_BAG_L1]   \n",
       "63                                                                                 []   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                             descendants  \n",
       "0                                                                                                                                                                                                                                                                                                                                                                                                     []  \n",
       "1                                                       [CatBoost_r9_BAG_L2_FULL, LightGBMXT_BAG_L2_FULL, CatBoost_r177_BAG_L2_FULL, LightGBM_r131_BAG_L2_FULL, CatBoost_BAG_L2_FULL, XGBoost_BAG_L2_FULL, LightGBMLarge_BAG_L2_FULL, LightGBM_r96_BAG_L2_FULL, CatBoost_r137_BAG_L2_FULL, NeuralNetFastAI_BAG_L2_FULL, NeuralNetFastAI_r191_BAG_L2_FULL, XGBoost_r33_BAG_L2_FULL, LightGBM_BAG_L2_FULL]  \n",
       "2   [CatBoost_r9_BAG_L2_FULL, WeightedEnsemble_L2_FULL, LightGBMXT_BAG_L2_FULL, CatBoost_r177_BAG_L2_FULL, LightGBM_r131_BAG_L2_FULL, CatBoost_BAG_L2_FULL, XGBoost_BAG_L2_FULL, LightGBMLarge_BAG_L2_FULL, WeightedEnsemble_L3_FULL, LightGBM_r96_BAG_L2_FULL, CatBoost_r137_BAG_L2_FULL, NeuralNetFastAI_BAG_L2_FULL, NeuralNetFastAI_r191_BAG_L2_FULL, XGBoost_r33_BAG_L2_FULL, LightGBM_BAG_L2_FULL]  \n",
       "3                                                                                                                                                                                                                                                                                                                                                                                                     []  \n",
       "4                                                                                                                                                                                                                                                                                                                                                                                                     []  \n",
       "..                                                                                                                                                                                                                                                                                                                                                                                                   ...  \n",
       "59                                                                                                                                                                                                                                                                                                                                                                                                    []  \n",
       "60                                                                                                                                                                                                                                                                                                                                                                                                    []  \n",
       "61                                                                                                                                                                                                                                                                                                                                                                                                    []  \n",
       "62                                                                                                                                                                                                                                                                                                                                                                                                    []  \n",
       "63                                                                                                                                                                                                                                                                                                                                                                                                    []  \n",
       "\n",
       "[64 rows x 45 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "These features in provided data are not utilized by the predictor and will be ignored: ['clin-Covid_sintomaSarpullido', 'ques-MMSE-fijacion-PD']\n",
      "Computing feature importance via permutation shuffling for 81 features using 382 rows with 5 shuffle sets...\n",
      "\t25.67s\t= Expected runtime (5.13s per shuffle set)\n",
      "\t6.21s\t= Actual runtime (Completed 5 of 5 shuffle sets)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>importance</th>\n",
       "      <th>stddev</th>\n",
       "      <th>p_value</th>\n",
       "      <th>n</th>\n",
       "      <th>p99_high</th>\n",
       "      <th>p99_low</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>etiq-diagExpTLPcode</th>\n",
       "      <td>0.272791</td>\n",
       "      <td>0.025795</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>5</td>\n",
       "      <td>0.325903</td>\n",
       "      <td>0.219678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>etiq-diagExpTLPtext</th>\n",
       "      <td>0.003265</td>\n",
       "      <td>0.002156</td>\n",
       "      <td>0.013821</td>\n",
       "      <td>5</td>\n",
       "      <td>0.007705</td>\n",
       "      <td>-0.001175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eval-TLP-Tavec-32_Recon_Ac_frente_RL_LP-PD</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eval-TLP-Tavec-3_RI_AT-PD</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eval-TLP-Tavec-10_RL_LP-PD</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ques-NavEspacial-All-PD</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ques-QuejasMemo-Total-PD</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>clin-tipoAlcohol</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>clin-añosSinFumar</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eval-TLP-Tavec-33_Recon_Ac_frente_RCl_LP-PD</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>81 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             importance    stddev   p_value  \\\n",
       "etiq-diagExpTLPcode                            0.272791  0.025795  0.000009   \n",
       "etiq-diagExpTLPtext                            0.003265  0.002156  0.013821   \n",
       "eval-TLP-Tavec-32_Recon_Ac_frente_RL_LP-PD     0.000000  0.000000  0.500000   \n",
       "eval-TLP-Tavec-3_RI_AT-PD                      0.000000  0.000000  0.500000   \n",
       "eval-TLP-Tavec-10_RL_LP-PD                     0.000000  0.000000  0.500000   \n",
       "...                                                 ...       ...       ...   \n",
       "ques-NavEspacial-All-PD                        0.000000  0.000000  0.500000   \n",
       "ques-QuejasMemo-Total-PD                       0.000000  0.000000  0.500000   \n",
       "clin-tipoAlcohol                               0.000000  0.000000  0.500000   \n",
       "clin-añosSinFumar                              0.000000  0.000000  0.500000   \n",
       "eval-TLP-Tavec-33_Recon_Ac_frente_RCl_LP-PD    0.000000  0.000000  0.500000   \n",
       "\n",
       "                                             n  p99_high   p99_low  \n",
       "etiq-diagExpTLPcode                          5  0.325903  0.219678  \n",
       "etiq-diagExpTLPtext                          5  0.007705 -0.001175  \n",
       "eval-TLP-Tavec-32_Recon_Ac_frente_RL_LP-PD   5  0.000000  0.000000  \n",
       "eval-TLP-Tavec-3_RI_AT-PD                    5  0.000000  0.000000  \n",
       "eval-TLP-Tavec-10_RL_LP-PD                   5  0.000000  0.000000  \n",
       "...                                         ..       ...       ...  \n",
       "ques-NavEspacial-All-PD                      5  0.000000  0.000000  \n",
       "ques-QuejasMemo-Total-PD                     5  0.000000  0.000000  \n",
       "clin-tipoAlcohol                             5  0.000000  0.000000  \n",
       "clin-añosSinFumar                            5  0.000000  0.000000  \n",
       "eval-TLP-Tavec-33_Recon_Ac_frente_RCl_LP-PD  5  0.000000  0.000000  \n",
       "\n",
       "[81 rows x 6 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.feature_importance(data=df_train)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
