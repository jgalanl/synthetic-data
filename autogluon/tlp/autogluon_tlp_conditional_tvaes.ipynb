{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from autogluon.tabular import TabularPredictor\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../../data/tlp/conditional-tvaes.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>demo-genero</th>\n",
       "      <th>demo-fechaEvaluacion</th>\n",
       "      <th>demo-fechaNacimiento</th>\n",
       "      <th>demo-rangoEdad</th>\n",
       "      <th>demo-edad</th>\n",
       "      <th>clin-reservaCognitiva_total</th>\n",
       "      <th>clin-reservaCognitiva_idiomas</th>\n",
       "      <th>clin-reservaCognitiva_ocupacion</th>\n",
       "      <th>clin-reservaCognitiva_escolaridad</th>\n",
       "      <th>clin-ansiedad</th>\n",
       "      <th>...</th>\n",
       "      <th>eval-TLP-Tavec-25_Discriminabilidad-PD</th>\n",
       "      <th>eval-TLP-Tavec-26_Sesgo-PD</th>\n",
       "      <th>eval-TLP-Tavec-27_RI_B_frente_RI_A1-PD</th>\n",
       "      <th>eval-TLP-Tavec-28_RL_CP_frente_RI_A5-PD</th>\n",
       "      <th>eval-TLP-Tavec-29_RCl_Cp_frente_RCl_LP-PD</th>\n",
       "      <th>eval-TLP-Tavec-30_RL_LP_frente_RL_CP-PD</th>\n",
       "      <th>eval-TLP-Tavec-31_RCl_LP_frente_RL_LP-PD</th>\n",
       "      <th>eval-TLP-Tavec-32_Recon_Ac_frente_RL_LP-PD</th>\n",
       "      <th>eval-TLP-Tavec-33_Recon_Ac_frente_RCl_LP-PD</th>\n",
       "      <th>ED_2Clases</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>2024-04-01T02:57:09</td>\n",
       "      <td>1957-08-23T13:14:06</td>\n",
       "      <td>Rango2</td>\n",
       "      <td>69</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>98.62</td>\n",
       "      <td>0.03</td>\n",
       "      <td>451.46</td>\n",
       "      <td>1983.23</td>\n",
       "      <td>-50.00</td>\n",
       "      <td>662.15</td>\n",
       "      <td>5.19</td>\n",
       "      <td>-0.90</td>\n",
       "      <td>-11.62</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2024-03-03T18:56:48</td>\n",
       "      <td>1948-03-17T08:37:02</td>\n",
       "      <td>Rango2</td>\n",
       "      <td>76</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>89.10</td>\n",
       "      <td>0.48</td>\n",
       "      <td>61.55</td>\n",
       "      <td>5865.54</td>\n",
       "      <td>-50.00</td>\n",
       "      <td>3023.67</td>\n",
       "      <td>-10.46</td>\n",
       "      <td>-29.40</td>\n",
       "      <td>-19.61</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2024-03-13T14:27:03</td>\n",
       "      <td>1950-06-24T21:56:13</td>\n",
       "      <td>Rango3</td>\n",
       "      <td>66</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>94.22</td>\n",
       "      <td>0.31</td>\n",
       "      <td>141.23</td>\n",
       "      <td>-100.00</td>\n",
       "      <td>-15.02</td>\n",
       "      <td>83.85</td>\n",
       "      <td>-8.94</td>\n",
       "      <td>-9.28</td>\n",
       "      <td>-19.99</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>2024-05-27T21:25:12</td>\n",
       "      <td>1956-11-05T18:38:57</td>\n",
       "      <td>Rango2</td>\n",
       "      <td>68</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>90.04</td>\n",
       "      <td>0.54</td>\n",
       "      <td>-71.43</td>\n",
       "      <td>2637.20</td>\n",
       "      <td>-50.00</td>\n",
       "      <td>-100.00</td>\n",
       "      <td>-0.80</td>\n",
       "      <td>-60.41</td>\n",
       "      <td>-20.56</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2024-04-30T03:24:45</td>\n",
       "      <td>1950-08-11T12:09:27</td>\n",
       "      <td>Rango2</td>\n",
       "      <td>64</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>86.35</td>\n",
       "      <td>-0.46</td>\n",
       "      <td>456.97</td>\n",
       "      <td>734.99</td>\n",
       "      <td>-50.00</td>\n",
       "      <td>-100.00</td>\n",
       "      <td>6.49</td>\n",
       "      <td>-20.69</td>\n",
       "      <td>-21.72</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 77 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   demo-genero demo-fechaEvaluacion demo-fechaNacimiento demo-rangoEdad  \\\n",
       "0            2  2024-04-01T02:57:09  1957-08-23T13:14:06         Rango2   \n",
       "1            2  2024-03-03T18:56:48  1948-03-17T08:37:02         Rango2   \n",
       "2            1  2024-03-13T14:27:03  1950-06-24T21:56:13         Rango3   \n",
       "3            2  2024-05-27T21:25:12  1956-11-05T18:38:57         Rango2   \n",
       "4            1  2024-04-30T03:24:45  1950-08-11T12:09:27         Rango2   \n",
       "\n",
       "   demo-edad  clin-reservaCognitiva_total  clin-reservaCognitiva_idiomas  \\\n",
       "0         69                           16                              0   \n",
       "1         76                           18                              1   \n",
       "2         66                           21                              1   \n",
       "3         68                           13                              0   \n",
       "4         64                           16                              1   \n",
       "\n",
       "   clin-reservaCognitiva_ocupacion  clin-reservaCognitiva_escolaridad  \\\n",
       "0                                2                                  4   \n",
       "1                                1                                  5   \n",
       "2                                3                                  5   \n",
       "3                                0                                  3   \n",
       "4                                2                                  4   \n",
       "\n",
       "   clin-ansiedad  ...  eval-TLP-Tavec-25_Discriminabilidad-PD  \\\n",
       "0           True  ...                                   98.62   \n",
       "1           True  ...                                   89.10   \n",
       "2           True  ...                                   94.22   \n",
       "3           True  ...                                   90.04   \n",
       "4          False  ...                                   86.35   \n",
       "\n",
       "   eval-TLP-Tavec-26_Sesgo-PD  eval-TLP-Tavec-27_RI_B_frente_RI_A1-PD  \\\n",
       "0                        0.03                                  451.46   \n",
       "1                        0.48                                   61.55   \n",
       "2                        0.31                                  141.23   \n",
       "3                        0.54                                  -71.43   \n",
       "4                       -0.46                                  456.97   \n",
       "\n",
       "   eval-TLP-Tavec-28_RL_CP_frente_RI_A5-PD  \\\n",
       "0                                  1983.23   \n",
       "1                                  5865.54   \n",
       "2                                  -100.00   \n",
       "3                                  2637.20   \n",
       "4                                   734.99   \n",
       "\n",
       "   eval-TLP-Tavec-29_RCl_Cp_frente_RCl_LP-PD  \\\n",
       "0                                     -50.00   \n",
       "1                                     -50.00   \n",
       "2                                     -15.02   \n",
       "3                                     -50.00   \n",
       "4                                     -50.00   \n",
       "\n",
       "   eval-TLP-Tavec-30_RL_LP_frente_RL_CP-PD  \\\n",
       "0                                   662.15   \n",
       "1                                  3023.67   \n",
       "2                                    83.85   \n",
       "3                                  -100.00   \n",
       "4                                  -100.00   \n",
       "\n",
       "   eval-TLP-Tavec-31_RCl_LP_frente_RL_LP-PD  \\\n",
       "0                                      5.19   \n",
       "1                                    -10.46   \n",
       "2                                     -8.94   \n",
       "3                                     -0.80   \n",
       "4                                      6.49   \n",
       "\n",
       "   eval-TLP-Tavec-32_Recon_Ac_frente_RL_LP-PD  \\\n",
       "0                                       -0.90   \n",
       "1                                      -29.40   \n",
       "2                                       -9.28   \n",
       "3                                      -60.41   \n",
       "4                                      -20.69   \n",
       "\n",
       "   eval-TLP-Tavec-33_Recon_Ac_frente_RCl_LP-PD  ED_2Clases  \n",
       "0                                       -11.62           D  \n",
       "1                                       -19.61           D  \n",
       "2                                       -19.99           D  \n",
       "3                                       -20.56           D  \n",
       "4                                       -21.72           D  \n",
       "\n",
       "[5 rows x 77 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4800, 77), (1200, 77))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train, df_test = train_test_split(df, test_size=0.2, random_state=42)\n",
    "df_train.shape, df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"AutogluonModels/synthetic/tvaes/v2\"\n"
     ]
    }
   ],
   "source": [
    "predictor= TabularPredictor(\n",
    "    label='ED_2Clases',\n",
    "    problem_type='binary',\n",
    "    eval_metric='roc_auc',\n",
    "    sample_weight='balance_weight',\n",
    "    path='AutogluonModels/synthetic/tvaes/v2'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.2\n",
      "Python Version:     3.10.2\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.26100\n",
      "CPU Count:          12\n",
      "Memory Avail:       11.73 GB / 15.94 GB (73.6%)\n",
      "Disk Space Avail:   92.38 GB / 446.36 GB (20.7%)\n",
      "===================================================\n",
      "Presets specified: ['high_quality']\n",
      "Setting dynamic_stacking from 'auto' to True. Reason: Enable dynamic_stacking when use_bag_holdout is disabled. (use_bag_holdout=False)\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=1\n",
      "Note: `save_bag_folds=False`! This will greatly reduce peak disk usage during fit (by ~8x), but runs the risk of an out-of-memory error during model refit if memory is small relative to the data size.\n",
      "\tYou can avoid this risk by setting `save_bag_folds=True`.\n",
      "DyStack is enabled (dynamic_stacking=True). AutoGluon will try to determine whether the input data is affected by stacked overfitting and enable or disable stacking as a consequence.\n",
      "\tThis is used to identify the optimal `num_stack_levels` value. Copies of AutoGluon will be fit on subsets of the data. Then holdout validation data is used to detect stacked overfitting.\n",
      "\tRunning DyStack for up to 900s of the 3600s of remaining time (25%).\n",
      "\tRunning DyStack sub-fit in a ray process to avoid memory leakage. Enabling ray logging (enable_ray_logging=True). Specify `ds_args={'enable_ray_logging': False}` if you experience logging issues.\n",
      "2025-01-31 15:18:57,921\tINFO worker.py:1743 -- Started a local Ray instance. View the dashboard at \u001b[1m\u001b[32m127.0.0.1:8265 \u001b[39m\u001b[22m\n",
      "\t\tContext path: \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\autogluon\\tlp\\AutogluonModels\\synthetic\\tvaes\\v2\\ds_sub_fit\\sub_fit_ho\"\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m Running DyStack sub-fit ...\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m Using predefined sample weighting strategy: balance_weight. Evaluation metrics will ignore sample weights, specify weight_evaluation=True to instead report weighted metrics.\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m Beginning AutoGluon training ... Time limit = 895s\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m AutoGluon will save models to \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\autogluon\\tlp\\AutogluonModels\\synthetic\\tvaes\\v2\\ds_sub_fit\\sub_fit_ho\"\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m Train Data Rows:    4266\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m Train Data Columns: 76\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m Label Column:       ED_2Clases\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m Problem Type:       binary\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m Preprocessing data ...\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m Selected class <--> label mapping:  class 1 = H, class 0 = D\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m \tNote: For your binary classification, AutoGluon arbitrarily selected which label-value represents positive (H) vs negative (D) class.\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m \tTo explicitly set the positive_class, either rename classes to 1 and 0, or specify positive_class in Predictor init.\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m Assigning sample weights to balance differences in frequency of classes.\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m Using Feature Generators to preprocess the data ...\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m Fitting AutoMLPipelineFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m \tAvailable Memory:                    11471.83 MB\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m \tTrain Data (Original)  Memory Usage: 2.99 MB (0.0% of available memory)\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m \tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m \tStage 1 Generators:\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m \t\tFitting AsTypeFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m \t\t\tNote: Converting 10 features to boolean dtype as they only contain 2 unique values.\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m \tStage 2 Generators:\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m \t\tFitting FillNaFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m \tStage 3 Generators:\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m \t\tFitting IdentityFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m \t\tFitting CategoryFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m \t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m \t\tFitting DatetimeFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m \tStage 4 Generators:\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m \t\tFitting DropUniqueFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m \tStage 5 Generators:\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m \t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m \tUseless Original Features (Count: 1): ['clin-Covid_sintomaSarpullido']\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m \t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m \t\tThis is typically a feature which has the same value for all rows.\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m \t\tThese features do not need to be present at inference time.\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m \tTypes of features in original data (raw dtype, special dtypes):\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m \t\t('bool', [])                       :  8 | ['clin-ansiedad', 'clin-depresion', 'clin-cardiopatiaIsquemica', 'clin-diabetes', 'clin-Hipercolesterolemia', ...]\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m \t\t('float', [])                      : 15 | ['ques-Sus-total-PD', 'eval-TLP-FigRey-totalCopia-PD', 'eval-TLP-FigRey-totalMemoria-PD', 'eval-TLP-Tavec-5_Rg_Pr-PD', 'eval-TLP-Tavec-6_Rg_Md-PD', ...]\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m \t\t('int', [])                        : 49 | ['demo-genero', 'demo-edad', 'clin-reservaCognitiva_total', 'clin-reservaCognitiva_idiomas', 'clin-reservaCognitiva_ocupacion', ...]\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m \t\t('object', [])                     :  1 | ['demo-rangoEdad']\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m \t\t('object', ['datetime_as_object']) :  2 | ['demo-fechaEvaluacion', 'demo-fechaNacimiento']\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m \tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m \t\t('category', [])             :  1 | ['demo-rangoEdad']\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m \t\t('float', [])                : 15 | ['ques-Sus-total-PD', 'eval-TLP-FigRey-totalCopia-PD', 'eval-TLP-FigRey-totalMemoria-PD', 'eval-TLP-Tavec-5_Rg_Pr-PD', 'eval-TLP-Tavec-6_Rg_Md-PD', ...]\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m \t\t('int', [])                  : 47 | ['demo-edad', 'clin-reservaCognitiva_total', 'clin-reservaCognitiva_idiomas', 'clin-reservaCognitiva_ocupacion', 'clin-reservaCognitiva_escolaridad', ...]\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m \t\t('int', ['bool'])            : 10 | ['demo-genero', 'clin-ansiedad', 'clin-depresion', 'clin-cardiopatiaIsquemica', 'clin-diabetes', ...]\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m \t\t('int', ['datetime_as_int']) :  9 | ['demo-fechaEvaluacion', 'demo-fechaEvaluacion.month', 'demo-fechaEvaluacion.day', 'demo-fechaEvaluacion.dayofweek', 'demo-fechaNacimiento', ...]\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m \t0.1s = Fit runtime\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m \t75 features in original data used to generate 82 features in processed data.\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m \tTrain Data (Processed) Memory Usage: 2.36 MB (0.0% of available memory)\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m Data preprocessing and feature engineering runtime = 0.13s ...\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m AutoGluon will gauge predictive performance using evaluation metric: 'roc_auc'\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m \tThis metric expects predicted probabilities rather than predicted class labels, so you'll need to use predict_proba() instead of predict()\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m \tTo change this, specify the eval_metric parameter of Predictor()\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m Large model count detected (112 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m User-specified model hyperparameters to be fit:\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m {\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m \t'NN_TORCH': [{}, {'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2}}, {'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7}}],\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m \t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m \t'CAT': [{}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5}}],\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m \t'XGB': [{}, {'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'name_suffix': '_r33', 'priority': -8}}, {'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'name_suffix': '_r89', 'priority': -16}}],\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m \t'FASTAI': [{}, {'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4}}, {'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11}}],\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m \t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m \t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m \t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m }\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m Excluded models: ['RF', 'KNN', 'XT'] (Specified by `excluded_model_types`)\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m Fitting 90 L1 models, fit_strategy=\"sequential\" ...\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 596.55s of the 895.05s of remaining time.\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.27%)\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m \t0.8994\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m \t3.42s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m \t0.2s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m Fitting model: LightGBM_BAG_L1 ... Training model for up to 587.54s of the 886.03s of remaining time.\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.29%)\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m \t0.8976\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m \t3.24s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m \t0.13s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m Fitting model: CatBoost_BAG_L1 ... Training model for up to 581.07s of the 879.57s of remaining time.\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.45%)\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m \t0.8966\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m \t51.74s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m \t0.06s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 525.94s of the 824.43s of remaining time.\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.24%)\n",
      "\u001b[36m(_ray_fit pid=19288)\u001b[0m No improvement since epoch 2: early stopping\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m \t0.866\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m \t9.08s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m \t0.15s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m Fitting model: XGBoost_BAG_L1 ... Training model for up to 513.80s of the 812.29s of remaining time.\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.61%)\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m \t0.8941\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m \t4.34s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m \t0.1s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m Fitting model: NeuralNetTorch_BAG_L1 ... Training model for up to 505.59s of the 804.09s of remaining time.\n",
      "\u001b[36m(_ray_fit pid=17124)\u001b[0m No improvement since epoch 3: early stopping\u001b[32m [repeated 7x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/ray-logging.html#log-deduplication for more options.)\u001b[0m\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.14%)\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m \tWarning: Exception caused NeuralNetTorch_BAG_L1 to fail during training... Skipping this model.\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m \t\t\u001b[36mray::_ray_fit()\u001b[39m (pid=16508, ip=127.0.0.1)\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m   File \"python\\ray\\_raylet.pyx\", line 1889, in ray._raylet.execute_task\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m     fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m     out = self._fit(**kwargs)\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 201, in _fit\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m     train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m     dataset = self._process_train_data(\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m     self.processor = create_preprocessor(\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\utils\\data_preprocessor.py\", line 40, in create_preprocessor\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m     return ColumnTransformer(\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m Detailed Traceback:\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 2106, in _train_and_save\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m     model = self._train_single(**model_fit_kwargs)\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 1993, in _train_single\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m     model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m     out = self._fit(**kwargs)\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\stacker_ensemble_model.py\", line 270, in _fit\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m     return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\bagged_ensemble_model.py\", line 298, in _fit\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m     self._fit_folds(\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\bagged_ensemble_model.py\", line 724, in _fit_folds\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m     fold_fitting_strategy.after_all_folds_scheduled()\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 690, in after_all_folds_scheduled\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m     self._run_parallel(X, y, X_pseudo, y_pseudo, model_base_ref, time_limit_fold, head_node_id)\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 631, in _run_parallel\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m     self._process_fold_results(finished, unfinished, fold_ctx)\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 587, in _process_fold_results\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m     raise processed_exception\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 550, in _process_fold_results\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m     fold_model, pred_proba, time_start_fit, time_end_fit, predict_time, predict_1_time, predict_n_size, fit_num_cpus, fit_num_gpus = self.ray.get(finished)\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m     return fn(*args, **kwargs)\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\client_mode_hook.py\", line 103, in wrapper\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m     return func(*args, **kwargs)\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\worker.py\", line 2667, in get\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m     values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\worker.py\", line 864, in get_objects\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m     raise value.as_instanceof_cause()\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m ray.exceptions.RayTaskError(TypeError): \u001b[36mray::_ray_fit()\u001b[39m (pid=16508, ip=127.0.0.1)\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m   File \"python\\ray\\_raylet.pyx\", line 1889, in ray._raylet.execute_task\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m     fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m     out = self._fit(**kwargs)\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 201, in _fit\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m     train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m     dataset = self._process_train_data(\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m     self.processor = create_preprocessor(\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\utils\\data_preprocessor.py\", line 40, in create_preprocessor\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m     return ColumnTransformer(\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m Fitting model: LightGBMLarge_BAG_L1 ... Training model for up to 498.95s of the 797.45s of remaining time.\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.88%)\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m \t0.8821\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m \t7.64s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m \t0.12s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m Fitting model: CatBoost_r177_BAG_L1 ... Training model for up to 487.97s of the 786.47s of remaining time.\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.51%)\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m \t0.8975\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m \t16.64s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m \t0.06s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m Fitting model: NeuralNetTorch_r79_BAG_L1 ... Training model for up to 467.84s of the 766.34s of remaining time.\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.14%)\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m \tWarning: Exception caused NeuralNetTorch_r79_BAG_L1 to fail during training... Skipping this model.\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m \t\t\u001b[36mray::_ray_fit()\u001b[39m (pid=23452, ip=127.0.0.1)\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m   File \"python\\ray\\_raylet.pyx\", line 1889, in ray._raylet.execute_task\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m     fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m     out = self._fit(**kwargs)\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 201, in _fit\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m     train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m     dataset = self._process_train_data(\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m     self.processor = create_preprocessor(\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\utils\\data_preprocessor.py\", line 40, in create_preprocessor\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m     return ColumnTransformer(\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m Detailed Traceback:\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 2106, in _train_and_save\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m     model = self._train_single(**model_fit_kwargs)\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 1993, in _train_single\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m     model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m     out = self._fit(**kwargs)\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\stacker_ensemble_model.py\", line 270, in _fit\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m     return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\bagged_ensemble_model.py\", line 298, in _fit\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m     self._fit_folds(\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\bagged_ensemble_model.py\", line 724, in _fit_folds\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m     fold_fitting_strategy.after_all_folds_scheduled()\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 690, in after_all_folds_scheduled\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m     self._run_parallel(X, y, X_pseudo, y_pseudo, model_base_ref, time_limit_fold, head_node_id)\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 631, in _run_parallel\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m     self._process_fold_results(finished, unfinished, fold_ctx)\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 587, in _process_fold_results\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m     raise processed_exception\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 550, in _process_fold_results\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m     fold_model, pred_proba, time_start_fit, time_end_fit, predict_time, predict_1_time, predict_n_size, fit_num_cpus, fit_num_gpus = self.ray.get(finished)\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m     return fn(*args, **kwargs)\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\client_mode_hook.py\", line 103, in wrapper\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m     return func(*args, **kwargs)\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\worker.py\", line 2667, in get\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m     values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\worker.py\", line 864, in get_objects\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m     raise value.as_instanceof_cause()\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m ray.exceptions.RayTaskError(TypeError): \u001b[36mray::_ray_fit()\u001b[39m (pid=23452, ip=127.0.0.1)\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m   File \"python\\ray\\_raylet.pyx\", line 1889, in ray._raylet.execute_task\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m     fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m     out = self._fit(**kwargs)\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 201, in _fit\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m     train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m     dataset = self._process_train_data(\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m     self.processor = create_preprocessor(\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\utils\\data_preprocessor.py\", line 40, in create_preprocessor\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m     return ColumnTransformer(\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m Fitting model: LightGBM_r131_BAG_L1 ... Training model for up to 461.59s of the 760.09s of remaining time.\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.51%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=24448)\u001b[0m [1000]\tvalid_set's binary_logloss: 0.389774\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_dystack pid=13492)\u001b[0m \t0.8982\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m \t7.24s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m \t0.38s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m Fitting model: NeuralNetFastAI_r191_BAG_L1 ... Training model for up to 450.95s of the 749.44s of remaining time.\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.33%)\n",
      "\u001b[36m(_ray_fit pid=24192)\u001b[0m No improvement since epoch 1: early stopping\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m \t0.865\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m \t17.42s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m \t0.26s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m Fitting model: CatBoost_r9_BAG_L1 ... Training model for up to 430.12s of the 728.61s of remaining time.\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=2.14%)\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m \t0.8961\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m \t142.17s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m \t0.08s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m Fitting model: LightGBM_r96_BAG_L1 ... Training model for up to 284.13s of the 582.63s of remaining time.\n",
      "\u001b[36m(_ray_fit pid=25596)\u001b[0m No improvement since epoch 3: early stopping\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.28%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=23944)\u001b[0m [1000]\tvalid_set's binary_logloss: 0.416472\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=19652)\u001b[0m [4000]\tvalid_set's binary_logloss: 0.37888\u001b[32m [repeated 24x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_dystack pid=13492)\u001b[0m \t0.9054\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m \t8.89s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m \t1.11s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m Fitting model: NeuralNetTorch_r22_BAG_L1 ... Training model for up to 272.00s of the 570.49s of remaining time.\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.17%)\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m \tWarning: Exception caused NeuralNetTorch_r22_BAG_L1 to fail during training... Skipping this model.\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m \t\t\u001b[36mray::_ray_fit()\u001b[39m (pid=19516, ip=127.0.0.1)\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m   File \"python\\ray\\_raylet.pyx\", line 1889, in ray._raylet.execute_task\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m     fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m     out = self._fit(**kwargs)\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 201, in _fit\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m     train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m     dataset = self._process_train_data(\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m     self.processor = create_preprocessor(\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\utils\\data_preprocessor.py\", line 40, in create_preprocessor\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m     return ColumnTransformer(\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m Detailed Traceback:\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 2106, in _train_and_save\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m     model = self._train_single(**model_fit_kwargs)\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 1993, in _train_single\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m     model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m     out = self._fit(**kwargs)\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\stacker_ensemble_model.py\", line 270, in _fit\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m     return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\bagged_ensemble_model.py\", line 298, in _fit\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m     self._fit_folds(\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\bagged_ensemble_model.py\", line 724, in _fit_folds\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m     fold_fitting_strategy.after_all_folds_scheduled()\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 690, in after_all_folds_scheduled\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m     self._run_parallel(X, y, X_pseudo, y_pseudo, model_base_ref, time_limit_fold, head_node_id)\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 631, in _run_parallel\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m     self._process_fold_results(finished, unfinished, fold_ctx)\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 587, in _process_fold_results\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m     raise processed_exception\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 550, in _process_fold_results\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m     fold_model, pred_proba, time_start_fit, time_end_fit, predict_time, predict_1_time, predict_n_size, fit_num_cpus, fit_num_gpus = self.ray.get(finished)\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m     return fn(*args, **kwargs)\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\client_mode_hook.py\", line 103, in wrapper\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m     return func(*args, **kwargs)\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\worker.py\", line 2667, in get\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m     values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\worker.py\", line 864, in get_objects\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m     raise value.as_instanceof_cause()\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m ray.exceptions.RayTaskError(TypeError): \u001b[36mray::_ray_fit()\u001b[39m (pid=19516, ip=127.0.0.1)\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m   File \"python\\ray\\_raylet.pyx\", line 1889, in ray._raylet.execute_task\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m     fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m     out = self._fit(**kwargs)\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 201, in _fit\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m     train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m     dataset = self._process_train_data(\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m     self.processor = create_preprocessor(\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\utils\\data_preprocessor.py\", line 40, in create_preprocessor\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m     return ColumnTransformer(\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): \u001b[36mray::_ray_fit()\u001b[39m (pid=20596, ip=127.0.0.1)\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m   File \"python\\ray\\_raylet.pyx\", line 1889, in ray._raylet.execute_task\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m     fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m     out = self._fit(**kwargs)\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 201, in _fit\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m     train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m     dataset = self._process_train_data(\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m     self.processor = create_preprocessor(\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\utils\\data_preprocessor.py\", line 40, in create_preprocessor\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m     return ColumnTransformer(\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m Fitting model: XGBoost_r33_BAG_L1 ... Training model for up to 265.73s of the 564.23s of remaining time.\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=4.37%)\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m \t0.8888\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m \t21.21s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m \t0.48s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m Fitting model: CatBoost_r137_BAG_L1 ... Training model for up to 241.13s of the 539.62s of remaining time.\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.36%)\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m \t0.8989\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m \t52.51s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m \t0.06s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m Fitting model: NeuralNetFastAI_r102_BAG_L1 ... Training model for up to 185.40s of the 483.90s of remaining time.\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.40%)\n",
      "\u001b[36m(_ray_fit pid=18820)\u001b[0m No improvement since epoch 3: early stopping\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m \t0.8503\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m \t6.31s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m \t0.13s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m Fitting model: CatBoost_r13_BAG_L1 ... Training model for up to 176.00s of the 474.50s of remaining time.\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=3.27%)\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_ray_fit pid=16688)\u001b[0m No improvement since epoch 3: early stopping\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m \t0.8973\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m \t103.71s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m \t0.07s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m Fitting model: LightGBM_r188_BAG_L1 ... Training model for up to 68.40s of the 366.89s of remaining time.\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=1.00%)\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m \t0.8908\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m \t5.42s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m \t0.17s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m Fitting model: NeuralNetFastAI_r145_BAG_L1 ... Training model for up to 59.87s of the 358.37s of remaining time.\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.35%)\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_ray_fit pid=2428)\u001b[0m No improvement since epoch 1: early stopping\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m \t0.8594\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m \t16.86s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m \t0.22s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m Fitting model: XGBoost_r89_BAG_L1 ... Training model for up to 39.83s of the 338.32s of remaining time.\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.65%)\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m \t0.8972\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m \t4.24s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m \t0.13s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m Fitting model: NeuralNetTorch_r30_BAG_L1 ... Training model for up to 32.26s of the 330.76s of remaining time.\n",
      "\u001b[36m(_ray_fit pid=23580)\u001b[0m No improvement since epoch 5: early stopping\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.18%)\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m \tWarning: Exception caused NeuralNetTorch_r30_BAG_L1 to fail during training... Skipping this model.\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m \t\t\u001b[36mray::_ray_fit()\u001b[39m (pid=17764, ip=127.0.0.1)\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m   File \"python\\ray\\_raylet.pyx\", line 1889, in ray._raylet.execute_task\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m     fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m     out = self._fit(**kwargs)\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 201, in _fit\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m     train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m     dataset = self._process_train_data(\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m     self.processor = create_preprocessor(\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\utils\\data_preprocessor.py\", line 40, in create_preprocessor\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m     return ColumnTransformer(\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m Detailed Traceback:\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 2106, in _train_and_save\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m     model = self._train_single(**model_fit_kwargs)\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 1993, in _train_single\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m     model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m     out = self._fit(**kwargs)\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\stacker_ensemble_model.py\", line 270, in _fit\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m     return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\bagged_ensemble_model.py\", line 298, in _fit\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m     self._fit_folds(\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\bagged_ensemble_model.py\", line 724, in _fit_folds\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m     fold_fitting_strategy.after_all_folds_scheduled()\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 690, in after_all_folds_scheduled\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m     self._run_parallel(X, y, X_pseudo, y_pseudo, model_base_ref, time_limit_fold, head_node_id)\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 631, in _run_parallel\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m     self._process_fold_results(finished, unfinished, fold_ctx)\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 587, in _process_fold_results\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m     raise processed_exception\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 550, in _process_fold_results\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m     fold_model, pred_proba, time_start_fit, time_end_fit, predict_time, predict_1_time, predict_n_size, fit_num_cpus, fit_num_gpus = self.ray.get(finished)\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m     return fn(*args, **kwargs)\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\client_mode_hook.py\", line 103, in wrapper\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m     return func(*args, **kwargs)\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\worker.py\", line 2667, in get\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m     values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\worker.py\", line 864, in get_objects\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m     raise value.as_instanceof_cause()\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m ray.exceptions.RayTaskError(TypeError): \u001b[36mray::_ray_fit()\u001b[39m (pid=17764, ip=127.0.0.1)\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m   File \"python\\ray\\_raylet.pyx\", line 1889, in ray._raylet.execute_task\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m     fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m     out = self._fit(**kwargs)\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 201, in _fit\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m     train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m     dataset = self._process_train_data(\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m     self.processor = create_preprocessor(\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\utils\\data_preprocessor.py\", line 40, in create_preprocessor\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m     return ColumnTransformer(\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m Fitting model: LightGBM_r130_BAG_L1 ... Training model for up to 25.76s of the 324.26s of remaining time.\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.97%)\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m \t0.8991\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m \t3.0s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m \t0.14s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m Fitting model: NeuralNetTorch_r86_BAG_L1 ... Training model for up to 19.37s of the 317.86s of remaining time.\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.26%)\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m \tWarning: Exception caused NeuralNetTorch_r86_BAG_L1 to fail during training... Skipping this model.\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m \t\t\u001b[36mray::_ray_fit()\u001b[39m (pid=16880, ip=127.0.0.1)\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m   File \"python\\ray\\_raylet.pyx\", line 1889, in ray._raylet.execute_task\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m     fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m     out = self._fit(**kwargs)\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 201, in _fit\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m     train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m     dataset = self._process_train_data(\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m     self.processor = create_preprocessor(\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\utils\\data_preprocessor.py\", line 40, in create_preprocessor\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m     return ColumnTransformer(\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m Detailed Traceback:\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 2106, in _train_and_save\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m     model = self._train_single(**model_fit_kwargs)\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 1993, in _train_single\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m     model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m     out = self._fit(**kwargs)\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\stacker_ensemble_model.py\", line 270, in _fit\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m     return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\bagged_ensemble_model.py\", line 298, in _fit\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m     self._fit_folds(\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\bagged_ensemble_model.py\", line 724, in _fit_folds\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m     fold_fitting_strategy.after_all_folds_scheduled()\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 690, in after_all_folds_scheduled\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m     self._run_parallel(X, y, X_pseudo, y_pseudo, model_base_ref, time_limit_fold, head_node_id)\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 631, in _run_parallel\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m     self._process_fold_results(finished, unfinished, fold_ctx)\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 587, in _process_fold_results\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m     raise processed_exception\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 550, in _process_fold_results\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m     fold_model, pred_proba, time_start_fit, time_end_fit, predict_time, predict_1_time, predict_n_size, fit_num_cpus, fit_num_gpus = self.ray.get(finished)\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m     return fn(*args, **kwargs)\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\client_mode_hook.py\", line 103, in wrapper\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m     return func(*args, **kwargs)\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\worker.py\", line 2667, in get\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m     values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\worker.py\", line 864, in get_objects\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m     raise value.as_instanceof_cause()\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m ray.exceptions.RayTaskError(TypeError): \u001b[36mray::_ray_fit()\u001b[39m (pid=16880, ip=127.0.0.1)\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m   File \"python\\ray\\_raylet.pyx\", line 1889, in ray._raylet.execute_task\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m     fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m     out = self._fit(**kwargs)\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 201, in _fit\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m     train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m     dataset = self._process_train_data(\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m     self.processor = create_preprocessor(\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\utils\\data_preprocessor.py\", line 40, in create_preprocessor\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m     return ColumnTransformer(\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m Fitting model: CatBoost_r50_BAG_L1 ... Training model for up to 12.81s of the 311.31s of remaining time.\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.57%)\n",
      "\u001b[36m(_ray_fit pid=14028)\u001b[0m \tRan out of time, early stopping on iteration 235.\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m \t0.8922\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m \t10.32s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m \t0.08s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m Fitting model: WeightedEnsemble_L2 ... Training model for up to 360.00s of the 297.31s of remaining time.\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m \tEnsemble Weights: {'LightGBM_r96_BAG_L1': 0.5, 'CatBoost_r137_BAG_L1': 0.125, 'XGBoost_r89_BAG_L1': 0.125, 'NeuralNetFastAI_BAG_L1': 0.083, 'CatBoost_r177_BAG_L1': 0.083, 'XGBoost_BAG_L1': 0.042, 'NeuralNetFastAI_r191_BAG_L1': 0.042}\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m \t0.9079\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m \t0.15s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m \t0.0s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m Excluded models: ['RF', 'KNN', 'XT'] (Specified by `excluded_model_types`)\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m Fitting 90 L2 models, fit_strategy=\"sequential\" ...\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m Fitting model: LightGBMXT_BAG_L2 ... Training model for up to 297.13s of the 297.01s of remaining time.\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.80%)\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m \t0.9033\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m \t2.05s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m \t0.05s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m Fitting model: LightGBM_BAG_L2 ... Training model for up to 291.87s of the 291.74s of remaining time.\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=1.02%)\n",
      "\u001b[36m(_ray_fit pid=24068)\u001b[0m \tRan out of time, early stopping on iteration 238.\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m \t0.9\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m \t2.53s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m \t0.06s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m Fitting model: CatBoost_BAG_L2 ... Training model for up to 285.82s of the 285.70s of remaining time.\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=1.57%)\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m \t0.9056\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m \t30.14s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m \t0.06s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m Fitting model: NeuralNetFastAI_BAG_L2 ... Training model for up to 252.16s of the 252.04s of remaining time.\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.67%)\n",
      "\u001b[36m(_ray_fit pid=20904)\u001b[0m No improvement since epoch 1: early stopping\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m \t0.887\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m \t9.12s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m \t0.17s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m Fitting model: XGBoost_BAG_L2 ... Training model for up to 239.90s of the 239.78s of remaining time.\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=3.22%)\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m \t0.8981\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m \t4.0s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m \t0.07s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m Fitting model: NeuralNetTorch_BAG_L2 ... Training model for up to 231.89s of the 231.77s of remaining time.\n",
      "\u001b[36m(_ray_fit pid=24256)\u001b[0m No improvement since epoch 2: early stopping\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.46%)\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m \tWarning: Exception caused NeuralNetTorch_BAG_L2 to fail during training... Skipping this model.\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m \t\t\u001b[36mray::_ray_fit()\u001b[39m (pid=20308, ip=127.0.0.1)\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m   File \"python\\ray\\_raylet.pyx\", line 1889, in ray._raylet.execute_task\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m     fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m     out = self._fit(**kwargs)\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 201, in _fit\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m     train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m     dataset = self._process_train_data(\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m     self.processor = create_preprocessor(\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\utils\\data_preprocessor.py\", line 40, in create_preprocessor\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m     return ColumnTransformer(\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m Detailed Traceback:\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 2106, in _train_and_save\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m     model = self._train_single(**model_fit_kwargs)\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 1993, in _train_single\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m     model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m     out = self._fit(**kwargs)\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\stacker_ensemble_model.py\", line 270, in _fit\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m     return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\bagged_ensemble_model.py\", line 298, in _fit\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m     self._fit_folds(\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\bagged_ensemble_model.py\", line 724, in _fit_folds\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m     fold_fitting_strategy.after_all_folds_scheduled()\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 690, in after_all_folds_scheduled\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m     self._run_parallel(X, y, X_pseudo, y_pseudo, model_base_ref, time_limit_fold, head_node_id)\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 631, in _run_parallel\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m     self._process_fold_results(finished, unfinished, fold_ctx)\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 587, in _process_fold_results\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m     raise processed_exception\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 550, in _process_fold_results\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m     fold_model, pred_proba, time_start_fit, time_end_fit, predict_time, predict_1_time, predict_n_size, fit_num_cpus, fit_num_gpus = self.ray.get(finished)\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m     return fn(*args, **kwargs)\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\client_mode_hook.py\", line 103, in wrapper\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m     return func(*args, **kwargs)\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\worker.py\", line 2667, in get\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m     values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\worker.py\", line 864, in get_objects\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m     raise value.as_instanceof_cause()\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m ray.exceptions.RayTaskError(TypeError): \u001b[36mray::_ray_fit()\u001b[39m (pid=20308, ip=127.0.0.1)\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m   File \"python\\ray\\_raylet.pyx\", line 1889, in ray._raylet.execute_task\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m     fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m     out = self._fit(**kwargs)\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 201, in _fit\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m     train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m     dataset = self._process_train_data(\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m     self.processor = create_preprocessor(\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\utils\\data_preprocessor.py\", line 40, in create_preprocessor\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m     return ColumnTransformer(\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m Fitting model: LightGBMLarge_BAG_L2 ... Training model for up to 225.30s of the 225.18s of remaining time.\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=4.36%)\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m \t0.8952\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m \t7.8s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m \t0.07s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m Fitting model: CatBoost_r177_BAG_L2 ... Training model for up to 214.15s of the 214.03s of remaining time.\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=2.19%)\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m \t0.9049\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m \t9.89s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m \t0.06s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m Fitting model: NeuralNetTorch_r79_BAG_L2 ... Training model for up to 200.88s of the 200.76s of remaining time.\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.59%)\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m \tWarning: Exception caused NeuralNetTorch_r79_BAG_L2 to fail during training... Skipping this model.\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m \t\t\u001b[36mray::_ray_fit()\u001b[39m (pid=25448, ip=127.0.0.1)\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m   File \"python\\ray\\_raylet.pyx\", line 1889, in ray._raylet.execute_task\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m     fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m     out = self._fit(**kwargs)\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 201, in _fit\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m     train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m     dataset = self._process_train_data(\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m     self.processor = create_preprocessor(\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\utils\\data_preprocessor.py\", line 40, in create_preprocessor\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m     return ColumnTransformer(\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m Detailed Traceback:\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 2106, in _train_and_save\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m     model = self._train_single(**model_fit_kwargs)\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 1993, in _train_single\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m     model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m     out = self._fit(**kwargs)\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\stacker_ensemble_model.py\", line 270, in _fit\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m     return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\bagged_ensemble_model.py\", line 298, in _fit\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m     self._fit_folds(\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\bagged_ensemble_model.py\", line 724, in _fit_folds\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m     fold_fitting_strategy.after_all_folds_scheduled()\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 690, in after_all_folds_scheduled\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m     self._run_parallel(X, y, X_pseudo, y_pseudo, model_base_ref, time_limit_fold, head_node_id)\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 631, in _run_parallel\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m     self._process_fold_results(finished, unfinished, fold_ctx)\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 587, in _process_fold_results\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m     raise processed_exception\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 550, in _process_fold_results\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m     fold_model, pred_proba, time_start_fit, time_end_fit, predict_time, predict_1_time, predict_n_size, fit_num_cpus, fit_num_gpus = self.ray.get(finished)\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m     return fn(*args, **kwargs)\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\client_mode_hook.py\", line 103, in wrapper\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m     return func(*args, **kwargs)\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\worker.py\", line 2667, in get\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m     values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\worker.py\", line 864, in get_objects\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m     raise value.as_instanceof_cause()\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m ray.exceptions.RayTaskError(TypeError): \u001b[36mray::_ray_fit()\u001b[39m (pid=25448, ip=127.0.0.1)\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m   File \"python\\ray\\_raylet.pyx\", line 1889, in ray._raylet.execute_task\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m     fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m     out = self._fit(**kwargs)\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 201, in _fit\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m     train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m     dataset = self._process_train_data(\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m     self.processor = create_preprocessor(\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\utils\\data_preprocessor.py\", line 40, in create_preprocessor\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m     return ColumnTransformer(\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m Fitting model: LightGBM_r131_BAG_L2 ... Training model for up to 194.21s of the 194.09s of remaining time.\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=6.18%)\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m \t0.8996\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m \t4.59s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m \t0.13s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m Fitting model: NeuralNetFastAI_r191_BAG_L2 ... Training model for up to 186.10s of the 185.98s of remaining time.\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=3.08%)\n",
      "\u001b[36m(_ray_fit pid=19632)\u001b[0m No improvement since epoch 0: early stopping\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m \t0.8861\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m \t21.95s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m \t0.25s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m Fitting model: CatBoost_r9_BAG_L2 ... Training model for up to 160.65s of the 160.53s of remaining time.\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m \tMemory not enough to fit 8 folds in parallel. Will train 4 folds in parallel instead (Estimated 15.59% memory usage per fold, 62.34%/80.00% total).\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=3, gpus=0, memory=15.59%)\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_ray_fit pid=14648)\u001b[0m No improvement since epoch 2: early stopping\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m \t0.9046\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m \t103.24s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m \t0.08s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m Fitting model: LightGBM_r96_BAG_L2 ... Training model for up to 53.32s of the 53.20s of remaining time.\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.73%)\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m \t0.9047\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m \t2.21s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m \t0.12s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m Fitting model: NeuralNetTorch_r22_BAG_L2 ... Training model for up to 47.98s of the 47.86s of remaining time.\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.56%)\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m \tWarning: Exception caused NeuralNetTorch_r22_BAG_L2 to fail during training... Skipping this model.\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m \t\t\u001b[36mray::_ray_fit()\u001b[39m (pid=18228, ip=127.0.0.1)\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m   File \"python\\ray\\_raylet.pyx\", line 1889, in ray._raylet.execute_task\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m     fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m     out = self._fit(**kwargs)\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 201, in _fit\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m     train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m     dataset = self._process_train_data(\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m     self.processor = create_preprocessor(\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\utils\\data_preprocessor.py\", line 40, in create_preprocessor\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m     return ColumnTransformer(\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m Detailed Traceback:\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 2106, in _train_and_save\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m     model = self._train_single(**model_fit_kwargs)\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 1993, in _train_single\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m     model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m     out = self._fit(**kwargs)\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\stacker_ensemble_model.py\", line 270, in _fit\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m     return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\bagged_ensemble_model.py\", line 298, in _fit\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m     self._fit_folds(\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\bagged_ensemble_model.py\", line 724, in _fit_folds\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m     fold_fitting_strategy.after_all_folds_scheduled()\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 690, in after_all_folds_scheduled\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m     self._run_parallel(X, y, X_pseudo, y_pseudo, model_base_ref, time_limit_fold, head_node_id)\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 631, in _run_parallel\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m     self._process_fold_results(finished, unfinished, fold_ctx)\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 587, in _process_fold_results\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m     raise processed_exception\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 550, in _process_fold_results\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m     fold_model, pred_proba, time_start_fit, time_end_fit, predict_time, predict_1_time, predict_n_size, fit_num_cpus, fit_num_gpus = self.ray.get(finished)\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m     return fn(*args, **kwargs)\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\client_mode_hook.py\", line 103, in wrapper\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m     return func(*args, **kwargs)\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\worker.py\", line 2667, in get\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m     values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\worker.py\", line 864, in get_objects\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m     raise value.as_instanceof_cause()\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m ray.exceptions.RayTaskError(TypeError): \u001b[36mray::_ray_fit()\u001b[39m (pid=18228, ip=127.0.0.1)\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m   File \"python\\ray\\_raylet.pyx\", line 1889, in ray._raylet.execute_task\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m     fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m     out = self._fit(**kwargs)\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 201, in _fit\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m     train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m     dataset = self._process_train_data(\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m     self.processor = create_preprocessor(\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\utils\\data_preprocessor.py\", line 40, in create_preprocessor\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m     return ColumnTransformer(\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m Fitting model: XGBoost_r33_BAG_L2 ... Training model for up to 41.34s of the 41.22s of remaining time.\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m \tMemory not enough to fit 8 folds in parallel. Will train 2 folds in parallel instead (Estimated 23.87% memory usage per fold, 47.74%/80.00% total).\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=6, gpus=0, memory=23.87%)\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m \t0.8992\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m \t27.18s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m \t0.09s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m Fitting model: CatBoost_r137_BAG_L2 ... Training model for up to 11.92s of the 11.80s of remaining time.\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=1.96%)\n",
      "\u001b[36m(_ray_fit pid=21916)\u001b[0m \tRan out of time, early stopping on iteration 231.\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m \t0.9049\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m \t9.69s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m \t0.08s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m Fitting model: WeightedEnsemble_L3 ... Training model for up to 360.00s of the -1.75s of remaining time.\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m \tEnsemble Weights: {'LightGBM_r96_BAG_L1': 0.435, 'CatBoost_BAG_L2': 0.435, 'CatBoost_r177_BAG_L2': 0.13}\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m \t0.9071\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m \t0.14s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m \t0.0s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m AutoGluon training complete, total runtime = 897.11s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 285.2 rows/s (534 batch size)\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m Automatically performing refit_full as a post-fit operation (due to `.fit(..., refit_full=True)`\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m Refitting models via `predictor.refit_full` using all of the data (combined train and validation)...\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m \tModels trained in this way will have the suffix \"_FULL\" and have NaN validation score.\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m \tThis process is not bound by time_limit, but should take less time than the original `predictor.fit` call.\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m \tTo learn more, refer to the `.refit_full` method docstring which explains how \"_FULL\" models differ from normal models.\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m Fitting model: LightGBMXT_BAG_L1_FULL ...\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m \t0.83s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m Fitting model: LightGBM_BAG_L1_FULL ...\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m \t1.65s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m Fitting model: CatBoost_BAG_L1_FULL ...\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m \t16.81s\t = Training   runtime\n",
      "\u001b[36m(_ray_fit pid=24988)\u001b[0m \tRan out of time, early stopping on iteration 232.\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m Fitting model: NeuralNetFastAI_BAG_L1_FULL ...\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m \tStopping at the best epoch learned earlier - 2.\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m \t0.97s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m Fitting model: XGBoost_BAG_L1_FULL ...\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m \t0.39s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m Fitting model: LightGBMLarge_BAG_L1_FULL ...\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m \t0.84s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m Fitting model: CatBoost_r177_BAG_L1_FULL ...\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m \t2.08s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m Fitting model: LightGBM_r131_BAG_L1_FULL ...\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m \t1.45s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m Fitting model: NeuralNetFastAI_r191_BAG_L1_FULL ...\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m \tStopping at the best epoch learned earlier - 2.\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m \t0.94s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m Fitting model: CatBoost_r9_BAG_L1_FULL ...\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m \t26.87s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m Fitting model: LightGBM_r96_BAG_L1_FULL ...\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m \t1.71s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m Fitting model: XGBoost_r33_BAG_L1_FULL ...\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m \t3.72s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m Fitting model: CatBoost_r137_BAG_L1_FULL ...\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m \t19.73s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m Fitting model: NeuralNetFastAI_r102_BAG_L1_FULL ...\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m \tStopping at the best epoch learned earlier - 22.\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m \t1.14s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m Fitting model: CatBoost_r13_BAG_L1_FULL ...\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m \t13.72s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m Fitting model: LightGBM_r188_BAG_L1_FULL ...\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m \t0.92s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m Fitting model: NeuralNetFastAI_r145_BAG_L1_FULL ...\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m \tStopping at the best epoch learned earlier - 2.\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m \t1.47s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m Fitting model: XGBoost_r89_BAG_L1_FULL ...\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m \t0.43s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m Fitting model: LightGBM_r130_BAG_L1_FULL ...\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m \t0.45s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m Fitting model: CatBoost_r50_BAG_L1_FULL ...\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m \t4.59s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m Fitting model: WeightedEnsemble_L2_FULL | Skipping fit via cloning parent ...\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m \tEnsemble Weights: {'LightGBM_r96_BAG_L1': 0.5, 'CatBoost_r137_BAG_L1': 0.125, 'XGBoost_r89_BAG_L1': 0.125, 'NeuralNetFastAI_BAG_L1': 0.083, 'CatBoost_r177_BAG_L1': 0.083, 'XGBoost_BAG_L1': 0.042, 'NeuralNetFastAI_r191_BAG_L1': 0.042}\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m \t0.15s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m Fitting 1 L2 models, fit_strategy=\"sequential\" ...\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m Fitting model: LightGBMXT_BAG_L2_FULL ...\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m \t0.19s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m Fitting 1 L2 models, fit_strategy=\"sequential\" ...\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m Fitting model: LightGBM_BAG_L2_FULL ...\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m \t0.21s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m Fitting 1 L2 models, fit_strategy=\"sequential\" ...\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m Fitting model: CatBoost_BAG_L2_FULL ...\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m \t2.95s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m Fitting 1 L2 models, fit_strategy=\"sequential\" ...\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m Fitting model: NeuralNetFastAI_BAG_L2_FULL ...\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m \tStopping at the best epoch learned earlier - 1.\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m \t0.53s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m Fitting 1 L2 models, fit_strategy=\"sequential\" ...\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m Fitting model: XGBoost_BAG_L2_FULL ...\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m \t0.17s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m Fitting 1 L2 models, fit_strategy=\"sequential\" ...\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m Fitting model: LightGBMLarge_BAG_L2_FULL ...\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m \t0.55s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m Fitting 1 L2 models, fit_strategy=\"sequential\" ...\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m Fitting model: CatBoost_r177_BAG_L2_FULL ...\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m \t0.38s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m Fitting 1 L2 models, fit_strategy=\"sequential\" ...\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m Fitting model: LightGBM_r131_BAG_L2_FULL ...\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m \t0.59s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m Fitting 1 L2 models, fit_strategy=\"sequential\" ...\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m Fitting model: NeuralNetFastAI_r191_BAG_L2_FULL ...\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m \tStopping at the best epoch learned earlier - 1.\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m \t0.67s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m Fitting 1 L2 models, fit_strategy=\"sequential\" ...\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m Fitting model: CatBoost_r9_BAG_L2_FULL ...\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m \t7.23s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m Fitting 1 L2 models, fit_strategy=\"sequential\" ...\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m Fitting model: LightGBM_r96_BAG_L2_FULL ...\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m \t0.29s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m Fitting 1 L2 models, fit_strategy=\"sequential\" ...\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m Fitting model: XGBoost_r33_BAG_L2_FULL ...\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m \t1.55s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m Fitting 1 L2 models, fit_strategy=\"sequential\" ...\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m Fitting model: CatBoost_r137_BAG_L2_FULL ...\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m \t2.02s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m Fitting model: WeightedEnsemble_L3_FULL | Skipping fit via cloning parent ...\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m \tEnsemble Weights: {'LightGBM_r96_BAG_L1': 0.435, 'CatBoost_BAG_L2': 0.435, 'CatBoost_r177_BAG_L2': 0.13}\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m \t0.14s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m Updated best model to \"WeightedEnsemble_L2_FULL\" (Previously \"WeightedEnsemble_L2\"). AutoGluon will default to using \"WeightedEnsemble_L2_FULL\" for predict() and predict_proba().\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m Refit complete, total runtime = 122.35s ... Best model: \"WeightedEnsemble_L2_FULL\"\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\autogluon\\tlp\\AutogluonModels\\synthetic\\tvaes\\v2\\ds_sub_fit\\sub_fit_ho\")\n",
      "\u001b[36m(_dystack pid=13492)\u001b[0m Deleting DyStack predictor artifacts (clean_up_fits=True) ...\n",
      "Leaderboard on holdout data (DyStack):\n",
      "                               model  score_holdout  score_val eval_metric  pred_time_test pred_time_val   fit_time  pred_time_test_marginal pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
      "0             LightGBMXT_BAG_L2_FULL       0.916157   0.903314     roc_auc        0.314551          None  27.261141                 0.022224                   None           0.188825            2       True         22\n",
      "1           LightGBM_r96_BAG_L2_FULL       0.915582   0.904685     roc_auc        0.318438          None  27.364592                 0.026111                   None           0.292277            2       True         32\n",
      "2             LightGBMXT_BAG_L1_FULL       0.915343   0.899395     roc_auc        0.021703          None   0.829423                 0.021703                   None           0.829423            1       True          1\n",
      "3          CatBoost_r137_BAG_L2_FULL       0.915315   0.904905     roc_auc        0.317441          None  29.095078                 0.025113                   None           2.022763            2       True         34\n",
      "4           WeightedEnsemble_L3_FULL       0.915077   0.907109     roc_auc        0.351806          None  30.542842                 0.010112                   None           0.135281            3       True         35\n",
      "5          LightGBM_r131_BAG_L2_FULL       0.915063   0.899555     roc_auc        0.323574          None  27.661031                 0.031247                   None           0.588715            2       True         29\n",
      "6               CatBoost_BAG_L2_FULL       0.914768   0.905606     roc_auc        0.316452          None  30.022639                 0.024124                   None           2.950324            2       True         24\n",
      "7                XGBoost_BAG_L2_FULL       0.914530   0.898140     roc_auc        0.341661          None  27.244735                 0.049333                   None           0.172420            2       True         26\n",
      "8           LightGBM_r96_BAG_L1_FULL       0.913660   0.905393     roc_auc        0.071465          None   1.713336                 0.071465                   None           1.713336            1       True         11\n",
      "9               LightGBM_BAG_L2_FULL       0.913246   0.899998     roc_auc        0.314447          None  27.286244                 0.022120                   None           0.213928            2       True         23\n",
      "10          WeightedEnsemble_L2_FULL       0.913029   0.907859     roc_auc        0.282624          None  26.388696                 0.011999                   None           0.145804            2       True         21\n",
      "11           XGBoost_r33_BAG_L2_FULL       0.912517   0.899151     roc_auc        0.335691          None  28.623796                 0.043364                   None           1.551480            2       True         33\n",
      "12         CatBoost_r177_BAG_L2_FULL       0.911822   0.904944     roc_auc        0.317570          None  27.457237                 0.025243                   None           0.384921            2       True         28\n",
      "13           CatBoost_r9_BAG_L2_FULL       0.911626   0.904626     roc_auc        0.320567          None  34.305293                 0.028239                   None           7.232977            2       True         31\n",
      "14         LightGBMLarge_BAG_L2_FULL       0.910897   0.895192     roc_auc        0.317445          None  27.620625                 0.025117                   None           0.548309            2       True         27\n",
      "15  NeuralNetFastAI_r191_BAG_L2_FULL       0.904360   0.886127     roc_auc        0.344575          None  27.738533                 0.052248                   None           0.666218            2       True         30\n",
      "16              CatBoost_BAG_L1_FULL       0.903532   0.896648     roc_auc        0.020163          None  16.808404                 0.020163                   None          16.808404            1       True          3\n",
      "17          CatBoost_r13_BAG_L1_FULL       0.900727   0.897260     roc_auc        0.023135          None  13.716705                 0.023135                   None          13.716705            1       True         15\n",
      "18         CatBoost_r177_BAG_L1_FULL       0.900558   0.897452     roc_auc        0.021119          None   2.077688                 0.021119                   None           2.077688            1       True          7\n",
      "19         CatBoost_r137_BAG_L1_FULL       0.900418   0.898925     roc_auc        0.021125          None  19.727692                 0.021125                   None          19.727692            1       True         13\n",
      "20         LightGBM_r188_BAG_L1_FULL       0.899787   0.890783     roc_auc        0.030276          None   0.915223                 0.030276                   None           0.915223            1       True         16\n",
      "21           XGBoost_r89_BAG_L1_FULL       0.899632   0.897187     roc_auc        0.033253          None   0.425682                 0.033253                   None           0.425682            1       True         18\n",
      "22              LightGBM_BAG_L1_FULL       0.899450   0.897639     roc_auc        0.020240          None   1.654831                 0.020240                   None           1.654831            1       True          2\n",
      "23               XGBoost_BAG_L1_FULL       0.899394   0.894058     roc_auc        0.031236          None   0.391483                 0.031236                   None           0.391483            1       True          5\n",
      "24         LightGBM_r130_BAG_L1_FULL       0.898847   0.899132     roc_auc        0.021118          None   0.447821                 0.021118                   None           0.447821            1       True         19\n",
      "25         LightGBM_r131_BAG_L1_FULL       0.898679   0.898247     roc_auc        0.041380          None   1.448779                 0.041380                   None           1.448779            1       True          8\n",
      "26       NeuralNetFastAI_BAG_L2_FULL       0.898075   0.887004     roc_auc        0.348705          None  27.599925                 0.056378                   None           0.527609            2       True         25\n",
      "27           CatBoost_r9_BAG_L1_FULL       0.897346   0.896061     roc_auc        0.030239          None  26.871658                 0.030239                   None          26.871658            1       True         10\n",
      "28          CatBoost_r50_BAG_L1_FULL       0.896266   0.892221     roc_auc        0.019120          None   4.589837                 0.019120                   None           4.589837            1       True         20\n",
      "29           XGBoost_r33_BAG_L1_FULL       0.890683   0.888780     roc_auc        0.058381          None   3.716110                 0.058381                   None           3.716110            1       True         12\n",
      "30  NeuralNetFastAI_r102_BAG_L1_FULL       0.884300   0.850333     roc_auc        0.033230          None   1.137637                 0.033230                   None           1.137637            1       True         14\n",
      "31         LightGBMLarge_BAG_L1_FULL       0.879938   0.882147     roc_auc        0.023103          None   0.835605                 0.023103                   None           0.835605            1       True          6\n",
      "32  NeuralNetFastAI_r145_BAG_L1_FULL       0.874214   0.859410     roc_auc        0.049423          None   1.470436                 0.049423                   None           1.470436            1       True         17\n",
      "33  NeuralNetFastAI_r191_BAG_L1_FULL       0.873639   0.864952     roc_auc        0.049241          None   0.939593                 0.049241                   None           0.939593            1       True          9\n",
      "34       NeuralNetFastAI_BAG_L1_FULL       0.873317   0.866026     roc_auc        0.043186          None   0.967419                 0.043186                   None           0.967419            1       True          4\n",
      "\t1\t = Optimal   num_stack_levels (Stacked Overfitting Occurred: False)\n",
      "\t1028s\t = DyStack   runtime |\t2572s\t = Remaining runtime\n",
      "Starting main fit with num_stack_levels=1.\n",
      "\tFor future fit calls on this dataset, you can skip DyStack to save time: `predictor.fit(..., dynamic_stacking=False, num_stack_levels=1)`\n",
      "Using predefined sample weighting strategy: balance_weight. Evaluation metrics will ignore sample weights, specify weight_evaluation=True to instead report weighted metrics.\n",
      "Beginning AutoGluon training ... Time limit = 2572s\n",
      "AutoGluon will save models to \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\autogluon\\tlp\\AutogluonModels\\synthetic\\tvaes\\v2\"\n",
      "Train Data Rows:    4800\n",
      "Train Data Columns: 76\n",
      "Label Column:       ED_2Clases\n",
      "Problem Type:       binary\n",
      "Preprocessing data ...\n",
      "Selected class <--> label mapping:  class 1 = H, class 0 = D\n",
      "\tNote: For your binary classification, AutoGluon arbitrarily selected which label-value represents positive (H) vs negative (D) class.\n",
      "\tTo explicitly set the positive_class, either rename classes to 1 and 0, or specify positive_class in Predictor init.\n",
      "Assigning sample weights to balance differences in frequency of classes.\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    2290.47 MB\n",
      "\tTrain Data (Original)  Memory Usage: 3.37 MB (0.1% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 10 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\t\tFitting DatetimeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUseless Original Features (Count: 1): ['clin-Covid_sintomaSarpullido']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('bool', [])                       :  8 | ['clin-ansiedad', 'clin-depresion', 'clin-cardiopatiaIsquemica', 'clin-diabetes', 'clin-Hipercolesterolemia', ...]\n",
      "\t\t('float', [])                      : 15 | ['ques-Sus-total-PD', 'eval-TLP-FigRey-totalCopia-PD', 'eval-TLP-FigRey-totalMemoria-PD', 'eval-TLP-Tavec-5_Rg_Pr-PD', 'eval-TLP-Tavec-6_Rg_Md-PD', ...]\n",
      "\t\t('int', [])                        : 49 | ['demo-genero', 'demo-edad', 'clin-reservaCognitiva_total', 'clin-reservaCognitiva_idiomas', 'clin-reservaCognitiva_ocupacion', ...]\n",
      "\t\t('object', [])                     :  1 | ['demo-rangoEdad']\n",
      "\t\t('object', ['datetime_as_object']) :  2 | ['demo-fechaEvaluacion', 'demo-fechaNacimiento']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', [])             :  1 | ['demo-rangoEdad']\n",
      "\t\t('float', [])                : 15 | ['ques-Sus-total-PD', 'eval-TLP-FigRey-totalCopia-PD', 'eval-TLP-FigRey-totalMemoria-PD', 'eval-TLP-Tavec-5_Rg_Pr-PD', 'eval-TLP-Tavec-6_Rg_Md-PD', ...]\n",
      "\t\t('int', [])                  : 47 | ['demo-edad', 'clin-reservaCognitiva_total', 'clin-reservaCognitiva_idiomas', 'clin-reservaCognitiva_ocupacion', 'clin-reservaCognitiva_escolaridad', ...]\n",
      "\t\t('int', ['bool'])            : 10 | ['demo-genero', 'clin-ansiedad', 'clin-depresion', 'clin-cardiopatiaIsquemica', 'clin-diabetes', ...]\n",
      "\t\t('int', ['datetime_as_int']) :  9 | ['demo-fechaEvaluacion', 'demo-fechaEvaluacion.month', 'demo-fechaEvaluacion.day', 'demo-fechaEvaluacion.dayofweek', 'demo-fechaNacimiento', ...]\n",
      "\t0.1s = Fit runtime\n",
      "\t75 features in original data used to generate 82 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 2.65 MB (0.1% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.19s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'roc_auc'\n",
      "\tThis metric expects predicted probabilities rather than predicted class labels, so you'll need to use predict_proba() instead of predict()\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Large model count detected (112 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': [{}, {'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2}}, {'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7}}],\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\n",
      "\t'CAT': [{}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5}}],\n",
      "\t'XGB': [{}, {'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'name_suffix': '_r33', 'priority': -8}}, {'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'name_suffix': '_r89', 'priority': -16}}],\n",
      "\t'FASTAI': [{}, {'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4}}, {'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11}}],\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Excluded models: ['KNN', 'RF', 'XT'] (Specified by `excluded_model_types`)\n",
      "Fitting 90 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 1714.10s of the 2571.79s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=1.61%)\n",
      "\t0.9028\t = Validation score   (roc_auc)\n",
      "\t4.35s\t = Training   runtime\n",
      "\t0.24s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 1703.77s of the 2561.45s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=1.16%)\n",
      "\t0.9014\t = Validation score   (roc_auc)\n",
      "\t4.75s\t = Training   runtime\n",
      "\t0.15s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L1 ... Training model for up to 1696.13s of the 2553.81s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=1.49%)\n",
      "\t0.903\t = Validation score   (roc_auc)\n",
      "\t69.71s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 1623.59s of the 2481.27s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.74%)\n",
      "\t0.8701\t = Validation score   (roc_auc)\n",
      "\t11.42s\t = Training   runtime\n",
      "\t0.18s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L1 ... Training model for up to 1609.79s of the 2467.47s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=1.95%)\n",
      "\t0.8981\t = Validation score   (roc_auc)\n",
      "\t6.22s\t = Training   runtime\n",
      "\t0.12s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_BAG_L1 ... Training model for up to 1600.91s of the 2458.59s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.35%)\n",
      "\tWarning: Exception caused NeuralNetTorch_BAG_L1 to fail during training... Skipping this model.\n",
      "\t\t\u001b[36mray::_ray_fit()\u001b[39m (pid=18032, ip=127.0.0.1)\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1889, in ray._raylet.execute_task\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 201, in _fit\n",
      "    train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "    dataset = self._process_train_data(\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "    self.processor = create_preprocessor(\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\utils\\data_preprocessor.py\", line 40, in create_preprocessor\n",
      "    return ColumnTransformer(\n",
      "TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 2106, in _train_and_save\n",
      "    model = self._train_single(**model_fit_kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 1993, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\stacker_ensemble_model.py\", line 270, in _fit\n",
      "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\bagged_ensemble_model.py\", line 298, in _fit\n",
      "    self._fit_folds(\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\bagged_ensemble_model.py\", line 724, in _fit_folds\n",
      "    fold_fitting_strategy.after_all_folds_scheduled()\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 690, in after_all_folds_scheduled\n",
      "    self._run_parallel(X, y, X_pseudo, y_pseudo, model_base_ref, time_limit_fold, head_node_id)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 631, in _run_parallel\n",
      "    self._process_fold_results(finished, unfinished, fold_ctx)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 587, in _process_fold_results\n",
      "    raise processed_exception\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 550, in _process_fold_results\n",
      "    fold_model, pred_proba, time_start_fit, time_end_fit, predict_time, predict_1_time, predict_n_size, fit_num_cpus, fit_num_gpus = self.ray.get(finished)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\worker.py\", line 2667, in get\n",
      "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\worker.py\", line 864, in get_objects\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(TypeError): \u001b[36mray::_ray_fit()\u001b[39m (pid=18032, ip=127.0.0.1)\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1889, in ray._raylet.execute_task\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 201, in _fit\n",
      "    train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "    dataset = self._process_train_data(\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "    self.processor = create_preprocessor(\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\utils\\data_preprocessor.py\", line 40, in create_preprocessor\n",
      "    return ColumnTransformer(\n",
      "TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "Fitting model: LightGBMLarge_BAG_L1 ... Training model for up to 1595.52s of the 2453.21s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=2.35%)\n",
      "2025-01-31 15:38:07,760\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-31 15:38:07,769\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-31 15:38:07,773\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-31 15:38:07,777\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-31 15:38:07,781\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-31 15:38:07,785\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-31 15:38:07,789\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\t0.8888\t = Validation score   (roc_auc)\n",
      "\t9.54s\t = Training   runtime\n",
      "\t0.16s\t = Validation runtime\n",
      "Fitting model: CatBoost_r177_BAG_L1 ... Training model for up to 1583.39s of the 2441.07s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=1.14%)\n",
      "\t0.9008\t = Validation score   (roc_auc)\n",
      "\t19.01s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r79_BAG_L1 ... Training model for up to 1561.79s of the 2419.47s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.35%)\n",
      "\tWarning: Exception caused NeuralNetTorch_r79_BAG_L1 to fail during training... Skipping this model.\n",
      "\t\t\u001b[36mray::_ray_fit()\u001b[39m (pid=24344, ip=127.0.0.1)\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1889, in ray._raylet.execute_task\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 201, in _fit\n",
      "    train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "    dataset = self._process_train_data(\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "    self.processor = create_preprocessor(\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\utils\\data_preprocessor.py\", line 40, in create_preprocessor\n",
      "    return ColumnTransformer(\n",
      "TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 2106, in _train_and_save\n",
      "    model = self._train_single(**model_fit_kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 1993, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\stacker_ensemble_model.py\", line 270, in _fit\n",
      "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\bagged_ensemble_model.py\", line 298, in _fit\n",
      "    self._fit_folds(\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\bagged_ensemble_model.py\", line 724, in _fit_folds\n",
      "    fold_fitting_strategy.after_all_folds_scheduled()\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 690, in after_all_folds_scheduled\n",
      "    self._run_parallel(X, y, X_pseudo, y_pseudo, model_base_ref, time_limit_fold, head_node_id)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 631, in _run_parallel\n",
      "    self._process_fold_results(finished, unfinished, fold_ctx)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 587, in _process_fold_results\n",
      "    raise processed_exception\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 550, in _process_fold_results\n",
      "    fold_model, pred_proba, time_start_fit, time_end_fit, predict_time, predict_1_time, predict_n_size, fit_num_cpus, fit_num_gpus = self.ray.get(finished)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\worker.py\", line 2667, in get\n",
      "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\worker.py\", line 864, in get_objects\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(TypeError): \u001b[36mray::_ray_fit()\u001b[39m (pid=24344, ip=127.0.0.1)\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1889, in ray._raylet.execute_task\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 201, in _fit\n",
      "    train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "    dataset = self._process_train_data(\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "    self.processor = create_preprocessor(\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\utils\\data_preprocessor.py\", line 40, in create_preprocessor\n",
      "    return ColumnTransformer(\n",
      "TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "Fitting model: LightGBM_r131_BAG_L1 ... Training model for up to 1556.47s of the 2414.16s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=1.34%)\n",
      "2025-01-31 15:38:46,193\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-31 15:38:46,197\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-31 15:38:46,201\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-31 15:38:46,204\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\t0.9023\t = Validation score   (roc_auc)\n",
      "\t9.2s\t = Training   runtime\n",
      "\t0.44s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r191_BAG_L1 ... Training model for up to 1544.62s of the 2402.30s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.83%)\n",
      "\t0.8687\t = Validation score   (roc_auc)\n",
      "\t20.86s\t = Training   runtime\n",
      "\t0.22s\t = Validation runtime\n",
      "Fitting model: CatBoost_r9_BAG_L1 ... Training model for up to 1521.18s of the 2378.86s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=6.31%)\n",
      "\t0.8998\t = Validation score   (roc_auc)\n",
      "\t158.91s\t = Training   runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitting model: LightGBM_r96_BAG_L1 ... Training model for up to 1359.15s of the 2216.84s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.40%)\n",
      "\t0.9048\t = Validation score   (roc_auc)\n",
      "\t10.94s\t = Training   runtime\n",
      "\t1.15s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r22_BAG_L1 ... Training model for up to 1345.71s of the 2203.40s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.25%)\n",
      "\tWarning: Exception caused NeuralNetTorch_r22_BAG_L1 to fail during training... Skipping this model.\n",
      "\t\t\u001b[36mray::_ray_fit()\u001b[39m (pid=1392, ip=127.0.0.1)\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1889, in ray._raylet.execute_task\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 201, in _fit\n",
      "    train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "    dataset = self._process_train_data(\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "    self.processor = create_preprocessor(\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\utils\\data_preprocessor.py\", line 40, in create_preprocessor\n",
      "    return ColumnTransformer(\n",
      "TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 2106, in _train_and_save\n",
      "    model = self._train_single(**model_fit_kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 1993, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\stacker_ensemble_model.py\", line 270, in _fit\n",
      "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\bagged_ensemble_model.py\", line 298, in _fit\n",
      "    self._fit_folds(\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\bagged_ensemble_model.py\", line 724, in _fit_folds\n",
      "    fold_fitting_strategy.after_all_folds_scheduled()\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 690, in after_all_folds_scheduled\n",
      "    self._run_parallel(X, y, X_pseudo, y_pseudo, model_base_ref, time_limit_fold, head_node_id)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 631, in _run_parallel\n",
      "    self._process_fold_results(finished, unfinished, fold_ctx)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 587, in _process_fold_results\n",
      "    raise processed_exception\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 550, in _process_fold_results\n",
      "    fold_model, pred_proba, time_start_fit, time_end_fit, predict_time, predict_1_time, predict_n_size, fit_num_cpus, fit_num_gpus = self.ray.get(finished)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\worker.py\", line 2667, in get\n",
      "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\worker.py\", line 864, in get_objects\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(TypeError): \u001b[36mray::_ray_fit()\u001b[39m (pid=1392, ip=127.0.0.1)\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1889, in ray._raylet.execute_task\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 201, in _fit\n",
      "    train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "    dataset = self._process_train_data(\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "    self.processor = create_preprocessor(\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\utils\\data_preprocessor.py\", line 40, in create_preprocessor\n",
      "    return ColumnTransformer(\n",
      "TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "Fitting model: XGBoost_r33_BAG_L1 ... Training model for up to 1340.39s of the 2198.07s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=4.95%)\n",
      "2025-01-31 15:42:22,797\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-31 15:42:22,803\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-31 15:42:22,806\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-31 15:42:22,811\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-31 15:42:22,816\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-31 15:42:22,821\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\t0.8921\t = Validation score   (roc_auc)\n",
      "\t27.5s\t = Training   runtime\n",
      "\t0.63s\t = Validation runtime\n",
      "Fitting model: CatBoost_r137_BAG_L1 ... Training model for up to 1310.22s of the 2167.91s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.41%)\n",
      "\t0.9007\t = Validation score   (roc_auc)\n",
      "\t68.41s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r102_BAG_L1 ... Training model for up to 1239.45s of the 2097.14s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.49%)\n",
      "\t0.8658\t = Validation score   (roc_auc)\n",
      "\t7.63s\t = Training   runtime\n",
      "\t0.12s\t = Validation runtime\n",
      "Fitting model: CatBoost_r13_BAG_L1 ... Training model for up to 1229.50s of the 2087.19s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=3.85%)\n",
      "2025-01-31 15:45:41,051\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-31 15:45:41,053\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-31 15:45:41,059\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\t0.9017\t = Validation score   (roc_auc)\n",
      "\t157.23s\t = Training   runtime\n",
      "\t0.1s\t = Validation runtime\n",
      "Fitting model: LightGBM_r188_BAG_L1 ... Training model for up to 1069.30s of the 1926.98s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=1.74%)\n",
      "\t0.8952\t = Validation score   (roc_auc)\n",
      "\t6.59s\t = Training   runtime\n",
      "\t0.26s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r145_BAG_L1 ... Training model for up to 1060.22s of the 1917.90s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.69%)\n",
      "\t0.8705\t = Validation score   (roc_auc)\n",
      "\t19.73s\t = Training   runtime\n",
      "\t0.24s\t = Validation runtime\n",
      "Fitting model: XGBoost_r89_BAG_L1 ... Training model for up to 1037.98s of the 1895.66s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=1.34%)\n",
      "\t0.8975\t = Validation score   (roc_auc)\n",
      "\t5.59s\t = Training   runtime\n",
      "\t0.13s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r30_BAG_L1 ... Training model for up to 1029.81s of the 1887.49s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.35%)\n",
      "\tWarning: Exception caused NeuralNetTorch_r30_BAG_L1 to fail during training... Skipping this model.\n",
      "\t\t\u001b[36mray::_ray_fit()\u001b[39m (pid=23908, ip=127.0.0.1)\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1889, in ray._raylet.execute_task\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 201, in _fit\n",
      "    train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "    dataset = self._process_train_data(\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "    self.processor = create_preprocessor(\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\utils\\data_preprocessor.py\", line 40, in create_preprocessor\n",
      "    return ColumnTransformer(\n",
      "TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 2106, in _train_and_save\n",
      "    model = self._train_single(**model_fit_kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 1993, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\stacker_ensemble_model.py\", line 270, in _fit\n",
      "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\bagged_ensemble_model.py\", line 298, in _fit\n",
      "    self._fit_folds(\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\bagged_ensemble_model.py\", line 724, in _fit_folds\n",
      "    fold_fitting_strategy.after_all_folds_scheduled()\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 690, in after_all_folds_scheduled\n",
      "    self._run_parallel(X, y, X_pseudo, y_pseudo, model_base_ref, time_limit_fold, head_node_id)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 631, in _run_parallel\n",
      "    self._process_fold_results(finished, unfinished, fold_ctx)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 587, in _process_fold_results\n",
      "    raise processed_exception\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 550, in _process_fold_results\n",
      "    fold_model, pred_proba, time_start_fit, time_end_fit, predict_time, predict_1_time, predict_n_size, fit_num_cpus, fit_num_gpus = self.ray.get(finished)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\worker.py\", line 2667, in get\n",
      "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\worker.py\", line 864, in get_objects\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(TypeError): \u001b[36mray::_ray_fit()\u001b[39m (pid=23908, ip=127.0.0.1)\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1889, in ray._raylet.execute_task\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 201, in _fit\n",
      "    train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "    dataset = self._process_train_data(\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "    self.processor = create_preprocessor(\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\utils\\data_preprocessor.py\", line 40, in create_preprocessor\n",
      "    return ColumnTransformer(\n",
      "TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "Fitting model: LightGBM_r130_BAG_L1 ... Training model for up to 1024.35s of the 1882.01s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=2.12%)\n",
      "2025-01-31 15:47:38,635\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-31 15:47:38,639\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-31 15:47:38,641\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-31 15:47:38,645\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-31 15:47:38,649\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-31 15:47:38,649\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\t0.9023\t = Validation score   (roc_auc)\n",
      "\t4.33s\t = Training   runtime\n",
      "\t0.15s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r86_BAG_L1 ... Training model for up to 1017.33s of the 1875.01s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.47%)\n",
      "\tWarning: Exception caused NeuralNetTorch_r86_BAG_L1 to fail during training... Skipping this model.\n",
      "\t\t\u001b[36mray::_ray_fit()\u001b[39m (pid=14768, ip=127.0.0.1)\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1889, in ray._raylet.execute_task\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 201, in _fit\n",
      "    train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "    dataset = self._process_train_data(\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "    self.processor = create_preprocessor(\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\utils\\data_preprocessor.py\", line 40, in create_preprocessor\n",
      "    return ColumnTransformer(\n",
      "TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 2106, in _train_and_save\n",
      "    model = self._train_single(**model_fit_kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 1993, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\stacker_ensemble_model.py\", line 270, in _fit\n",
      "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\bagged_ensemble_model.py\", line 298, in _fit\n",
      "    self._fit_folds(\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\bagged_ensemble_model.py\", line 724, in _fit_folds\n",
      "    fold_fitting_strategy.after_all_folds_scheduled()\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 690, in after_all_folds_scheduled\n",
      "    self._run_parallel(X, y, X_pseudo, y_pseudo, model_base_ref, time_limit_fold, head_node_id)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 631, in _run_parallel\n",
      "    self._process_fold_results(finished, unfinished, fold_ctx)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 587, in _process_fold_results\n",
      "    raise processed_exception\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 550, in _process_fold_results\n",
      "    fold_model, pred_proba, time_start_fit, time_end_fit, predict_time, predict_1_time, predict_n_size, fit_num_cpus, fit_num_gpus = self.ray.get(finished)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\worker.py\", line 2667, in get\n",
      "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\worker.py\", line 864, in get_objects\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(TypeError): \u001b[36mray::_ray_fit()\u001b[39m (pid=14768, ip=127.0.0.1)\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1889, in ray._raylet.execute_task\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 201, in _fit\n",
      "    train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "    dataset = self._process_train_data(\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "    self.processor = create_preprocessor(\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\utils\\data_preprocessor.py\", line 40, in create_preprocessor\n",
      "    return ColumnTransformer(\n",
      "TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "Fitting model: CatBoost_r50_BAG_L1 ... Training model for up to 1011.54s of the 1869.22s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.83%)\n",
      "2025-01-31 15:47:51,734\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-31 15:47:51,738\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-31 15:47:51,741\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-31 15:47:51,744\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-31 15:47:51,748\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-31 15:47:51,752\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-31 15:47:51,755\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\t0.9009\t = Validation score   (roc_auc)\n",
      "\t48.0s\t = Training   runtime\n",
      "\t0.09s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r11_BAG_L1 ... Training model for up to 960.87s of the 1818.56s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.69%)\n",
      "\t0.8707\t = Validation score   (roc_auc)\n",
      "\t34.03s\t = Training   runtime\n",
      "\t0.28s\t = Validation runtime\n",
      "Fitting model: XGBoost_r194_BAG_L1 ... Training model for up to 924.44s of the 1782.12s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=3.15%)\n",
      "2025-01-31 15:49:17,117\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\t0.8966\t = Validation score   (roc_auc)\n",
      "\t6.37s\t = Training   runtime\n",
      "\t0.12s\t = Validation runtime\n",
      "Fitting model: CatBoost_r69_BAG_L1 ... Training model for up to 915.11s of the 1772.79s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.93%)\n",
      "\t0.9012\t = Validation score   (roc_auc)\n",
      "\t65.77s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r103_BAG_L1 ... Training model for up to 846.45s of the 1704.13s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.64%)\n",
      "\t0.8603\t = Validation score   (roc_auc)\n",
      "\t14.39s\t = Training   runtime\n",
      "\t0.2s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r14_BAG_L1 ... Training model for up to 829.63s of the 1687.31s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.36%)\n",
      "\tWarning: Exception caused NeuralNetTorch_r14_BAG_L1 to fail during training... Skipping this model.\n",
      "\t\t\u001b[36mray::_ray_fit()\u001b[39m (pid=17420, ip=127.0.0.1)\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1889, in ray._raylet.execute_task\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 201, in _fit\n",
      "    train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "    dataset = self._process_train_data(\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "    self.processor = create_preprocessor(\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\utils\\data_preprocessor.py\", line 40, in create_preprocessor\n",
      "    return ColumnTransformer(\n",
      "TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 2106, in _train_and_save\n",
      "    model = self._train_single(**model_fit_kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 1993, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\stacker_ensemble_model.py\", line 270, in _fit\n",
      "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\bagged_ensemble_model.py\", line 298, in _fit\n",
      "    self._fit_folds(\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\bagged_ensemble_model.py\", line 724, in _fit_folds\n",
      "    fold_fitting_strategy.after_all_folds_scheduled()\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 690, in after_all_folds_scheduled\n",
      "    self._run_parallel(X, y, X_pseudo, y_pseudo, model_base_ref, time_limit_fold, head_node_id)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 631, in _run_parallel\n",
      "    self._process_fold_results(finished, unfinished, fold_ctx)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 587, in _process_fold_results\n",
      "    raise processed_exception\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 550, in _process_fold_results\n",
      "    fold_model, pred_proba, time_start_fit, time_end_fit, predict_time, predict_1_time, predict_n_size, fit_num_cpus, fit_num_gpus = self.ray.get(finished)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\worker.py\", line 2667, in get\n",
      "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\worker.py\", line 864, in get_objects\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(TypeError): \u001b[36mray::_ray_fit()\u001b[39m (pid=17420, ip=127.0.0.1)\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1889, in ray._raylet.execute_task\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 201, in _fit\n",
      "    train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "    dataset = self._process_train_data(\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "    self.processor = create_preprocessor(\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\utils\\data_preprocessor.py\", line 40, in create_preprocessor\n",
      "    return ColumnTransformer(\n",
      "TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "Fitting model: LightGBM_r161_BAG_L1 ... Training model for up to 824.21s of the 1681.89s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=3.17%)\n",
      "2025-01-31 15:50:59,199\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-31 15:50:59,199\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-31 15:50:59,209\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-31 15:50:59,211\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-31 15:50:59,217\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-31 15:50:59,221\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\t0.8902\t = Validation score   (roc_auc)\n",
      "\t15.63s\t = Training   runtime\n",
      "\t0.57s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r143_BAG_L1 ... Training model for up to 805.83s of the 1663.51s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.69%)\n",
      "\t0.889\t = Validation score   (roc_auc)\n",
      "\t10.59s\t = Training   runtime\n",
      "\t0.12s\t = Validation runtime\n",
      "Fitting model: CatBoost_r70_BAG_L1 ... Training model for up to 792.77s of the 1650.46s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=2.03%)\n",
      "\t0.901\t = Validation score   (roc_auc)\n",
      "\t75.33s\t = Training   runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r156_BAG_L1 ... Training model for up to 714.28s of the 1571.96s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.65%)\n",
      "\t0.8862\t = Validation score   (roc_auc)\n",
      "\t10.65s\t = Training   runtime\n",
      "\t0.15s\t = Validation runtime\n",
      "Fitting model: LightGBM_r196_BAG_L1 ... Training model for up to 701.23s of the 1558.91s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=3.62%)\n",
      "\t0.8987\t = Validation score   (roc_auc)\n",
      "\t25.52s\t = Training   runtime\n",
      "\t3.18s\t = Validation runtime\n",
      "Fitting model: CatBoost_r167_BAG_L1 ... Training model for up to 672.43s of the 1530.11s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=1.30%)\n",
      "\t0.8997\t = Validation score   (roc_auc)\n",
      "\t57.75s\t = Training   runtime\n",
      "\t0.1s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r95_BAG_L1 ... Training model for up to 612.26s of the 1469.95s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.49%)\n",
      "2025-01-31 15:54:33,155\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\t0.859\t = Validation score   (roc_auc)\n",
      "\t17.07s\t = Training   runtime\n",
      "\t0.21s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r41_BAG_L1 ... Training model for up to 592.81s of the 1450.49s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.40%)\n",
      "\tWarning: Exception caused NeuralNetTorch_r41_BAG_L1 to fail during training... Skipping this model.\n",
      "\t\t\u001b[36mray::_ray_fit()\u001b[39m (pid=14100, ip=127.0.0.1)\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1889, in ray._raylet.execute_task\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 201, in _fit\n",
      "    train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "    dataset = self._process_train_data(\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "    self.processor = create_preprocessor(\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\utils\\data_preprocessor.py\", line 40, in create_preprocessor\n",
      "    return ColumnTransformer(\n",
      "TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 2106, in _train_and_save\n",
      "    model = self._train_single(**model_fit_kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 1993, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\stacker_ensemble_model.py\", line 270, in _fit\n",
      "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\bagged_ensemble_model.py\", line 298, in _fit\n",
      "    self._fit_folds(\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\bagged_ensemble_model.py\", line 724, in _fit_folds\n",
      "    fold_fitting_strategy.after_all_folds_scheduled()\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 690, in after_all_folds_scheduled\n",
      "    self._run_parallel(X, y, X_pseudo, y_pseudo, model_base_ref, time_limit_fold, head_node_id)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 631, in _run_parallel\n",
      "    self._process_fold_results(finished, unfinished, fold_ctx)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 587, in _process_fold_results\n",
      "    raise processed_exception\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 550, in _process_fold_results\n",
      "    fold_model, pred_proba, time_start_fit, time_end_fit, predict_time, predict_1_time, predict_n_size, fit_num_cpus, fit_num_gpus = self.ray.get(finished)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\worker.py\", line 2667, in get\n",
      "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\worker.py\", line 864, in get_objects\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(TypeError): \u001b[36mray::_ray_fit()\u001b[39m (pid=14100, ip=127.0.0.1)\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1889, in ray._raylet.execute_task\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 201, in _fit\n",
      "    train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "    dataset = self._process_train_data(\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "    self.processor = create_preprocessor(\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\utils\\data_preprocessor.py\", line 40, in create_preprocessor\n",
      "    return ColumnTransformer(\n",
      "TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "Fitting model: XGBoost_r98_BAG_L1 ... Training model for up to 586.74s of the 1444.43s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=2.64%)\n",
      "2025-01-31 15:54:56,172\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-31 15:54:56,176\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-31 15:54:56,180\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-31 15:54:56,182\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-31 15:54:56,187\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-31 15:54:56,193\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\t0.8976\t = Validation score   (roc_auc)\n",
      "\t46.83s\t = Training   runtime\n",
      "\t0.6s\t = Validation runtime\n",
      "Fitting model: LightGBM_r15_BAG_L1 ... Training model for up to 537.19s of the 1394.88s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.50%)\n",
      "\t0.9027\t = Validation score   (roc_auc)\n",
      "\t7.99s\t = Training   runtime\n",
      "\t0.39s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r158_BAG_L1 ... Training model for up to 526.79s of the 1384.48s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.29%)\n",
      "\tWarning: Exception caused NeuralNetTorch_r158_BAG_L1 to fail during training... Skipping this model.\n",
      "\t\t\u001b[36mray::_ray_fit()\u001b[39m (pid=19116, ip=127.0.0.1)\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1889, in ray._raylet.execute_task\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 201, in _fit\n",
      "    train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "    dataset = self._process_train_data(\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "    self.processor = create_preprocessor(\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\utils\\data_preprocessor.py\", line 40, in create_preprocessor\n",
      "    return ColumnTransformer(\n",
      "TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 2106, in _train_and_save\n",
      "    model = self._train_single(**model_fit_kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 1993, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\stacker_ensemble_model.py\", line 270, in _fit\n",
      "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\bagged_ensemble_model.py\", line 298, in _fit\n",
      "    self._fit_folds(\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\bagged_ensemble_model.py\", line 724, in _fit_folds\n",
      "    fold_fitting_strategy.after_all_folds_scheduled()\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 690, in after_all_folds_scheduled\n",
      "    self._run_parallel(X, y, X_pseudo, y_pseudo, model_base_ref, time_limit_fold, head_node_id)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 631, in _run_parallel\n",
      "    self._process_fold_results(finished, unfinished, fold_ctx)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 587, in _process_fold_results\n",
      "    raise processed_exception\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 550, in _process_fold_results\n",
      "    fold_model, pred_proba, time_start_fit, time_end_fit, predict_time, predict_1_time, predict_n_size, fit_num_cpus, fit_num_gpus = self.ray.get(finished)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\worker.py\", line 2667, in get\n",
      "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\worker.py\", line 864, in get_objects\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(TypeError): \u001b[36mray::_ray_fit()\u001b[39m (pid=19116, ip=127.0.0.1)\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1889, in ray._raylet.execute_task\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 201, in _fit\n",
      "    train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "    dataset = self._process_train_data(\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "    self.processor = create_preprocessor(\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\utils\\data_preprocessor.py\", line 40, in create_preprocessor\n",
      "    return ColumnTransformer(\n",
      "TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "Fitting model: CatBoost_r86_BAG_L1 ... Training model for up to 521.48s of the 1379.16s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=3.55%)\n",
      "2025-01-31 15:56:01,721\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-31 15:56:01,723\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-31 15:56:01,723\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-31 15:56:01,723\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-31 15:56:01,736\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-31 15:56:01,740\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-31 15:57:53,286\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\t0.8987\t = Validation score   (roc_auc)\n",
      "\t121.55s\t = Training   runtime\n",
      "\t0.09s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r37_BAG_L1 ... Training model for up to 397.29s of the 1254.96s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.52%)\n",
      "\t0.8786\t = Validation score   (roc_auc)\n",
      "\t15.07s\t = Training   runtime\n",
      "\t0.15s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r197_BAG_L1 ... Training model for up to 379.82s of the 1237.51s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.31%)\n",
      "\tWarning: Exception caused NeuralNetTorch_r197_BAG_L1 to fail during training... Skipping this model.\n",
      "\t\t\u001b[36mray::_ray_fit()\u001b[39m (pid=14120, ip=127.0.0.1)\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1889, in ray._raylet.execute_task\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 201, in _fit\n",
      "    train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "    dataset = self._process_train_data(\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "    self.processor = create_preprocessor(\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\utils\\data_preprocessor.py\", line 40, in create_preprocessor\n",
      "    return ColumnTransformer(\n",
      "TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 2106, in _train_and_save\n",
      "    model = self._train_single(**model_fit_kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 1993, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\stacker_ensemble_model.py\", line 270, in _fit\n",
      "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\bagged_ensemble_model.py\", line 298, in _fit\n",
      "    self._fit_folds(\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\bagged_ensemble_model.py\", line 724, in _fit_folds\n",
      "    fold_fitting_strategy.after_all_folds_scheduled()\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 690, in after_all_folds_scheduled\n",
      "    self._run_parallel(X, y, X_pseudo, y_pseudo, model_base_ref, time_limit_fold, head_node_id)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 631, in _run_parallel\n",
      "    self._process_fold_results(finished, unfinished, fold_ctx)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 587, in _process_fold_results\n",
      "    raise processed_exception\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 550, in _process_fold_results\n",
      "    fold_model, pred_proba, time_start_fit, time_end_fit, predict_time, predict_1_time, predict_n_size, fit_num_cpus, fit_num_gpus = self.ray.get(finished)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\worker.py\", line 2667, in get\n",
      "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\worker.py\", line 864, in get_objects\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(TypeError): \u001b[36mray::_ray_fit()\u001b[39m (pid=14120, ip=127.0.0.1)\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1889, in ray._raylet.execute_task\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 201, in _fit\n",
      "    train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "    dataset = self._process_train_data(\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "    self.processor = create_preprocessor(\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\utils\\data_preprocessor.py\", line 40, in create_preprocessor\n",
      "    return ColumnTransformer(\n",
      "TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "Fitting model: CatBoost_r49_BAG_L1 ... Training model for up to 374.18s of the 1231.87s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.50%)\n",
      "2025-01-31 15:58:28,939\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-31 15:58:28,942\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-31 15:58:28,946\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-31 15:58:28,948\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-31 15:58:28,950\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-31 15:58:28,968\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-31 15:58:28,973\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\t0.901\t = Validation score   (roc_auc)\n",
      "\t16.98s\t = Training   runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: LightGBM_r143_BAG_L1 ... Training model for up to 354.59s of the 1212.27s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=1.80%)\n",
      "\t0.8949\t = Validation score   (roc_auc)\n",
      "\t13.27s\t = Training   runtime\n",
      "\t0.39s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r134_BAG_L1 ... Training model for up to 338.90s of the 1196.58s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.52%)\n",
      "\t0.8793\t = Validation score   (roc_auc)\n",
      "\t19.38s\t = Training   runtime\n",
      "\t0.2s\t = Validation runtime\n",
      "Fitting model: LightGBM_r94_BAG_L1 ... Training model for up to 317.03s of the 1174.71s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.46%)\n",
      "\t0.9046\t = Validation score   (roc_auc)\n",
      "\t5.45s\t = Training   runtime\n",
      "\t0.38s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r143_BAG_L1 ... Training model for up to 308.99s of the 1166.68s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.28%)\n",
      "\tWarning: Exception caused NeuralNetTorch_r143_BAG_L1 to fail during training... Skipping this model.\n",
      "\t\t\u001b[36mray::_ray_fit()\u001b[39m (pid=10556, ip=127.0.0.1)\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1889, in ray._raylet.execute_task\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 201, in _fit\n",
      "    train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "    dataset = self._process_train_data(\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "    self.processor = create_preprocessor(\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\utils\\data_preprocessor.py\", line 40, in create_preprocessor\n",
      "    return ColumnTransformer(\n",
      "TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 2106, in _train_and_save\n",
      "    model = self._train_single(**model_fit_kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 1993, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\stacker_ensemble_model.py\", line 270, in _fit\n",
      "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\bagged_ensemble_model.py\", line 298, in _fit\n",
      "    self._fit_folds(\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\bagged_ensemble_model.py\", line 724, in _fit_folds\n",
      "    fold_fitting_strategy.after_all_folds_scheduled()\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 690, in after_all_folds_scheduled\n",
      "    self._run_parallel(X, y, X_pseudo, y_pseudo, model_base_ref, time_limit_fold, head_node_id)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 631, in _run_parallel\n",
      "    self._process_fold_results(finished, unfinished, fold_ctx)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 587, in _process_fold_results\n",
      "    raise processed_exception\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 550, in _process_fold_results\n",
      "    fold_model, pred_proba, time_start_fit, time_end_fit, predict_time, predict_1_time, predict_n_size, fit_num_cpus, fit_num_gpus = self.ray.get(finished)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\worker.py\", line 2667, in get\n",
      "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\worker.py\", line 864, in get_objects\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(TypeError): \u001b[36mray::_ray_fit()\u001b[39m (pid=10556, ip=127.0.0.1)\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1889, in ray._raylet.execute_task\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 201, in _fit\n",
      "    train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "    dataset = self._process_train_data(\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "    self.processor = create_preprocessor(\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\utils\\data_preprocessor.py\", line 40, in create_preprocessor\n",
      "    return ColumnTransformer(\n",
      "TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "Fitting model: CatBoost_r128_BAG_L1 ... Training model for up to 303.47s of the 1161.16s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=2.82%)\n",
      "2025-01-31 15:59:39,552\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-31 15:59:39,556\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-31 15:59:39,559\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-31 15:59:39,561\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-31 15:59:39,563\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\t0.8983\t = Validation score   (roc_auc)\n",
      "\t81.46s\t = Training   runtime\n",
      "\t0.1s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r111_BAG_L1 ... Training model for up to 219.32s of the 1077.01s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.58%)\n",
      "\t0.8814\t = Validation score   (roc_auc)\n",
      "\t9.45s\t = Training   runtime\n",
      "\t0.09s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r31_BAG_L1 ... Training model for up to 207.51s of the 1065.19s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.64%)\n",
      "\tWarning: Exception caused NeuralNetTorch_r31_BAG_L1 to fail during training... Skipping this model.\n",
      "\t\t\u001b[36mray::_ray_fit()\u001b[39m (pid=16916, ip=127.0.0.1)\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1889, in ray._raylet.execute_task\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 201, in _fit\n",
      "    train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "    dataset = self._process_train_data(\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "    self.processor = create_preprocessor(\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\utils\\data_preprocessor.py\", line 40, in create_preprocessor\n",
      "    return ColumnTransformer(\n",
      "TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 2106, in _train_and_save\n",
      "    model = self._train_single(**model_fit_kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 1993, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\stacker_ensemble_model.py\", line 270, in _fit\n",
      "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\bagged_ensemble_model.py\", line 298, in _fit\n",
      "    self._fit_folds(\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\bagged_ensemble_model.py\", line 724, in _fit_folds\n",
      "    fold_fitting_strategy.after_all_folds_scheduled()\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 690, in after_all_folds_scheduled\n",
      "    self._run_parallel(X, y, X_pseudo, y_pseudo, model_base_ref, time_limit_fold, head_node_id)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 631, in _run_parallel\n",
      "    self._process_fold_results(finished, unfinished, fold_ctx)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 587, in _process_fold_results\n",
      "    raise processed_exception\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 550, in _process_fold_results\n",
      "    fold_model, pred_proba, time_start_fit, time_end_fit, predict_time, predict_1_time, predict_n_size, fit_num_cpus, fit_num_gpus = self.ray.get(finished)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\worker.py\", line 2667, in get\n",
      "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\worker.py\", line 864, in get_objects\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(TypeError): \u001b[36mray::_ray_fit()\u001b[39m (pid=16916, ip=127.0.0.1)\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1889, in ray._raylet.execute_task\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 201, in _fit\n",
      "    train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "    dataset = self._process_train_data(\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "    self.processor = create_preprocessor(\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\utils\\data_preprocessor.py\", line 40, in create_preprocessor\n",
      "    return ColumnTransformer(\n",
      "TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "Fitting model: NeuralNetFastAI_r65_BAG_L1 ... Training model for up to 201.31s of the 1058.99s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.64%)\n",
      "2025-01-31 16:01:22,304\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-31 16:01:22,307\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-31 16:01:22,310\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-31 16:01:22,312\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-31 16:01:22,316\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-31 16:01:22,319\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\t0.8713\t = Validation score   (roc_auc)\n",
      "\t11.05s\t = Training   runtime\n",
      "\t0.09s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r88_BAG_L1 ... Training model for up to 187.72s of the 1045.41s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=1.25%)\n",
      "\t0.866\t = Validation score   (roc_auc)\n",
      "\t9.54s\t = Training   runtime\n",
      "\t0.14s\t = Validation runtime\n",
      "Fitting model: LightGBM_r30_BAG_L1 ... Training model for up to 175.38s of the 1033.07s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=2.96%)\n",
      "2025-01-31 16:01:50,757\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\t0.8958\t = Validation score   (roc_auc)\n",
      "\t12.77s\t = Training   runtime\n",
      "\t0.99s\t = Validation runtime\n",
      "Fitting model: XGBoost_r49_BAG_L1 ... Training model for up to 159.52s of the 1017.19s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=1.81%)\n",
      "\t0.898\t = Validation score   (roc_auc)\n",
      "\t10.84s\t = Training   runtime\n",
      "\t0.21s\t = Validation runtime\n",
      "Fitting model: CatBoost_r5_BAG_L1 ... Training model for up to 146.16s of the 1003.84s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.52%)\n",
      "\t0.9011\t = Validation score   (roc_auc)\n",
      "\t19.0s\t = Training   runtime\n",
      "\t0.09s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r87_BAG_L1 ... Training model for up to 124.71s of the 982.40s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.34%)\n",
      "\tWarning: Exception caused NeuralNetTorch_r87_BAG_L1 to fail during training... Skipping this model.\n",
      "\t\t\u001b[36mray::_ray_fit()\u001b[39m (pid=5720, ip=127.0.0.1)\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1889, in ray._raylet.execute_task\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 201, in _fit\n",
      "    train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "    dataset = self._process_train_data(\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "    self.processor = create_preprocessor(\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\utils\\data_preprocessor.py\", line 40, in create_preprocessor\n",
      "    return ColumnTransformer(\n",
      "TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 2106, in _train_and_save\n",
      "    model = self._train_single(**model_fit_kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 1993, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\stacker_ensemble_model.py\", line 270, in _fit\n",
      "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\bagged_ensemble_model.py\", line 298, in _fit\n",
      "    self._fit_folds(\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\bagged_ensemble_model.py\", line 724, in _fit_folds\n",
      "    fold_fitting_strategy.after_all_folds_scheduled()\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 690, in after_all_folds_scheduled\n",
      "    self._run_parallel(X, y, X_pseudo, y_pseudo, model_base_ref, time_limit_fold, head_node_id)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 631, in _run_parallel\n",
      "    self._process_fold_results(finished, unfinished, fold_ctx)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 587, in _process_fold_results\n",
      "    raise processed_exception\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 550, in _process_fold_results\n",
      "    fold_model, pred_proba, time_start_fit, time_end_fit, predict_time, predict_1_time, predict_n_size, fit_num_cpus, fit_num_gpus = self.ray.get(finished)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\worker.py\", line 2667, in get\n",
      "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\worker.py\", line 864, in get_objects\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(TypeError): \u001b[36mray::_ray_fit()\u001b[39m (pid=5720, ip=127.0.0.1)\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1889, in ray._raylet.execute_task\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 201, in _fit\n",
      "    train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "    dataset = self._process_train_data(\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "    self.processor = create_preprocessor(\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\utils\\data_preprocessor.py\", line 40, in create_preprocessor\n",
      "    return ColumnTransformer(\n",
      "TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "Fitting model: NeuralNetTorch_r71_BAG_L1 ... Training model for up to 119.31s of the 977.00s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.48%)\n",
      "\tWarning: Exception caused NeuralNetTorch_r71_BAG_L1 to fail during training... Skipping this model.\n",
      "\t\t\u001b[36mray::_ray_fit()\u001b[39m (pid=1648, ip=127.0.0.1)\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1889, in ray._raylet.execute_task\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 201, in _fit\n",
      "    train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "    dataset = self._process_train_data(\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "    self.processor = create_preprocessor(\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\utils\\data_preprocessor.py\", line 40, in create_preprocessor\n",
      "    return ColumnTransformer(\n",
      "TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 2106, in _train_and_save\n",
      "    model = self._train_single(**model_fit_kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 1993, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\stacker_ensemble_model.py\", line 270, in _fit\n",
      "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\bagged_ensemble_model.py\", line 298, in _fit\n",
      "    self._fit_folds(\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\bagged_ensemble_model.py\", line 724, in _fit_folds\n",
      "    fold_fitting_strategy.after_all_folds_scheduled()\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 690, in after_all_folds_scheduled\n",
      "    self._run_parallel(X, y, X_pseudo, y_pseudo, model_base_ref, time_limit_fold, head_node_id)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 631, in _run_parallel\n",
      "    self._process_fold_results(finished, unfinished, fold_ctx)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 587, in _process_fold_results\n",
      "    raise processed_exception\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 550, in _process_fold_results\n",
      "    fold_model, pred_proba, time_start_fit, time_end_fit, predict_time, predict_1_time, predict_n_size, fit_num_cpus, fit_num_gpus = self.ray.get(finished)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\worker.py\", line 2667, in get\n",
      "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\worker.py\", line 864, in get_objects\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(TypeError): \u001b[36mray::_ray_fit()\u001b[39m (pid=1648, ip=127.0.0.1)\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1889, in ray._raylet.execute_task\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 201, in _fit\n",
      "    train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "    dataset = self._process_train_data(\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "    self.processor = create_preprocessor(\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\utils\\data_preprocessor.py\", line 40, in create_preprocessor\n",
      "    return ColumnTransformer(\n",
      "TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "2025-01-31 16:02:43,839\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-31 16:02:43,839\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-31 16:02:43,849\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-31 16:02:43,853\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-31 16:02:43,855\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-31 16:02:43,861\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "Fitting model: CatBoost_r143_BAG_L1 ... Training model for up to 113.73s of the 971.41s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=2.44%)\n",
      "2025-01-31 16:02:48,909\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-31 16:02:48,909\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-31 16:02:48,909\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-31 16:02:48,909\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-31 16:02:48,921\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-31 16:02:49,922\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-31 16:02:56,062\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\t0.898\t = Validation score   (roc_auc)\n",
      "\t24.13s\t = Training   runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: XGBoost_r31_BAG_L1 ... Training model for up to 87.02s of the 944.71s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=1.34%)\n",
      "\t0.901\t = Validation score   (roc_auc)\n",
      "\t26.67s\t = Training   runtime\n",
      "\t0.81s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r185_BAG_L1 ... Training model for up to 57.79s of the 915.47s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.39%)\n",
      "\tWarning: Exception caused NeuralNetTorch_r185_BAG_L1 to fail during training... Skipping this model.\n",
      "\t\t\u001b[36mray::_ray_fit()\u001b[39m (pid=1156, ip=127.0.0.1)\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1889, in ray._raylet.execute_task\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 201, in _fit\n",
      "    train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "    dataset = self._process_train_data(\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "    self.processor = create_preprocessor(\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\utils\\data_preprocessor.py\", line 40, in create_preprocessor\n",
      "    return ColumnTransformer(\n",
      "TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 2106, in _train_and_save\n",
      "    model = self._train_single(**model_fit_kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 1993, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\stacker_ensemble_model.py\", line 270, in _fit\n",
      "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\bagged_ensemble_model.py\", line 298, in _fit\n",
      "    self._fit_folds(\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\bagged_ensemble_model.py\", line 724, in _fit_folds\n",
      "    fold_fitting_strategy.after_all_folds_scheduled()\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 690, in after_all_folds_scheduled\n",
      "    self._run_parallel(X, y, X_pseudo, y_pseudo, model_base_ref, time_limit_fold, head_node_id)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 631, in _run_parallel\n",
      "    self._process_fold_results(finished, unfinished, fold_ctx)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 587, in _process_fold_results\n",
      "    raise processed_exception\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 550, in _process_fold_results\n",
      "    fold_model, pred_proba, time_start_fit, time_end_fit, predict_time, predict_1_time, predict_n_size, fit_num_cpus, fit_num_gpus = self.ray.get(finished)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\worker.py\", line 2667, in get\n",
      "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\worker.py\", line 864, in get_objects\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(TypeError): \u001b[36mray::_ray_fit()\u001b[39m (pid=1156, ip=127.0.0.1)\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1889, in ray._raylet.execute_task\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 201, in _fit\n",
      "    train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "    dataset = self._process_train_data(\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "    self.processor = create_preprocessor(\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\utils\\data_preprocessor.py\", line 40, in create_preprocessor\n",
      "    return ColumnTransformer(\n",
      "TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "Fitting model: NeuralNetFastAI_r160_BAG_L1 ... Training model for up to 52.54s of the 910.23s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=1.00%)\n",
      "2025-01-31 16:03:50,406\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-31 16:03:50,409\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-31 16:03:50,411\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-31 16:03:50,416\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-31 16:03:50,418\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-31 16:03:50,423\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\t0.887\t = Validation score   (roc_auc)\n",
      "\t16.82s\t = Training   runtime\n",
      "\t0.26s\t = Validation runtime\n",
      "Fitting model: CatBoost_r60_BAG_L1 ... Training model for up to 33.10s of the 890.79s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=1.49%)\n",
      "\t0.897\t = Validation score   (roc_auc)\n",
      "\t27.36s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: LightGBM_r135_BAG_L1 ... Training model for up to 2.45s of the 860.14s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=3.28%)\n",
      "\t0.8995\t = Validation score   (roc_auc)\n",
      "\t3.46s\t = Training   runtime\n",
      "\t0.22s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 360.00s of the 853.20s of remaining time.\n",
      "\tEnsemble Weights: {'LightGBM_r96_BAG_L1': 0.222, 'CatBoost_BAG_L1': 0.167, 'LightGBM_r94_BAG_L1': 0.167, 'NeuralNetFastAI_r160_BAG_L1': 0.167, 'XGBoost_BAG_L1': 0.111, 'NeuralNetFastAI_r143_BAG_L1': 0.111, 'XGBoost_r31_BAG_L1': 0.056}\n",
      "\t0.9111\t = Validation score   (roc_auc)\n",
      "\t0.13s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Excluded models: ['KNN', 'RF', 'XT'] (Specified by `excluded_model_types`)\n",
      "Fitting 90 L2 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBMXT_BAG_L2 ... Training model for up to 853.04s of the 852.87s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=1.02%)\n",
      "\t0.9075\t = Validation score   (roc_auc)\n",
      "\t3.06s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L2 ... Training model for up to 847.47s of the 847.30s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=1.28%)\n",
      "\t0.9041\t = Validation score   (roc_auc)\n",
      "\t3.78s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L2 ... Training model for up to 840.91s of the 840.74s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=1.96%)\n",
      "\t0.9096\t = Validation score   (roc_auc)\n",
      "\t40.63s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L2 ... Training model for up to 797.44s of the 797.27s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.88%)\n",
      "\t0.8954\t = Validation score   (roc_auc)\n",
      "\t10.75s\t = Training   runtime\n",
      "\t0.19s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L2 ... Training model for up to 784.24s of the 784.07s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=3.66%)\n",
      "\t0.9039\t = Validation score   (roc_auc)\n",
      "\t5.2s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_BAG_L2 ... Training model for up to 775.96s of the 775.77s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.59%)\n",
      "\tWarning: Exception caused NeuralNetTorch_BAG_L2 to fail during training... Skipping this model.\n",
      "\t\t\u001b[36mray::_ray_fit()\u001b[39m (pid=8368, ip=127.0.0.1)\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1889, in ray._raylet.execute_task\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 201, in _fit\n",
      "    train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "    dataset = self._process_train_data(\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "    self.processor = create_preprocessor(\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\utils\\data_preprocessor.py\", line 40, in create_preprocessor\n",
      "    return ColumnTransformer(\n",
      "TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 2106, in _train_and_save\n",
      "    model = self._train_single(**model_fit_kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 1993, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\stacker_ensemble_model.py\", line 270, in _fit\n",
      "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\bagged_ensemble_model.py\", line 298, in _fit\n",
      "    self._fit_folds(\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\bagged_ensemble_model.py\", line 724, in _fit_folds\n",
      "    fold_fitting_strategy.after_all_folds_scheduled()\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 690, in after_all_folds_scheduled\n",
      "    self._run_parallel(X, y, X_pseudo, y_pseudo, model_base_ref, time_limit_fold, head_node_id)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 631, in _run_parallel\n",
      "    self._process_fold_results(finished, unfinished, fold_ctx)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 587, in _process_fold_results\n",
      "    raise processed_exception\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 550, in _process_fold_results\n",
      "    fold_model, pred_proba, time_start_fit, time_end_fit, predict_time, predict_1_time, predict_n_size, fit_num_cpus, fit_num_gpus = self.ray.get(finished)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\worker.py\", line 2667, in get\n",
      "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\worker.py\", line 864, in get_objects\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(TypeError): \u001b[36mray::_ray_fit()\u001b[39m (pid=8368, ip=127.0.0.1)\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1889, in ray._raylet.execute_task\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 201, in _fit\n",
      "    train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "    dataset = self._process_train_data(\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "    self.processor = create_preprocessor(\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\utils\\data_preprocessor.py\", line 40, in create_preprocessor\n",
      "    return ColumnTransformer(\n",
      "TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "Fitting model: LightGBMLarge_BAG_L2 ... Training model for up to 769.98s of the 769.81s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=3.68%)\n",
      "2025-01-31 16:06:10,608\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-31 16:06:10,613\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-31 16:06:10,617\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-31 16:06:10,621\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-31 16:06:10,624\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-31 16:06:10,630\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\t0.9014\t = Validation score   (roc_auc)\n",
      "\t9.12s\t = Training   runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitting model: CatBoost_r177_BAG_L2 ... Training model for up to 758.18s of the 758.01s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=2.04%)\n",
      "\t0.9096\t = Validation score   (roc_auc)\n",
      "\t11.32s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r79_BAG_L2 ... Training model for up to 744.15s of the 743.98s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.56%)\n",
      "2025-01-31 16:06:34,024\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-31 16:06:34,028\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\tWarning: Exception caused NeuralNetTorch_r79_BAG_L2 to fail during training... Skipping this model.\n",
      "\t\t\u001b[36mray::_ray_fit()\u001b[39m (pid=21872, ip=127.0.0.1)\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1889, in ray._raylet.execute_task\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 201, in _fit\n",
      "    train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "    dataset = self._process_train_data(\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "    self.processor = create_preprocessor(\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\utils\\data_preprocessor.py\", line 40, in create_preprocessor\n",
      "    return ColumnTransformer(\n",
      "TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 2106, in _train_and_save\n",
      "    model = self._train_single(**model_fit_kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 1993, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\stacker_ensemble_model.py\", line 270, in _fit\n",
      "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\bagged_ensemble_model.py\", line 298, in _fit\n",
      "    self._fit_folds(\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\bagged_ensemble_model.py\", line 724, in _fit_folds\n",
      "    fold_fitting_strategy.after_all_folds_scheduled()\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 690, in after_all_folds_scheduled\n",
      "    self._run_parallel(X, y, X_pseudo, y_pseudo, model_base_ref, time_limit_fold, head_node_id)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 631, in _run_parallel\n",
      "    self._process_fold_results(finished, unfinished, fold_ctx)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 587, in _process_fold_results\n",
      "    raise processed_exception\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 550, in _process_fold_results\n",
      "    fold_model, pred_proba, time_start_fit, time_end_fit, predict_time, predict_1_time, predict_n_size, fit_num_cpus, fit_num_gpus = self.ray.get(finished)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\worker.py\", line 2667, in get\n",
      "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\worker.py\", line 864, in get_objects\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(TypeError): \u001b[36mray::_ray_fit()\u001b[39m (pid=21872, ip=127.0.0.1)\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1889, in ray._raylet.execute_task\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 201, in _fit\n",
      "    train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "    dataset = self._process_train_data(\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "    self.processor = create_preprocessor(\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\utils\\data_preprocessor.py\", line 40, in create_preprocessor\n",
      "    return ColumnTransformer(\n",
      "TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "Fitting model: LightGBM_r131_BAG_L2 ... Training model for up to 738.54s of the 738.37s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=1.91%)\n",
      "2025-01-31 16:06:42,907\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-31 16:06:42,911\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-31 16:06:42,915\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-31 16:06:42,918\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-31 16:06:42,922\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-31 16:06:42,924\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-31 16:06:42,929\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\t0.9044\t = Validation score   (roc_auc)\n",
      "\t6.07s\t = Training   runtime\n",
      "\t0.17s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r191_BAG_L2 ... Training model for up to 729.76s of the 729.59s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.95%)\n",
      "\t0.891\t = Validation score   (roc_auc)\n",
      "\t20.24s\t = Training   runtime\n",
      "\t0.27s\t = Validation runtime\n",
      "Fitting model: CatBoost_r9_BAG_L2 ... Training model for up to 707.01s of the 706.84s of remaining time.\n",
      "\tMemory not enough to fit 8 folds in parallel. Will train 4 folds in parallel instead (Estimated 11.97% memory usage per fold, 47.87%/80.00% total).\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=3, gpus=0, memory=11.97%)\n",
      "2025-01-31 16:08:16,191\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\t0.9092\t = Validation score   (roc_auc)\n",
      "\t113.08s\t = Training   runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitting model: LightGBM_r96_BAG_L2 ... Training model for up to 591.73s of the 591.56s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.85%)\n",
      "\t0.9095\t = Validation score   (roc_auc)\n",
      "\t2.28s\t = Training   runtime\n",
      "\t0.13s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r22_BAG_L2 ... Training model for up to 586.20s of the 586.02s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.64%)\n",
      "\tWarning: Exception caused NeuralNetTorch_r22_BAG_L2 to fail during training... Skipping this model.\n",
      "\t\t\u001b[36mray::_ray_fit()\u001b[39m (pid=15972, ip=127.0.0.1)\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1889, in ray._raylet.execute_task\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 201, in _fit\n",
      "    train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "    dataset = self._process_train_data(\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "    self.processor = create_preprocessor(\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\utils\\data_preprocessor.py\", line 40, in create_preprocessor\n",
      "    return ColumnTransformer(\n",
      "TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 2106, in _train_and_save\n",
      "    model = self._train_single(**model_fit_kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 1993, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\stacker_ensemble_model.py\", line 270, in _fit\n",
      "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\bagged_ensemble_model.py\", line 298, in _fit\n",
      "    self._fit_folds(\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\bagged_ensemble_model.py\", line 724, in _fit_folds\n",
      "    fold_fitting_strategy.after_all_folds_scheduled()\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 690, in after_all_folds_scheduled\n",
      "    self._run_parallel(X, y, X_pseudo, y_pseudo, model_base_ref, time_limit_fold, head_node_id)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 631, in _run_parallel\n",
      "    self._process_fold_results(finished, unfinished, fold_ctx)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 587, in _process_fold_results\n",
      "    raise processed_exception\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 550, in _process_fold_results\n",
      "    fold_model, pred_proba, time_start_fit, time_end_fit, predict_time, predict_1_time, predict_n_size, fit_num_cpus, fit_num_gpus = self.ray.get(finished)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\worker.py\", line 2667, in get\n",
      "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\worker.py\", line 864, in get_objects\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(TypeError): \u001b[36mray::_ray_fit()\u001b[39m (pid=15972, ip=127.0.0.1)\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1889, in ray._raylet.execute_task\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 201, in _fit\n",
      "    train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "    dataset = self._process_train_data(\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "    self.processor = create_preprocessor(\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\utils\\data_preprocessor.py\", line 40, in create_preprocessor\n",
      "    return ColumnTransformer(\n",
      "TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "Fitting model: XGBoost_r33_BAG_L2 ... Training model for up to 580.31s of the 580.14s of remaining time.\n",
      "\tMemory not enough to fit 8 folds in parallel. Will train 4 folds in parallel instead (Estimated 15.22% memory usage per fold, 60.86%/80.00% total).\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=3, gpus=0, memory=15.22%)\n",
      "2025-01-31 16:09:20,160\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-31 16:09:21,175\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-31 16:09:21,179\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-31 16:09:21,183\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-31 16:09:21,186\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-31 16:09:21,191\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-31 16:09:38,175\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\t0.9044\t = Validation score   (roc_auc)\n",
      "\t21.53s\t = Training   runtime\n",
      "\t0.13s\t = Validation runtime\n",
      "Fitting model: CatBoost_r137_BAG_L2 ... Training model for up to 556.83s of the 556.66s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.98%)\n",
      "2025-01-31 16:09:43,743\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\t0.9103\t = Validation score   (roc_auc)\n",
      "\t23.25s\t = Training   runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r102_BAG_L2 ... Training model for up to 529.99s of the 529.82s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=1.03%)\n",
      "\t0.8858\t = Validation score   (roc_auc)\n",
      "\t8.52s\t = Training   runtime\n",
      "\t0.15s\t = Validation runtime\n",
      "Fitting model: CatBoost_r13_BAG_L2 ... Training model for up to 519.01s of the 518.84s of remaining time.\n",
      "\tMemory not enough to fit 8 folds in parallel. Will train 4 folds in parallel instead (Estimated 12.27% memory usage per fold, 49.08%/80.00% total).\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=3, gpus=0, memory=12.27%)\n",
      "2025-01-31 16:10:44,942\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\t0.9099\t = Validation score   (roc_auc)\n",
      "\t45.99s\t = Training   runtime\n",
      "\t0.09s\t = Validation runtime\n",
      "Fitting model: LightGBM_r188_BAG_L2 ... Training model for up to 470.67s of the 470.50s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=2.91%)\n",
      "\t0.907\t = Validation score   (roc_auc)\n",
      "\t4.46s\t = Training   runtime\n",
      "\t0.11s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r145_BAG_L2 ... Training model for up to 462.75s of the 462.57s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=1.19%)\n",
      "\t0.8953\t = Validation score   (roc_auc)\n",
      "\t18.13s\t = Training   runtime\n",
      "\t0.25s\t = Validation runtime\n",
      "Fitting model: XGBoost_r89_BAG_L2 ... Training model for up to 441.89s of the 441.72s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=2.39%)\n",
      "\t0.9062\t = Validation score   (roc_auc)\n",
      "\t4.05s\t = Training   runtime\n",
      "\t0.09s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r30_BAG_L2 ... Training model for up to 434.77s of the 434.60s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.53%)\n",
      "\tWarning: Exception caused NeuralNetTorch_r30_BAG_L2 to fail during training... Skipping this model.\n",
      "\t\t\u001b[36mray::_ray_fit()\u001b[39m (pid=23036, ip=127.0.0.1)\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1889, in ray._raylet.execute_task\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 201, in _fit\n",
      "    train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "    dataset = self._process_train_data(\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "    self.processor = create_preprocessor(\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\utils\\data_preprocessor.py\", line 40, in create_preprocessor\n",
      "    return ColumnTransformer(\n",
      "TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 2106, in _train_and_save\n",
      "    model = self._train_single(**model_fit_kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 1993, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\stacker_ensemble_model.py\", line 270, in _fit\n",
      "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\bagged_ensemble_model.py\", line 298, in _fit\n",
      "    self._fit_folds(\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\bagged_ensemble_model.py\", line 724, in _fit_folds\n",
      "    fold_fitting_strategy.after_all_folds_scheduled()\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 690, in after_all_folds_scheduled\n",
      "    self._run_parallel(X, y, X_pseudo, y_pseudo, model_base_ref, time_limit_fold, head_node_id)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 631, in _run_parallel\n",
      "    self._process_fold_results(finished, unfinished, fold_ctx)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 587, in _process_fold_results\n",
      "    raise processed_exception\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 550, in _process_fold_results\n",
      "    fold_model, pred_proba, time_start_fit, time_end_fit, predict_time, predict_1_time, predict_n_size, fit_num_cpus, fit_num_gpus = self.ray.get(finished)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\worker.py\", line 2667, in get\n",
      "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\worker.py\", line 864, in get_objects\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(TypeError): \u001b[36mray::_ray_fit()\u001b[39m (pid=23036, ip=127.0.0.1)\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1889, in ray._raylet.execute_task\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 201, in _fit\n",
      "    train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "    dataset = self._process_train_data(\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "    self.processor = create_preprocessor(\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\utils\\data_preprocessor.py\", line 40, in create_preprocessor\n",
      "    return ColumnTransformer(\n",
      "TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "Fitting model: LightGBM_r130_BAG_L2 ... Training model for up to 428.88s of the 428.71s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=2.36%)\n",
      "2025-01-31 16:11:52,442\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-31 16:11:52,446\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-31 16:11:52,451\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-31 16:11:52,455\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-31 16:11:52,457\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\t0.9046\t = Validation score   (roc_auc)\n",
      "\t3.66s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r86_BAG_L2 ... Training model for up to 422.54s of the 422.36s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.62%)\n",
      "\tWarning: Exception caused NeuralNetTorch_r86_BAG_L2 to fail during training... Skipping this model.\n",
      "\t\t\u001b[36mray::_ray_fit()\u001b[39m (pid=16424, ip=127.0.0.1)\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1889, in ray._raylet.execute_task\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 201, in _fit\n",
      "    train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "    dataset = self._process_train_data(\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "    self.processor = create_preprocessor(\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\utils\\data_preprocessor.py\", line 40, in create_preprocessor\n",
      "    return ColumnTransformer(\n",
      "TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 2106, in _train_and_save\n",
      "    model = self._train_single(**model_fit_kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 1993, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\stacker_ensemble_model.py\", line 270, in _fit\n",
      "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\bagged_ensemble_model.py\", line 298, in _fit\n",
      "    self._fit_folds(\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\bagged_ensemble_model.py\", line 724, in _fit_folds\n",
      "    fold_fitting_strategy.after_all_folds_scheduled()\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 690, in after_all_folds_scheduled\n",
      "    self._run_parallel(X, y, X_pseudo, y_pseudo, model_base_ref, time_limit_fold, head_node_id)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 631, in _run_parallel\n",
      "    self._process_fold_results(finished, unfinished, fold_ctx)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 587, in _process_fold_results\n",
      "    raise processed_exception\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 550, in _process_fold_results\n",
      "    fold_model, pred_proba, time_start_fit, time_end_fit, predict_time, predict_1_time, predict_n_size, fit_num_cpus, fit_num_gpus = self.ray.get(finished)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\worker.py\", line 2667, in get\n",
      "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\worker.py\", line 864, in get_objects\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(TypeError): \u001b[36mray::_ray_fit()\u001b[39m (pid=16424, ip=127.0.0.1)\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1889, in ray._raylet.execute_task\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 201, in _fit\n",
      "    train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "    dataset = self._process_train_data(\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "    self.processor = create_preprocessor(\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\utils\\data_preprocessor.py\", line 40, in create_preprocessor\n",
      "    return ColumnTransformer(\n",
      "TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "Fitting model: CatBoost_r50_BAG_L2 ... Training model for up to 416.69s of the 416.51s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=1.27%)\n",
      "2025-01-31 16:12:04,559\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-31 16:12:04,559\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-31 16:12:04,565\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-31 16:12:04,569\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\t0.9094\t = Validation score   (roc_auc)\n",
      "\t24.79s\t = Training   runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r11_BAG_L2 ... Training model for up to 389.16s of the 388.99s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=1.18%)\n",
      "\t0.9004\t = Validation score   (roc_auc)\n",
      "\t33.31s\t = Training   runtime\n",
      "\t0.31s\t = Validation runtime\n",
      "Fitting model: XGBoost_r194_BAG_L2 ... Training model for up to 353.40s of the 353.23s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=3.78%)\n",
      "2025-01-31 16:13:05,361\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\t0.9032\t = Validation score   (roc_auc)\n",
      "\t6.11s\t = Training   runtime\n",
      "\t0.12s\t = Validation runtime\n",
      "Fitting model: CatBoost_r69_BAG_L2 ... Training model for up to 344.77s of the 344.60s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=1.49%)\n",
      "\t0.9098\t = Validation score   (roc_auc)\n",
      "\t28.08s\t = Training   runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r103_BAG_L2 ... Training model for up to 313.77s of the 313.60s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.99%)\n",
      "\t0.8962\t = Validation score   (roc_auc)\n",
      "\t12.61s\t = Training   runtime\n",
      "\t0.17s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r14_BAG_L2 ... Training model for up to 298.77s of the 298.60s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=1.31%)\n",
      "\tWarning: Exception caused NeuralNetTorch_r14_BAG_L2 to fail during training... Skipping this model.\n",
      "\t\t\u001b[36mray::_ray_fit()\u001b[39m (pid=10700, ip=127.0.0.1)\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1889, in ray._raylet.execute_task\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 201, in _fit\n",
      "    train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "    dataset = self._process_train_data(\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "    self.processor = create_preprocessor(\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\utils\\data_preprocessor.py\", line 40, in create_preprocessor\n",
      "    return ColumnTransformer(\n",
      "TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 2106, in _train_and_save\n",
      "    model = self._train_single(**model_fit_kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 1993, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\stacker_ensemble_model.py\", line 270, in _fit\n",
      "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\bagged_ensemble_model.py\", line 298, in _fit\n",
      "    self._fit_folds(\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\bagged_ensemble_model.py\", line 724, in _fit_folds\n",
      "    fold_fitting_strategy.after_all_folds_scheduled()\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 690, in after_all_folds_scheduled\n",
      "    self._run_parallel(X, y, X_pseudo, y_pseudo, model_base_ref, time_limit_fold, head_node_id)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 631, in _run_parallel\n",
      "    self._process_fold_results(finished, unfinished, fold_ctx)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 587, in _process_fold_results\n",
      "    raise processed_exception\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 550, in _process_fold_results\n",
      "    fold_model, pred_proba, time_start_fit, time_end_fit, predict_time, predict_1_time, predict_n_size, fit_num_cpus, fit_num_gpus = self.ray.get(finished)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\worker.py\", line 2667, in get\n",
      "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\worker.py\", line 864, in get_objects\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(TypeError): \u001b[36mray::_ray_fit()\u001b[39m (pid=10700, ip=127.0.0.1)\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1889, in ray._raylet.execute_task\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 201, in _fit\n",
      "    train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "    dataset = self._process_train_data(\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "    self.processor = create_preprocessor(\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\utils\\data_preprocessor.py\", line 40, in create_preprocessor\n",
      "    return ColumnTransformer(\n",
      "TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "Fitting model: LightGBM_r161_BAG_L2 ... Training model for up to 292.46s of the 292.28s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=6.80%)\n",
      "2025-01-31 16:14:08,629\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-31 16:14:08,634\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-31 16:14:08,634\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-31 16:14:08,634\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-31 16:14:08,644\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-31 16:14:08,663\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-31 16:14:08,668\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\t0.9039\t = Validation score   (roc_auc)\n",
      "\t12.5s\t = Training   runtime\n",
      "\t0.28s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r143_BAG_L2 ... Training model for up to 277.22s of the 277.05s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=1.06%)\n",
      "\t0.9028\t = Validation score   (roc_auc)\n",
      "\t10.32s\t = Training   runtime\n",
      "\t0.12s\t = Validation runtime\n",
      "Fitting model: CatBoost_r70_BAG_L2 ... Training model for up to 264.30s of the 264.13s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=4.32%)\n",
      "\t0.91\t = Validation score   (roc_auc)\n",
      "\t50.4s\t = Training   runtime\n",
      "\t0.09s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r156_BAG_L2 ... Training model for up to 210.74s of the 210.56s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=1.00%)\n",
      "\t0.9017\t = Validation score   (roc_auc)\n",
      "\t10.09s\t = Training   runtime\n",
      "\t0.14s\t = Validation runtime\n",
      "Fitting model: LightGBM_r196_BAG_L2 ... Training model for up to 198.22s of the 198.05s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=5.48%)\n",
      "\t0.9082\t = Validation score   (roc_auc)\n",
      "\t10.24s\t = Training   runtime\n",
      "\t0.6s\t = Validation runtime\n",
      "Fitting model: CatBoost_r167_BAG_L2 ... Training model for up to 184.99s of the 184.82s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=3.04%)\n",
      "2025-01-31 16:16:15,061\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\t0.9089\t = Validation score   (roc_auc)\n",
      "\t38.96s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r95_BAG_L2 ... Training model for up to 143.61s of the 143.44s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=1.00%)\n",
      "\t0.8942\t = Validation score   (roc_auc)\n",
      "\t17.24s\t = Training   runtime\n",
      "\t0.25s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r41_BAG_L2 ... Training model for up to 123.99s of the 123.82s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=1.31%)\n",
      "\tWarning: Exception caused NeuralNetTorch_r41_BAG_L2 to fail during training... Skipping this model.\n",
      "\t\t\u001b[36mray::_ray_fit()\u001b[39m (pid=15864, ip=127.0.0.1)\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1889, in ray._raylet.execute_task\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 201, in _fit\n",
      "    train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "    dataset = self._process_train_data(\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "    self.processor = create_preprocessor(\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\utils\\data_preprocessor.py\", line 40, in create_preprocessor\n",
      "    return ColumnTransformer(\n",
      "TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 2106, in _train_and_save\n",
      "    model = self._train_single(**model_fit_kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 1993, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\stacker_ensemble_model.py\", line 270, in _fit\n",
      "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\bagged_ensemble_model.py\", line 298, in _fit\n",
      "    self._fit_folds(\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\bagged_ensemble_model.py\", line 724, in _fit_folds\n",
      "    fold_fitting_strategy.after_all_folds_scheduled()\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 690, in after_all_folds_scheduled\n",
      "    self._run_parallel(X, y, X_pseudo, y_pseudo, model_base_ref, time_limit_fold, head_node_id)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 631, in _run_parallel\n",
      "    self._process_fold_results(finished, unfinished, fold_ctx)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 587, in _process_fold_results\n",
      "    raise processed_exception\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 550, in _process_fold_results\n",
      "    fold_model, pred_proba, time_start_fit, time_end_fit, predict_time, predict_1_time, predict_n_size, fit_num_cpus, fit_num_gpus = self.ray.get(finished)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\worker.py\", line 2667, in get\n",
      "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\worker.py\", line 864, in get_objects\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(TypeError): \u001b[36mray::_ray_fit()\u001b[39m (pid=15864, ip=127.0.0.1)\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1889, in ray._raylet.execute_task\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 201, in _fit\n",
      "    train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "    dataset = self._process_train_data(\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "    self.processor = create_preprocessor(\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\utils\\data_preprocessor.py\", line 40, in create_preprocessor\n",
      "    return ColumnTransformer(\n",
      "TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "Fitting model: XGBoost_r98_BAG_L2 ... Training model for up to 117.78s of the 117.60s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=8.58%)\n",
      "2025-01-31 16:17:03,112\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-31 16:17:03,114\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-31 16:17:03,114\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-31 16:17:03,124\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-31 16:17:03,128\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-31 16:17:03,132\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\t0.9062\t = Validation score   (roc_auc)\n",
      "\t21.4s\t = Training   runtime\n",
      "\t0.24s\t = Validation runtime\n",
      "Fitting model: LightGBM_r15_BAG_L2 ... Training model for up to 93.69s of the 93.52s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=1.10%)\n",
      "\t0.9065\t = Validation score   (roc_auc)\n",
      "\t3.97s\t = Training   runtime\n",
      "\t0.13s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r158_BAG_L2 ... Training model for up to 87.22s of the 87.03s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.72%)\n",
      "\tWarning: Exception caused NeuralNetTorch_r158_BAG_L2 to fail during training... Skipping this model.\n",
      "\t\t\u001b[36mray::_ray_fit()\u001b[39m (pid=25216, ip=127.0.0.1)\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1889, in ray._raylet.execute_task\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 201, in _fit\n",
      "    train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "    dataset = self._process_train_data(\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "    self.processor = create_preprocessor(\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\utils\\data_preprocessor.py\", line 40, in create_preprocessor\n",
      "    return ColumnTransformer(\n",
      "TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 2106, in _train_and_save\n",
      "    model = self._train_single(**model_fit_kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 1993, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\stacker_ensemble_model.py\", line 270, in _fit\n",
      "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\bagged_ensemble_model.py\", line 298, in _fit\n",
      "    self._fit_folds(\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\bagged_ensemble_model.py\", line 724, in _fit_folds\n",
      "    fold_fitting_strategy.after_all_folds_scheduled()\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 690, in after_all_folds_scheduled\n",
      "    self._run_parallel(X, y, X_pseudo, y_pseudo, model_base_ref, time_limit_fold, head_node_id)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 631, in _run_parallel\n",
      "    self._process_fold_results(finished, unfinished, fold_ctx)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 587, in _process_fold_results\n",
      "    raise processed_exception\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 550, in _process_fold_results\n",
      "    fold_model, pred_proba, time_start_fit, time_end_fit, predict_time, predict_1_time, predict_n_size, fit_num_cpus, fit_num_gpus = self.ray.get(finished)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\worker.py\", line 2667, in get\n",
      "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\worker.py\", line 864, in get_objects\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(TypeError): \u001b[36mray::_ray_fit()\u001b[39m (pid=25216, ip=127.0.0.1)\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1889, in ray._raylet.execute_task\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 201, in _fit\n",
      "    train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "    dataset = self._process_train_data(\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "    self.processor = create_preprocessor(\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\utils\\data_preprocessor.py\", line 40, in create_preprocessor\n",
      "    return ColumnTransformer(\n",
      "TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "Fitting model: CatBoost_r86_BAG_L2 ... Training model for up to 81.35s of the 81.18s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=9.32%)\n",
      "2025-01-31 16:17:39,445\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-31 16:17:39,450\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-31 16:17:39,450\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-31 16:17:39,457\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\t0.9092\t = Validation score   (roc_auc)\n",
      "\t65.9s\t = Training   runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r37_BAG_L2 ... Training model for up to 12.79s of the 12.62s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=1.64%)\n",
      "2025-01-31 16:18:46,478\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-31 16:18:46,478\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\t0.8996\t = Validation score   (roc_auc)\n",
      "\t13.3s\t = Training   runtime\n",
      "\t0.18s\t = Validation runtime\n",
      "2025-01-31 16:18:58,695\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-31 16:18:58,699\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-31 16:18:58,701\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "Fitting model: WeightedEnsemble_L3 ... Training model for up to 360.00s of the -3.90s of remaining time.\n",
      "\tEnsemble Weights: {'CatBoost_r137_BAG_L2': 0.478, 'CatBoost_r70_BAG_L2': 0.391, 'NeuralNetFastAI_r156_BAG_L2': 0.13}\n",
      "\t0.911\t = Validation score   (roc_auc)\n",
      "\t0.17s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 2576.11s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 207.1 rows/s (600 batch size)\n",
      "Automatically performing refit_full as a post-fit operation (due to `.fit(..., refit_full=True)`\n",
      "Refitting models via `predictor.refit_full` using all of the data (combined train and validation)...\n",
      "\tModels trained in this way will have the suffix \"_FULL\" and have NaN validation score.\n",
      "\tThis process is not bound by time_limit, but should take less time than the original `predictor.fit` call.\n",
      "\tTo learn more, refer to the `.refit_full` method docstring which explains how \"_FULL\" models differ from normal models.\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBMXT_BAG_L1_FULL ...\n",
      "\t0.95s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBM_BAG_L1_FULL ...\n",
      "\t0.55s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: CatBoost_BAG_L1_FULL ...\n",
      "\t23.6s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: NeuralNetFastAI_BAG_L1_FULL ...\n",
      "\tStopping at the best epoch learned earlier - 2.\n",
      "\t0.94s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: XGBoost_BAG_L1_FULL ...\n",
      "\t0.45s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBMLarge_BAG_L1_FULL ...\n",
      "\t1.1s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: CatBoost_r177_BAG_L1_FULL ...\n",
      "\t2.32s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBM_r131_BAG_L1_FULL ...\n",
      "\t1.7s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: NeuralNetFastAI_r191_BAG_L1_FULL ...\n",
      "\tStopping at the best epoch learned earlier - 2.\n",
      "\t1.11s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: CatBoost_r9_BAG_L1_FULL ...\n",
      "\t31.22s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBM_r96_BAG_L1_FULL ...\n",
      "\t1.74s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: XGBoost_r33_BAG_L1_FULL ...\n",
      "\t4.16s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: CatBoost_r137_BAG_L1_FULL ...\n",
      "\t24.35s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: NeuralNetFastAI_r102_BAG_L1_FULL ...\n",
      "\tStopping at the best epoch learned earlier - 4.\n",
      "\t0.39s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: CatBoost_r13_BAG_L1_FULL ...\n",
      "\t16.78s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBM_r188_BAG_L1_FULL ...\n",
      "\t1.07s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: NeuralNetFastAI_r145_BAG_L1_FULL ...\n",
      "\tStopping at the best epoch learned earlier - 3.\n",
      "\t2.18s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: XGBoost_r89_BAG_L1_FULL ...\n",
      "\t0.41s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBM_r130_BAG_L1_FULL ...\n",
      "\t0.53s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: CatBoost_r50_BAG_L1_FULL ...\n",
      "\t11.68s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: NeuralNetFastAI_r11_BAG_L1_FULL ...\n",
      "\tStopping at the best epoch learned earlier - 16.\n",
      "\t9.06s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: XGBoost_r194_BAG_L1_FULL ...\n",
      "\t0.49s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: CatBoost_r69_BAG_L1_FULL ...\n",
      "\t19.92s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: NeuralNetFastAI_r103_BAG_L1_FULL ...\n",
      "\tStopping at the best epoch learned earlier - 2.\n",
      "\t0.84s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBM_r161_BAG_L1_FULL ...\n",
      "\t2.97s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: NeuralNetFastAI_r143_BAG_L1_FULL ...\n",
      "\tStopping at the best epoch learned earlier - 23.\n",
      "\t1.85s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: CatBoost_r70_BAG_L1_FULL ...\n",
      "\t17.45s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: NeuralNetFastAI_r156_BAG_L1_FULL ...\n",
      "\tStopping at the best epoch learned earlier - 19.\n",
      "\t1.05s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBM_r196_BAG_L1_FULL ...\n",
      "\t6.52s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: CatBoost_r167_BAG_L1_FULL ...\n",
      "\t13.55s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: NeuralNetFastAI_r95_BAG_L1_FULL ...\n",
      "\tStopping at the best epoch learned earlier - 0.\n",
      "\t0.63s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: XGBoost_r98_BAG_L1_FULL ...\n",
      "\t7.84s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBM_r15_BAG_L1_FULL ...\n",
      "\t1.17s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: CatBoost_r86_BAG_L1_FULL ...\n",
      "\t31.36s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: NeuralNetFastAI_r37_BAG_L1_FULL ...\n",
      "\tStopping at the best epoch learned earlier - 11.\n",
      "\t2.06s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: CatBoost_r49_BAG_L1_FULL ...\n",
      "\t3.06s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBM_r143_BAG_L1_FULL ...\n",
      "\t2.34s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: NeuralNetFastAI_r134_BAG_L1_FULL ...\n",
      "\tStopping at the best epoch learned earlier - 8.\n",
      "\t1.07s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBM_r94_BAG_L1_FULL ...\n",
      "\t0.74s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: CatBoost_r128_BAG_L1_FULL ...\n",
      "\t8.96s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: NeuralNetFastAI_r111_BAG_L1_FULL ...\n",
      "\tStopping at the best epoch learned earlier - 18.\n",
      "\t1.34s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: NeuralNetFastAI_r65_BAG_L1_FULL ...\n",
      "\tStopping at the best epoch learned earlier - 34.\n",
      "\t2.44s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: NeuralNetFastAI_r88_BAG_L1_FULL ...\n",
      "\tStopping at the best epoch learned earlier - 3.\n",
      "\t0.4s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBM_r30_BAG_L1_FULL ...\n",
      "\t2.88s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: XGBoost_r49_BAG_L1_FULL ...\n",
      "\t1.03s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: CatBoost_r5_BAG_L1_FULL ...\n",
      "\t3.54s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: CatBoost_r143_BAG_L1_FULL ...\n",
      "\t2.68s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: XGBoost_r31_BAG_L1_FULL ...\n",
      "\t3.36s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: NeuralNetFastAI_r160_BAG_L1_FULL ...\n",
      "\tStopping at the best epoch learned earlier - 13.\n",
      "\t7.39s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: CatBoost_r60_BAG_L1_FULL ...\n",
      "2025-01-31 16:23:57,547\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\t13.64s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBM_r135_BAG_L1_FULL ...\n",
      "\t0.69s\t = Training   runtime\n",
      "Fitting model: WeightedEnsemble_L2_FULL | Skipping fit via cloning parent ...\n",
      "\tEnsemble Weights: {'LightGBM_r96_BAG_L1': 0.222, 'CatBoost_BAG_L1': 0.167, 'LightGBM_r94_BAG_L1': 0.167, 'NeuralNetFastAI_r160_BAG_L1': 0.167, 'XGBoost_BAG_L1': 0.111, 'NeuralNetFastAI_r143_BAG_L1': 0.111, 'XGBoost_r31_BAG_L1': 0.056}\n",
      "\t0.13s\t = Training   runtime\n",
      "Fitting 1 L2 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBMXT_BAG_L2_FULL ...\n",
      "\t0.23s\t = Training   runtime\n",
      "Fitting 1 L2 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBM_BAG_L2_FULL ...\n",
      "\t0.23s\t = Training   runtime\n",
      "Fitting 1 L2 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: CatBoost_BAG_L2_FULL ...\n",
      "\t4.38s\t = Training   runtime\n",
      "Fitting 1 L2 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: NeuralNetFastAI_BAG_L2_FULL ...\n",
      "\tStopping at the best epoch learned earlier - 1.\n",
      "\t0.56s\t = Training   runtime\n",
      "Fitting 1 L2 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: XGBoost_BAG_L2_FULL ...\n",
      "\t0.16s\t = Training   runtime\n",
      "Fitting 1 L2 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBMLarge_BAG_L2_FULL ...\n",
      "\t0.58s\t = Training   runtime\n",
      "Fitting 1 L2 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: CatBoost_r177_BAG_L2_FULL ...\n",
      "\t0.48s\t = Training   runtime\n",
      "Fitting 1 L2 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBM_r131_BAG_L2_FULL ...\n",
      "\t0.68s\t = Training   runtime\n",
      "Fitting 1 L2 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: NeuralNetFastAI_r191_BAG_L2_FULL ...\n",
      "\tStopping at the best epoch learned earlier - 1.\n",
      "\t0.8s\t = Training   runtime\n",
      "Fitting 1 L2 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: CatBoost_r9_BAG_L2_FULL ...\n",
      "\t9.18s\t = Training   runtime\n",
      "Fitting 1 L2 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBM_r96_BAG_L2_FULL ...\n",
      "\t0.32s\t = Training   runtime\n",
      "Fitting 1 L2 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: XGBoost_r33_BAG_L2_FULL ...\n",
      "\t1.65s\t = Training   runtime\n",
      "Fitting 1 L2 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: CatBoost_r137_BAG_L2_FULL ...\n",
      "\t3.19s\t = Training   runtime\n",
      "Fitting 1 L2 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: NeuralNetFastAI_r102_BAG_L2_FULL ...\n",
      "\tStopping at the best epoch learned earlier - 3.\n",
      "\t0.32s\t = Training   runtime\n",
      "Fitting 1 L2 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: CatBoost_r13_BAG_L2_FULL ...\n",
      "2025-01-31 16:24:34,030\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-31 16:24:34,033\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-31 16:24:34,036\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\t4.4s\t = Training   runtime\n",
      "Fitting 1 L2 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBM_r188_BAG_L2_FULL ...\n",
      "\t0.46s\t = Training   runtime\n",
      "Fitting 1 L2 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: NeuralNetFastAI_r145_BAG_L2_FULL ...\n",
      "\tStopping at the best epoch learned earlier - 0.\n",
      "\t0.64s\t = Training   runtime\n",
      "Fitting 1 L2 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: XGBoost_r89_BAG_L2_FULL ...\n",
      "\t0.16s\t = Training   runtime\n",
      "Fitting 1 L2 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBM_r130_BAG_L2_FULL ...\n",
      "\t0.25s\t = Training   runtime\n",
      "Fitting 1 L2 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: CatBoost_r50_BAG_L2_FULL ...\n",
      "\t2.13s\t = Training   runtime\n",
      "Fitting 1 L2 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: NeuralNetFastAI_r11_BAG_L2_FULL ...\n",
      "\tStopping at the best epoch learned earlier - 10.\n",
      "\t5.75s\t = Training   runtime\n",
      "Fitting 1 L2 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: XGBoost_r194_BAG_L2_FULL ...\n",
      "\t0.21s\t = Training   runtime\n",
      "Fitting 1 L2 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: CatBoost_r69_BAG_L2_FULL ...\n",
      "\t4.03s\t = Training   runtime\n",
      "Fitting 1 L2 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: NeuralNetFastAI_r103_BAG_L2_FULL ...\n",
      "\tStopping at the best epoch learned earlier - 0.\n",
      "\t0.37s\t = Training   runtime\n",
      "Fitting 1 L2 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBM_r161_BAG_L2_FULL ...\n",
      "\t1.6s\t = Training   runtime\n",
      "Fitting 1 L2 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: NeuralNetFastAI_r143_BAG_L2_FULL ...\n",
      "\tStopping at the best epoch learned earlier - 15.\n",
      "\t1.36s\t = Training   runtime\n",
      "Fitting 1 L2 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: CatBoost_r70_BAG_L2_FULL ...\n",
      "\t5.04s\t = Training   runtime\n",
      "Fitting 1 L2 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: NeuralNetFastAI_r156_BAG_L2_FULL ...\n",
      "\tStopping at the best epoch learned earlier - 12.\n",
      "\t0.78s\t = Training   runtime\n",
      "Fitting 1 L2 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBM_r196_BAG_L2_FULL ...\n",
      "\t2.11s\t = Training   runtime\n",
      "Fitting 1 L2 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: CatBoost_r167_BAG_L2_FULL ...\n",
      "\t2.53s\t = Training   runtime\n",
      "Fitting 1 L2 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: NeuralNetFastAI_r95_BAG_L2_FULL ...\n",
      "\tStopping at the best epoch learned earlier - 0.\n",
      "\t0.64s\t = Training   runtime\n",
      "Fitting 1 L2 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: XGBoost_r98_BAG_L2_FULL ...\n",
      "\t2.77s\t = Training   runtime\n",
      "Fitting 1 L2 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBM_r15_BAG_L2_FULL ...\n",
      "\t0.39s\t = Training   runtime\n",
      "Fitting 1 L2 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: CatBoost_r86_BAG_L2_FULL ...\n",
      "\t7.83s\t = Training   runtime\n",
      "Fitting 1 L2 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: NeuralNetFastAI_r37_BAG_L2_FULL ...\n",
      "\tStopping at the best epoch learned earlier - 1.\n",
      "\t0.46s\t = Training   runtime\n",
      "Fitting model: WeightedEnsemble_L3_FULL | Skipping fit via cloning parent ...\n",
      "\tEnsemble Weights: {'CatBoost_r137_BAG_L2': 0.478, 'CatBoost_r70_BAG_L2': 0.391, 'NeuralNetFastAI_r156_BAG_L2': 0.13}\n",
      "\t0.17s\t = Training   runtime\n",
      "Updated best model to \"WeightedEnsemble_L2_FULL\" (Previously \"WeightedEnsemble_L2\"). AutoGluon will default to using \"WeightedEnsemble_L2_FULL\" for predict() and predict_proba().\n",
      "Refit complete, total runtime = 378.96s ... Best model: \"WeightedEnsemble_L2_FULL\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\autogluon\\tlp\\AutogluonModels\\synthetic\\tvaes\\v2\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<autogluon.tabular.predictor.predictor.TabularPredictor at 0x22c33acb460>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.fit(\n",
    "    train_data = df_train,\n",
    "    presets = ['high_quality'],\n",
    "    time_limit = 1 * 3600,\n",
    "    auto_stack = True,\n",
    "    excluded_model_types=['KNN','RF','XT', 'LR'],\n",
    "    verbosity = 2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Summary of fit() ***\n",
      "Estimated performance of each model:\n",
      "                                model  score_val eval_metric  pred_time_val    fit_time  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
      "0                 WeightedEnsemble_L2   0.911074     roc_auc       2.897264  146.529078                0.000000           0.129485            2      False         52\n",
      "1                 WeightedEnsemble_L3   0.911033     roc_auc       3.299675  387.538390                0.000000           0.166321            3      False         88\n",
      "2                CatBoost_r137_BAG_L2   0.910302     roc_auc       3.064874  326.876730                0.067865          23.250679            2      False         65\n",
      "3                 CatBoost_r70_BAG_L2   0.910039     roc_auc       3.087677  354.028247                0.090668          50.402197            2      False         79\n",
      "4                 CatBoost_r13_BAG_L2   0.909949     roc_auc       3.087793  349.611053                0.090785          45.985003            2      False         67\n",
      "5                 CatBoost_r69_BAG_L2   0.909776     roc_auc       3.070728  331.709805                0.073719          28.083755            2      False         75\n",
      "6                     CatBoost_BAG_L2   0.909630     roc_auc       3.035154  344.256500                0.038146          40.630450            2      False         55\n",
      "7                CatBoost_r177_BAG_L2   0.909613     roc_auc       3.060164  314.942793                0.063156          11.316743            2      False         59\n",
      "8                 LightGBM_r96_BAG_L2   0.909455     roc_auc       3.126633  305.905140                0.129625           2.279089            2      False         63\n",
      "9                 CatBoost_r50_BAG_L2   0.909358     roc_auc       3.064761  328.416392                0.067753          24.790341            2      False         72\n",
      "10                CatBoost_r86_BAG_L2   0.909213     roc_auc       3.065552  369.526231                0.068543          65.900181            2      False         86\n",
      "11                 CatBoost_r9_BAG_L2   0.909212     roc_auc       3.077652  416.702047                0.080643         113.075997            2      False         62\n",
      "12               CatBoost_r167_BAG_L2   0.908904     roc_auc       3.056360  342.585976                0.059351          38.959926            2      False         82\n",
      "13               LightGBM_r196_BAG_L2   0.908153     roc_auc       3.593885  313.861449                0.596876          10.235399            2      False         81\n",
      "14                  LightGBMXT_BAG_L2   0.907500     roc_auc       3.060122  306.689819                0.063114           3.063769            2      False         53\n",
      "15               LightGBM_r188_BAG_L2   0.906985     roc_auc       3.108249  308.088045                0.111240           4.461994            2      False         68\n",
      "16                LightGBM_r15_BAG_L2   0.906545     roc_auc       3.124896  307.600092                0.127887           3.974042            2      False         85\n",
      "17                 XGBoost_r89_BAG_L2   0.906183     roc_auc       3.087224  307.677944                0.090215           4.051893            2      False         70\n",
      "18                 XGBoost_r98_BAG_L2   0.906167     roc_auc       3.241902  325.028203                0.244893          21.402153            2      False         84\n",
      "19                LightGBM_r96_BAG_L1   0.904789     roc_auc       1.149961   10.938354                1.149961          10.938354            1      False         11\n",
      "20               LightGBM_r130_BAG_L2   0.904628     roc_auc       3.049236  307.287332                0.052227           3.661282            2      False         71\n",
      "21                LightGBM_r94_BAG_L1   0.904615     roc_auc       0.377503    5.446769                0.377503           5.446769            1      False         39\n",
      "22                 XGBoost_r33_BAG_L2   0.904389     roc_auc       3.122138  325.156329                0.125129          21.530279            2      False         64\n",
      "23               LightGBM_r131_BAG_L2   0.904361     roc_auc       3.164526  309.692677                0.167517           6.066627            2      False         60\n",
      "24                    LightGBM_BAG_L2   0.904071     roc_auc       3.035890  307.401224                0.038881           3.775173            2      False         54\n",
      "25                     XGBoost_BAG_L2   0.903944     roc_auc       3.043994  308.826370                0.046985           5.200320            2      False         57\n",
      "26               LightGBM_r161_BAG_L2   0.903940     roc_auc       3.280203  316.130221                0.283195          12.504171            2      False         77\n",
      "27                XGBoost_r194_BAG_L2   0.903248     roc_auc       3.119658  309.737716                0.122649           6.111666            2      False         74\n",
      "28                    CatBoost_BAG_L1   0.903021     roc_auc       0.056222   69.710648                0.056222          69.710648            1      False          3\n",
      "29        NeuralNetFastAI_r143_BAG_L2   0.902827     roc_auc       3.114432  313.948284                0.117423          10.322234            2      False         78\n",
      "30                  LightGBMXT_BAG_L1   0.902806     roc_auc       0.238564    4.346591                0.238564           4.346591            1      False          1\n",
      "31                LightGBM_r15_BAG_L1   0.902658     roc_auc       0.391478    7.994087                0.391478           7.994087            1      False         33\n",
      "32               LightGBM_r130_BAG_L1   0.902327     roc_auc       0.148870    4.334281                0.148870           4.334281            1      False         19\n",
      "33               LightGBM_r131_BAG_L1   0.902292     roc_auc       0.443214    9.197148                0.443214           9.197148            1      False          8\n",
      "34        NeuralNetFastAI_r156_BAG_L2   0.901748     roc_auc       3.141142  313.719193                0.144134          10.093142            2      False         80\n",
      "35                CatBoost_r13_BAG_L1   0.901738     roc_auc       0.099745  157.226457                0.099745         157.226457            1      False         15\n",
      "36               LightGBMLarge_BAG_L2   0.901355     roc_auc       3.079610  312.742756                0.082602           9.116705            2      False         58\n",
      "37                    LightGBM_BAG_L1   0.901355     roc_auc       0.151477    4.751272                0.151477           4.751272            1      False          2\n",
      "38                CatBoost_r69_BAG_L1   0.901174     roc_auc       0.059606   65.773505                0.059606          65.773505            1      False         23\n",
      "39                 CatBoost_r5_BAG_L1   0.901104     roc_auc       0.090667   19.002113                0.090667          19.002113            1      False         46\n",
      "40                CatBoost_r49_BAG_L1   0.901038     roc_auc       0.065837   16.980327                0.065837          16.980327            1      False         36\n",
      "41                 XGBoost_r31_BAG_L1   0.901030     roc_auc       0.809785   26.666716                0.809785          26.666716            1      False         48\n",
      "42                CatBoost_r70_BAG_L1   0.901006     roc_auc       0.082489   75.333797                0.082489          75.333797            1      False         27\n",
      "43                CatBoost_r50_BAG_L1   0.900869     roc_auc       0.085652   47.998418                0.085652          47.998418            1      False         20\n",
      "44               CatBoost_r177_BAG_L1   0.900812     roc_auc       0.057547   19.008647                0.057547          19.008647            1      False          7\n",
      "45               CatBoost_r137_BAG_L1   0.900693     roc_auc       0.060981   68.410044                0.060981          68.410044            1      False         13\n",
      "46         NeuralNetFastAI_r11_BAG_L2   0.900409     roc_auc       3.306945  336.934028                0.309936          33.307978            2      False         73\n",
      "47                 CatBoost_r9_BAG_L1   0.899850     roc_auc       0.082791  158.911187                0.082791         158.911187            1      False         10\n",
      "48               CatBoost_r167_BAG_L1   0.899698     roc_auc       0.101464   57.753372                0.101464          57.753372            1      False         30\n",
      "49         NeuralNetFastAI_r37_BAG_L2   0.899636     roc_auc       3.181283  316.930867                0.184274          13.304817            2      False         87\n",
      "50               LightGBM_r135_BAG_L1   0.899487     roc_auc       0.219799    3.457448                0.219799           3.457448            1      False         51\n",
      "51                CatBoost_r86_BAG_L1   0.898726     roc_auc       0.089626  121.553257                0.089626         121.553257            1      False         34\n",
      "52               LightGBM_r196_BAG_L1   0.898705     roc_auc       3.182227   25.517148                3.182227          25.517148            1      False         29\n",
      "53               CatBoost_r128_BAG_L1   0.898287     roc_auc       0.095771   81.456391                0.095771          81.456391            1      False         40\n",
      "54                     XGBoost_BAG_L1   0.898114     roc_auc       0.119161    6.224126                0.119161           6.224126            1      False          5\n",
      "55                 XGBoost_r49_BAG_L1   0.898047     roc_auc       0.210434   10.835276                0.210434          10.835276            1      False         45\n",
      "56               CatBoost_r143_BAG_L1   0.898023     roc_auc       0.074313   24.129541                0.074313          24.129541            1      False         47\n",
      "57                 XGBoost_r98_BAG_L1   0.897638     roc_auc       0.603683   46.827370                0.603683          46.827370            1      False         32\n",
      "58                 XGBoost_r89_BAG_L1   0.897530     roc_auc       0.126611    5.593415                0.126611           5.593415            1      False         18\n",
      "59                CatBoost_r60_BAG_L1   0.897005     roc_auc       0.046140   27.362073                0.046140          27.362073            1      False         50\n",
      "60                XGBoost_r194_BAG_L1   0.896600     roc_auc       0.122422    6.372080                0.122422           6.372080            1      False         22\n",
      "61        NeuralNetFastAI_r103_BAG_L2   0.896191     roc_auc       3.171586  316.240102                0.174577          12.614052            2      False         76\n",
      "62                LightGBM_r30_BAG_L1   0.895819     roc_auc       0.990996   12.766691                0.990996          12.766691            1      False         44\n",
      "63             NeuralNetFastAI_BAG_L2   0.895393     roc_auc       3.191318  314.379109                0.194309          10.753059            2      False         56\n",
      "64        NeuralNetFastAI_r145_BAG_L2   0.895311     roc_auc       3.242669  321.759092                0.245660          18.133042            2      False         69\n",
      "65               LightGBM_r188_BAG_L1   0.895218     roc_auc       0.256268    6.585804                0.256268           6.585804            1      False         16\n",
      "66               LightGBM_r143_BAG_L1   0.894942     roc_auc       0.385953   13.265254                0.385953          13.265254            1      False         37\n",
      "67         NeuralNetFastAI_r95_BAG_L2   0.894192     roc_auc       3.245792  320.863558                0.248783          17.237508            2      False         83\n",
      "68                 XGBoost_r33_BAG_L1   0.892071     roc_auc       0.632430   27.499620                0.632430          27.499620            1      False         12\n",
      "69        NeuralNetFastAI_r191_BAG_L2   0.891007     roc_auc       3.267116  323.868467                0.270107          20.242417            2      False         61\n",
      "70               LightGBM_r161_BAG_L1   0.890207     roc_auc       0.572995   15.627007                0.572995          15.627007            1      False         25\n",
      "71        NeuralNetFastAI_r143_BAG_L1   0.889045     roc_auc       0.123570   10.589227                0.123570          10.589227            1      False         26\n",
      "72               LightGBMLarge_BAG_L1   0.888761     roc_auc       0.160994    9.541237                0.160994           9.541237            1      False          6\n",
      "73        NeuralNetFastAI_r160_BAG_L1   0.887028     roc_auc       0.261061   16.823753                0.261061          16.823753            1      False         49\n",
      "74        NeuralNetFastAI_r156_BAG_L1   0.886226     roc_auc       0.153006   10.651237                0.153006          10.651237            1      False         28\n",
      "75        NeuralNetFastAI_r102_BAG_L2   0.885824     roc_auc       3.150446  312.142100                0.153438           8.516049            2      False         66\n",
      "76        NeuralNetFastAI_r111_BAG_L1   0.881355     roc_auc       0.087130    9.450645                0.087130           9.450645            1      False         41\n",
      "77        NeuralNetFastAI_r134_BAG_L1   0.879291     roc_auc       0.196182   19.378126                0.196182          19.378126            1      False         38\n",
      "78         NeuralNetFastAI_r37_BAG_L1   0.878560     roc_auc       0.145787   15.068810                0.145787          15.068810            1      False         35\n",
      "79         NeuralNetFastAI_r65_BAG_L1   0.871349     roc_auc       0.085450   11.045218                0.085450          11.045218            1      False         42\n",
      "80         NeuralNetFastAI_r11_BAG_L1   0.870689     roc_auc       0.284972   34.026868                0.284972          34.026868            1      False         21\n",
      "81        NeuralNetFastAI_r145_BAG_L1   0.870477     roc_auc       0.240611   19.727080                0.240611          19.727080            1      False         17\n",
      "82             NeuralNetFastAI_BAG_L1   0.870143     roc_auc       0.175600   11.417816                0.175600          11.417816            1      False          4\n",
      "83        NeuralNetFastAI_r191_BAG_L1   0.868672     roc_auc       0.218605   20.858164                0.218605          20.858164            1      False          9\n",
      "84         NeuralNetFastAI_r88_BAG_L1   0.866002     roc_auc       0.139551    9.542048                0.139551           9.542048            1      False         43\n",
      "85        NeuralNetFastAI_r102_BAG_L1   0.865822     roc_auc       0.121675    7.627099                0.121675           7.627099            1      False         14\n",
      "86        NeuralNetFastAI_r103_BAG_L1   0.860325     roc_auc       0.200892   14.394548                0.200892          14.394548            1      False         24\n",
      "87         NeuralNetFastAI_r95_BAG_L1   0.859048     roc_auc       0.210637   17.066844                0.210637          17.066844            1      False         31\n",
      "88            XGBoost_r98_BAG_L2_FULL        NaN     roc_auc            NaN   58.675283                     NaN           2.767180            2       True        172\n",
      "89            XGBoost_r98_BAG_L1_FULL        NaN     roc_auc            NaN    7.839517                     NaN           7.839517            1       True        120\n",
      "90            XGBoost_r89_BAG_L2_FULL        NaN     roc_auc            NaN   56.069339                     NaN           0.161236            2       True        158\n",
      "91            XGBoost_r89_BAG_L1_FULL        NaN     roc_auc            NaN    0.409754                     NaN           0.409754            1       True        106\n",
      "92            XGBoost_r49_BAG_L1_FULL        NaN     roc_auc            NaN    1.033710                     NaN           1.033710            1       True        133\n",
      "93            XGBoost_r33_BAG_L2_FULL        NaN     roc_auc            NaN   57.558530                     NaN           1.650427            2       True        152\n",
      "94            XGBoost_r33_BAG_L1_FULL        NaN     roc_auc            NaN    4.163792                     NaN           4.163792            1       True        100\n",
      "95            XGBoost_r31_BAG_L1_FULL        NaN     roc_auc            NaN    3.360509                     NaN           3.360509            1       True        136\n",
      "96           XGBoost_r194_BAG_L2_FULL        NaN     roc_auc            NaN   56.114675                     NaN           0.206572            2       True        162\n",
      "97           XGBoost_r194_BAG_L1_FULL        NaN     roc_auc            NaN    0.491244                     NaN           0.491244            1       True        110\n",
      "98                XGBoost_BAG_L2_FULL        NaN     roc_auc            NaN   56.065321                     NaN           0.157218            2       True        145\n",
      "99                XGBoost_BAG_L1_FULL        NaN     roc_auc            NaN    0.448566                     NaN           0.448566            1       True         93\n",
      "100          WeightedEnsemble_L3_FULL        NaN     roc_auc            NaN   65.086806                     NaN           0.166321            3       True        176\n",
      "101          WeightedEnsemble_L2_FULL        NaN     roc_auc            NaN   39.258367                     NaN           0.129485            2       True        140\n",
      "102   NeuralNetFastAI_r95_BAG_L2_FULL        NaN     roc_auc            NaN   56.544495                     NaN           0.636392            2       True        171\n",
      "103   NeuralNetFastAI_r95_BAG_L1_FULL        NaN     roc_auc            NaN    0.632626                     NaN           0.632626            1       True        119\n",
      "104   NeuralNetFastAI_r88_BAG_L1_FULL        NaN     roc_auc            NaN    0.399451                     NaN           0.399451            1       True        131\n",
      "105   NeuralNetFastAI_r65_BAG_L1_FULL        NaN     roc_auc            NaN    2.439636                     NaN           2.439636            1       True        130\n",
      "106   NeuralNetFastAI_r37_BAG_L2_FULL        NaN     roc_auc            NaN   56.367335                     NaN           0.459232            2       True        175\n",
      "107   NeuralNetFastAI_r37_BAG_L1_FULL        NaN     roc_auc            NaN    2.056264                     NaN           2.056264            1       True        123\n",
      "108  NeuralNetFastAI_r191_BAG_L2_FULL        NaN     roc_auc            NaN   56.708848                     NaN           0.800745            2       True        149\n",
      "109  NeuralNetFastAI_r191_BAG_L1_FULL        NaN     roc_auc            NaN    1.114490                     NaN           1.114490            1       True         97\n",
      "110  NeuralNetFastAI_r160_BAG_L1_FULL        NaN     roc_auc            NaN    7.392132                     NaN           7.392132            1       True        137\n",
      "111  NeuralNetFastAI_r156_BAG_L2_FULL        NaN     roc_auc            NaN   56.692823                     NaN           0.784720            2       True        168\n",
      "112  NeuralNetFastAI_r156_BAG_L1_FULL        NaN     roc_auc            NaN    1.050899                     NaN           1.050899            1       True        116\n",
      "113  NeuralNetFastAI_r145_BAG_L2_FULL        NaN     roc_auc            NaN   56.550533                     NaN           0.642430            2       True        157\n",
      "114  NeuralNetFastAI_r145_BAG_L1_FULL        NaN     roc_auc            NaN    2.177873                     NaN           2.177873            1       True        105\n",
      "115  NeuralNetFastAI_r143_BAG_L2_FULL        NaN     roc_auc            NaN   57.266732                     NaN           1.358629            2       True        166\n",
      "116  NeuralNetFastAI_r143_BAG_L1_FULL        NaN     roc_auc            NaN    1.847588                     NaN           1.847588            1       True        114\n",
      "117  NeuralNetFastAI_r134_BAG_L1_FULL        NaN     roc_auc            NaN    1.070724                     NaN           1.070724            1       True        126\n",
      "118   NeuralNetFastAI_r11_BAG_L2_FULL        NaN     roc_auc            NaN   61.653331                     NaN           5.745228            2       True        161\n",
      "119   NeuralNetFastAI_r11_BAG_L1_FULL        NaN     roc_auc            NaN    9.060886                     NaN           9.060886            1       True        109\n",
      "120  NeuralNetFastAI_r111_BAG_L1_FULL        NaN     roc_auc            NaN    1.342406                     NaN           1.342406            1       True        129\n",
      "121  NeuralNetFastAI_r103_BAG_L2_FULL        NaN     roc_auc            NaN   56.281591                     NaN           0.373488            2       True        164\n",
      "122  NeuralNetFastAI_r103_BAG_L1_FULL        NaN     roc_auc            NaN    0.842819                     NaN           0.842819            1       True        112\n",
      "123  NeuralNetFastAI_r102_BAG_L2_FULL        NaN     roc_auc            NaN   56.231646                     NaN           0.323543            2       True        154\n",
      "124  NeuralNetFastAI_r102_BAG_L1_FULL        NaN     roc_auc            NaN    0.386713                     NaN           0.386713            1       True        102\n",
      "125       NeuralNetFastAI_BAG_L2_FULL        NaN     roc_auc            NaN   56.464810                     NaN           0.556707            2       True        144\n",
      "126       NeuralNetFastAI_BAG_L1_FULL        NaN     roc_auc            NaN    0.940652                     NaN           0.940652            1       True         92\n",
      "127          LightGBM_r96_BAG_L2_FULL        NaN     roc_auc            NaN   56.223660                     NaN           0.315557            2       True        151\n",
      "128          LightGBM_r96_BAG_L1_FULL        NaN     roc_auc            NaN    1.742055                     NaN           1.742055            1       True         99\n",
      "129          LightGBM_r94_BAG_L1_FULL        NaN     roc_auc            NaN    0.740285                     NaN           0.740285            1       True        127\n",
      "130          LightGBM_r30_BAG_L1_FULL        NaN     roc_auc            NaN    2.881838                     NaN           2.881838            1       True        132\n",
      "131         LightGBM_r196_BAG_L2_FULL        NaN     roc_auc            NaN   58.019241                     NaN           2.111138            2       True        169\n",
      "132         LightGBM_r196_BAG_L1_FULL        NaN     roc_auc            NaN    6.519710                     NaN           6.519710            1       True        117\n",
      "133         LightGBM_r188_BAG_L2_FULL        NaN     roc_auc            NaN   56.364626                     NaN           0.456523            2       True        156\n",
      "134         LightGBM_r188_BAG_L1_FULL        NaN     roc_auc            NaN    1.074952                     NaN           1.074952            1       True        104\n",
      "135         LightGBM_r161_BAG_L2_FULL        NaN     roc_auc            NaN   57.504074                     NaN           1.595971            2       True        165\n",
      "136         LightGBM_r161_BAG_L1_FULL        NaN     roc_auc            NaN    2.968254                     NaN           2.968254            1       True        113\n",
      "137          LightGBM_r15_BAG_L2_FULL        NaN     roc_auc            NaN   56.301040                     NaN           0.392937            2       True        173\n",
      "138          LightGBM_r15_BAG_L1_FULL        NaN     roc_auc            NaN    1.173070                     NaN           1.173070            1       True        121\n",
      "139         LightGBM_r143_BAG_L1_FULL        NaN     roc_auc            NaN    2.336067                     NaN           2.336067            1       True        125\n",
      "140         LightGBM_r135_BAG_L1_FULL        NaN     roc_auc            NaN    0.693728                     NaN           0.693728            1       True        139\n",
      "141         LightGBM_r131_BAG_L2_FULL        NaN     roc_auc            NaN   56.591838                     NaN           0.683735            2       True        148\n",
      "142         LightGBM_r131_BAG_L1_FULL        NaN     roc_auc            NaN    1.699913                     NaN           1.699913            1       True         96\n",
      "143         LightGBM_r130_BAG_L2_FULL        NaN     roc_auc            NaN   56.157686                     NaN           0.249583            2       True        159\n",
      "144         LightGBM_r130_BAG_L1_FULL        NaN     roc_auc            NaN    0.533559                     NaN           0.533559            1       True        107\n",
      "145              LightGBM_BAG_L2_FULL        NaN     roc_auc            NaN   56.141407                     NaN           0.233305            2       True        142\n",
      "146              LightGBM_BAG_L1_FULL        NaN     roc_auc            NaN    0.551250                     NaN           0.551250            1       True         90\n",
      "147            LightGBMXT_BAG_L2_FULL        NaN     roc_auc            NaN   56.140971                     NaN           0.232868            2       True        141\n",
      "148            LightGBMXT_BAG_L1_FULL        NaN     roc_auc            NaN    0.951507                     NaN           0.951507            1       True         89\n",
      "149         LightGBMLarge_BAG_L2_FULL        NaN     roc_auc            NaN   56.484105                     NaN           0.576002            2       True        146\n",
      "150         LightGBMLarge_BAG_L1_FULL        NaN     roc_auc            NaN    1.096782                     NaN           1.096782            1       True         94\n",
      "151           CatBoost_r9_BAG_L2_FULL        NaN     roc_auc            NaN   65.089544                     NaN           9.181441            2       True        150\n",
      "152           CatBoost_r9_BAG_L1_FULL        NaN     roc_auc            NaN   31.222354                     NaN          31.222354            1       True         98\n",
      "153          CatBoost_r86_BAG_L2_FULL        NaN     roc_auc            NaN   63.734315                     NaN           7.826212            2       True        174\n",
      "154          CatBoost_r86_BAG_L1_FULL        NaN     roc_auc            NaN   31.355246                     NaN          31.355246            1       True        122\n",
      "155          CatBoost_r70_BAG_L2_FULL        NaN     roc_auc            NaN   60.943178                     NaN           5.035075            2       True        167\n",
      "156          CatBoost_r70_BAG_L1_FULL        NaN     roc_auc            NaN   17.450675                     NaN          17.450675            1       True        115\n",
      "157          CatBoost_r69_BAG_L2_FULL        NaN     roc_auc            NaN   59.935033                     NaN           4.026930            2       True        163\n",
      "158          CatBoost_r69_BAG_L1_FULL        NaN     roc_auc            NaN   19.920913                     NaN          19.920913            1       True        111\n",
      "159          CatBoost_r60_BAG_L1_FULL        NaN     roc_auc            NaN   13.637514                     NaN          13.637514            1       True        138\n",
      "160           CatBoost_r5_BAG_L1_FULL        NaN     roc_auc            NaN    3.541711                     NaN           3.541711            1       True        134\n",
      "161          CatBoost_r50_BAG_L2_FULL        NaN     roc_auc            NaN   58.042283                     NaN           2.134180            2       True        160\n",
      "162          CatBoost_r50_BAG_L1_FULL        NaN     roc_auc            NaN   11.676720                     NaN          11.676720            1       True        108\n",
      "163          CatBoost_r49_BAG_L1_FULL        NaN     roc_auc            NaN    3.060637                     NaN           3.060637            1       True        124\n",
      "164         CatBoost_r177_BAG_L2_FULL        NaN     roc_auc            NaN   56.385371                     NaN           0.477268            2       True        147\n",
      "165         CatBoost_r177_BAG_L1_FULL        NaN     roc_auc            NaN    2.316745                     NaN           2.316745            1       True         95\n",
      "166         CatBoost_r167_BAG_L2_FULL        NaN     roc_auc            NaN   58.440608                     NaN           2.532505            2       True        170\n",
      "167         CatBoost_r167_BAG_L1_FULL        NaN     roc_auc            NaN   13.545654                     NaN          13.545654            1       True        118\n",
      "168         CatBoost_r143_BAG_L1_FULL        NaN     roc_auc            NaN    2.677202                     NaN           2.677202            1       True        135\n",
      "169          CatBoost_r13_BAG_L2_FULL        NaN     roc_auc            NaN   60.307606                     NaN           4.399503            2       True        155\n",
      "170          CatBoost_r13_BAG_L1_FULL        NaN     roc_auc            NaN   16.779221                     NaN          16.779221            1       True        103\n",
      "171         CatBoost_r137_BAG_L2_FULL        NaN     roc_auc            NaN   59.100690                     NaN           3.192587            2       True        153\n",
      "172         CatBoost_r137_BAG_L1_FULL        NaN     roc_auc            NaN   24.345965                     NaN          24.345965            1       True        101\n",
      "173         CatBoost_r128_BAG_L1_FULL        NaN     roc_auc            NaN    8.960422                     NaN           8.960422            1       True        128\n",
      "174              CatBoost_BAG_L2_FULL        NaN     roc_auc            NaN   60.284806                     NaN           4.376703            2       True        143\n",
      "175              CatBoost_BAG_L1_FULL        NaN     roc_auc            NaN   23.597747                     NaN          23.597747            1       True         91\n",
      "Number of models trained: 176\n",
      "Types of models trained:\n",
      "{'StackerEnsembleModel_XGBoost', 'StackerEnsembleModel_NNFastAiTabular', 'StackerEnsembleModel_LGB', 'StackerEnsembleModel_CatBoost', 'WeightedEnsembleModel'}\n",
      "Bagging used: True  (with 8 folds)\n",
      "Multi-layer stack-ensembling used: True  (with 3 levels)\n",
      "Feature Metadata (Processed):\n",
      "(raw dtype, special dtypes):\n",
      "('category', [])             :  1 | ['demo-rangoEdad']\n",
      "('float', [])                : 15 | ['ques-Sus-total-PD', 'eval-TLP-FigRey-totalCopia-PD', 'eval-TLP-FigRey-totalMemoria-PD', 'eval-TLP-Tavec-5_Rg_Pr-PD', 'eval-TLP-Tavec-6_Rg_Md-PD', ...]\n",
      "('int', [])                  : 47 | ['demo-edad', 'clin-reservaCognitiva_total', 'clin-reservaCognitiva_idiomas', 'clin-reservaCognitiva_ocupacion', 'clin-reservaCognitiva_escolaridad', ...]\n",
      "('int', ['bool'])            : 10 | ['demo-genero', 'clin-ansiedad', 'clin-depresion', 'clin-cardiopatiaIsquemica', 'clin-diabetes', ...]\n",
      "('int', ['datetime_as_int']) :  9 | ['demo-fechaEvaluacion', 'demo-fechaEvaluacion.month', 'demo-fechaEvaluacion.day', 'demo-fechaEvaluacion.dayofweek', 'demo-fechaNacimiento', ...]\n",
      "Plot summary of models saved to file: c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\autogluon\\tlp\\AutogluonModels\\synthetic\\tvaes\\v2SummaryOfModels.html\n",
      "*** End of fit() summary ***\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'model_types': {'LightGBMXT_BAG_L1': 'StackerEnsembleModel_LGB',\n",
       "  'LightGBM_BAG_L1': 'StackerEnsembleModel_LGB',\n",
       "  'CatBoost_BAG_L1': 'StackerEnsembleModel_CatBoost',\n",
       "  'NeuralNetFastAI_BAG_L1': 'StackerEnsembleModel_NNFastAiTabular',\n",
       "  'XGBoost_BAG_L1': 'StackerEnsembleModel_XGBoost',\n",
       "  'LightGBMLarge_BAG_L1': 'StackerEnsembleModel_LGB',\n",
       "  'CatBoost_r177_BAG_L1': 'StackerEnsembleModel_CatBoost',\n",
       "  'LightGBM_r131_BAG_L1': 'StackerEnsembleModel_LGB',\n",
       "  'NeuralNetFastAI_r191_BAG_L1': 'StackerEnsembleModel_NNFastAiTabular',\n",
       "  'CatBoost_r9_BAG_L1': 'StackerEnsembleModel_CatBoost',\n",
       "  'LightGBM_r96_BAG_L1': 'StackerEnsembleModel_LGB',\n",
       "  'XGBoost_r33_BAG_L1': 'StackerEnsembleModel_XGBoost',\n",
       "  'CatBoost_r137_BAG_L1': 'StackerEnsembleModel_CatBoost',\n",
       "  'NeuralNetFastAI_r102_BAG_L1': 'StackerEnsembleModel_NNFastAiTabular',\n",
       "  'CatBoost_r13_BAG_L1': 'StackerEnsembleModel_CatBoost',\n",
       "  'LightGBM_r188_BAG_L1': 'StackerEnsembleModel_LGB',\n",
       "  'NeuralNetFastAI_r145_BAG_L1': 'StackerEnsembleModel_NNFastAiTabular',\n",
       "  'XGBoost_r89_BAG_L1': 'StackerEnsembleModel_XGBoost',\n",
       "  'LightGBM_r130_BAG_L1': 'StackerEnsembleModel_LGB',\n",
       "  'CatBoost_r50_BAG_L1': 'StackerEnsembleModel_CatBoost',\n",
       "  'NeuralNetFastAI_r11_BAG_L1': 'StackerEnsembleModel_NNFastAiTabular',\n",
       "  'XGBoost_r194_BAG_L1': 'StackerEnsembleModel_XGBoost',\n",
       "  'CatBoost_r69_BAG_L1': 'StackerEnsembleModel_CatBoost',\n",
       "  'NeuralNetFastAI_r103_BAG_L1': 'StackerEnsembleModel_NNFastAiTabular',\n",
       "  'LightGBM_r161_BAG_L1': 'StackerEnsembleModel_LGB',\n",
       "  'NeuralNetFastAI_r143_BAG_L1': 'StackerEnsembleModel_NNFastAiTabular',\n",
       "  'CatBoost_r70_BAG_L1': 'StackerEnsembleModel_CatBoost',\n",
       "  'NeuralNetFastAI_r156_BAG_L1': 'StackerEnsembleModel_NNFastAiTabular',\n",
       "  'LightGBM_r196_BAG_L1': 'StackerEnsembleModel_LGB',\n",
       "  'CatBoost_r167_BAG_L1': 'StackerEnsembleModel_CatBoost',\n",
       "  'NeuralNetFastAI_r95_BAG_L1': 'StackerEnsembleModel_NNFastAiTabular',\n",
       "  'XGBoost_r98_BAG_L1': 'StackerEnsembleModel_XGBoost',\n",
       "  'LightGBM_r15_BAG_L1': 'StackerEnsembleModel_LGB',\n",
       "  'CatBoost_r86_BAG_L1': 'StackerEnsembleModel_CatBoost',\n",
       "  'NeuralNetFastAI_r37_BAG_L1': 'StackerEnsembleModel_NNFastAiTabular',\n",
       "  'CatBoost_r49_BAG_L1': 'StackerEnsembleModel_CatBoost',\n",
       "  'LightGBM_r143_BAG_L1': 'StackerEnsembleModel_LGB',\n",
       "  'NeuralNetFastAI_r134_BAG_L1': 'StackerEnsembleModel_NNFastAiTabular',\n",
       "  'LightGBM_r94_BAG_L1': 'StackerEnsembleModel_LGB',\n",
       "  'CatBoost_r128_BAG_L1': 'StackerEnsembleModel_CatBoost',\n",
       "  'NeuralNetFastAI_r111_BAG_L1': 'StackerEnsembleModel_NNFastAiTabular',\n",
       "  'NeuralNetFastAI_r65_BAG_L1': 'StackerEnsembleModel_NNFastAiTabular',\n",
       "  'NeuralNetFastAI_r88_BAG_L1': 'StackerEnsembleModel_NNFastAiTabular',\n",
       "  'LightGBM_r30_BAG_L1': 'StackerEnsembleModel_LGB',\n",
       "  'XGBoost_r49_BAG_L1': 'StackerEnsembleModel_XGBoost',\n",
       "  'CatBoost_r5_BAG_L1': 'StackerEnsembleModel_CatBoost',\n",
       "  'CatBoost_r143_BAG_L1': 'StackerEnsembleModel_CatBoost',\n",
       "  'XGBoost_r31_BAG_L1': 'StackerEnsembleModel_XGBoost',\n",
       "  'NeuralNetFastAI_r160_BAG_L1': 'StackerEnsembleModel_NNFastAiTabular',\n",
       "  'CatBoost_r60_BAG_L1': 'StackerEnsembleModel_CatBoost',\n",
       "  'LightGBM_r135_BAG_L1': 'StackerEnsembleModel_LGB',\n",
       "  'WeightedEnsemble_L2': 'WeightedEnsembleModel',\n",
       "  'LightGBMXT_BAG_L2': 'StackerEnsembleModel_LGB',\n",
       "  'LightGBM_BAG_L2': 'StackerEnsembleModel_LGB',\n",
       "  'CatBoost_BAG_L2': 'StackerEnsembleModel_CatBoost',\n",
       "  'NeuralNetFastAI_BAG_L2': 'StackerEnsembleModel_NNFastAiTabular',\n",
       "  'XGBoost_BAG_L2': 'StackerEnsembleModel_XGBoost',\n",
       "  'LightGBMLarge_BAG_L2': 'StackerEnsembleModel_LGB',\n",
       "  'CatBoost_r177_BAG_L2': 'StackerEnsembleModel_CatBoost',\n",
       "  'LightGBM_r131_BAG_L2': 'StackerEnsembleModel_LGB',\n",
       "  'NeuralNetFastAI_r191_BAG_L2': 'StackerEnsembleModel_NNFastAiTabular',\n",
       "  'CatBoost_r9_BAG_L2': 'StackerEnsembleModel_CatBoost',\n",
       "  'LightGBM_r96_BAG_L2': 'StackerEnsembleModel_LGB',\n",
       "  'XGBoost_r33_BAG_L2': 'StackerEnsembleModel_XGBoost',\n",
       "  'CatBoost_r137_BAG_L2': 'StackerEnsembleModel_CatBoost',\n",
       "  'NeuralNetFastAI_r102_BAG_L2': 'StackerEnsembleModel_NNFastAiTabular',\n",
       "  'CatBoost_r13_BAG_L2': 'StackerEnsembleModel_CatBoost',\n",
       "  'LightGBM_r188_BAG_L2': 'StackerEnsembleModel_LGB',\n",
       "  'NeuralNetFastAI_r145_BAG_L2': 'StackerEnsembleModel_NNFastAiTabular',\n",
       "  'XGBoost_r89_BAG_L2': 'StackerEnsembleModel_XGBoost',\n",
       "  'LightGBM_r130_BAG_L2': 'StackerEnsembleModel_LGB',\n",
       "  'CatBoost_r50_BAG_L2': 'StackerEnsembleModel_CatBoost',\n",
       "  'NeuralNetFastAI_r11_BAG_L2': 'StackerEnsembleModel_NNFastAiTabular',\n",
       "  'XGBoost_r194_BAG_L2': 'StackerEnsembleModel_XGBoost',\n",
       "  'CatBoost_r69_BAG_L2': 'StackerEnsembleModel_CatBoost',\n",
       "  'NeuralNetFastAI_r103_BAG_L2': 'StackerEnsembleModel_NNFastAiTabular',\n",
       "  'LightGBM_r161_BAG_L2': 'StackerEnsembleModel_LGB',\n",
       "  'NeuralNetFastAI_r143_BAG_L2': 'StackerEnsembleModel_NNFastAiTabular',\n",
       "  'CatBoost_r70_BAG_L2': 'StackerEnsembleModel_CatBoost',\n",
       "  'NeuralNetFastAI_r156_BAG_L2': 'StackerEnsembleModel_NNFastAiTabular',\n",
       "  'LightGBM_r196_BAG_L2': 'StackerEnsembleModel_LGB',\n",
       "  'CatBoost_r167_BAG_L2': 'StackerEnsembleModel_CatBoost',\n",
       "  'NeuralNetFastAI_r95_BAG_L2': 'StackerEnsembleModel_NNFastAiTabular',\n",
       "  'XGBoost_r98_BAG_L2': 'StackerEnsembleModel_XGBoost',\n",
       "  'LightGBM_r15_BAG_L2': 'StackerEnsembleModel_LGB',\n",
       "  'CatBoost_r86_BAG_L2': 'StackerEnsembleModel_CatBoost',\n",
       "  'NeuralNetFastAI_r37_BAG_L2': 'StackerEnsembleModel_NNFastAiTabular',\n",
       "  'WeightedEnsemble_L3': 'WeightedEnsembleModel',\n",
       "  'LightGBMXT_BAG_L1_FULL': 'StackerEnsembleModel_LGB',\n",
       "  'LightGBM_BAG_L1_FULL': 'StackerEnsembleModel_LGB',\n",
       "  'CatBoost_BAG_L1_FULL': 'StackerEnsembleModel_CatBoost',\n",
       "  'NeuralNetFastAI_BAG_L1_FULL': 'StackerEnsembleModel_NNFastAiTabular',\n",
       "  'XGBoost_BAG_L1_FULL': 'StackerEnsembleModel_XGBoost',\n",
       "  'LightGBMLarge_BAG_L1_FULL': 'StackerEnsembleModel_LGB',\n",
       "  'CatBoost_r177_BAG_L1_FULL': 'StackerEnsembleModel_CatBoost',\n",
       "  'LightGBM_r131_BAG_L1_FULL': 'StackerEnsembleModel_LGB',\n",
       "  'NeuralNetFastAI_r191_BAG_L1_FULL': 'StackerEnsembleModel_NNFastAiTabular',\n",
       "  'CatBoost_r9_BAG_L1_FULL': 'StackerEnsembleModel_CatBoost',\n",
       "  'LightGBM_r96_BAG_L1_FULL': 'StackerEnsembleModel_LGB',\n",
       "  'XGBoost_r33_BAG_L1_FULL': 'StackerEnsembleModel_XGBoost',\n",
       "  'CatBoost_r137_BAG_L1_FULL': 'StackerEnsembleModel_CatBoost',\n",
       "  'NeuralNetFastAI_r102_BAG_L1_FULL': 'StackerEnsembleModel_NNFastAiTabular',\n",
       "  'CatBoost_r13_BAG_L1_FULL': 'StackerEnsembleModel_CatBoost',\n",
       "  'LightGBM_r188_BAG_L1_FULL': 'StackerEnsembleModel_LGB',\n",
       "  'NeuralNetFastAI_r145_BAG_L1_FULL': 'StackerEnsembleModel_NNFastAiTabular',\n",
       "  'XGBoost_r89_BAG_L1_FULL': 'StackerEnsembleModel_XGBoost',\n",
       "  'LightGBM_r130_BAG_L1_FULL': 'StackerEnsembleModel_LGB',\n",
       "  'CatBoost_r50_BAG_L1_FULL': 'StackerEnsembleModel_CatBoost',\n",
       "  'NeuralNetFastAI_r11_BAG_L1_FULL': 'StackerEnsembleModel_NNFastAiTabular',\n",
       "  'XGBoost_r194_BAG_L1_FULL': 'StackerEnsembleModel_XGBoost',\n",
       "  'CatBoost_r69_BAG_L1_FULL': 'StackerEnsembleModel_CatBoost',\n",
       "  'NeuralNetFastAI_r103_BAG_L1_FULL': 'StackerEnsembleModel_NNFastAiTabular',\n",
       "  'LightGBM_r161_BAG_L1_FULL': 'StackerEnsembleModel_LGB',\n",
       "  'NeuralNetFastAI_r143_BAG_L1_FULL': 'StackerEnsembleModel_NNFastAiTabular',\n",
       "  'CatBoost_r70_BAG_L1_FULL': 'StackerEnsembleModel_CatBoost',\n",
       "  'NeuralNetFastAI_r156_BAG_L1_FULL': 'StackerEnsembleModel_NNFastAiTabular',\n",
       "  'LightGBM_r196_BAG_L1_FULL': 'StackerEnsembleModel_LGB',\n",
       "  'CatBoost_r167_BAG_L1_FULL': 'StackerEnsembleModel_CatBoost',\n",
       "  'NeuralNetFastAI_r95_BAG_L1_FULL': 'StackerEnsembleModel_NNFastAiTabular',\n",
       "  'XGBoost_r98_BAG_L1_FULL': 'StackerEnsembleModel_XGBoost',\n",
       "  'LightGBM_r15_BAG_L1_FULL': 'StackerEnsembleModel_LGB',\n",
       "  'CatBoost_r86_BAG_L1_FULL': 'StackerEnsembleModel_CatBoost',\n",
       "  'NeuralNetFastAI_r37_BAG_L1_FULL': 'StackerEnsembleModel_NNFastAiTabular',\n",
       "  'CatBoost_r49_BAG_L1_FULL': 'StackerEnsembleModel_CatBoost',\n",
       "  'LightGBM_r143_BAG_L1_FULL': 'StackerEnsembleModel_LGB',\n",
       "  'NeuralNetFastAI_r134_BAG_L1_FULL': 'StackerEnsembleModel_NNFastAiTabular',\n",
       "  'LightGBM_r94_BAG_L1_FULL': 'StackerEnsembleModel_LGB',\n",
       "  'CatBoost_r128_BAG_L1_FULL': 'StackerEnsembleModel_CatBoost',\n",
       "  'NeuralNetFastAI_r111_BAG_L1_FULL': 'StackerEnsembleModel_NNFastAiTabular',\n",
       "  'NeuralNetFastAI_r65_BAG_L1_FULL': 'StackerEnsembleModel_NNFastAiTabular',\n",
       "  'NeuralNetFastAI_r88_BAG_L1_FULL': 'StackerEnsembleModel_NNFastAiTabular',\n",
       "  'LightGBM_r30_BAG_L1_FULL': 'StackerEnsembleModel_LGB',\n",
       "  'XGBoost_r49_BAG_L1_FULL': 'StackerEnsembleModel_XGBoost',\n",
       "  'CatBoost_r5_BAG_L1_FULL': 'StackerEnsembleModel_CatBoost',\n",
       "  'CatBoost_r143_BAG_L1_FULL': 'StackerEnsembleModel_CatBoost',\n",
       "  'XGBoost_r31_BAG_L1_FULL': 'StackerEnsembleModel_XGBoost',\n",
       "  'NeuralNetFastAI_r160_BAG_L1_FULL': 'StackerEnsembleModel_NNFastAiTabular',\n",
       "  'CatBoost_r60_BAG_L1_FULL': 'StackerEnsembleModel_CatBoost',\n",
       "  'LightGBM_r135_BAG_L1_FULL': 'StackerEnsembleModel_LGB',\n",
       "  'WeightedEnsemble_L2_FULL': 'WeightedEnsembleModel',\n",
       "  'LightGBMXT_BAG_L2_FULL': 'StackerEnsembleModel_LGB',\n",
       "  'LightGBM_BAG_L2_FULL': 'StackerEnsembleModel_LGB',\n",
       "  'CatBoost_BAG_L2_FULL': 'StackerEnsembleModel_CatBoost',\n",
       "  'NeuralNetFastAI_BAG_L2_FULL': 'StackerEnsembleModel_NNFastAiTabular',\n",
       "  'XGBoost_BAG_L2_FULL': 'StackerEnsembleModel_XGBoost',\n",
       "  'LightGBMLarge_BAG_L2_FULL': 'StackerEnsembleModel_LGB',\n",
       "  'CatBoost_r177_BAG_L2_FULL': 'StackerEnsembleModel_CatBoost',\n",
       "  'LightGBM_r131_BAG_L2_FULL': 'StackerEnsembleModel_LGB',\n",
       "  'NeuralNetFastAI_r191_BAG_L2_FULL': 'StackerEnsembleModel_NNFastAiTabular',\n",
       "  'CatBoost_r9_BAG_L2_FULL': 'StackerEnsembleModel_CatBoost',\n",
       "  'LightGBM_r96_BAG_L2_FULL': 'StackerEnsembleModel_LGB',\n",
       "  'XGBoost_r33_BAG_L2_FULL': 'StackerEnsembleModel_XGBoost',\n",
       "  'CatBoost_r137_BAG_L2_FULL': 'StackerEnsembleModel_CatBoost',\n",
       "  'NeuralNetFastAI_r102_BAG_L2_FULL': 'StackerEnsembleModel_NNFastAiTabular',\n",
       "  'CatBoost_r13_BAG_L2_FULL': 'StackerEnsembleModel_CatBoost',\n",
       "  'LightGBM_r188_BAG_L2_FULL': 'StackerEnsembleModel_LGB',\n",
       "  'NeuralNetFastAI_r145_BAG_L2_FULL': 'StackerEnsembleModel_NNFastAiTabular',\n",
       "  'XGBoost_r89_BAG_L2_FULL': 'StackerEnsembleModel_XGBoost',\n",
       "  'LightGBM_r130_BAG_L2_FULL': 'StackerEnsembleModel_LGB',\n",
       "  'CatBoost_r50_BAG_L2_FULL': 'StackerEnsembleModel_CatBoost',\n",
       "  'NeuralNetFastAI_r11_BAG_L2_FULL': 'StackerEnsembleModel_NNFastAiTabular',\n",
       "  'XGBoost_r194_BAG_L2_FULL': 'StackerEnsembleModel_XGBoost',\n",
       "  'CatBoost_r69_BAG_L2_FULL': 'StackerEnsembleModel_CatBoost',\n",
       "  'NeuralNetFastAI_r103_BAG_L2_FULL': 'StackerEnsembleModel_NNFastAiTabular',\n",
       "  'LightGBM_r161_BAG_L2_FULL': 'StackerEnsembleModel_LGB',\n",
       "  'NeuralNetFastAI_r143_BAG_L2_FULL': 'StackerEnsembleModel_NNFastAiTabular',\n",
       "  'CatBoost_r70_BAG_L2_FULL': 'StackerEnsembleModel_CatBoost',\n",
       "  'NeuralNetFastAI_r156_BAG_L2_FULL': 'StackerEnsembleModel_NNFastAiTabular',\n",
       "  'LightGBM_r196_BAG_L2_FULL': 'StackerEnsembleModel_LGB',\n",
       "  'CatBoost_r167_BAG_L2_FULL': 'StackerEnsembleModel_CatBoost',\n",
       "  'NeuralNetFastAI_r95_BAG_L2_FULL': 'StackerEnsembleModel_NNFastAiTabular',\n",
       "  'XGBoost_r98_BAG_L2_FULL': 'StackerEnsembleModel_XGBoost',\n",
       "  'LightGBM_r15_BAG_L2_FULL': 'StackerEnsembleModel_LGB',\n",
       "  'CatBoost_r86_BAG_L2_FULL': 'StackerEnsembleModel_CatBoost',\n",
       "  'NeuralNetFastAI_r37_BAG_L2_FULL': 'StackerEnsembleModel_NNFastAiTabular',\n",
       "  'WeightedEnsemble_L3_FULL': 'WeightedEnsembleModel'},\n",
       " 'model_performance': {'LightGBMXT_BAG_L1': 0.9028061760839858,\n",
       "  'LightGBM_BAG_L1': 0.9013545709934893,\n",
       "  'CatBoost_BAG_L1': 0.9030209393296436,\n",
       "  'NeuralNetFastAI_BAG_L1': 0.8701427177290444,\n",
       "  'XGBoost_BAG_L1': 0.8981140245260668,\n",
       "  'LightGBMLarge_BAG_L1': 0.8887614063676521,\n",
       "  'CatBoost_r177_BAG_L1': 0.9008120203526805,\n",
       "  'LightGBM_r131_BAG_L1': 0.9022915776521916,\n",
       "  'NeuralNetFastAI_r191_BAG_L1': 0.8686724488965041,\n",
       "  'CatBoost_r9_BAG_L1': 0.8998498393442447,\n",
       "  'LightGBM_r96_BAG_L1': 0.9047886995295522,\n",
       "  'XGBoost_r33_BAG_L1': 0.8920714861252006,\n",
       "  'CatBoost_r137_BAG_L1': 0.9006930932522152,\n",
       "  'NeuralNetFastAI_r102_BAG_L1': 0.8658222784661563,\n",
       "  'CatBoost_r13_BAG_L1': 0.9017375683418488,\n",
       "  'LightGBM_r188_BAG_L1': 0.8952182798418912,\n",
       "  'NeuralNetFastAI_r145_BAG_L1': 0.8704771025399877,\n",
       "  'XGBoost_r89_BAG_L1': 0.897529632379839,\n",
       "  'LightGBM_r130_BAG_L1': 0.9023266481256135,\n",
       "  'CatBoost_r50_BAG_L1': 0.9008694873165549,\n",
       "  'NeuralNetFastAI_r11_BAG_L1': 0.8706886538858519,\n",
       "  'XGBoost_r194_BAG_L1': 0.8965998307936466,\n",
       "  'CatBoost_r69_BAG_L1': 0.901173836524023,\n",
       "  'NeuralNetFastAI_r103_BAG_L1': 0.8603252421815849,\n",
       "  'LightGBM_r161_BAG_L1': 0.8902071953152791,\n",
       "  'NeuralNetFastAI_r143_BAG_L1': 0.8890450084386158,\n",
       "  'CatBoost_r70_BAG_L1': 0.9010059496537312,\n",
       "  'NeuralNetFastAI_r156_BAG_L1': 0.8862261757332811,\n",
       "  'LightGBM_r196_BAG_L1': 0.8987050140880869,\n",
       "  'CatBoost_r167_BAG_L1': 0.8996979251648181,\n",
       "  'NeuralNetFastAI_r95_BAG_L1': 0.8590484686095825,\n",
       "  'XGBoost_r98_BAG_L1': 0.897637708467488,\n",
       "  'LightGBM_r15_BAG_L1': 0.9026577342286606,\n",
       "  'CatBoost_r86_BAG_L1': 0.8987261952651042,\n",
       "  'NeuralNetFastAI_r37_BAG_L1': 0.8785598917746025,\n",
       "  'CatBoost_r49_BAG_L1': 0.9010380686516671,\n",
       "  'LightGBM_r143_BAG_L1': 0.8949424036920529,\n",
       "  'NeuralNetFastAI_r134_BAG_L1': 0.8792907291897974,\n",
       "  'LightGBM_r94_BAG_L1': 0.9046150833244935,\n",
       "  'CatBoost_r128_BAG_L1': 0.8982865990338953,\n",
       "  'NeuralNetFastAI_r111_BAG_L1': 0.8813550258679465,\n",
       "  'NeuralNetFastAI_r65_BAG_L1': 0.8713487426974854,\n",
       "  'NeuralNetFastAI_r88_BAG_L1': 0.8660017976221872,\n",
       "  'LightGBM_r30_BAG_L1': 0.8958189919113947,\n",
       "  'XGBoost_r49_BAG_L1': 0.8980467482466066,\n",
       "  'CatBoost_r5_BAG_L1': 0.9011035219609742,\n",
       "  'CatBoost_r143_BAG_L1': 0.898022876018411,\n",
       "  'XGBoost_r31_BAG_L1': 0.9010300823062344,\n",
       "  'NeuralNetFastAI_r160_BAG_L1': 0.8870281089844477,\n",
       "  'CatBoost_r60_BAG_L1': 0.8970051378243563,\n",
       "  'LightGBM_r135_BAG_L1': 0.8994869814756719,\n",
       "  'WeightedEnsemble_L2': 0.9110737797688856,\n",
       "  'LightGBMXT_BAG_L2': 0.9074997165715453,\n",
       "  'LightGBM_BAG_L2': 0.9040707097135315,\n",
       "  'CatBoost_BAG_L2': 0.9096296401752065,\n",
       "  'NeuralNetFastAI_BAG_L2': 0.8953929377441803,\n",
       "  'XGBoost_BAG_L2': 0.9039439698838386,\n",
       "  'LightGBMLarge_BAG_L2': 0.9013547446096943,\n",
       "  'CatBoost_r177_BAG_L2': 0.909613146635726,\n",
       "  'LightGBM_r131_BAG_L2': 0.9043612564326975,\n",
       "  'NeuralNetFastAI_r191_BAG_L2': 0.8910065243233699,\n",
       "  'CatBoost_r9_BAG_L2': 0.909211919585835,\n",
       "  'LightGBM_r96_BAG_L2': 0.9094553295053275,\n",
       "  'XGBoost_r33_BAG_L2': 0.904389208641712,\n",
       "  'CatBoost_r137_BAG_L2': 0.9103015348887841,\n",
       "  'NeuralNetFastAI_r102_BAG_L2': 0.88582390698616,\n",
       "  'CatBoost_r13_BAG_L2': 0.9099489203763097,\n",
       "  'LightGBM_r188_BAG_L2': 0.9069845972911358,\n",
       "  'NeuralNetFastAI_r145_BAG_L2': 0.8953111645115976,\n",
       "  'XGBoost_r89_BAG_L2': 0.9061828376561744,\n",
       "  'LightGBM_r130_BAG_L2': 0.904628451772283,\n",
       "  'CatBoost_r50_BAG_L2': 0.9093581044304946,\n",
       "  'NeuralNetFastAI_r11_BAG_L2': 0.9004086231002264,\n",
       "  'XGBoost_r194_BAG_L2': 0.9032484633663731,\n",
       "  'CatBoost_r69_BAG_L2': 0.909775825019866,\n",
       "  'NeuralNetFastAI_r103_BAG_L2': 0.8961907042064255,\n",
       "  'LightGBM_r161_BAG_L2': 0.9039397162868147,\n",
       "  'NeuralNetFastAI_r143_BAG_L2': 0.9028270968366955,\n",
       "  'CatBoost_r70_BAG_L2': 0.9100386799543251,\n",
       "  'NeuralNetFastAI_r156_BAG_L2': 0.9017478116979474,\n",
       "  'LightGBM_r196_BAG_L2': 0.9081530343511816,\n",
       "  'CatBoost_r167_BAG_L2': 0.9089044452866759,\n",
       "  'NeuralNetFastAI_r95_BAG_L2': 0.8941923816861987,\n",
       "  'XGBoost_r98_BAG_L2': 0.9061672121977191,\n",
       "  'LightGBM_r15_BAG_L2': 0.9065447406356193,\n",
       "  'CatBoost_r86_BAG_L2': 0.9092131348992705,\n",
       "  'NeuralNetFastAI_r37_BAG_L2': 0.8996357705634072,\n",
       "  'WeightedEnsemble_L3': 0.9110328063444918,\n",
       "  'LightGBMXT_BAG_L1_FULL': None,\n",
       "  'LightGBM_BAG_L1_FULL': None,\n",
       "  'CatBoost_BAG_L1_FULL': None,\n",
       "  'NeuralNetFastAI_BAG_L1_FULL': None,\n",
       "  'XGBoost_BAG_L1_FULL': None,\n",
       "  'LightGBMLarge_BAG_L1_FULL': None,\n",
       "  'CatBoost_r177_BAG_L1_FULL': None,\n",
       "  'LightGBM_r131_BAG_L1_FULL': None,\n",
       "  'NeuralNetFastAI_r191_BAG_L1_FULL': None,\n",
       "  'CatBoost_r9_BAG_L1_FULL': None,\n",
       "  'LightGBM_r96_BAG_L1_FULL': None,\n",
       "  'XGBoost_r33_BAG_L1_FULL': None,\n",
       "  'CatBoost_r137_BAG_L1_FULL': None,\n",
       "  'NeuralNetFastAI_r102_BAG_L1_FULL': None,\n",
       "  'CatBoost_r13_BAG_L1_FULL': None,\n",
       "  'LightGBM_r188_BAG_L1_FULL': None,\n",
       "  'NeuralNetFastAI_r145_BAG_L1_FULL': None,\n",
       "  'XGBoost_r89_BAG_L1_FULL': None,\n",
       "  'LightGBM_r130_BAG_L1_FULL': None,\n",
       "  'CatBoost_r50_BAG_L1_FULL': None,\n",
       "  'NeuralNetFastAI_r11_BAG_L1_FULL': None,\n",
       "  'XGBoost_r194_BAG_L1_FULL': None,\n",
       "  'CatBoost_r69_BAG_L1_FULL': None,\n",
       "  'NeuralNetFastAI_r103_BAG_L1_FULL': None,\n",
       "  'LightGBM_r161_BAG_L1_FULL': None,\n",
       "  'NeuralNetFastAI_r143_BAG_L1_FULL': None,\n",
       "  'CatBoost_r70_BAG_L1_FULL': None,\n",
       "  'NeuralNetFastAI_r156_BAG_L1_FULL': None,\n",
       "  'LightGBM_r196_BAG_L1_FULL': None,\n",
       "  'CatBoost_r167_BAG_L1_FULL': None,\n",
       "  'NeuralNetFastAI_r95_BAG_L1_FULL': None,\n",
       "  'XGBoost_r98_BAG_L1_FULL': None,\n",
       "  'LightGBM_r15_BAG_L1_FULL': None,\n",
       "  'CatBoost_r86_BAG_L1_FULL': None,\n",
       "  'NeuralNetFastAI_r37_BAG_L1_FULL': None,\n",
       "  'CatBoost_r49_BAG_L1_FULL': None,\n",
       "  'LightGBM_r143_BAG_L1_FULL': None,\n",
       "  'NeuralNetFastAI_r134_BAG_L1_FULL': None,\n",
       "  'LightGBM_r94_BAG_L1_FULL': None,\n",
       "  'CatBoost_r128_BAG_L1_FULL': None,\n",
       "  'NeuralNetFastAI_r111_BAG_L1_FULL': None,\n",
       "  'NeuralNetFastAI_r65_BAG_L1_FULL': None,\n",
       "  'NeuralNetFastAI_r88_BAG_L1_FULL': None,\n",
       "  'LightGBM_r30_BAG_L1_FULL': None,\n",
       "  'XGBoost_r49_BAG_L1_FULL': None,\n",
       "  'CatBoost_r5_BAG_L1_FULL': None,\n",
       "  'CatBoost_r143_BAG_L1_FULL': None,\n",
       "  'XGBoost_r31_BAG_L1_FULL': None,\n",
       "  'NeuralNetFastAI_r160_BAG_L1_FULL': None,\n",
       "  'CatBoost_r60_BAG_L1_FULL': None,\n",
       "  'LightGBM_r135_BAG_L1_FULL': None,\n",
       "  'WeightedEnsemble_L2_FULL': None,\n",
       "  'LightGBMXT_BAG_L2_FULL': None,\n",
       "  'LightGBM_BAG_L2_FULL': None,\n",
       "  'CatBoost_BAG_L2_FULL': None,\n",
       "  'NeuralNetFastAI_BAG_L2_FULL': None,\n",
       "  'XGBoost_BAG_L2_FULL': None,\n",
       "  'LightGBMLarge_BAG_L2_FULL': None,\n",
       "  'CatBoost_r177_BAG_L2_FULL': None,\n",
       "  'LightGBM_r131_BAG_L2_FULL': None,\n",
       "  'NeuralNetFastAI_r191_BAG_L2_FULL': None,\n",
       "  'CatBoost_r9_BAG_L2_FULL': None,\n",
       "  'LightGBM_r96_BAG_L2_FULL': None,\n",
       "  'XGBoost_r33_BAG_L2_FULL': None,\n",
       "  'CatBoost_r137_BAG_L2_FULL': None,\n",
       "  'NeuralNetFastAI_r102_BAG_L2_FULL': None,\n",
       "  'CatBoost_r13_BAG_L2_FULL': None,\n",
       "  'LightGBM_r188_BAG_L2_FULL': None,\n",
       "  'NeuralNetFastAI_r145_BAG_L2_FULL': None,\n",
       "  'XGBoost_r89_BAG_L2_FULL': None,\n",
       "  'LightGBM_r130_BAG_L2_FULL': None,\n",
       "  'CatBoost_r50_BAG_L2_FULL': None,\n",
       "  'NeuralNetFastAI_r11_BAG_L2_FULL': None,\n",
       "  'XGBoost_r194_BAG_L2_FULL': None,\n",
       "  'CatBoost_r69_BAG_L2_FULL': None,\n",
       "  'NeuralNetFastAI_r103_BAG_L2_FULL': None,\n",
       "  'LightGBM_r161_BAG_L2_FULL': None,\n",
       "  'NeuralNetFastAI_r143_BAG_L2_FULL': None,\n",
       "  'CatBoost_r70_BAG_L2_FULL': None,\n",
       "  'NeuralNetFastAI_r156_BAG_L2_FULL': None,\n",
       "  'LightGBM_r196_BAG_L2_FULL': None,\n",
       "  'CatBoost_r167_BAG_L2_FULL': None,\n",
       "  'NeuralNetFastAI_r95_BAG_L2_FULL': None,\n",
       "  'XGBoost_r98_BAG_L2_FULL': None,\n",
       "  'LightGBM_r15_BAG_L2_FULL': None,\n",
       "  'CatBoost_r86_BAG_L2_FULL': None,\n",
       "  'NeuralNetFastAI_r37_BAG_L2_FULL': None,\n",
       "  'WeightedEnsemble_L3_FULL': None},\n",
       " 'model_best': 'WeightedEnsemble_L2_FULL',\n",
       " 'model_paths': {'LightGBMXT_BAG_L1': ['LightGBMXT_BAG_L1'],\n",
       "  'LightGBM_BAG_L1': ['LightGBM_BAG_L1'],\n",
       "  'CatBoost_BAG_L1': ['CatBoost_BAG_L1'],\n",
       "  'NeuralNetFastAI_BAG_L1': ['NeuralNetFastAI_BAG_L1'],\n",
       "  'XGBoost_BAG_L1': ['XGBoost_BAG_L1'],\n",
       "  'LightGBMLarge_BAG_L1': ['LightGBMLarge_BAG_L1'],\n",
       "  'CatBoost_r177_BAG_L1': ['CatBoost_r177_BAG_L1'],\n",
       "  'LightGBM_r131_BAG_L1': ['LightGBM_r131_BAG_L1'],\n",
       "  'NeuralNetFastAI_r191_BAG_L1': ['NeuralNetFastAI_r191_BAG_L1'],\n",
       "  'CatBoost_r9_BAG_L1': ['CatBoost_r9_BAG_L1'],\n",
       "  'LightGBM_r96_BAG_L1': ['LightGBM_r96_BAG_L1'],\n",
       "  'XGBoost_r33_BAG_L1': ['XGBoost_r33_BAG_L1'],\n",
       "  'CatBoost_r137_BAG_L1': ['CatBoost_r137_BAG_L1'],\n",
       "  'NeuralNetFastAI_r102_BAG_L1': ['NeuralNetFastAI_r102_BAG_L1'],\n",
       "  'CatBoost_r13_BAG_L1': ['CatBoost_r13_BAG_L1'],\n",
       "  'LightGBM_r188_BAG_L1': ['LightGBM_r188_BAG_L1'],\n",
       "  'NeuralNetFastAI_r145_BAG_L1': ['NeuralNetFastAI_r145_BAG_L1'],\n",
       "  'XGBoost_r89_BAG_L1': ['XGBoost_r89_BAG_L1'],\n",
       "  'LightGBM_r130_BAG_L1': ['LightGBM_r130_BAG_L1'],\n",
       "  'CatBoost_r50_BAG_L1': ['CatBoost_r50_BAG_L1'],\n",
       "  'NeuralNetFastAI_r11_BAG_L1': ['NeuralNetFastAI_r11_BAG_L1'],\n",
       "  'XGBoost_r194_BAG_L1': ['XGBoost_r194_BAG_L1'],\n",
       "  'CatBoost_r69_BAG_L1': ['CatBoost_r69_BAG_L1'],\n",
       "  'NeuralNetFastAI_r103_BAG_L1': ['NeuralNetFastAI_r103_BAG_L1'],\n",
       "  'LightGBM_r161_BAG_L1': ['LightGBM_r161_BAG_L1'],\n",
       "  'NeuralNetFastAI_r143_BAG_L1': ['NeuralNetFastAI_r143_BAG_L1'],\n",
       "  'CatBoost_r70_BAG_L1': ['CatBoost_r70_BAG_L1'],\n",
       "  'NeuralNetFastAI_r156_BAG_L1': ['NeuralNetFastAI_r156_BAG_L1'],\n",
       "  'LightGBM_r196_BAG_L1': ['LightGBM_r196_BAG_L1'],\n",
       "  'CatBoost_r167_BAG_L1': ['CatBoost_r167_BAG_L1'],\n",
       "  'NeuralNetFastAI_r95_BAG_L1': ['NeuralNetFastAI_r95_BAG_L1'],\n",
       "  'XGBoost_r98_BAG_L1': ['XGBoost_r98_BAG_L1'],\n",
       "  'LightGBM_r15_BAG_L1': ['LightGBM_r15_BAG_L1'],\n",
       "  'CatBoost_r86_BAG_L1': ['CatBoost_r86_BAG_L1'],\n",
       "  'NeuralNetFastAI_r37_BAG_L1': ['NeuralNetFastAI_r37_BAG_L1'],\n",
       "  'CatBoost_r49_BAG_L1': ['CatBoost_r49_BAG_L1'],\n",
       "  'LightGBM_r143_BAG_L1': ['LightGBM_r143_BAG_L1'],\n",
       "  'NeuralNetFastAI_r134_BAG_L1': ['NeuralNetFastAI_r134_BAG_L1'],\n",
       "  'LightGBM_r94_BAG_L1': ['LightGBM_r94_BAG_L1'],\n",
       "  'CatBoost_r128_BAG_L1': ['CatBoost_r128_BAG_L1'],\n",
       "  'NeuralNetFastAI_r111_BAG_L1': ['NeuralNetFastAI_r111_BAG_L1'],\n",
       "  'NeuralNetFastAI_r65_BAG_L1': ['NeuralNetFastAI_r65_BAG_L1'],\n",
       "  'NeuralNetFastAI_r88_BAG_L1': ['NeuralNetFastAI_r88_BAG_L1'],\n",
       "  'LightGBM_r30_BAG_L1': ['LightGBM_r30_BAG_L1'],\n",
       "  'XGBoost_r49_BAG_L1': ['XGBoost_r49_BAG_L1'],\n",
       "  'CatBoost_r5_BAG_L1': ['CatBoost_r5_BAG_L1'],\n",
       "  'CatBoost_r143_BAG_L1': ['CatBoost_r143_BAG_L1'],\n",
       "  'XGBoost_r31_BAG_L1': ['XGBoost_r31_BAG_L1'],\n",
       "  'NeuralNetFastAI_r160_BAG_L1': ['NeuralNetFastAI_r160_BAG_L1'],\n",
       "  'CatBoost_r60_BAG_L1': ['CatBoost_r60_BAG_L1'],\n",
       "  'LightGBM_r135_BAG_L1': ['LightGBM_r135_BAG_L1'],\n",
       "  'WeightedEnsemble_L2': ['WeightedEnsemble_L2'],\n",
       "  'LightGBMXT_BAG_L2': ['LightGBMXT_BAG_L2'],\n",
       "  'LightGBM_BAG_L2': ['LightGBM_BAG_L2'],\n",
       "  'CatBoost_BAG_L2': ['CatBoost_BAG_L2'],\n",
       "  'NeuralNetFastAI_BAG_L2': ['NeuralNetFastAI_BAG_L2'],\n",
       "  'XGBoost_BAG_L2': ['XGBoost_BAG_L2'],\n",
       "  'LightGBMLarge_BAG_L2': ['LightGBMLarge_BAG_L2'],\n",
       "  'CatBoost_r177_BAG_L2': ['CatBoost_r177_BAG_L2'],\n",
       "  'LightGBM_r131_BAG_L2': ['LightGBM_r131_BAG_L2'],\n",
       "  'NeuralNetFastAI_r191_BAG_L2': ['NeuralNetFastAI_r191_BAG_L2'],\n",
       "  'CatBoost_r9_BAG_L2': ['CatBoost_r9_BAG_L2'],\n",
       "  'LightGBM_r96_BAG_L2': ['LightGBM_r96_BAG_L2'],\n",
       "  'XGBoost_r33_BAG_L2': ['XGBoost_r33_BAG_L2'],\n",
       "  'CatBoost_r137_BAG_L2': ['CatBoost_r137_BAG_L2'],\n",
       "  'NeuralNetFastAI_r102_BAG_L2': ['NeuralNetFastAI_r102_BAG_L2'],\n",
       "  'CatBoost_r13_BAG_L2': ['CatBoost_r13_BAG_L2'],\n",
       "  'LightGBM_r188_BAG_L2': ['LightGBM_r188_BAG_L2'],\n",
       "  'NeuralNetFastAI_r145_BAG_L2': ['NeuralNetFastAI_r145_BAG_L2'],\n",
       "  'XGBoost_r89_BAG_L2': ['XGBoost_r89_BAG_L2'],\n",
       "  'LightGBM_r130_BAG_L2': ['LightGBM_r130_BAG_L2'],\n",
       "  'CatBoost_r50_BAG_L2': ['CatBoost_r50_BAG_L2'],\n",
       "  'NeuralNetFastAI_r11_BAG_L2': ['NeuralNetFastAI_r11_BAG_L2'],\n",
       "  'XGBoost_r194_BAG_L2': ['XGBoost_r194_BAG_L2'],\n",
       "  'CatBoost_r69_BAG_L2': ['CatBoost_r69_BAG_L2'],\n",
       "  'NeuralNetFastAI_r103_BAG_L2': ['NeuralNetFastAI_r103_BAG_L2'],\n",
       "  'LightGBM_r161_BAG_L2': ['LightGBM_r161_BAG_L2'],\n",
       "  'NeuralNetFastAI_r143_BAG_L2': ['NeuralNetFastAI_r143_BAG_L2'],\n",
       "  'CatBoost_r70_BAG_L2': ['CatBoost_r70_BAG_L2'],\n",
       "  'NeuralNetFastAI_r156_BAG_L2': ['NeuralNetFastAI_r156_BAG_L2'],\n",
       "  'LightGBM_r196_BAG_L2': ['LightGBM_r196_BAG_L2'],\n",
       "  'CatBoost_r167_BAG_L2': ['CatBoost_r167_BAG_L2'],\n",
       "  'NeuralNetFastAI_r95_BAG_L2': ['NeuralNetFastAI_r95_BAG_L2'],\n",
       "  'XGBoost_r98_BAG_L2': ['XGBoost_r98_BAG_L2'],\n",
       "  'LightGBM_r15_BAG_L2': ['LightGBM_r15_BAG_L2'],\n",
       "  'CatBoost_r86_BAG_L2': ['CatBoost_r86_BAG_L2'],\n",
       "  'NeuralNetFastAI_r37_BAG_L2': ['NeuralNetFastAI_r37_BAG_L2'],\n",
       "  'WeightedEnsemble_L3': ['WeightedEnsemble_L3'],\n",
       "  'LightGBMXT_BAG_L1_FULL': ['LightGBMXT_BAG_L1_FULL'],\n",
       "  'LightGBM_BAG_L1_FULL': ['LightGBM_BAG_L1_FULL'],\n",
       "  'CatBoost_BAG_L1_FULL': ['CatBoost_BAG_L1_FULL'],\n",
       "  'NeuralNetFastAI_BAG_L1_FULL': ['NeuralNetFastAI_BAG_L1_FULL'],\n",
       "  'XGBoost_BAG_L1_FULL': ['XGBoost_BAG_L1_FULL'],\n",
       "  'LightGBMLarge_BAG_L1_FULL': ['LightGBMLarge_BAG_L1_FULL'],\n",
       "  'CatBoost_r177_BAG_L1_FULL': ['CatBoost_r177_BAG_L1_FULL'],\n",
       "  'LightGBM_r131_BAG_L1_FULL': ['LightGBM_r131_BAG_L1_FULL'],\n",
       "  'NeuralNetFastAI_r191_BAG_L1_FULL': ['NeuralNetFastAI_r191_BAG_L1_FULL'],\n",
       "  'CatBoost_r9_BAG_L1_FULL': ['CatBoost_r9_BAG_L1_FULL'],\n",
       "  'LightGBM_r96_BAG_L1_FULL': ['LightGBM_r96_BAG_L1_FULL'],\n",
       "  'XGBoost_r33_BAG_L1_FULL': ['XGBoost_r33_BAG_L1_FULL'],\n",
       "  'CatBoost_r137_BAG_L1_FULL': ['CatBoost_r137_BAG_L1_FULL'],\n",
       "  'NeuralNetFastAI_r102_BAG_L1_FULL': ['NeuralNetFastAI_r102_BAG_L1_FULL'],\n",
       "  'CatBoost_r13_BAG_L1_FULL': ['CatBoost_r13_BAG_L1_FULL'],\n",
       "  'LightGBM_r188_BAG_L1_FULL': ['LightGBM_r188_BAG_L1_FULL'],\n",
       "  'NeuralNetFastAI_r145_BAG_L1_FULL': ['NeuralNetFastAI_r145_BAG_L1_FULL'],\n",
       "  'XGBoost_r89_BAG_L1_FULL': ['XGBoost_r89_BAG_L1_FULL'],\n",
       "  'LightGBM_r130_BAG_L1_FULL': ['LightGBM_r130_BAG_L1_FULL'],\n",
       "  'CatBoost_r50_BAG_L1_FULL': ['CatBoost_r50_BAG_L1_FULL'],\n",
       "  'NeuralNetFastAI_r11_BAG_L1_FULL': ['NeuralNetFastAI_r11_BAG_L1_FULL'],\n",
       "  'XGBoost_r194_BAG_L1_FULL': ['XGBoost_r194_BAG_L1_FULL'],\n",
       "  'CatBoost_r69_BAG_L1_FULL': ['CatBoost_r69_BAG_L1_FULL'],\n",
       "  'NeuralNetFastAI_r103_BAG_L1_FULL': ['NeuralNetFastAI_r103_BAG_L1_FULL'],\n",
       "  'LightGBM_r161_BAG_L1_FULL': ['LightGBM_r161_BAG_L1_FULL'],\n",
       "  'NeuralNetFastAI_r143_BAG_L1_FULL': ['NeuralNetFastAI_r143_BAG_L1_FULL'],\n",
       "  'CatBoost_r70_BAG_L1_FULL': ['CatBoost_r70_BAG_L1_FULL'],\n",
       "  'NeuralNetFastAI_r156_BAG_L1_FULL': ['NeuralNetFastAI_r156_BAG_L1_FULL'],\n",
       "  'LightGBM_r196_BAG_L1_FULL': ['LightGBM_r196_BAG_L1_FULL'],\n",
       "  'CatBoost_r167_BAG_L1_FULL': ['CatBoost_r167_BAG_L1_FULL'],\n",
       "  'NeuralNetFastAI_r95_BAG_L1_FULL': ['NeuralNetFastAI_r95_BAG_L1_FULL'],\n",
       "  'XGBoost_r98_BAG_L1_FULL': ['XGBoost_r98_BAG_L1_FULL'],\n",
       "  'LightGBM_r15_BAG_L1_FULL': ['LightGBM_r15_BAG_L1_FULL'],\n",
       "  'CatBoost_r86_BAG_L1_FULL': ['CatBoost_r86_BAG_L1_FULL'],\n",
       "  'NeuralNetFastAI_r37_BAG_L1_FULL': ['NeuralNetFastAI_r37_BAG_L1_FULL'],\n",
       "  'CatBoost_r49_BAG_L1_FULL': ['CatBoost_r49_BAG_L1_FULL'],\n",
       "  'LightGBM_r143_BAG_L1_FULL': ['LightGBM_r143_BAG_L1_FULL'],\n",
       "  'NeuralNetFastAI_r134_BAG_L1_FULL': ['NeuralNetFastAI_r134_BAG_L1_FULL'],\n",
       "  'LightGBM_r94_BAG_L1_FULL': ['LightGBM_r94_BAG_L1_FULL'],\n",
       "  'CatBoost_r128_BAG_L1_FULL': ['CatBoost_r128_BAG_L1_FULL'],\n",
       "  'NeuralNetFastAI_r111_BAG_L1_FULL': ['NeuralNetFastAI_r111_BAG_L1_FULL'],\n",
       "  'NeuralNetFastAI_r65_BAG_L1_FULL': ['NeuralNetFastAI_r65_BAG_L1_FULL'],\n",
       "  'NeuralNetFastAI_r88_BAG_L1_FULL': ['NeuralNetFastAI_r88_BAG_L1_FULL'],\n",
       "  'LightGBM_r30_BAG_L1_FULL': ['LightGBM_r30_BAG_L1_FULL'],\n",
       "  'XGBoost_r49_BAG_L1_FULL': ['XGBoost_r49_BAG_L1_FULL'],\n",
       "  'CatBoost_r5_BAG_L1_FULL': ['CatBoost_r5_BAG_L1_FULL'],\n",
       "  'CatBoost_r143_BAG_L1_FULL': ['CatBoost_r143_BAG_L1_FULL'],\n",
       "  'XGBoost_r31_BAG_L1_FULL': ['XGBoost_r31_BAG_L1_FULL'],\n",
       "  'NeuralNetFastAI_r160_BAG_L1_FULL': ['NeuralNetFastAI_r160_BAG_L1_FULL'],\n",
       "  'CatBoost_r60_BAG_L1_FULL': ['CatBoost_r60_BAG_L1_FULL'],\n",
       "  'LightGBM_r135_BAG_L1_FULL': ['LightGBM_r135_BAG_L1_FULL'],\n",
       "  'WeightedEnsemble_L2_FULL': ['WeightedEnsemble_L2_FULL'],\n",
       "  'LightGBMXT_BAG_L2_FULL': ['LightGBMXT_BAG_L2_FULL'],\n",
       "  'LightGBM_BAG_L2_FULL': ['LightGBM_BAG_L2_FULL'],\n",
       "  'CatBoost_BAG_L2_FULL': ['CatBoost_BAG_L2_FULL'],\n",
       "  'NeuralNetFastAI_BAG_L2_FULL': ['NeuralNetFastAI_BAG_L2_FULL'],\n",
       "  'XGBoost_BAG_L2_FULL': ['XGBoost_BAG_L2_FULL'],\n",
       "  'LightGBMLarge_BAG_L2_FULL': ['LightGBMLarge_BAG_L2_FULL'],\n",
       "  'CatBoost_r177_BAG_L2_FULL': ['CatBoost_r177_BAG_L2_FULL'],\n",
       "  'LightGBM_r131_BAG_L2_FULL': ['LightGBM_r131_BAG_L2_FULL'],\n",
       "  'NeuralNetFastAI_r191_BAG_L2_FULL': ['NeuralNetFastAI_r191_BAG_L2_FULL'],\n",
       "  'CatBoost_r9_BAG_L2_FULL': ['CatBoost_r9_BAG_L2_FULL'],\n",
       "  'LightGBM_r96_BAG_L2_FULL': ['LightGBM_r96_BAG_L2_FULL'],\n",
       "  'XGBoost_r33_BAG_L2_FULL': ['XGBoost_r33_BAG_L2_FULL'],\n",
       "  'CatBoost_r137_BAG_L2_FULL': ['CatBoost_r137_BAG_L2_FULL'],\n",
       "  'NeuralNetFastAI_r102_BAG_L2_FULL': ['NeuralNetFastAI_r102_BAG_L2_FULL'],\n",
       "  'CatBoost_r13_BAG_L2_FULL': ['CatBoost_r13_BAG_L2_FULL'],\n",
       "  'LightGBM_r188_BAG_L2_FULL': ['LightGBM_r188_BAG_L2_FULL'],\n",
       "  'NeuralNetFastAI_r145_BAG_L2_FULL': ['NeuralNetFastAI_r145_BAG_L2_FULL'],\n",
       "  'XGBoost_r89_BAG_L2_FULL': ['XGBoost_r89_BAG_L2_FULL'],\n",
       "  'LightGBM_r130_BAG_L2_FULL': ['LightGBM_r130_BAG_L2_FULL'],\n",
       "  'CatBoost_r50_BAG_L2_FULL': ['CatBoost_r50_BAG_L2_FULL'],\n",
       "  'NeuralNetFastAI_r11_BAG_L2_FULL': ['NeuralNetFastAI_r11_BAG_L2_FULL'],\n",
       "  'XGBoost_r194_BAG_L2_FULL': ['XGBoost_r194_BAG_L2_FULL'],\n",
       "  'CatBoost_r69_BAG_L2_FULL': ['CatBoost_r69_BAG_L2_FULL'],\n",
       "  'NeuralNetFastAI_r103_BAG_L2_FULL': ['NeuralNetFastAI_r103_BAG_L2_FULL'],\n",
       "  'LightGBM_r161_BAG_L2_FULL': ['LightGBM_r161_BAG_L2_FULL'],\n",
       "  'NeuralNetFastAI_r143_BAG_L2_FULL': ['NeuralNetFastAI_r143_BAG_L2_FULL'],\n",
       "  'CatBoost_r70_BAG_L2_FULL': ['CatBoost_r70_BAG_L2_FULL'],\n",
       "  'NeuralNetFastAI_r156_BAG_L2_FULL': ['NeuralNetFastAI_r156_BAG_L2_FULL'],\n",
       "  'LightGBM_r196_BAG_L2_FULL': ['LightGBM_r196_BAG_L2_FULL'],\n",
       "  'CatBoost_r167_BAG_L2_FULL': ['CatBoost_r167_BAG_L2_FULL'],\n",
       "  'NeuralNetFastAI_r95_BAG_L2_FULL': ['NeuralNetFastAI_r95_BAG_L2_FULL'],\n",
       "  'XGBoost_r98_BAG_L2_FULL': ['XGBoost_r98_BAG_L2_FULL'],\n",
       "  'LightGBM_r15_BAG_L2_FULL': ['LightGBM_r15_BAG_L2_FULL'],\n",
       "  'CatBoost_r86_BAG_L2_FULL': ['CatBoost_r86_BAG_L2_FULL'],\n",
       "  'NeuralNetFastAI_r37_BAG_L2_FULL': ['NeuralNetFastAI_r37_BAG_L2_FULL'],\n",
       "  'WeightedEnsemble_L3_FULL': ['WeightedEnsemble_L3_FULL']},\n",
       " 'model_fit_times': {'LightGBMXT_BAG_L1': 4.346591472625732,\n",
       "  'LightGBM_BAG_L1': 4.751271963119507,\n",
       "  'CatBoost_BAG_L1': 69.71064758300781,\n",
       "  'NeuralNetFastAI_BAG_L1': 11.417816162109375,\n",
       "  'XGBoost_BAG_L1': 6.22412633895874,\n",
       "  'LightGBMLarge_BAG_L1': 9.541236877441406,\n",
       "  'CatBoost_r177_BAG_L1': 19.008647203445435,\n",
       "  'LightGBM_r131_BAG_L1': 9.197148323059082,\n",
       "  'NeuralNetFastAI_r191_BAG_L1': 20.858163595199585,\n",
       "  'CatBoost_r9_BAG_L1': 158.91118669509888,\n",
       "  'LightGBM_r96_BAG_L1': 10.938354253768921,\n",
       "  'XGBoost_r33_BAG_L1': 27.499619960784912,\n",
       "  'CatBoost_r137_BAG_L1': 68.41004419326782,\n",
       "  'NeuralNetFastAI_r102_BAG_L1': 7.627098798751831,\n",
       "  'CatBoost_r13_BAG_L1': 157.22645688056946,\n",
       "  'LightGBM_r188_BAG_L1': 6.585803747177124,\n",
       "  'NeuralNetFastAI_r145_BAG_L1': 19.72707962989807,\n",
       "  'XGBoost_r89_BAG_L1': 5.5934154987335205,\n",
       "  'LightGBM_r130_BAG_L1': 4.3342812061309814,\n",
       "  'CatBoost_r50_BAG_L1': 47.99841833114624,\n",
       "  'NeuralNetFastAI_r11_BAG_L1': 34.02686834335327,\n",
       "  'XGBoost_r194_BAG_L1': 6.372080087661743,\n",
       "  'CatBoost_r69_BAG_L1': 65.77350544929504,\n",
       "  'NeuralNetFastAI_r103_BAG_L1': 14.394548416137695,\n",
       "  'LightGBM_r161_BAG_L1': 15.627007007598877,\n",
       "  'NeuralNetFastAI_r143_BAG_L1': 10.589227437973022,\n",
       "  'CatBoost_r70_BAG_L1': 75.33379650115967,\n",
       "  'NeuralNetFastAI_r156_BAG_L1': 10.651236534118652,\n",
       "  'LightGBM_r196_BAG_L1': 25.5171480178833,\n",
       "  'CatBoost_r167_BAG_L1': 57.753371715545654,\n",
       "  'NeuralNetFastAI_r95_BAG_L1': 17.06684398651123,\n",
       "  'XGBoost_r98_BAG_L1': 46.827370405197144,\n",
       "  'LightGBM_r15_BAG_L1': 7.994086980819702,\n",
       "  'CatBoost_r86_BAG_L1': 121.55325651168823,\n",
       "  'NeuralNetFastAI_r37_BAG_L1': 15.068809509277344,\n",
       "  'CatBoost_r49_BAG_L1': 16.980326890945435,\n",
       "  'LightGBM_r143_BAG_L1': 13.26525354385376,\n",
       "  'NeuralNetFastAI_r134_BAG_L1': 19.3781259059906,\n",
       "  'LightGBM_r94_BAG_L1': 5.4467689990997314,\n",
       "  'CatBoost_r128_BAG_L1': 81.45639109611511,\n",
       "  'NeuralNetFastAI_r111_BAG_L1': 9.450645446777344,\n",
       "  'NeuralNetFastAI_r65_BAG_L1': 11.045217752456665,\n",
       "  'NeuralNetFastAI_r88_BAG_L1': 9.542047500610352,\n",
       "  'LightGBM_r30_BAG_L1': 12.766691207885742,\n",
       "  'XGBoost_r49_BAG_L1': 10.835276365280151,\n",
       "  'CatBoost_r5_BAG_L1': 19.002113103866577,\n",
       "  'CatBoost_r143_BAG_L1': 24.12954068183899,\n",
       "  'XGBoost_r31_BAG_L1': 26.6667160987854,\n",
       "  'NeuralNetFastAI_r160_BAG_L1': 16.823752880096436,\n",
       "  'CatBoost_r60_BAG_L1': 27.362073183059692,\n",
       "  'LightGBM_r135_BAG_L1': 3.4574482440948486,\n",
       "  'WeightedEnsemble_L2': 0.1294848918914795,\n",
       "  'LightGBMXT_BAG_L2': 3.0637686252593994,\n",
       "  'LightGBM_BAG_L2': 3.7751734256744385,\n",
       "  'CatBoost_BAG_L2': 40.6304497718811,\n",
       "  'NeuralNetFastAI_BAG_L2': 10.753058671951294,\n",
       "  'XGBoost_BAG_L2': 5.20032000541687,\n",
       "  'LightGBMLarge_BAG_L2': 9.116705179214478,\n",
       "  'CatBoost_r177_BAG_L2': 11.316742658615112,\n",
       "  'LightGBM_r131_BAG_L2': 6.06662654876709,\n",
       "  'NeuralNetFastAI_r191_BAG_L2': 20.242416858673096,\n",
       "  'CatBoost_r9_BAG_L2': 113.07599687576294,\n",
       "  'LightGBM_r96_BAG_L2': 2.2790892124176025,\n",
       "  'XGBoost_r33_BAG_L2': 21.53027892112732,\n",
       "  'CatBoost_r137_BAG_L2': 23.25067925453186,\n",
       "  'NeuralNetFastAI_r102_BAG_L2': 8.516049146652222,\n",
       "  'CatBoost_r13_BAG_L2': 45.98500299453735,\n",
       "  'LightGBM_r188_BAG_L2': 4.461994409561157,\n",
       "  'NeuralNetFastAI_r145_BAG_L2': 18.133041858673096,\n",
       "  'XGBoost_r89_BAG_L2': 4.05189323425293,\n",
       "  'LightGBM_r130_BAG_L2': 3.6612815856933594,\n",
       "  'CatBoost_r50_BAG_L2': 24.7903413772583,\n",
       "  'NeuralNetFastAI_r11_BAG_L2': 33.3079776763916,\n",
       "  'XGBoost_r194_BAG_L2': 6.111665725708008,\n",
       "  'CatBoost_r69_BAG_L2': 28.083754777908325,\n",
       "  'NeuralNetFastAI_r103_BAG_L2': 12.614051580429077,\n",
       "  'LightGBM_r161_BAG_L2': 12.504170656204224,\n",
       "  'NeuralNetFastAI_r143_BAG_L2': 10.32223391532898,\n",
       "  'CatBoost_r70_BAG_L2': 50.40219688415527,\n",
       "  'NeuralNetFastAI_r156_BAG_L2': 10.09314227104187,\n",
       "  'LightGBM_r196_BAG_L2': 10.235398530960083,\n",
       "  'CatBoost_r167_BAG_L2': 38.95992588996887,\n",
       "  'NeuralNetFastAI_r95_BAG_L2': 17.237507820129395,\n",
       "  'XGBoost_r98_BAG_L2': 21.40215253829956,\n",
       "  'LightGBM_r15_BAG_L2': 3.974041700363159,\n",
       "  'CatBoost_r86_BAG_L2': 65.90018081665039,\n",
       "  'NeuralNetFastAI_r37_BAG_L2': 13.304816961288452,\n",
       "  'WeightedEnsemble_L3': 0.16632080078125,\n",
       "  'LightGBMXT_BAG_L1_FULL': 0.9515066146850586,\n",
       "  'LightGBM_BAG_L1_FULL': 0.5512495040893555,\n",
       "  'CatBoost_BAG_L1_FULL': 23.59774661064148,\n",
       "  'NeuralNetFastAI_BAG_L1_FULL': 0.9406518936157227,\n",
       "  'XGBoost_BAG_L1_FULL': 0.4485659599304199,\n",
       "  'LightGBMLarge_BAG_L1_FULL': 1.0967817306518555,\n",
       "  'CatBoost_r177_BAG_L1_FULL': 2.3167452812194824,\n",
       "  'LightGBM_r131_BAG_L1_FULL': 1.6999125480651855,\n",
       "  'NeuralNetFastAI_r191_BAG_L1_FULL': 1.114490032196045,\n",
       "  'CatBoost_r9_BAG_L1_FULL': 31.2223539352417,\n",
       "  'LightGBM_r96_BAG_L1_FULL': 1.7420549392700195,\n",
       "  'XGBoost_r33_BAG_L1_FULL': 4.163792133331299,\n",
       "  'CatBoost_r137_BAG_L1_FULL': 24.345964908599854,\n",
       "  'NeuralNetFastAI_r102_BAG_L1_FULL': 0.38671326637268066,\n",
       "  'CatBoost_r13_BAG_L1_FULL': 16.779221296310425,\n",
       "  'LightGBM_r188_BAG_L1_FULL': 1.0749516487121582,\n",
       "  'NeuralNetFastAI_r145_BAG_L1_FULL': 2.177872657775879,\n",
       "  'XGBoost_r89_BAG_L1_FULL': 0.40975356101989746,\n",
       "  'LightGBM_r130_BAG_L1_FULL': 0.5335593223571777,\n",
       "  'CatBoost_r50_BAG_L1_FULL': 11.676720380783081,\n",
       "  'NeuralNetFastAI_r11_BAG_L1_FULL': 9.060885906219482,\n",
       "  'XGBoost_r194_BAG_L1_FULL': 0.4912436008453369,\n",
       "  'CatBoost_r69_BAG_L1_FULL': 19.920912981033325,\n",
       "  'NeuralNetFastAI_r103_BAG_L1_FULL': 0.8428187370300293,\n",
       "  'LightGBM_r161_BAG_L1_FULL': 2.968254327774048,\n",
       "  'NeuralNetFastAI_r143_BAG_L1_FULL': 1.847588062286377,\n",
       "  'CatBoost_r70_BAG_L1_FULL': 17.450674772262573,\n",
       "  'NeuralNetFastAI_r156_BAG_L1_FULL': 1.050898551940918,\n",
       "  'LightGBM_r196_BAG_L1_FULL': 6.519710063934326,\n",
       "  'CatBoost_r167_BAG_L1_FULL': 13.545654058456421,\n",
       "  'NeuralNetFastAI_r95_BAG_L1_FULL': 0.6326258182525635,\n",
       "  'XGBoost_r98_BAG_L1_FULL': 7.83951735496521,\n",
       "  'LightGBM_r15_BAG_L1_FULL': 1.1730704307556152,\n",
       "  'CatBoost_r86_BAG_L1_FULL': 31.35524606704712,\n",
       "  'NeuralNetFastAI_r37_BAG_L1_FULL': 2.0562639236450195,\n",
       "  'CatBoost_r49_BAG_L1_FULL': 3.060636520385742,\n",
       "  'LightGBM_r143_BAG_L1_FULL': 2.3360674381256104,\n",
       "  'NeuralNetFastAI_r134_BAG_L1_FULL': 1.0707237720489502,\n",
       "  'LightGBM_r94_BAG_L1_FULL': 0.7402853965759277,\n",
       "  'CatBoost_r128_BAG_L1_FULL': 8.960421800613403,\n",
       "  'NeuralNetFastAI_r111_BAG_L1_FULL': 1.3424062728881836,\n",
       "  'NeuralNetFastAI_r65_BAG_L1_FULL': 2.439636468887329,\n",
       "  'NeuralNetFastAI_r88_BAG_L1_FULL': 0.39945101737976074,\n",
       "  'LightGBM_r30_BAG_L1_FULL': 2.8818376064300537,\n",
       "  'XGBoost_r49_BAG_L1_FULL': 1.0337095260620117,\n",
       "  'CatBoost_r5_BAG_L1_FULL': 3.541710615158081,\n",
       "  'CatBoost_r143_BAG_L1_FULL': 2.677201986312866,\n",
       "  'XGBoost_r31_BAG_L1_FULL': 3.360509157180786,\n",
       "  'NeuralNetFastAI_r160_BAG_L1_FULL': 7.392131567001343,\n",
       "  'CatBoost_r60_BAG_L1_FULL': 13.637514352798462,\n",
       "  'LightGBM_r135_BAG_L1_FULL': 0.6937282085418701,\n",
       "  'WeightedEnsemble_L2_FULL': 0.1294848918914795,\n",
       "  'LightGBMXT_BAG_L2_FULL': 0.23286771774291992,\n",
       "  'LightGBM_BAG_L2_FULL': 0.23330450057983398,\n",
       "  'CatBoost_BAG_L2_FULL': 4.376702547073364,\n",
       "  'NeuralNetFastAI_BAG_L2_FULL': 0.5567071437835693,\n",
       "  'XGBoost_BAG_L2_FULL': 0.15721821784973145,\n",
       "  'LightGBMLarge_BAG_L2_FULL': 0.5760021209716797,\n",
       "  'CatBoost_r177_BAG_L2_FULL': 0.4772684574127197,\n",
       "  'LightGBM_r131_BAG_L2_FULL': 0.683734655380249,\n",
       "  'NeuralNetFastAI_r191_BAG_L2_FULL': 0.8007452487945557,\n",
       "  'CatBoost_r9_BAG_L2_FULL': 9.181440830230713,\n",
       "  'LightGBM_r96_BAG_L2_FULL': 0.31555676460266113,\n",
       "  'XGBoost_r33_BAG_L2_FULL': 1.6504266262054443,\n",
       "  'CatBoost_r137_BAG_L2_FULL': 3.192587375640869,\n",
       "  'NeuralNetFastAI_r102_BAG_L2_FULL': 0.32354283332824707,\n",
       "  'CatBoost_r13_BAG_L2_FULL': 4.399502992630005,\n",
       "  'LightGBM_r188_BAG_L2_FULL': 0.45652294158935547,\n",
       "  'NeuralNetFastAI_r145_BAG_L2_FULL': 0.6424295902252197,\n",
       "  'XGBoost_r89_BAG_L2_FULL': 0.16123604774475098,\n",
       "  'LightGBM_r130_BAG_L2_FULL': 0.24958252906799316,\n",
       "  'CatBoost_r50_BAG_L2_FULL': 2.1341803073883057,\n",
       "  'NeuralNetFastAI_r11_BAG_L2_FULL': 5.745227813720703,\n",
       "  'XGBoost_r194_BAG_L2_FULL': 0.2065718173980713,\n",
       "  'CatBoost_r69_BAG_L2_FULL': 4.02692985534668,\n",
       "  'NeuralNetFastAI_r103_BAG_L2_FULL': 0.3734884262084961,\n",
       "  'LightGBM_r161_BAG_L2_FULL': 1.595970630645752,\n",
       "  'NeuralNetFastAI_r143_BAG_L2_FULL': 1.3586292266845703,\n",
       "  'CatBoost_r70_BAG_L2_FULL': 5.0350751876831055,\n",
       "  'NeuralNetFastAI_r156_BAG_L2_FULL': 0.784719705581665,\n",
       "  'LightGBM_r196_BAG_L2_FULL': 2.111137628555298,\n",
       "  'CatBoost_r167_BAG_L2_FULL': 2.5325050354003906,\n",
       "  'NeuralNetFastAI_r95_BAG_L2_FULL': 0.63639235496521,\n",
       "  'XGBoost_r98_BAG_L2_FULL': 2.7671802043914795,\n",
       "  'LightGBM_r15_BAG_L2_FULL': 0.39293694496154785,\n",
       "  'CatBoost_r86_BAG_L2_FULL': 7.826212167739868,\n",
       "  'NeuralNetFastAI_r37_BAG_L2_FULL': 0.4592318534851074,\n",
       "  'WeightedEnsemble_L3_FULL': 0.16632080078125},\n",
       " 'model_pred_times': {'LightGBMXT_BAG_L1': 0.23856353759765625,\n",
       "  'LightGBM_BAG_L1': 0.15147709846496582,\n",
       "  'CatBoost_BAG_L1': 0.05622243881225586,\n",
       "  'NeuralNetFastAI_BAG_L1': 0.1755998134613037,\n",
       "  'XGBoost_BAG_L1': 0.11916089057922363,\n",
       "  'LightGBMLarge_BAG_L1': 0.1609935760498047,\n",
       "  'CatBoost_r177_BAG_L1': 0.05754661560058594,\n",
       "  'LightGBM_r131_BAG_L1': 0.44321441650390625,\n",
       "  'NeuralNetFastAI_r191_BAG_L1': 0.21860504150390625,\n",
       "  'CatBoost_r9_BAG_L1': 0.08279109001159668,\n",
       "  'LightGBM_r96_BAG_L1': 1.149961233139038,\n",
       "  'XGBoost_r33_BAG_L1': 0.6324295997619629,\n",
       "  'CatBoost_r137_BAG_L1': 0.060981035232543945,\n",
       "  'NeuralNetFastAI_r102_BAG_L1': 0.1216745376586914,\n",
       "  'CatBoost_r13_BAG_L1': 0.09974455833435059,\n",
       "  'LightGBM_r188_BAG_L1': 0.256267786026001,\n",
       "  'NeuralNetFastAI_r145_BAG_L1': 0.24061107635498047,\n",
       "  'XGBoost_r89_BAG_L1': 0.12661075592041016,\n",
       "  'LightGBM_r130_BAG_L1': 0.14886975288391113,\n",
       "  'CatBoost_r50_BAG_L1': 0.08565163612365723,\n",
       "  'NeuralNetFastAI_r11_BAG_L1': 0.2849724292755127,\n",
       "  'XGBoost_r194_BAG_L1': 0.12242245674133301,\n",
       "  'CatBoost_r69_BAG_L1': 0.05960559844970703,\n",
       "  'NeuralNetFastAI_r103_BAG_L1': 0.20089173316955566,\n",
       "  'LightGBM_r161_BAG_L1': 0.5729949474334717,\n",
       "  'NeuralNetFastAI_r143_BAG_L1': 0.12357020378112793,\n",
       "  'CatBoost_r70_BAG_L1': 0.082489013671875,\n",
       "  'NeuralNetFastAI_r156_BAG_L1': 0.15300631523132324,\n",
       "  'LightGBM_r196_BAG_L1': 3.1822266578674316,\n",
       "  'CatBoost_r167_BAG_L1': 0.10146379470825195,\n",
       "  'NeuralNetFastAI_r95_BAG_L1': 0.21063709259033203,\n",
       "  'XGBoost_r98_BAG_L1': 0.6036829948425293,\n",
       "  'LightGBM_r15_BAG_L1': 0.3914780616760254,\n",
       "  'CatBoost_r86_BAG_L1': 0.08962583541870117,\n",
       "  'NeuralNetFastAI_r37_BAG_L1': 0.14578723907470703,\n",
       "  'CatBoost_r49_BAG_L1': 0.06583690643310547,\n",
       "  'LightGBM_r143_BAG_L1': 0.3859531879425049,\n",
       "  'NeuralNetFastAI_r134_BAG_L1': 0.1961817741394043,\n",
       "  'LightGBM_r94_BAG_L1': 0.3775033950805664,\n",
       "  'CatBoost_r128_BAG_L1': 0.09577131271362305,\n",
       "  'NeuralNetFastAI_r111_BAG_L1': 0.08713030815124512,\n",
       "  'NeuralNetFastAI_r65_BAG_L1': 0.0854499340057373,\n",
       "  'NeuralNetFastAI_r88_BAG_L1': 0.13955116271972656,\n",
       "  'LightGBM_r30_BAG_L1': 0.9909958839416504,\n",
       "  'XGBoost_r49_BAG_L1': 0.2104339599609375,\n",
       "  'CatBoost_r5_BAG_L1': 0.0906670093536377,\n",
       "  'CatBoost_r143_BAG_L1': 0.07431292533874512,\n",
       "  'XGBoost_r31_BAG_L1': 0.8097848892211914,\n",
       "  'NeuralNetFastAI_r160_BAG_L1': 0.2610611915588379,\n",
       "  'CatBoost_r60_BAG_L1': 0.04613995552062988,\n",
       "  'LightGBM_r135_BAG_L1': 0.21979856491088867,\n",
       "  'WeightedEnsemble_L2': 0.0,\n",
       "  'LightGBMXT_BAG_L2': 0.06311368942260742,\n",
       "  'LightGBM_BAG_L2': 0.03888082504272461,\n",
       "  'CatBoost_BAG_L2': 0.03814554214477539,\n",
       "  'NeuralNetFastAI_BAG_L2': 0.19430923461914062,\n",
       "  'XGBoost_BAG_L2': 0.04698538780212402,\n",
       "  'LightGBMLarge_BAG_L2': 0.08260154724121094,\n",
       "  'CatBoost_r177_BAG_L2': 0.0631556510925293,\n",
       "  'LightGBM_r131_BAG_L2': 0.16751694679260254,\n",
       "  'NeuralNetFastAI_r191_BAG_L2': 0.27010679244995117,\n",
       "  'CatBoost_r9_BAG_L2': 0.0806431770324707,\n",
       "  'LightGBM_r96_BAG_L2': 0.129624605178833,\n",
       "  'XGBoost_r33_BAG_L2': 0.12512874603271484,\n",
       "  'CatBoost_r137_BAG_L2': 0.06786513328552246,\n",
       "  'NeuralNetFastAI_r102_BAG_L2': 0.15343761444091797,\n",
       "  'CatBoost_r13_BAG_L2': 0.09078454971313477,\n",
       "  'LightGBM_r188_BAG_L2': 0.11124038696289062,\n",
       "  'NeuralNetFastAI_r145_BAG_L2': 0.24566030502319336,\n",
       "  'XGBoost_r89_BAG_L2': 0.09021496772766113,\n",
       "  'LightGBM_r130_BAG_L2': 0.052227020263671875,\n",
       "  'CatBoost_r50_BAG_L2': 0.06775259971618652,\n",
       "  'NeuralNetFastAI_r11_BAG_L2': 0.3099358081817627,\n",
       "  'XGBoost_r194_BAG_L2': 0.12264895439147949,\n",
       "  'CatBoost_r69_BAG_L2': 0.07371878623962402,\n",
       "  'NeuralNetFastAI_r103_BAG_L2': 0.174576997756958,\n",
       "  'LightGBM_r161_BAG_L2': 0.28319454193115234,\n",
       "  'NeuralNetFastAI_r143_BAG_L2': 0.11742281913757324,\n",
       "  'CatBoost_r70_BAG_L2': 0.0906679630279541,\n",
       "  'NeuralNetFastAI_r156_BAG_L2': 0.1441335678100586,\n",
       "  'LightGBM_r196_BAG_L2': 0.5968761444091797,\n",
       "  'CatBoost_r167_BAG_L2': 0.05935096740722656,\n",
       "  'NeuralNetFastAI_r95_BAG_L2': 0.24878287315368652,\n",
       "  'XGBoost_r98_BAG_L2': 0.24489331245422363,\n",
       "  'LightGBM_r15_BAG_L2': 0.12788748741149902,\n",
       "  'CatBoost_r86_BAG_L2': 0.0685434341430664,\n",
       "  'NeuralNetFastAI_r37_BAG_L2': 0.18427419662475586,\n",
       "  'WeightedEnsemble_L3': 0.0,\n",
       "  'LightGBMXT_BAG_L1_FULL': None,\n",
       "  'LightGBM_BAG_L1_FULL': None,\n",
       "  'CatBoost_BAG_L1_FULL': None,\n",
       "  'NeuralNetFastAI_BAG_L1_FULL': None,\n",
       "  'XGBoost_BAG_L1_FULL': None,\n",
       "  'LightGBMLarge_BAG_L1_FULL': None,\n",
       "  'CatBoost_r177_BAG_L1_FULL': None,\n",
       "  'LightGBM_r131_BAG_L1_FULL': None,\n",
       "  'NeuralNetFastAI_r191_BAG_L1_FULL': None,\n",
       "  'CatBoost_r9_BAG_L1_FULL': None,\n",
       "  'LightGBM_r96_BAG_L1_FULL': None,\n",
       "  'XGBoost_r33_BAG_L1_FULL': None,\n",
       "  'CatBoost_r137_BAG_L1_FULL': None,\n",
       "  'NeuralNetFastAI_r102_BAG_L1_FULL': None,\n",
       "  'CatBoost_r13_BAG_L1_FULL': None,\n",
       "  'LightGBM_r188_BAG_L1_FULL': None,\n",
       "  'NeuralNetFastAI_r145_BAG_L1_FULL': None,\n",
       "  'XGBoost_r89_BAG_L1_FULL': None,\n",
       "  'LightGBM_r130_BAG_L1_FULL': None,\n",
       "  'CatBoost_r50_BAG_L1_FULL': None,\n",
       "  'NeuralNetFastAI_r11_BAG_L1_FULL': None,\n",
       "  'XGBoost_r194_BAG_L1_FULL': None,\n",
       "  'CatBoost_r69_BAG_L1_FULL': None,\n",
       "  'NeuralNetFastAI_r103_BAG_L1_FULL': None,\n",
       "  'LightGBM_r161_BAG_L1_FULL': None,\n",
       "  'NeuralNetFastAI_r143_BAG_L1_FULL': None,\n",
       "  'CatBoost_r70_BAG_L1_FULL': None,\n",
       "  'NeuralNetFastAI_r156_BAG_L1_FULL': None,\n",
       "  'LightGBM_r196_BAG_L1_FULL': None,\n",
       "  'CatBoost_r167_BAG_L1_FULL': None,\n",
       "  'NeuralNetFastAI_r95_BAG_L1_FULL': None,\n",
       "  'XGBoost_r98_BAG_L1_FULL': None,\n",
       "  'LightGBM_r15_BAG_L1_FULL': None,\n",
       "  'CatBoost_r86_BAG_L1_FULL': None,\n",
       "  'NeuralNetFastAI_r37_BAG_L1_FULL': None,\n",
       "  'CatBoost_r49_BAG_L1_FULL': None,\n",
       "  'LightGBM_r143_BAG_L1_FULL': None,\n",
       "  'NeuralNetFastAI_r134_BAG_L1_FULL': None,\n",
       "  'LightGBM_r94_BAG_L1_FULL': None,\n",
       "  'CatBoost_r128_BAG_L1_FULL': None,\n",
       "  'NeuralNetFastAI_r111_BAG_L1_FULL': None,\n",
       "  'NeuralNetFastAI_r65_BAG_L1_FULL': None,\n",
       "  'NeuralNetFastAI_r88_BAG_L1_FULL': None,\n",
       "  'LightGBM_r30_BAG_L1_FULL': None,\n",
       "  'XGBoost_r49_BAG_L1_FULL': None,\n",
       "  'CatBoost_r5_BAG_L1_FULL': None,\n",
       "  'CatBoost_r143_BAG_L1_FULL': None,\n",
       "  'XGBoost_r31_BAG_L1_FULL': None,\n",
       "  'NeuralNetFastAI_r160_BAG_L1_FULL': None,\n",
       "  'CatBoost_r60_BAG_L1_FULL': None,\n",
       "  'LightGBM_r135_BAG_L1_FULL': None,\n",
       "  'WeightedEnsemble_L2_FULL': None,\n",
       "  'LightGBMXT_BAG_L2_FULL': None,\n",
       "  'LightGBM_BAG_L2_FULL': None,\n",
       "  'CatBoost_BAG_L2_FULL': None,\n",
       "  'NeuralNetFastAI_BAG_L2_FULL': None,\n",
       "  'XGBoost_BAG_L2_FULL': None,\n",
       "  'LightGBMLarge_BAG_L2_FULL': None,\n",
       "  'CatBoost_r177_BAG_L2_FULL': None,\n",
       "  'LightGBM_r131_BAG_L2_FULL': None,\n",
       "  'NeuralNetFastAI_r191_BAG_L2_FULL': None,\n",
       "  'CatBoost_r9_BAG_L2_FULL': None,\n",
       "  'LightGBM_r96_BAG_L2_FULL': None,\n",
       "  'XGBoost_r33_BAG_L2_FULL': None,\n",
       "  'CatBoost_r137_BAG_L2_FULL': None,\n",
       "  'NeuralNetFastAI_r102_BAG_L2_FULL': None,\n",
       "  'CatBoost_r13_BAG_L2_FULL': None,\n",
       "  'LightGBM_r188_BAG_L2_FULL': None,\n",
       "  'NeuralNetFastAI_r145_BAG_L2_FULL': None,\n",
       "  'XGBoost_r89_BAG_L2_FULL': None,\n",
       "  'LightGBM_r130_BAG_L2_FULL': None,\n",
       "  'CatBoost_r50_BAG_L2_FULL': None,\n",
       "  'NeuralNetFastAI_r11_BAG_L2_FULL': None,\n",
       "  'XGBoost_r194_BAG_L2_FULL': None,\n",
       "  'CatBoost_r69_BAG_L2_FULL': None,\n",
       "  'NeuralNetFastAI_r103_BAG_L2_FULL': None,\n",
       "  'LightGBM_r161_BAG_L2_FULL': None,\n",
       "  'NeuralNetFastAI_r143_BAG_L2_FULL': None,\n",
       "  'CatBoost_r70_BAG_L2_FULL': None,\n",
       "  'NeuralNetFastAI_r156_BAG_L2_FULL': None,\n",
       "  'LightGBM_r196_BAG_L2_FULL': None,\n",
       "  'CatBoost_r167_BAG_L2_FULL': None,\n",
       "  'NeuralNetFastAI_r95_BAG_L2_FULL': None,\n",
       "  'XGBoost_r98_BAG_L2_FULL': None,\n",
       "  'LightGBM_r15_BAG_L2_FULL': None,\n",
       "  'CatBoost_r86_BAG_L2_FULL': None,\n",
       "  'NeuralNetFastAI_r37_BAG_L2_FULL': None,\n",
       "  'WeightedEnsemble_L3_FULL': None},\n",
       " 'num_bag_folds': 8,\n",
       " 'max_stack_level': 3,\n",
       " 'num_classes': 2,\n",
       " 'model_hyperparams': {'LightGBMXT_BAG_L1': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': False},\n",
       "  'LightGBM_BAG_L1': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': False},\n",
       "  'CatBoost_BAG_L1': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': False},\n",
       "  'NeuralNetFastAI_BAG_L1': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': False},\n",
       "  'XGBoost_BAG_L1': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': False},\n",
       "  'LightGBMLarge_BAG_L1': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': False},\n",
       "  'CatBoost_r177_BAG_L1': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': False},\n",
       "  'LightGBM_r131_BAG_L1': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': False},\n",
       "  'NeuralNetFastAI_r191_BAG_L1': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': False},\n",
       "  'CatBoost_r9_BAG_L1': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': False},\n",
       "  'LightGBM_r96_BAG_L1': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': False},\n",
       "  'XGBoost_r33_BAG_L1': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': False},\n",
       "  'CatBoost_r137_BAG_L1': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': False},\n",
       "  'NeuralNetFastAI_r102_BAG_L1': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': False},\n",
       "  'CatBoost_r13_BAG_L1': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': False},\n",
       "  'LightGBM_r188_BAG_L1': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': False},\n",
       "  'NeuralNetFastAI_r145_BAG_L1': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': False},\n",
       "  'XGBoost_r89_BAG_L1': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': False},\n",
       "  'LightGBM_r130_BAG_L1': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': False},\n",
       "  'CatBoost_r50_BAG_L1': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': False},\n",
       "  'NeuralNetFastAI_r11_BAG_L1': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': False},\n",
       "  'XGBoost_r194_BAG_L1': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': False},\n",
       "  'CatBoost_r69_BAG_L1': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': False},\n",
       "  'NeuralNetFastAI_r103_BAG_L1': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': False},\n",
       "  'LightGBM_r161_BAG_L1': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': False},\n",
       "  'NeuralNetFastAI_r143_BAG_L1': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': False},\n",
       "  'CatBoost_r70_BAG_L1': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': False},\n",
       "  'NeuralNetFastAI_r156_BAG_L1': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': False},\n",
       "  'LightGBM_r196_BAG_L1': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': False},\n",
       "  'CatBoost_r167_BAG_L1': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': False},\n",
       "  'NeuralNetFastAI_r95_BAG_L1': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': False},\n",
       "  'XGBoost_r98_BAG_L1': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': False},\n",
       "  'LightGBM_r15_BAG_L1': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': False},\n",
       "  'CatBoost_r86_BAG_L1': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': False},\n",
       "  'NeuralNetFastAI_r37_BAG_L1': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': False},\n",
       "  'CatBoost_r49_BAG_L1': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': False},\n",
       "  'LightGBM_r143_BAG_L1': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': False},\n",
       "  'NeuralNetFastAI_r134_BAG_L1': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': False},\n",
       "  'LightGBM_r94_BAG_L1': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': False},\n",
       "  'CatBoost_r128_BAG_L1': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': False},\n",
       "  'NeuralNetFastAI_r111_BAG_L1': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': False},\n",
       "  'NeuralNetFastAI_r65_BAG_L1': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': False},\n",
       "  'NeuralNetFastAI_r88_BAG_L1': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': False},\n",
       "  'LightGBM_r30_BAG_L1': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': False},\n",
       "  'XGBoost_r49_BAG_L1': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': False},\n",
       "  'CatBoost_r5_BAG_L1': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': False},\n",
       "  'CatBoost_r143_BAG_L1': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': False},\n",
       "  'XGBoost_r31_BAG_L1': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': False},\n",
       "  'NeuralNetFastAI_r160_BAG_L1': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': False},\n",
       "  'CatBoost_r60_BAG_L1': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': False},\n",
       "  'LightGBM_r135_BAG_L1': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': False},\n",
       "  'WeightedEnsemble_L2': {'use_orig_features': False,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True},\n",
       "  'LightGBMXT_BAG_L2': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': False},\n",
       "  'LightGBM_BAG_L2': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': False},\n",
       "  'CatBoost_BAG_L2': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': False},\n",
       "  'NeuralNetFastAI_BAG_L2': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': False},\n",
       "  'XGBoost_BAG_L2': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': False},\n",
       "  'LightGBMLarge_BAG_L2': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': False},\n",
       "  'CatBoost_r177_BAG_L2': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': False},\n",
       "  'LightGBM_r131_BAG_L2': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': False},\n",
       "  'NeuralNetFastAI_r191_BAG_L2': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': False},\n",
       "  'CatBoost_r9_BAG_L2': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': False},\n",
       "  'LightGBM_r96_BAG_L2': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': False},\n",
       "  'XGBoost_r33_BAG_L2': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': False},\n",
       "  'CatBoost_r137_BAG_L2': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': False},\n",
       "  'NeuralNetFastAI_r102_BAG_L2': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': False},\n",
       "  'CatBoost_r13_BAG_L2': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': False},\n",
       "  'LightGBM_r188_BAG_L2': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': False},\n",
       "  'NeuralNetFastAI_r145_BAG_L2': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': False},\n",
       "  'XGBoost_r89_BAG_L2': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': False},\n",
       "  'LightGBM_r130_BAG_L2': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': False},\n",
       "  'CatBoost_r50_BAG_L2': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': False},\n",
       "  'NeuralNetFastAI_r11_BAG_L2': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': False},\n",
       "  'XGBoost_r194_BAG_L2': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': False},\n",
       "  'CatBoost_r69_BAG_L2': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': False},\n",
       "  'NeuralNetFastAI_r103_BAG_L2': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': False},\n",
       "  'LightGBM_r161_BAG_L2': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': False},\n",
       "  'NeuralNetFastAI_r143_BAG_L2': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': False},\n",
       "  'CatBoost_r70_BAG_L2': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': False},\n",
       "  'NeuralNetFastAI_r156_BAG_L2': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': False},\n",
       "  'LightGBM_r196_BAG_L2': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': False},\n",
       "  'CatBoost_r167_BAG_L2': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': False},\n",
       "  'NeuralNetFastAI_r95_BAG_L2': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': False},\n",
       "  'XGBoost_r98_BAG_L2': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': False},\n",
       "  'LightGBM_r15_BAG_L2': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': False},\n",
       "  'CatBoost_r86_BAG_L2': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': False},\n",
       "  'NeuralNetFastAI_r37_BAG_L2': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': False},\n",
       "  'WeightedEnsemble_L3': {'use_orig_features': False,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True},\n",
       "  'LightGBMXT_BAG_L1_FULL': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True},\n",
       "  'LightGBM_BAG_L1_FULL': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True},\n",
       "  'CatBoost_BAG_L1_FULL': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True},\n",
       "  'NeuralNetFastAI_BAG_L1_FULL': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True},\n",
       "  'XGBoost_BAG_L1_FULL': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True},\n",
       "  'LightGBMLarge_BAG_L1_FULL': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True},\n",
       "  'CatBoost_r177_BAG_L1_FULL': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True},\n",
       "  'LightGBM_r131_BAG_L1_FULL': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True},\n",
       "  'NeuralNetFastAI_r191_BAG_L1_FULL': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True},\n",
       "  'CatBoost_r9_BAG_L1_FULL': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True},\n",
       "  'LightGBM_r96_BAG_L1_FULL': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True},\n",
       "  'XGBoost_r33_BAG_L1_FULL': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True},\n",
       "  'CatBoost_r137_BAG_L1_FULL': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True},\n",
       "  'NeuralNetFastAI_r102_BAG_L1_FULL': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True},\n",
       "  'CatBoost_r13_BAG_L1_FULL': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True},\n",
       "  'LightGBM_r188_BAG_L1_FULL': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True},\n",
       "  'NeuralNetFastAI_r145_BAG_L1_FULL': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True},\n",
       "  'XGBoost_r89_BAG_L1_FULL': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True},\n",
       "  'LightGBM_r130_BAG_L1_FULL': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True},\n",
       "  'CatBoost_r50_BAG_L1_FULL': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True},\n",
       "  'NeuralNetFastAI_r11_BAG_L1_FULL': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True},\n",
       "  'XGBoost_r194_BAG_L1_FULL': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True},\n",
       "  'CatBoost_r69_BAG_L1_FULL': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True},\n",
       "  'NeuralNetFastAI_r103_BAG_L1_FULL': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True},\n",
       "  'LightGBM_r161_BAG_L1_FULL': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True},\n",
       "  'NeuralNetFastAI_r143_BAG_L1_FULL': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True},\n",
       "  'CatBoost_r70_BAG_L1_FULL': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True},\n",
       "  'NeuralNetFastAI_r156_BAG_L1_FULL': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True},\n",
       "  'LightGBM_r196_BAG_L1_FULL': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True},\n",
       "  'CatBoost_r167_BAG_L1_FULL': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True},\n",
       "  'NeuralNetFastAI_r95_BAG_L1_FULL': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True},\n",
       "  'XGBoost_r98_BAG_L1_FULL': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True},\n",
       "  'LightGBM_r15_BAG_L1_FULL': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True},\n",
       "  'CatBoost_r86_BAG_L1_FULL': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True},\n",
       "  'NeuralNetFastAI_r37_BAG_L1_FULL': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True},\n",
       "  'CatBoost_r49_BAG_L1_FULL': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True},\n",
       "  'LightGBM_r143_BAG_L1_FULL': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True},\n",
       "  'NeuralNetFastAI_r134_BAG_L1_FULL': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True},\n",
       "  'LightGBM_r94_BAG_L1_FULL': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True},\n",
       "  'CatBoost_r128_BAG_L1_FULL': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True},\n",
       "  'NeuralNetFastAI_r111_BAG_L1_FULL': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True},\n",
       "  'NeuralNetFastAI_r65_BAG_L1_FULL': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True},\n",
       "  'NeuralNetFastAI_r88_BAG_L1_FULL': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True},\n",
       "  'LightGBM_r30_BAG_L1_FULL': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True},\n",
       "  'XGBoost_r49_BAG_L1_FULL': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True},\n",
       "  'CatBoost_r5_BAG_L1_FULL': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True},\n",
       "  'CatBoost_r143_BAG_L1_FULL': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True},\n",
       "  'XGBoost_r31_BAG_L1_FULL': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True},\n",
       "  'NeuralNetFastAI_r160_BAG_L1_FULL': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True},\n",
       "  'CatBoost_r60_BAG_L1_FULL': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True},\n",
       "  'LightGBM_r135_BAG_L1_FULL': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True},\n",
       "  'WeightedEnsemble_L2_FULL': {'use_orig_features': False,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True},\n",
       "  'LightGBMXT_BAG_L2_FULL': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True},\n",
       "  'LightGBM_BAG_L2_FULL': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True},\n",
       "  'CatBoost_BAG_L2_FULL': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True},\n",
       "  'NeuralNetFastAI_BAG_L2_FULL': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True},\n",
       "  'XGBoost_BAG_L2_FULL': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True},\n",
       "  'LightGBMLarge_BAG_L2_FULL': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True},\n",
       "  'CatBoost_r177_BAG_L2_FULL': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True},\n",
       "  'LightGBM_r131_BAG_L2_FULL': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True},\n",
       "  'NeuralNetFastAI_r191_BAG_L2_FULL': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True},\n",
       "  'CatBoost_r9_BAG_L2_FULL': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True},\n",
       "  'LightGBM_r96_BAG_L2_FULL': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True},\n",
       "  'XGBoost_r33_BAG_L2_FULL': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True},\n",
       "  'CatBoost_r137_BAG_L2_FULL': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True},\n",
       "  'NeuralNetFastAI_r102_BAG_L2_FULL': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True},\n",
       "  'CatBoost_r13_BAG_L2_FULL': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True},\n",
       "  'LightGBM_r188_BAG_L2_FULL': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True},\n",
       "  'NeuralNetFastAI_r145_BAG_L2_FULL': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True},\n",
       "  'XGBoost_r89_BAG_L2_FULL': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True},\n",
       "  'LightGBM_r130_BAG_L2_FULL': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True},\n",
       "  'CatBoost_r50_BAG_L2_FULL': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True},\n",
       "  'NeuralNetFastAI_r11_BAG_L2_FULL': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True},\n",
       "  'XGBoost_r194_BAG_L2_FULL': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True},\n",
       "  'CatBoost_r69_BAG_L2_FULL': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True},\n",
       "  'NeuralNetFastAI_r103_BAG_L2_FULL': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True},\n",
       "  'LightGBM_r161_BAG_L2_FULL': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True},\n",
       "  'NeuralNetFastAI_r143_BAG_L2_FULL': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True},\n",
       "  'CatBoost_r70_BAG_L2_FULL': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True},\n",
       "  'NeuralNetFastAI_r156_BAG_L2_FULL': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True},\n",
       "  'LightGBM_r196_BAG_L2_FULL': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True},\n",
       "  'CatBoost_r167_BAG_L2_FULL': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True},\n",
       "  'NeuralNetFastAI_r95_BAG_L2_FULL': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True},\n",
       "  'XGBoost_r98_BAG_L2_FULL': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True},\n",
       "  'LightGBM_r15_BAG_L2_FULL': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True},\n",
       "  'CatBoost_r86_BAG_L2_FULL': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True},\n",
       "  'NeuralNetFastAI_r37_BAG_L2_FULL': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True},\n",
       "  'WeightedEnsemble_L3_FULL': {'use_orig_features': False,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True}},\n",
       " 'leaderboard':                          model  score_val eval_metric  pred_time_val  \\\n",
       " 0          WeightedEnsemble_L2   0.911074     roc_auc       2.897264   \n",
       " 1          WeightedEnsemble_L3   0.911033     roc_auc       3.299675   \n",
       " 2         CatBoost_r137_BAG_L2   0.910302     roc_auc       3.064874   \n",
       " 3          CatBoost_r70_BAG_L2   0.910039     roc_auc       3.087677   \n",
       " 4          CatBoost_r13_BAG_L2   0.909949     roc_auc       3.087793   \n",
       " ..                         ...        ...         ...            ...   \n",
       " 171  CatBoost_r137_BAG_L2_FULL        NaN     roc_auc            NaN   \n",
       " 172  CatBoost_r137_BAG_L1_FULL        NaN     roc_auc            NaN   \n",
       " 173  CatBoost_r128_BAG_L1_FULL        NaN     roc_auc            NaN   \n",
       " 174       CatBoost_BAG_L2_FULL        NaN     roc_auc            NaN   \n",
       " 175       CatBoost_BAG_L1_FULL        NaN     roc_auc            NaN   \n",
       " \n",
       "        fit_time  pred_time_val_marginal  fit_time_marginal  stack_level  \\\n",
       " 0    146.529078                0.000000           0.129485            2   \n",
       " 1    387.538390                0.000000           0.166321            3   \n",
       " 2    326.876730                0.067865          23.250679            2   \n",
       " 3    354.028247                0.090668          50.402197            2   \n",
       " 4    349.611053                0.090785          45.985003            2   \n",
       " ..          ...                     ...                ...          ...   \n",
       " 171   59.100690                     NaN           3.192587            2   \n",
       " 172   24.345965                     NaN          24.345965            1   \n",
       " 173    8.960422                     NaN           8.960422            1   \n",
       " 174   60.284806                     NaN           4.376703            2   \n",
       " 175   23.597747                     NaN          23.597747            1   \n",
       " \n",
       "      can_infer  fit_order  \n",
       " 0        False         52  \n",
       " 1        False         88  \n",
       " 2        False         65  \n",
       " 3        False         79  \n",
       " 4        False         67  \n",
       " ..         ...        ...  \n",
       " 171       True        153  \n",
       " 172       True        101  \n",
       " 173       True        128  \n",
       " 174       True        143  \n",
       " 175       True         91  \n",
       " \n",
       " [176 rows x 10 columns]}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.fit_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "auxiliary_metrics = ['accuracy', 'balanced_accuracy', 'f1', 'f1_macro', 'f1_micro', 'roc_auc', 'average_precision', 'precision', 'recall', 'log_loss', 'pac_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluation: roc_auc on test data: 0.9305451725949125\n",
      "Evaluations on test data:\n",
      "{\n",
      "    \"roc_auc\": 0.9305451725949125,\n",
      "    \"accuracy\": 0.8583333333333333,\n",
      "    \"balanced_accuracy\": 0.8589171027510136,\n",
      "    \"mcc\": 0.7181935608411317,\n",
      "    \"f1\": 0.859504132231405,\n",
      "    \"precision\": 0.8346709470304976,\n",
      "    \"recall\": 0.8858603066439523\n",
      "}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'roc_auc': 0.9305451725949125,\n",
       " 'accuracy': 0.8583333333333333,\n",
       " 'balanced_accuracy': 0.8589171027510136,\n",
       " 'mcc': 0.7181935608411317,\n",
       " 'f1': 0.859504132231405,\n",
       " 'precision': 0.8346709470304976,\n",
       " 'recall': 0.8858603066439523}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.evaluate(\n",
    "    df_test,\n",
    "    silent = False,\n",
    "    auxiliary_metrics = auxiliary_metrics\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'WeightedEnsemble_L2_FULL'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.model_best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictors = predictor.leaderboard(\n",
    "    df_test,\n",
    "    extra_metrics = auxiliary_metrics,\n",
    "    extra_info=True,\n",
    "    silent=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>roc_auc</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>balanced_accuracy</th>\n",
       "      <th>f1</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>num_features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.931482</td>\n",
       "      <td>0.860833</td>\n",
       "      <td>0.861328</td>\n",
       "      <td>0.861411</td>\n",
       "      <td>0.839806</td>\n",
       "      <td>0.884157</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.931468</td>\n",
       "      <td>0.858333</td>\n",
       "      <td>0.858917</td>\n",
       "      <td>0.859504</td>\n",
       "      <td>0.834671</td>\n",
       "      <td>0.885860</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.930545</td>\n",
       "      <td>0.858333</td>\n",
       "      <td>0.858917</td>\n",
       "      <td>0.859504</td>\n",
       "      <td>0.834671</td>\n",
       "      <td>0.885860</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.930526</td>\n",
       "      <td>0.855000</td>\n",
       "      <td>0.855365</td>\n",
       "      <td>0.854758</td>\n",
       "      <td>0.837971</td>\n",
       "      <td>0.872232</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.930503</td>\n",
       "      <td>0.857500</td>\n",
       "      <td>0.858101</td>\n",
       "      <td>0.858794</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.885860</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>176 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      roc_auc  accuracy  balanced_accuracy        f1  precision    recall  \\\n",
       "0    0.931482  0.860833           0.861328  0.861411   0.839806  0.884157   \n",
       "1    0.931468  0.858333           0.858917  0.859504   0.834671  0.885860   \n",
       "2    0.930545  0.858333           0.858917  0.859504   0.834671  0.885860   \n",
       "3    0.930526  0.855000           0.855365  0.854758   0.837971  0.872232   \n",
       "4    0.930503  0.857500           0.858101  0.858794   0.833333  0.885860   \n",
       "..        ...       ...                ...       ...        ...       ...   \n",
       "171       NaN       NaN                NaN       NaN        NaN       NaN   \n",
       "172       NaN       NaN                NaN       NaN        NaN       NaN   \n",
       "173       NaN       NaN                NaN       NaN        NaN       NaN   \n",
       "174       NaN       NaN                NaN       NaN        NaN       NaN   \n",
       "175       NaN       NaN                NaN       NaN        NaN       NaN   \n",
       "\n",
       "     num_features  \n",
       "0              90  \n",
       "1              90  \n",
       "2               7  \n",
       "3              90  \n",
       "4               3  \n",
       "..            ...  \n",
       "171            82  \n",
       "172            82  \n",
       "173            82  \n",
       "174            82  \n",
       "175            82  \n",
       "\n",
       "[176 rows x 7 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictors[['roc_auc', 'accuracy', 'balanced_accuracy', 'f1', 'precision', 'recall', 'num_features']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "These features in provided data are not utilized by the predictor and will be ignored: ['clin-Covid_sintomaSarpullido']\n",
      "Computing feature importance via permutation shuffling for 75 features using 4800 rows with 5 shuffle sets...\n",
      "\t305.5s\t= Expected runtime (61.1s per shuffle set)\n",
      "\t222.35s\t= Actual runtime (Completed 5 of 5 shuffle sets)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>importance</th>\n",
       "      <th>stddev</th>\n",
       "      <th>p_value</th>\n",
       "      <th>n</th>\n",
       "      <th>p99_high</th>\n",
       "      <th>p99_low</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>eval-TLP-Stroop-palabrasColor-PD</th>\n",
       "      <td>1.066962e-02</td>\n",
       "      <td>4.488318e-04</td>\n",
       "      <td>3.748834e-07</td>\n",
       "      <td>5</td>\n",
       "      <td>1.159377e-02</td>\n",
       "      <td>9.745468e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eval-TLP-Stroop-palabras-PD</th>\n",
       "      <td>8.031937e-03</td>\n",
       "      <td>4.375546e-04</td>\n",
       "      <td>1.052719e-06</td>\n",
       "      <td>5</td>\n",
       "      <td>8.932868e-03</td>\n",
       "      <td>7.131006e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>demo-fechaNacimiento</th>\n",
       "      <td>6.812891e-03</td>\n",
       "      <td>4.072885e-04</td>\n",
       "      <td>1.525448e-06</td>\n",
       "      <td>5</td>\n",
       "      <td>7.651504e-03</td>\n",
       "      <td>5.974278e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eval-TLP-CubCorsi-totalDirectos-PD</th>\n",
       "      <td>4.655345e-03</td>\n",
       "      <td>4.493189e-04</td>\n",
       "      <td>1.028531e-05</td>\n",
       "      <td>5</td>\n",
       "      <td>5.580499e-03</td>\n",
       "      <td>3.730191e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eval-TLP-Tavec-7_Rg_Rc-PD</th>\n",
       "      <td>4.270716e-03</td>\n",
       "      <td>5.531067e-04</td>\n",
       "      <td>3.301897e-05</td>\n",
       "      <td>5</td>\n",
       "      <td>5.409570e-03</td>\n",
       "      <td>3.131861e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ques-MMSE-concentracion-PD</th>\n",
       "      <td>8.906511e-05</td>\n",
       "      <td>7.010527e-06</td>\n",
       "      <td>4.568506e-06</td>\n",
       "      <td>5</td>\n",
       "      <td>1.034999e-04</td>\n",
       "      <td>7.463034e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ques-MMSE-orientacion-PD</th>\n",
       "      <td>8.288438e-05</td>\n",
       "      <td>3.936201e-05</td>\n",
       "      <td>4.625060e-03</td>\n",
       "      <td>5</td>\n",
       "      <td>1.639313e-04</td>\n",
       "      <td>1.837446e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>clin-cardiopatiaIsquemica</th>\n",
       "      <td>7.944678e-05</td>\n",
       "      <td>1.813047e-05</td>\n",
       "      <td>3.040476e-04</td>\n",
       "      <td>5</td>\n",
       "      <td>1.167777e-04</td>\n",
       "      <td>4.211589e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ques-MMSE-lenguaje-PD</th>\n",
       "      <td>1.677133e-05</td>\n",
       "      <td>1.242515e-05</td>\n",
       "      <td>1.961592e-02</td>\n",
       "      <td>5</td>\n",
       "      <td>4.235488e-05</td>\n",
       "      <td>-8.812226e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ques-MMSE-fijacion-PD</th>\n",
       "      <td>1.041697e-07</td>\n",
       "      <td>2.329306e-07</td>\n",
       "      <td>1.869505e-01</td>\n",
       "      <td>5</td>\n",
       "      <td>5.837770e-07</td>\n",
       "      <td>-3.754376e-07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>75 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      importance        stddev       p_value  \\\n",
       "eval-TLP-Stroop-palabrasColor-PD    1.066962e-02  4.488318e-04  3.748834e-07   \n",
       "eval-TLP-Stroop-palabras-PD         8.031937e-03  4.375546e-04  1.052719e-06   \n",
       "demo-fechaNacimiento                6.812891e-03  4.072885e-04  1.525448e-06   \n",
       "eval-TLP-CubCorsi-totalDirectos-PD  4.655345e-03  4.493189e-04  1.028531e-05   \n",
       "eval-TLP-Tavec-7_Rg_Rc-PD           4.270716e-03  5.531067e-04  3.301897e-05   \n",
       "...                                          ...           ...           ...   \n",
       "ques-MMSE-concentracion-PD          8.906511e-05  7.010527e-06  4.568506e-06   \n",
       "ques-MMSE-orientacion-PD            8.288438e-05  3.936201e-05  4.625060e-03   \n",
       "clin-cardiopatiaIsquemica           7.944678e-05  1.813047e-05  3.040476e-04   \n",
       "ques-MMSE-lenguaje-PD               1.677133e-05  1.242515e-05  1.961592e-02   \n",
       "ques-MMSE-fijacion-PD               1.041697e-07  2.329306e-07  1.869505e-01   \n",
       "\n",
       "                                    n      p99_high       p99_low  \n",
       "eval-TLP-Stroop-palabrasColor-PD    5  1.159377e-02  9.745468e-03  \n",
       "eval-TLP-Stroop-palabras-PD         5  8.932868e-03  7.131006e-03  \n",
       "demo-fechaNacimiento                5  7.651504e-03  5.974278e-03  \n",
       "eval-TLP-CubCorsi-totalDirectos-PD  5  5.580499e-03  3.730191e-03  \n",
       "eval-TLP-Tavec-7_Rg_Rc-PD           5  5.409570e-03  3.131861e-03  \n",
       "...                                ..           ...           ...  \n",
       "ques-MMSE-concentracion-PD          5  1.034999e-04  7.463034e-05  \n",
       "ques-MMSE-orientacion-PD            5  1.639313e-04  1.837446e-06  \n",
       "clin-cardiopatiaIsquemica           5  1.167777e-04  4.211589e-05  \n",
       "ques-MMSE-lenguaje-PD               5  4.235488e-05 -8.812226e-06  \n",
       "ques-MMSE-fijacion-PD               5  5.837770e-07 -3.754376e-07  \n",
       "\n",
       "[75 rows x 6 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.feature_importance(data=df_train)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
