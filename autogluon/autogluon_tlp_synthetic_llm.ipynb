{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from autogluon.tabular import TabularPredictor\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../../data/tlp/llm.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_columns = [\n",
    "    'ISC.resultadosCovid.numDosis',\n",
    "    'ISC.resultadosCovid.numVecesCovid',\n",
    "    'ISC.resultadosCovid.numVecesCovid_mode',\n",
    "    'ISC.resultadosCovid.pasadoCovid',\n",
    "    'ISC.resultadosCovid.sentimientoAislado',\n",
    "    'ISC.resultadosCovid.sentimientoAislado_mediaFiltro',\n",
    "    'ISC.resultadosCovid.sentimientoAislado_mode',\n",
    "    'ISC.resultadosCovid.sintomaCansancio',\n",
    "    'ISC.resultadosCovid.sintomaDiarrea',\n",
    "    'ISC.resultadosCovid.sintomaDifRespirar',\n",
    "    'ISC.resultadosCovid.sintomaDolCabeza',\n",
    "    'ISC.resultadosCovid.sintomaDolGarganta',\n",
    "    'ISC.resultadosCovid.sintomaDolMuscular',\n",
    "    'ISC.resultadosCovid.sintomaEscalofrios',\n",
    "    'ISC.resultadosCovid.sintomaFiebre',\n",
    "    'ISC.resultadosCovid.sintomaOtro',\n",
    "    'ISC.resultadosCovid.sintomaOtroString',\n",
    "    'ISC.resultadosCovid.sintomaPerGusto',\n",
    "    'ISC.resultadosCovid.sintomaPerOlfato',\n",
    "    'ISC.resultadosCovid.vacunado',\n",
    "    'ISC.resultadosObservacion.añosSinFumar',\n",
    "    'ISC.resultadosObservacion.añosSinFumar_Rangos',\n",
    "    'ISC.resultadosObservacion.consumoAlcohol_UBEsemanal',\n",
    "    'ISC.resultadosObservacion.consumoAlcohol_UBEsemanal_knn',\n",
    "    'ISC.resultadosObservacion.consumoAlcohol_UBEsemanal_mode&rangoEdad',\n",
    "    'ISC.resultadosObservacion.enfermedadesAltTiroides',\n",
    "    'ISC.resultadosObservacion.enfermedadesAntecedentesCardiacos',\n",
    "    'ISC.resultadosObservacion.enfermedadesCardiopatiaIsquemica',\n",
    "    'ISC.resultadosObservacion.enfermedadesHepatica',\n",
    "    'ISC.resultadosObservacion.enfermedadesNinguna',\n",
    "    'ISC.resultadosObservacion.enfermedadesOtros',\n",
    "    'ISC.resultadosObservacion.enfermedadesRenal',\n",
    "    'ISC.resultadosObservacion.entorno',\n",
    "    'ISC.resultadosObservacion.familiaresAlzheimer',\n",
    "    'ISC.resultadosObservacion.familiaresOtraDemencia',\n",
    "    'ISC.resultadosObservacion.fumador',\n",
    "    'ISC.resultadosObservacion.numCigarros',\n",
    "    'ISC.resultadosObservacion.numCigarrosDia_knn',\n",
    "    'ISC.resultadosObservacion.numCigarrosDia_mode&rangoEdad',\n",
    "    'ISC.resultadosObservacion.tratCronico',\n",
    "    'ISC.resultadosObservacion.tratPsicologic',\n",
    "    'ISC.resultadosObservacion.tratPsiquiatrico',\n",
    "    'ISC.resultadosOtros.frecOlvidos',\n",
    "    'ISC.resultadosOtros.frecUsoEmail',\n",
    "    'ISC.resultadosOtros.frecUsoMovil',\n",
    "    'ISC.resultadosOtros.frecUsoOrdenador',\n",
    "    'ISC.resultadosOtros.frecUsoRSociales',\n",
    "    'ISC.resultadosOtros.frecUsoTele',\n",
    "    'ISC.resultadosOtros.nivelActFisica',\n",
    "    'ISC.resultadosOtros.nivelSociabilidad',\n",
    "    'ISC.resultadosReservaCognitiva.actividadLectora',\n",
    "    'ISC.resultadosReservaCognitiva.cursos',\n",
    "    'ISC.resultadosReservaCognitiva.escolaridadPadres',\n",
    "    'ISC.resultadosReservaCognitiva.formacionMusical',\n",
    "    'ISC.resultadosReservaCognitiva.juegos'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pt_columns = [column for column in df.columns if 'PT' in column ]\n",
    "pz_columns = [column for column in df.columns if 'PZ' in column ]\n",
    "pdc_columns = [column for column in df.columns if 'PDC' in column]\n",
    "drop_columns.extend(pt_columns)\n",
    "drop_columns.extend(pz_columns)\n",
    "drop_columns.extend(pdc_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ED_2Clases</th>\n",
       "      <th>ISC.FPacientes.genero</th>\n",
       "      <th>ISC.FPacientes.Edad</th>\n",
       "      <th>ISC.resultadosCribaje.Total.PD</th>\n",
       "      <th>ISC.resultadosObservacion.alcohol</th>\n",
       "      <th>ISC.resultadosObservacion.ansiedad</th>\n",
       "      <th>ISC.resultadosObservacion.depresion</th>\n",
       "      <th>ISC.resultadosObservacion.enfermedadesDiabetes</th>\n",
       "      <th>ISC.resultadosObservacion.enfermedadesHipercolesterolemia</th>\n",
       "      <th>ISC.resultadosObservacion.enfermedadesHipertension</th>\n",
       "      <th>...</th>\n",
       "      <th>TLP.Tavec.23_FP.PD</th>\n",
       "      <th>TLP.Tavec.24_Discriminabilidad.PD</th>\n",
       "      <th>TLP.Tavec.25_Sesgo.PD</th>\n",
       "      <th>TLP.Tavec.26_RI-B_frente_RI-A1.PD</th>\n",
       "      <th>TLP.Tavec.27_RL-CP_frente_RI-A5.PD</th>\n",
       "      <th>TLP.Tavec.28_RCl-Cp_frente_RCl-LP.PD</th>\n",
       "      <th>TLP.Tavec.29_RL-LP_frente_RL-CP.PD</th>\n",
       "      <th>TLP.Tavec.30_RCl-LP_frente_RL-LP.PD</th>\n",
       "      <th>TLP.Tavec.31_Recon-Ac_frente_RL-LP.PD</th>\n",
       "      <th>TLP.Tavec.32_Recon-Ac_frente_RCl-LP.PD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>D</td>\n",
       "      <td>2</td>\n",
       "      <td>82</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>84.090909</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>-20.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>33.333333</td>\n",
       "      <td>37.500000</td>\n",
       "      <td>-33.333333</td>\n",
       "      <td>-38.461538</td>\n",
       "      <td>-7.692308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D</td>\n",
       "      <td>2</td>\n",
       "      <td>75</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>79.545455</td>\n",
       "      <td>-0.333333</td>\n",
       "      <td>-71.428571</td>\n",
       "      <td>12.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-20.000000</td>\n",
       "      <td>-20.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>H</td>\n",
       "      <td>2</td>\n",
       "      <td>72</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>88.636364</td>\n",
       "      <td>-0.600000</td>\n",
       "      <td>-14.285714</td>\n",
       "      <td>75.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>-20.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-16.666667</td>\n",
       "      <td>-16.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>D</td>\n",
       "      <td>2</td>\n",
       "      <td>60</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>90.909091</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>16.666667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>-20.000000</td>\n",
       "      <td>-50.000000</td>\n",
       "      <td>-37.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>D</td>\n",
       "      <td>2</td>\n",
       "      <td>64</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>86.363636</td>\n",
       "      <td>-0.714286</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-33.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-10.000000</td>\n",
       "      <td>-10.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 68 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  ED_2Clases  ISC.FPacientes.genero  ISC.FPacientes.Edad  \\\n",
       "0          D                      2                   82   \n",
       "1          D                      2                   75   \n",
       "2          H                      2                   72   \n",
       "3          D                      2                   60   \n",
       "4          D                      2                   64   \n",
       "\n",
       "   ISC.resultadosCribaje.Total.PD  ISC.resultadosObservacion.alcohol  \\\n",
       "0                              16                                  0   \n",
       "1                              16                                  0   \n",
       "2                              14                                  0   \n",
       "3                              11                                  0   \n",
       "4                              14                                  0   \n",
       "\n",
       "   ISC.resultadosObservacion.ansiedad  ISC.resultadosObservacion.depresion  \\\n",
       "0                                   0                                    1   \n",
       "1                                   1                                    1   \n",
       "2                                   0                                    0   \n",
       "3                                   0                                    0   \n",
       "4                                   0                                    0   \n",
       "\n",
       "   ISC.resultadosObservacion.enfermedadesDiabetes  \\\n",
       "0                                               1   \n",
       "1                                               0   \n",
       "2                                               0   \n",
       "3                                               0   \n",
       "4                                               0   \n",
       "\n",
       "   ISC.resultadosObservacion.enfermedadesHipercolesterolemia  \\\n",
       "0                                                  1           \n",
       "1                                                  0           \n",
       "2                                                  0           \n",
       "3                                                  0           \n",
       "4                                                  0           \n",
       "\n",
       "   ISC.resultadosObservacion.enfermedadesHipertension  ...  \\\n",
       "0                                                  0   ...   \n",
       "1                                                  0   ...   \n",
       "2                                                  0   ...   \n",
       "3                                                  0   ...   \n",
       "4                                                  0   ...   \n",
       "\n",
       "   TLP.Tavec.23_FP.PD  TLP.Tavec.24_Discriminabilidad.PD  \\\n",
       "0                   4                          84.090909   \n",
       "1                   3                          79.545455   \n",
       "2                   1                          88.636364   \n",
       "3                   4                          90.909091   \n",
       "4                   0                          86.363636   \n",
       "\n",
       "   TLP.Tavec.25_Sesgo.PD  TLP.Tavec.26_RI-B_frente_RI-A1.PD  \\\n",
       "0               0.142857                         -20.000000   \n",
       "1              -0.333333                         -71.428571   \n",
       "2              -0.600000                         -14.285714   \n",
       "3               0.600000                          60.000000   \n",
       "4              -0.714286                           0.000000   \n",
       "\n",
       "   TLP.Tavec.27_RL-CP_frente_RI-A5.PD  TLP.Tavec.28_RCl-Cp_frente_RCl-LP.PD  \\\n",
       "0                            0.000000                             33.333333   \n",
       "1                           12.500000                              0.000000   \n",
       "2                           75.000000                             25.000000   \n",
       "3                           16.666667                              0.000000   \n",
       "4                           66.666667                              0.000000   \n",
       "\n",
       "   TLP.Tavec.29_RL-LP_frente_RL-CP.PD  TLP.Tavec.30_RCl-LP_frente_RL-LP.PD  \\\n",
       "0                           37.500000                           -33.333333   \n",
       "1                            0.000000                             0.000000   \n",
       "2                          -20.000000                             0.000000   \n",
       "3                           50.000000                           -20.000000   \n",
       "4                          -33.333333                             0.000000   \n",
       "\n",
       "   TLP.Tavec.31_Recon-Ac_frente_RL-LP.PD  \\\n",
       "0                             -38.461538   \n",
       "1                             -20.000000   \n",
       "2                             -16.666667   \n",
       "3                             -50.000000   \n",
       "4                             -10.000000   \n",
       "\n",
       "   TLP.Tavec.32_Recon-Ac_frente_RCl-LP.PD  \n",
       "0                               -7.692308  \n",
       "1                              -20.000000  \n",
       "2                              -16.666667  \n",
       "3                              -37.500000  \n",
       "4                              -10.000000  \n",
       "\n",
       "[5 rows x 68 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop(columns=drop_columns, inplace=True)\n",
    "df.replace([np.inf, -np.inf], 0, inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((376, 68), (94, 68))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train, df_test = train_test_split(df, test_size=0.2, random_state=42)\n",
    "df_train.shape, df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"AutogluonModels/synthetic/llm/v1\"\n"
     ]
    }
   ],
   "source": [
    "predictor= TabularPredictor(\n",
    "    label='ED_2Clases',\n",
    "    problem_type='binary',\n",
    "    eval_metric='roc_auc',\n",
    "    sample_weight='balance_weight',\n",
    "    path='AutogluonModels/synthetic/llm/v1'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.2\n",
      "Python Version:     3.10.2\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.26100\n",
      "CPU Count:          12\n",
      "Memory Avail:       10.26 GB / 15.94 GB (64.4%)\n",
      "Disk Space Avail:   117.59 GB / 446.36 GB (26.3%)\n",
      "===================================================\n",
      "Presets specified: ['high_quality']\n",
      "Setting dynamic_stacking from 'auto' to True. Reason: Enable dynamic_stacking when use_bag_holdout is disabled. (use_bag_holdout=False)\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=1\n",
      "Note: `save_bag_folds=False`! This will greatly reduce peak disk usage during fit (by ~8x), but runs the risk of an out-of-memory error during model refit if memory is small relative to the data size.\n",
      "\tYou can avoid this risk by setting `save_bag_folds=True`.\n",
      "DyStack is enabled (dynamic_stacking=True). AutoGluon will try to determine whether the input data is affected by stacked overfitting and enable or disable stacking as a consequence.\n",
      "\tThis is used to identify the optimal `num_stack_levels` value. Copies of AutoGluon will be fit on subsets of the data. Then holdout validation data is used to detect stacked overfitting.\n",
      "\tRunning DyStack for up to 225s of the 900s of remaining time (25%).\n",
      "\tRunning DyStack sub-fit in a ray process to avoid memory leakage. Enabling ray logging (enable_ray_logging=True). Specify `ds_args={'enable_ray_logging': False}` if you experience logging issues.\n",
      "2025-01-26 23:54:15,901\tINFO worker.py:1743 -- Started a local Ray instance. View the dashboard at \u001b[1m\u001b[32m127.0.0.1:8265 \u001b[39m\u001b[22m\n",
      "\t\tContext path: \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\autogluon\\tlp\\AutogluonModels\\synthetic\\llm\\v1\\ds_sub_fit\\sub_fit_ho\"\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m Running DyStack sub-fit ...\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m Using predefined sample weighting strategy: balance_weight. Evaluation metrics will ignore sample weights, specify weight_evaluation=True to instead report weighted metrics.\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m Beginning AutoGluon training ... Time limit = 220s\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m AutoGluon will save models to \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\autogluon\\tlp\\AutogluonModels\\synthetic\\llm\\v1\\ds_sub_fit\\sub_fit_ho\"\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m Train Data Rows:    334\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m Train Data Columns: 67\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m Label Column:       ED_2Clases\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m Problem Type:       binary\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m Preprocessing data ...\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m Selected class <--> label mapping:  class 1 = H, class 0 = D\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m \tNote: For your binary classification, AutoGluon arbitrarily selected which label-value represents positive (H) vs negative (D) class.\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m \tTo explicitly set the positive_class, either rename classes to 1 and 0, or specify positive_class in Predictor init.\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m Assigning sample weights to balance differences in frequency of classes.\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m Using Feature Generators to preprocess the data ...\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m Fitting AutoMLPipelineFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m \tAvailable Memory:                    9935.27 MB\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m \tTrain Data (Original)  Memory Usage: 0.17 MB (0.0% of available memory)\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m \tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m \tStage 1 Generators:\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m \t\tFitting AsTypeFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m \t\t\tNote: Converting 8 features to boolean dtype as they only contain 2 unique values.\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m \tStage 2 Generators:\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m \t\tFitting FillNaFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m \tStage 3 Generators:\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m \t\tFitting IdentityFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m \tStage 4 Generators:\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m \t\tFitting DropUniqueFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m \tStage 5 Generators:\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m \t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m \tTypes of features in original data (raw dtype, special dtypes):\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m \t\t('float', []) : 15 | ['TLP.FigRey.Copia.PD', 'TLP.FigRey.Memoria.PD', 'TLP.Stroop.interferencia.PD', 'TLP.Tavec.04_Rg-Pr.PD', 'TLP.Tavec.05_Rg-Md.PD', ...]\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m \t\t('int', [])   : 52 | ['ISC.FPacientes.genero', 'ISC.FPacientes.Edad', 'ISC.resultadosCribaje.Total.PD', 'ISC.resultadosObservacion.alcohol', 'ISC.resultadosObservacion.ansiedad', ...]\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m \tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m \t\t('float', [])     : 15 | ['TLP.FigRey.Copia.PD', 'TLP.FigRey.Memoria.PD', 'TLP.Stroop.interferencia.PD', 'TLP.Tavec.04_Rg-Pr.PD', 'TLP.Tavec.05_Rg-Md.PD', ...]\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m \t\t('int', [])       : 44 | ['ISC.FPacientes.Edad', 'ISC.resultadosCribaje.Total.PD', 'ISC.resultadosReservaCognitiva.Total.PD', 'ISC.resultadosReservaCognitiva.escolaridad', 'ISC.resultadosReservaCognitiva.idiomas', ...]\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m \t\t('int', ['bool']) :  8 | ['ISC.FPacientes.genero', 'ISC.resultadosObservacion.alcohol', 'ISC.resultadosObservacion.ansiedad', 'ISC.resultadosObservacion.depresion', 'ISC.resultadosObservacion.enfermedadesDiabetes', ...]\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m \t0.1s = Fit runtime\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m \t67 features in original data used to generate 67 features in processed data.\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m \tTrain Data (Processed) Memory Usage: 0.15 MB (0.0% of available memory)\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m Data preprocessing and feature engineering runtime = 0.07s ...\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m AutoGluon will gauge predictive performance using evaluation metric: 'roc_auc'\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m \tThis metric expects predicted probabilities rather than predicted class labels, so you'll need to use predict_proba() instead of predict()\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m \tTo change this, specify the eval_metric parameter of Predictor()\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m Large model count detected (112 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m User-specified model hyperparameters to be fit:\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m {\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m \t'NN_TORCH': [{}, {'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2}}, {'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7}}],\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m \t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m \t'CAT': [{}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5}}],\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m \t'XGB': [{}, {'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'name_suffix': '_r33', 'priority': -8}}, {'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'name_suffix': '_r89', 'priority': -16}}],\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m \t'FASTAI': [{}, {'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4}}, {'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11}}],\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m \t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m \t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m \t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m }\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m Excluded models: ['XT', 'RF', 'KNN'] (Specified by `excluded_model_types`)\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m Fitting 90 L1 models, fit_strategy=\"sequential\" ...\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 146.80s of the 220.24s of remaining time.\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.14%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=8568)\u001b[0m [1000]\tvalid_set's binary_logloss: 0.30616\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_dystack pid=7432)\u001b[0m \t0.9061\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m \t1.63s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m \t0.03s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m Fitting model: LightGBM_BAG_L1 ... Training model for up to 139.47s of the 212.90s of remaining time.\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.15%)\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m \t0.9105\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m \t1.02s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m \t0.01s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m Fitting model: CatBoost_BAG_L1 ... Training model for up to 134.63s of the 208.06s of remaining time.\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.31%)\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m \t0.9283\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m \t21.77s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m \t0.03s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 109.35s of the 182.78s of remaining time.\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.02%)\n",
      "\u001b[36m(_ray_fit pid=14320)\u001b[0m No improvement since epoch 7: early stopping\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m \t0.8994\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m \t5.66s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m \t0.07s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m Fitting model: XGBoost_BAG_L1 ... Training model for up to 100.44s of the 173.88s of remaining time.\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.40%)\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m \t0.912\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m \t6.83s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m \t0.05s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m Fitting model: NeuralNetTorch_BAG_L1 ... Training model for up to 89.40s of the 162.84s of remaining time.\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.01%)\n",
      "\u001b[36m(_ray_fit pid=20484)\u001b[0m No improvement since epoch 8: early stopping\u001b[32m [repeated 2x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/ray-logging.html#log-deduplication for more options.)\u001b[0m\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m \tWarning: Exception caused NeuralNetTorch_BAG_L1 to fail during training... Skipping this model.\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m \t\t\u001b[36mray::_ray_fit()\u001b[39m (pid=8616, ip=127.0.0.1)\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m   File \"python\\ray\\_raylet.pyx\", line 1889, in ray._raylet.execute_task\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m     fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m     out = self._fit(**kwargs)\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 201, in _fit\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m     train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m     dataset = self._process_train_data(\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m     self.processor = create_preprocessor(\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\utils\\data_preprocessor.py\", line 40, in create_preprocessor\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m     return ColumnTransformer(\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m Detailed Traceback:\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 2106, in _train_and_save\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m     model = self._train_single(**model_fit_kwargs)\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 1993, in _train_single\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m     model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m     out = self._fit(**kwargs)\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\stacker_ensemble_model.py\", line 270, in _fit\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m     return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\bagged_ensemble_model.py\", line 298, in _fit\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m     self._fit_folds(\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\bagged_ensemble_model.py\", line 724, in _fit_folds\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m     fold_fitting_strategy.after_all_folds_scheduled()\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 690, in after_all_folds_scheduled\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m     self._run_parallel(X, y, X_pseudo, y_pseudo, model_base_ref, time_limit_fold, head_node_id)\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 631, in _run_parallel\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m     self._process_fold_results(finished, unfinished, fold_ctx)\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 587, in _process_fold_results\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m     raise processed_exception\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 550, in _process_fold_results\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m     fold_model, pred_proba, time_start_fit, time_end_fit, predict_time, predict_1_time, predict_n_size, fit_num_cpus, fit_num_gpus = self.ray.get(finished)\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m     return fn(*args, **kwargs)\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\client_mode_hook.py\", line 103, in wrapper\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m     return func(*args, **kwargs)\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\worker.py\", line 2667, in get\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m     values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\worker.py\", line 864, in get_objects\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m     raise value.as_instanceof_cause()\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m ray.exceptions.RayTaskError(TypeError): \u001b[36mray::_ray_fit()\u001b[39m (pid=8616, ip=127.0.0.1)\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m   File \"python\\ray\\_raylet.pyx\", line 1889, in ray._raylet.execute_task\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m     fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m     out = self._fit(**kwargs)\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 201, in _fit\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m     train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m     dataset = self._process_train_data(\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m     self.processor = create_preprocessor(\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\utils\\data_preprocessor.py\", line 40, in create_preprocessor\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m     return ColumnTransformer(\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m Fitting model: LightGBMLarge_BAG_L1 ... Training model for up to 82.90s of the 156.34s of remaining time.\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.72%)\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m \t0.891\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m \t1.64s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m \t0.02s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m Fitting model: CatBoost_r177_BAG_L1 ... Training model for up to 77.81s of the 151.25s of remaining time.\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.35%)\n",
      "\u001b[36m(_ray_fit pid=27208)\u001b[0m \tRan out of time, early stopping on iteration 6116.\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m \t0.9154\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m \t62.32s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m \t0.04s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m Fitting model: NeuralNetTorch_r79_BAG_L1 ... Training model for up to 11.77s of the 85.21s of remaining time.\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.01%)\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m \tWarning: Exception caused NeuralNetTorch_r79_BAG_L1 to fail during training... Skipping this model.\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m \t\t\u001b[36mray::_ray_fit()\u001b[39m (pid=11248, ip=127.0.0.1)\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m   File \"python\\ray\\_raylet.pyx\", line 1889, in ray._raylet.execute_task\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m     fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m     out = self._fit(**kwargs)\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 201, in _fit\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m     train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m     dataset = self._process_train_data(\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m     self.processor = create_preprocessor(\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\utils\\data_preprocessor.py\", line 40, in create_preprocessor\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m     return ColumnTransformer(\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m Detailed Traceback:\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 2106, in _train_and_save\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m     model = self._train_single(**model_fit_kwargs)\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 1993, in _train_single\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m     model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m     out = self._fit(**kwargs)\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\stacker_ensemble_model.py\", line 270, in _fit\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m     return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\bagged_ensemble_model.py\", line 298, in _fit\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m     self._fit_folds(\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\bagged_ensemble_model.py\", line 724, in _fit_folds\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m     fold_fitting_strategy.after_all_folds_scheduled()\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 690, in after_all_folds_scheduled\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m     self._run_parallel(X, y, X_pseudo, y_pseudo, model_base_ref, time_limit_fold, head_node_id)\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 631, in _run_parallel\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m     self._process_fold_results(finished, unfinished, fold_ctx)\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 587, in _process_fold_results\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m     raise processed_exception\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 550, in _process_fold_results\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m     fold_model, pred_proba, time_start_fit, time_end_fit, predict_time, predict_1_time, predict_n_size, fit_num_cpus, fit_num_gpus = self.ray.get(finished)\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m     return fn(*args, **kwargs)\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\client_mode_hook.py\", line 103, in wrapper\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m     return func(*args, **kwargs)\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\worker.py\", line 2667, in get\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m     values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\worker.py\", line 864, in get_objects\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m     raise value.as_instanceof_cause()\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m ray.exceptions.RayTaskError(TypeError): \u001b[36mray::_ray_fit()\u001b[39m (pid=11248, ip=127.0.0.1)\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m   File \"python\\ray\\_raylet.pyx\", line 1889, in ray._raylet.execute_task\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m     fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m     out = self._fit(**kwargs)\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 201, in _fit\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m     train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m     dataset = self._process_train_data(\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m     self.processor = create_preprocessor(\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\utils\\data_preprocessor.py\", line 40, in create_preprocessor\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m     return ColumnTransformer(\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m Fitting model: LightGBM_r131_BAG_L1 ... Training model for up to 4.98s of the 78.42s of remaining time.\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.36%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=6200)\u001b[0m [1000]\tvalid_set's binary_logloss: 0.347338\n",
      "\u001b[36m(_ray_fit pid=19356)\u001b[0m [1000]\tvalid_set's binary_logloss: 0.222005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_dystack pid=7432)\u001b[0m \t0.9081\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m \t2.52s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m \t0.02s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m Fitting model: WeightedEnsemble_L2 ... Training model for up to 220.25s of the 72.29s of remaining time.\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m \tEnsemble Weights: {'CatBoost_BAG_L1': 0.571, 'NeuralNetFastAI_BAG_L1': 0.214, 'XGBoost_BAG_L1': 0.214}\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m \t0.9343\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m \t0.03s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m \t0.0s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m Excluded models: ['XT', 'RF', 'KNN'] (Specified by `excluded_model_types`)\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m Fitting 90 L2 models, fit_strategy=\"sequential\" ...\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m Fitting model: LightGBMXT_BAG_L2 ... Training model for up to 72.26s of the 72.22s of remaining time.\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.21%)\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m \t0.9292\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m \t0.94s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m \t0.02s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m Fitting model: LightGBM_BAG_L2 ... Training model for up to 67.60s of the 67.55s of remaining time.\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.24%)\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m \t0.9174\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m \t0.8s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m \t0.03s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m Fitting model: CatBoost_BAG_L2 ... Training model for up to 63.05s of the 63.01s of remaining time.\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.49%)\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m \t0.9274\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m \t6.75s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m \t0.04s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m Fitting model: NeuralNetFastAI_BAG_L2 ... Training model for up to 52.53s of the 52.49s of remaining time.\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.03%)\n",
      "\u001b[36m(_ray_fit pid=21052)\u001b[0m No improvement since epoch 7: early stopping\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m \t0.9111\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m \t5.89s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m \t0.11s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m Fitting model: XGBoost_BAG_L2 ... Training model for up to 43.13s of the 43.09s of remaining time.\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.66%)\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m \t0.9156\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m \t1.21s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m \t0.04s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m Fitting model: NeuralNetTorch_BAG_L2 ... Training model for up to 37.43s of the 37.39s of remaining time.\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.02%)\n",
      "\u001b[36m(_ray_fit pid=13572)\u001b[0m No improvement since epoch 9: early stopping\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m \tWarning: Exception caused NeuralNetTorch_BAG_L2 to fail during training... Skipping this model.\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m \t\t\u001b[36mray::_ray_fit()\u001b[39m (pid=8288, ip=127.0.0.1)\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m   File \"python\\ray\\_raylet.pyx\", line 1889, in ray._raylet.execute_task\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m     fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m     out = self._fit(**kwargs)\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 201, in _fit\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m     train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m     dataset = self._process_train_data(\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m     self.processor = create_preprocessor(\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\utils\\data_preprocessor.py\", line 40, in create_preprocessor\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m     return ColumnTransformer(\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m Detailed Traceback:\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 2106, in _train_and_save\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m     model = self._train_single(**model_fit_kwargs)\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 1993, in _train_single\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m     model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m     out = self._fit(**kwargs)\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\stacker_ensemble_model.py\", line 270, in _fit\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m     return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\bagged_ensemble_model.py\", line 298, in _fit\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m     self._fit_folds(\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\bagged_ensemble_model.py\", line 724, in _fit_folds\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m     fold_fitting_strategy.after_all_folds_scheduled()\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 690, in after_all_folds_scheduled\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m     self._run_parallel(X, y, X_pseudo, y_pseudo, model_base_ref, time_limit_fold, head_node_id)\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 631, in _run_parallel\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m     self._process_fold_results(finished, unfinished, fold_ctx)\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 587, in _process_fold_results\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m     raise processed_exception\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 550, in _process_fold_results\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m     fold_model, pred_proba, time_start_fit, time_end_fit, predict_time, predict_1_time, predict_n_size, fit_num_cpus, fit_num_gpus = self.ray.get(finished)\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m     return fn(*args, **kwargs)\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\client_mode_hook.py\", line 103, in wrapper\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m     return func(*args, **kwargs)\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\worker.py\", line 2667, in get\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m     values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\worker.py\", line 864, in get_objects\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m     raise value.as_instanceof_cause()\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m ray.exceptions.RayTaskError(TypeError): \u001b[36mray::_ray_fit()\u001b[39m (pid=8288, ip=127.0.0.1)\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m   File \"python\\ray\\_raylet.pyx\", line 1889, in ray._raylet.execute_task\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m     fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m     out = self._fit(**kwargs)\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 201, in _fit\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m     train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m     dataset = self._process_train_data(\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m     self.processor = create_preprocessor(\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\utils\\data_preprocessor.py\", line 40, in create_preprocessor\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m     return ColumnTransformer(\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m Fitting model: LightGBMLarge_BAG_L2 ... Training model for up to 30.09s of the 30.04s of remaining time.\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=1.21%)\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m \t0.883\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m \t1.62s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m \t0.02s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m Fitting model: CatBoost_r177_BAG_L2 ... Training model for up to 24.95s of the 24.90s of remaining time.\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.73%)\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m \t0.9278\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m \t6.73s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m \t0.06s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m Fitting model: NeuralNetTorch_r79_BAG_L2 ... Training model for up to 14.33s of the 14.29s of remaining time.\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.02%)\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m \tWarning: Exception caused NeuralNetTorch_r79_BAG_L2 to fail during training... Skipping this model.\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m \t\t\u001b[36mray::_ray_fit()\u001b[39m (pid=26560, ip=127.0.0.1)\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m   File \"python\\ray\\_raylet.pyx\", line 1889, in ray._raylet.execute_task\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m     fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m     out = self._fit(**kwargs)\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 201, in _fit\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m     train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m     dataset = self._process_train_data(\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m     self.processor = create_preprocessor(\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\utils\\data_preprocessor.py\", line 40, in create_preprocessor\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m     return ColumnTransformer(\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m Detailed Traceback:\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 2106, in _train_and_save\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m     model = self._train_single(**model_fit_kwargs)\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 1993, in _train_single\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m     model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m     out = self._fit(**kwargs)\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\stacker_ensemble_model.py\", line 270, in _fit\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m     return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\bagged_ensemble_model.py\", line 298, in _fit\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m     self._fit_folds(\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\bagged_ensemble_model.py\", line 724, in _fit_folds\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m     fold_fitting_strategy.after_all_folds_scheduled()\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 690, in after_all_folds_scheduled\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m     self._run_parallel(X, y, X_pseudo, y_pseudo, model_base_ref, time_limit_fold, head_node_id)\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 631, in _run_parallel\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m     self._process_fold_results(finished, unfinished, fold_ctx)\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 587, in _process_fold_results\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m     raise processed_exception\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 550, in _process_fold_results\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m     fold_model, pred_proba, time_start_fit, time_end_fit, predict_time, predict_1_time, predict_n_size, fit_num_cpus, fit_num_gpus = self.ray.get(finished)\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m     return fn(*args, **kwargs)\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\client_mode_hook.py\", line 103, in wrapper\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m     return func(*args, **kwargs)\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\worker.py\", line 2667, in get\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m     values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\worker.py\", line 864, in get_objects\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m     raise value.as_instanceof_cause()\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m ray.exceptions.RayTaskError(TypeError): \u001b[36mray::_ray_fit()\u001b[39m (pid=26560, ip=127.0.0.1)\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m   File \"python\\ray\\_raylet.pyx\", line 1889, in ray._raylet.execute_task\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m     fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m     out = self._fit(**kwargs)\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 201, in _fit\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m     train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m     dataset = self._process_train_data(\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m     self.processor = create_preprocessor(\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m   File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\utils\\data_preprocessor.py\", line 40, in create_preprocessor\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m     return ColumnTransformer(\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m Fitting model: LightGBM_r131_BAG_L2 ... Training model for up to 7.25s of the 7.21s of remaining time.\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.93%)\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m \t0.9212\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m \t1.34s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m \t0.03s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m Fitting model: WeightedEnsemble_L3 ... Training model for up to 220.25s of the 1.71s of remaining time.\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m \tEnsemble Weights: {'LightGBMXT_BAG_L2': 0.455, 'CatBoost_BAG_L1': 0.364, 'NeuralNetFastAI_BAG_L2': 0.182}\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m \t0.933\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m \t0.03s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m \t0.0s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m AutoGluon training complete, total runtime = 218.66s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 281.0 rows/s (42 batch size)\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m Automatically performing refit_full as a post-fit operation (due to `.fit(..., refit_full=True)`\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m Refitting models via `predictor.refit_full` using all of the data (combined train and validation)...\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m \tModels trained in this way will have the suffix \"_FULL\" and have NaN validation score.\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m \tThis process is not bound by time_limit, but should take less time than the original `predictor.fit` call.\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m \tTo learn more, refer to the `.refit_full` method docstring which explains how \"_FULL\" models differ from normal models.\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m Fitting model: LightGBMXT_BAG_L1_FULL ...\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m \t0.36s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m Fitting model: LightGBM_BAG_L1_FULL ...\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m \t0.12s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m Fitting model: CatBoost_BAG_L1_FULL ...\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m \t2.07s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m Fitting model: NeuralNetFastAI_BAG_L1_FULL ...\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m \tStopping at the best epoch learned earlier - 10.\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m \t0.46s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m Fitting model: XGBoost_BAG_L1_FULL ...\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m \t0.44s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m Fitting model: LightGBMLarge_BAG_L1_FULL ...\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m \t0.25s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m Fitting model: CatBoost_r177_BAG_L1_FULL ...\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m \t2.54s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m Fitting model: LightGBM_r131_BAG_L1_FULL ...\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m \t0.31s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m Fitting model: WeightedEnsemble_L2_FULL | Skipping fit via cloning parent ...\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m \tEnsemble Weights: {'CatBoost_BAG_L1': 0.571, 'NeuralNetFastAI_BAG_L1': 0.214, 'XGBoost_BAG_L1': 0.214}\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m \t0.03s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m Fitting 1 L2 models, fit_strategy=\"sequential\" ...\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m Fitting model: LightGBMXT_BAG_L2_FULL ...\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m \t0.12s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m Fitting 1 L2 models, fit_strategy=\"sequential\" ...\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m Fitting model: LightGBM_BAG_L2_FULL ...\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m \t0.11s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m Fitting 1 L2 models, fit_strategy=\"sequential\" ...\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m Fitting model: CatBoost_BAG_L2_FULL ...\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m \t0.41s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m Fitting 1 L2 models, fit_strategy=\"sequential\" ...\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m Fitting model: NeuralNetFastAI_BAG_L2_FULL ...\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m \tStopping at the best epoch learned earlier - 9.\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m \t0.3s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m Fitting 1 L2 models, fit_strategy=\"sequential\" ...\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m Fitting model: XGBoost_BAG_L2_FULL ...\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m \t0.06s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m Fitting 1 L2 models, fit_strategy=\"sequential\" ...\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m Fitting model: LightGBMLarge_BAG_L2_FULL ...\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m \t0.18s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m Fitting 1 L2 models, fit_strategy=\"sequential\" ...\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m Fitting model: CatBoost_r177_BAG_L2_FULL ...\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m \t0.26s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m Fitting 1 L2 models, fit_strategy=\"sequential\" ...\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m Fitting model: LightGBM_r131_BAG_L2_FULL ...\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m \t0.17s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m Fitting model: WeightedEnsemble_L3_FULL | Skipping fit via cloning parent ...\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m \tEnsemble Weights: {'LightGBMXT_BAG_L2': 0.455, 'CatBoost_BAG_L1': 0.364, 'NeuralNetFastAI_BAG_L2': 0.182}\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m \t0.03s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m Updated best model to \"WeightedEnsemble_L2_FULL\" (Previously \"WeightedEnsemble_L2\"). AutoGluon will default to using \"WeightedEnsemble_L2_FULL\" for predict() and predict_proba().\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m Refit complete, total runtime = 10.23s ... Best model: \"WeightedEnsemble_L2_FULL\"\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\autogluon\\tlp\\AutogluonModels\\synthetic\\llm\\v1\\ds_sub_fit\\sub_fit_ho\")\n",
      "\u001b[36m(_dystack pid=7432)\u001b[0m Deleting DyStack predictor artifacts (clean_up_fits=True) ...\n",
      "Leaderboard on holdout data (DyStack):\n",
      "                          model  score_holdout  score_val eval_metric  pred_time_test pred_time_val  fit_time  pred_time_test_marginal pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
      "0           XGBoost_BAG_L2_FULL       0.927438   0.915555     roc_auc        0.181024          None  3.137087                 0.034439                   None           0.057386            2       True         14\n",
      "1        LightGBMXT_BAG_L2_FULL       0.920635   0.929181     roc_auc        0.169030          None  3.196512                 0.022445                   None           0.116811            2       True         10\n",
      "2     LightGBMLarge_BAG_L2_FULL       0.913832   0.883032     roc_auc        0.177225          None  3.258391                 0.030639                   None           0.178690            2       True         15\n",
      "3          CatBoost_BAG_L2_FULL       0.904762   0.927424     roc_auc        0.166484          None  3.485070                 0.019899                   None           0.405369            2       True         12\n",
      "4          LightGBM_BAG_L2_FULL       0.891156   0.917420     roc_auc        0.164550          None  3.191911                 0.017965                   None           0.112210            2       True         11\n",
      "5      WeightedEnsemble_L3_FULL       0.891156   0.933018     roc_auc        0.208184          None  3.522928                 0.011024                   None           0.029373            3       True         18\n",
      "6          CatBoost_BAG_L1_FULL       0.886621   0.928285     roc_auc        0.014234          None  2.069492                 0.014234                   None           2.069492            1       True          3\n",
      "7     LightGBM_r131_BAG_L2_FULL       0.886621   0.921185     roc_auc        0.179472          None  3.245119                 0.032887                   None           0.165418            2       True         17\n",
      "8     CatBoost_r177_BAG_L2_FULL       0.882086   0.927818     roc_auc        0.169499          None  3.343707                 0.022913                   None           0.264005            2       True         16\n",
      "9     CatBoost_r177_BAG_L1_FULL       0.875283   0.915448     roc_auc        0.018840          None  2.537881                 0.018840                   None           2.537881            1       True          7\n",
      "10     WeightedEnsemble_L2_FULL       0.873016   0.934309     roc_auc        0.106812          None  2.989778                 0.011276                   None           0.025686            2       True          9\n",
      "11         LightGBM_BAG_L1_FULL       0.873016   0.910499     roc_auc        0.051050          None  0.115609                 0.051050                   None           0.115609            1       True          2\n",
      "12    LightGBM_r131_BAG_L1_FULL       0.863946   0.908133     roc_auc        0.046502          None  0.308162                 0.046502                   None           0.308162            1       True          8\n",
      "13  NeuralNetFastAI_BAG_L2_FULL       0.859410   0.911109     roc_auc        0.174716          None  3.376744                 0.028130                   None           0.297043            2       True         13\n",
      "14          XGBoost_BAG_L1_FULL       0.857143   0.912005     roc_auc        0.049296          None  0.435618                 0.049296                   None           0.435618            1       True          5\n",
      "15    LightGBMLarge_BAG_L1_FULL       0.834467   0.890993     roc_auc        0.031150          None  0.246542                 0.031150                   None           0.246542            1       True          6\n",
      "16  NeuralNetFastAI_BAG_L1_FULL       0.827664   0.899419     roc_auc        0.032006          None  0.458982                 0.032006                   None           0.458982            1       True          4\n",
      "17       LightGBMXT_BAG_L1_FULL       0.823129   0.906089     roc_auc        0.025751          None  0.362932                 0.025751                   None           0.362932            1       True          1\n",
      "\t1\t = Optimal   num_stack_levels (Stacked Overfitting Occurred: False)\n",
      "\t236s\t = DyStack   runtime |\t664s\t = Remaining runtime\n",
      "Starting main fit with num_stack_levels=1.\n",
      "\tFor future fit calls on this dataset, you can skip DyStack to save time: `predictor.fit(..., dynamic_stacking=False, num_stack_levels=1)`\n",
      "Using predefined sample weighting strategy: balance_weight. Evaluation metrics will ignore sample weights, specify weight_evaluation=True to instead report weighted metrics.\n",
      "Beginning AutoGluon training ... Time limit = 664s\n",
      "AutoGluon will save models to \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\autogluon\\tlp\\AutogluonModels\\synthetic\\llm\\v1\"\n",
      "Train Data Rows:    376\n",
      "Train Data Columns: 67\n",
      "Label Column:       ED_2Clases\n",
      "Problem Type:       binary\n",
      "Preprocessing data ...\n",
      "Selected class <--> label mapping:  class 1 = H, class 0 = D\n",
      "\tNote: For your binary classification, AutoGluon arbitrarily selected which label-value represents positive (H) vs negative (D) class.\n",
      "\tTo explicitly set the positive_class, either rename classes to 1 and 0, or specify positive_class in Predictor init.\n",
      "Assigning sample weights to balance differences in frequency of classes.\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    2805.25 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.19 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 8 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 15 | ['TLP.FigRey.Copia.PD', 'TLP.FigRey.Memoria.PD', 'TLP.Stroop.interferencia.PD', 'TLP.Tavec.04_Rg-Pr.PD', 'TLP.Tavec.05_Rg-Md.PD', ...]\n",
      "\t\t('int', [])   : 52 | ['ISC.FPacientes.genero', 'ISC.FPacientes.Edad', 'ISC.resultadosCribaje.Total.PD', 'ISC.resultadosObservacion.alcohol', 'ISC.resultadosObservacion.ansiedad', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', [])     : 15 | ['TLP.FigRey.Copia.PD', 'TLP.FigRey.Memoria.PD', 'TLP.Stroop.interferencia.PD', 'TLP.Tavec.04_Rg-Pr.PD', 'TLP.Tavec.05_Rg-Md.PD', ...]\n",
      "\t\t('int', [])       : 44 | ['ISC.FPacientes.Edad', 'ISC.resultadosCribaje.Total.PD', 'ISC.resultadosReservaCognitiva.Total.PD', 'ISC.resultadosReservaCognitiva.escolaridad', 'ISC.resultadosReservaCognitiva.idiomas', ...]\n",
      "\t\t('int', ['bool']) :  8 | ['ISC.FPacientes.genero', 'ISC.resultadosObservacion.alcohol', 'ISC.resultadosObservacion.ansiedad', 'ISC.resultadosObservacion.depresion', 'ISC.resultadosObservacion.enfermedadesDiabetes', ...]\n",
      "\t0.1s = Fit runtime\n",
      "\t67 features in original data used to generate 67 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.17 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.14s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'roc_auc'\n",
      "\tThis metric expects predicted probabilities rather than predicted class labels, so you'll need to use predict_proba() instead of predict()\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Large model count detected (112 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': [{}, {'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2}}, {'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7}}],\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\n",
      "\t'CAT': [{}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5}}],\n",
      "\t'XGB': [{}, {'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'name_suffix': '_r33', 'priority': -8}}, {'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'name_suffix': '_r89', 'priority': -16}}],\n",
      "\t'FASTAI': [{}, {'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4}}, {'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11}}],\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Excluded models: ['RF', 'KNN', 'XT'] (Specified by `excluded_model_types`)\n",
      "Fitting 90 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 442.22s of the 663.49s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.52%)\n",
      "\t0.8842\t = Validation score   (roc_auc)\n",
      "\t1.01s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 435.22s of the 656.49s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.79%)\n",
      "\t0.8934\t = Validation score   (roc_auc)\n",
      "\t1.92s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L1 ... Training model for up to 430.01s of the 651.27s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=1.28%)\n",
      "\t0.9166\t = Validation score   (roc_auc)\n",
      "\t12.37s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 414.52s of the 635.79s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.07%)\n",
      "\t0.8969\t = Validation score   (roc_auc)\n",
      "\t6.96s\t = Training   runtime\n",
      "\t0.09s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L1 ... Training model for up to 404.78s of the 626.05s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=2.03%)\n",
      "\t0.8879\t = Validation score   (roc_auc)\n",
      "\t2.06s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_BAG_L1 ... Training model for up to 399.35s of the 620.62s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.04%)\n",
      "\tWarning: Exception caused NeuralNetTorch_BAG_L1 to fail during training... Skipping this model.\n",
      "\t\t\u001b[36mray::_ray_fit()\u001b[39m (pid=17024, ip=127.0.0.1)\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1889, in ray._raylet.execute_task\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 201, in _fit\n",
      "    train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "    dataset = self._process_train_data(\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "    self.processor = create_preprocessor(\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\utils\\data_preprocessor.py\", line 40, in create_preprocessor\n",
      "    return ColumnTransformer(\n",
      "TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 2106, in _train_and_save\n",
      "    model = self._train_single(**model_fit_kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 1993, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\stacker_ensemble_model.py\", line 270, in _fit\n",
      "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\bagged_ensemble_model.py\", line 298, in _fit\n",
      "    self._fit_folds(\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\bagged_ensemble_model.py\", line 724, in _fit_folds\n",
      "    fold_fitting_strategy.after_all_folds_scheduled()\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 690, in after_all_folds_scheduled\n",
      "    self._run_parallel(X, y, X_pseudo, y_pseudo, model_base_ref, time_limit_fold, head_node_id)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 631, in _run_parallel\n",
      "    self._process_fold_results(finished, unfinished, fold_ctx)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 587, in _process_fold_results\n",
      "    raise processed_exception\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 550, in _process_fold_results\n",
      "    fold_model, pred_proba, time_start_fit, time_end_fit, predict_time, predict_1_time, predict_n_size, fit_num_cpus, fit_num_gpus = self.ray.get(finished)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\worker.py\", line 2667, in get\n",
      "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\worker.py\", line 864, in get_objects\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(TypeError): \u001b[36mray::_ray_fit()\u001b[39m (pid=17024, ip=127.0.0.1)\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1889, in ray._raylet.execute_task\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 201, in _fit\n",
      "    train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "    dataset = self._process_train_data(\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "    self.processor = create_preprocessor(\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\utils\\data_preprocessor.py\", line 40, in create_preprocessor\n",
      "    return ColumnTransformer(\n",
      "TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "Fitting model: LightGBMLarge_BAG_L1 ... Training model for up to 392.91s of the 614.18s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=2.85%)\n",
      "\t0.8596\t = Validation score   (roc_auc)\n",
      "\t2.58s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: CatBoost_r177_BAG_L1 ... Training model for up to 387.61s of the 608.88s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=1.14%)\n",
      "2025-01-26 23:59:04,805\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-26 23:59:04,809\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-26 23:59:04,813\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-26 23:59:04,818\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\t0.91\t = Validation score   (roc_auc)\n",
      "\t12.87s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r79_BAG_L1 ... Training model for up to 371.94s of the 593.19s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.03%)\n",
      "\tWarning: Exception caused NeuralNetTorch_r79_BAG_L1 to fail during training... Skipping this model.\n",
      "\t\t\u001b[36mray::_ray_fit()\u001b[39m (pid=24916, ip=127.0.0.1)\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1889, in ray._raylet.execute_task\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 201, in _fit\n",
      "    train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "    dataset = self._process_train_data(\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "    self.processor = create_preprocessor(\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\utils\\data_preprocessor.py\", line 40, in create_preprocessor\n",
      "    return ColumnTransformer(\n",
      "TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 2106, in _train_and_save\n",
      "    model = self._train_single(**model_fit_kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 1993, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\stacker_ensemble_model.py\", line 270, in _fit\n",
      "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\bagged_ensemble_model.py\", line 298, in _fit\n",
      "    self._fit_folds(\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\bagged_ensemble_model.py\", line 724, in _fit_folds\n",
      "    fold_fitting_strategy.after_all_folds_scheduled()\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 690, in after_all_folds_scheduled\n",
      "    self._run_parallel(X, y, X_pseudo, y_pseudo, model_base_ref, time_limit_fold, head_node_id)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 631, in _run_parallel\n",
      "    self._process_fold_results(finished, unfinished, fold_ctx)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 587, in _process_fold_results\n",
      "    raise processed_exception\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 550, in _process_fold_results\n",
      "    fold_model, pred_proba, time_start_fit, time_end_fit, predict_time, predict_1_time, predict_n_size, fit_num_cpus, fit_num_gpus = self.ray.get(finished)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\worker.py\", line 2667, in get\n",
      "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\worker.py\", line 864, in get_objects\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(TypeError): \u001b[36mray::_ray_fit()\u001b[39m (pid=24916, ip=127.0.0.1)\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1889, in ray._raylet.execute_task\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 201, in _fit\n",
      "    train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "    dataset = self._process_train_data(\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "    self.processor = create_preprocessor(\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\utils\\data_preprocessor.py\", line 40, in create_preprocessor\n",
      "    return ColumnTransformer(\n",
      "TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "Fitting model: LightGBM_r131_BAG_L1 ... Training model for up to 366.32s of the 587.59s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=1.25%)\n",
      "\t0.8964\t = Validation score   (roc_auc)\n",
      "\t2.44s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r191_BAG_L1 ... Training model for up to 361.09s of the 582.36s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.08%)\n",
      "2025-01-26 23:59:30,986\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-26 23:59:31,001\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-26 23:59:31,003\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-26 23:59:31,007\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-26 23:59:31,009\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\t0.9019\t = Validation score   (roc_auc)\n",
      "\t7.4s\t = Training   runtime\n",
      "\t0.1s\t = Validation runtime\n",
      "Fitting model: CatBoost_r9_BAG_L1 ... Training model for up to 351.00s of the 572.27s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=7.37%)\n",
      "\t0.9082\t = Validation score   (roc_auc)\n",
      "\t282.46s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: LightGBM_r96_BAG_L1 ... Training model for up to 65.44s of the 286.71s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.18%)\n",
      "\t0.8786\t = Validation score   (roc_auc)\n",
      "\t3.36s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r22_BAG_L1 ... Training model for up to 59.42s of the 280.69s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.03%)\n",
      "\tWarning: Exception caused NeuralNetTorch_r22_BAG_L1 to fail during training... Skipping this model.\n",
      "\t\t\u001b[36mray::_ray_fit()\u001b[39m (pid=8288, ip=127.0.0.1)\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1889, in ray._raylet.execute_task\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 201, in _fit\n",
      "    train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "    dataset = self._process_train_data(\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "    self.processor = create_preprocessor(\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\utils\\data_preprocessor.py\", line 40, in create_preprocessor\n",
      "    return ColumnTransformer(\n",
      "TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 2106, in _train_and_save\n",
      "    model = self._train_single(**model_fit_kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 1993, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\stacker_ensemble_model.py\", line 270, in _fit\n",
      "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\bagged_ensemble_model.py\", line 298, in _fit\n",
      "    self._fit_folds(\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\bagged_ensemble_model.py\", line 724, in _fit_folds\n",
      "    fold_fitting_strategy.after_all_folds_scheduled()\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 690, in after_all_folds_scheduled\n",
      "    self._run_parallel(X, y, X_pseudo, y_pseudo, model_base_ref, time_limit_fold, head_node_id)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 631, in _run_parallel\n",
      "    self._process_fold_results(finished, unfinished, fold_ctx)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 587, in _process_fold_results\n",
      "    raise processed_exception\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 550, in _process_fold_results\n",
      "    fold_model, pred_proba, time_start_fit, time_end_fit, predict_time, predict_1_time, predict_n_size, fit_num_cpus, fit_num_gpus = self.ray.get(finished)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\worker.py\", line 2667, in get\n",
      "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\worker.py\", line 864, in get_objects\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(TypeError): \u001b[36mray::_ray_fit()\u001b[39m (pid=8288, ip=127.0.0.1)\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1889, in ray._raylet.execute_task\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 201, in _fit\n",
      "    train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "    dataset = self._process_train_data(\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "    self.processor = create_preprocessor(\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\utils\\data_preprocessor.py\", line 40, in create_preprocessor\n",
      "    return ColumnTransformer(\n",
      "TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "Fitting model: XGBoost_r33_BAG_L1 ... Training model for up to 53.58s of the 274.85s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=6.91%)\n",
      "2025-01-27 00:04:44,061\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-27 00:04:44,065\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-27 00:04:44,069\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-27 00:04:44,071\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-27 00:04:44,073\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-27 00:04:44,078\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\t0.892\t = Validation score   (roc_auc)\n",
      "\t4.73s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: CatBoost_r137_BAG_L1 ... Training model for up to 46.34s of the 267.61s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.19%)\n",
      "\t0.9084\t = Validation score   (roc_auc)\n",
      "\t6.8s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r102_BAG_L1 ... Training model for up to 37.08s of the 258.35s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.05%)\n",
      "\t0.9037\t = Validation score   (roc_auc)\n",
      "\t8.59s\t = Training   runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitting model: CatBoost_r13_BAG_L1 ... Training model for up to 25.87s of the 247.14s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=3.66%)\n",
      "\t0.906\t = Validation score   (roc_auc)\n",
      "\t21.36s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: LightGBM_r188_BAG_L1 ... Training model for up to 0.79s of the 222.06s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=1.01%)\n",
      "\t0.8921\t = Validation score   (roc_auc)\n",
      "\t1.64s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 360.00s of the 216.45s of remaining time.\n",
      "\tEnsemble Weights: {'CatBoost_BAG_L1': 0.5, 'NeuralNetFastAI_r102_BAG_L1': 0.5}\n",
      "\t0.9366\t = Validation score   (roc_auc)\n",
      "\t0.04s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Excluded models: ['RF', 'KNN', 'XT'] (Specified by `excluded_model_types`)\n",
      "Fitting 90 L2 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBMXT_BAG_L2 ... Training model for up to 216.39s of the 216.29s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.26%)\n",
      "\t0.9333\t = Validation score   (roc_auc)\n",
      "\t1.86s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L2 ... Training model for up to 211.82s of the 211.72s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.28%)\n",
      "\t0.9182\t = Validation score   (roc_auc)\n",
      "\t1.86s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L2 ... Training model for up to 207.06s of the 206.96s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.55%)\n",
      "2025-01-27 00:05:58,920\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-27 00:05:58,923\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-27 00:05:58,925\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\t0.9289\t = Validation score   (roc_auc)\n",
      "\t12.35s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L2 ... Training model for up to 191.84s of the 191.75s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.03%)\n",
      "\t0.9142\t = Validation score   (roc_auc)\n",
      "\t6.42s\t = Training   runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L2 ... Training model for up to 182.86s of the 182.76s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.74%)\n",
      "\t0.918\t = Validation score   (roc_auc)\n",
      "\t2.05s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_BAG_L2 ... Training model for up to 177.47s of the 177.37s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.02%)\n",
      "\tWarning: Exception caused NeuralNetTorch_BAG_L2 to fail during training... Skipping this model.\n",
      "\t\t\u001b[36mray::_ray_fit()\u001b[39m (pid=18036, ip=127.0.0.1)\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1889, in ray._raylet.execute_task\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 201, in _fit\n",
      "    train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "    dataset = self._process_train_data(\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "    self.processor = create_preprocessor(\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\utils\\data_preprocessor.py\", line 40, in create_preprocessor\n",
      "    return ColumnTransformer(\n",
      "TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 2106, in _train_and_save\n",
      "    model = self._train_single(**model_fit_kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 1993, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\stacker_ensemble_model.py\", line 270, in _fit\n",
      "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\bagged_ensemble_model.py\", line 298, in _fit\n",
      "    self._fit_folds(\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\bagged_ensemble_model.py\", line 724, in _fit_folds\n",
      "    fold_fitting_strategy.after_all_folds_scheduled()\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 690, in after_all_folds_scheduled\n",
      "    self._run_parallel(X, y, X_pseudo, y_pseudo, model_base_ref, time_limit_fold, head_node_id)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 631, in _run_parallel\n",
      "    self._process_fold_results(finished, unfinished, fold_ctx)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 587, in _process_fold_results\n",
      "    raise processed_exception\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 550, in _process_fold_results\n",
      "    fold_model, pred_proba, time_start_fit, time_end_fit, predict_time, predict_1_time, predict_n_size, fit_num_cpus, fit_num_gpus = self.ray.get(finished)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\worker.py\", line 2667, in get\n",
      "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\worker.py\", line 864, in get_objects\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(TypeError): \u001b[36mray::_ray_fit()\u001b[39m (pid=18036, ip=127.0.0.1)\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1889, in ray._raylet.execute_task\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 201, in _fit\n",
      "    train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "    dataset = self._process_train_data(\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "    self.processor = create_preprocessor(\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\utils\\data_preprocessor.py\", line 40, in create_preprocessor\n",
      "    return ColumnTransformer(\n",
      "TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "Fitting model: LightGBMLarge_BAG_L2 ... Training model for up to 171.50s of the 171.41s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=1.32%)\n",
      "2025-01-27 00:06:25,487\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-27 00:06:25,505\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\t0.9035\t = Validation score   (roc_auc)\n",
      "\t2.7s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: CatBoost_r177_BAG_L2 ... Training model for up to 166.13s of the 166.03s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.69%)\n",
      "2025-01-27 00:06:27,787\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-27 00:06:27,791\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-27 00:06:27,795\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\t0.9276\t = Validation score   (roc_auc)\n",
      "\t8.3s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r79_BAG_L2 ... Training model for up to 154.88s of the 154.79s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.02%)\n",
      "\tWarning: Exception caused NeuralNetTorch_r79_BAG_L2 to fail during training... Skipping this model.\n",
      "\t\t\u001b[36mray::_ray_fit()\u001b[39m (pid=1868, ip=127.0.0.1)\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1889, in ray._raylet.execute_task\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 201, in _fit\n",
      "    train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "    dataset = self._process_train_data(\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "    self.processor = create_preprocessor(\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\utils\\data_preprocessor.py\", line 40, in create_preprocessor\n",
      "    return ColumnTransformer(\n",
      "TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 2106, in _train_and_save\n",
      "    model = self._train_single(**model_fit_kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 1993, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\stacker_ensemble_model.py\", line 270, in _fit\n",
      "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\bagged_ensemble_model.py\", line 298, in _fit\n",
      "    self._fit_folds(\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\bagged_ensemble_model.py\", line 724, in _fit_folds\n",
      "    fold_fitting_strategy.after_all_folds_scheduled()\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 690, in after_all_folds_scheduled\n",
      "    self._run_parallel(X, y, X_pseudo, y_pseudo, model_base_ref, time_limit_fold, head_node_id)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 631, in _run_parallel\n",
      "    self._process_fold_results(finished, unfinished, fold_ctx)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 587, in _process_fold_results\n",
      "    raise processed_exception\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 550, in _process_fold_results\n",
      "    fold_model, pred_proba, time_start_fit, time_end_fit, predict_time, predict_1_time, predict_n_size, fit_num_cpus, fit_num_gpus = self.ray.get(finished)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\worker.py\", line 2667, in get\n",
      "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\worker.py\", line 864, in get_objects\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(TypeError): \u001b[36mray::_ray_fit()\u001b[39m (pid=1868, ip=127.0.0.1)\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1889, in ray._raylet.execute_task\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 201, in _fit\n",
      "    train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "    dataset = self._process_train_data(\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "    self.processor = create_preprocessor(\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\utils\\data_preprocessor.py\", line 40, in create_preprocessor\n",
      "    return ColumnTransformer(\n",
      "TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "Fitting model: LightGBM_r131_BAG_L2 ... Training model for up to 148.97s of the 148.87s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.78%)\n",
      "\t0.9176\t = Validation score   (roc_auc)\n",
      "\t2.48s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r191_BAG_L2 ... Training model for up to 143.70s of the 143.60s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.05%)\n",
      "2025-01-27 00:06:49,971\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-27 00:06:49,972\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-27 00:06:49,978\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-27 00:06:49,980\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-27 00:06:49,983\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\t0.914\t = Validation score   (roc_auc)\n",
      "\t7.3s\t = Training   runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitting model: CatBoost_r9_BAG_L2 ... Training model for up to 133.74s of the 133.64s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=4.99%)\n",
      "\t0.9255\t = Validation score   (roc_auc)\n",
      "\t26.3s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: LightGBM_r96_BAG_L2 ... Training model for up to 104.14s of the 104.04s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.18%)\n",
      "\t0.931\t = Validation score   (roc_auc)\n",
      "\t3.58s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r22_BAG_L2 ... Training model for up to 98.04s of the 97.94s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.02%)\n",
      "\tWarning: Exception caused NeuralNetTorch_r22_BAG_L2 to fail during training... Skipping this model.\n",
      "\t\t\u001b[36mray::_ray_fit()\u001b[39m (pid=23080, ip=127.0.0.1)\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1889, in ray._raylet.execute_task\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 201, in _fit\n",
      "    train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "    dataset = self._process_train_data(\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "    self.processor = create_preprocessor(\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\utils\\data_preprocessor.py\", line 40, in create_preprocessor\n",
      "    return ColumnTransformer(\n",
      "TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 2106, in _train_and_save\n",
      "    model = self._train_single(**model_fit_kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 1993, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\stacker_ensemble_model.py\", line 270, in _fit\n",
      "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\bagged_ensemble_model.py\", line 298, in _fit\n",
      "    self._fit_folds(\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\bagged_ensemble_model.py\", line 724, in _fit_folds\n",
      "    fold_fitting_strategy.after_all_folds_scheduled()\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 690, in after_all_folds_scheduled\n",
      "    self._run_parallel(X, y, X_pseudo, y_pseudo, model_base_ref, time_limit_fold, head_node_id)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 631, in _run_parallel\n",
      "    self._process_fold_results(finished, unfinished, fold_ctx)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 587, in _process_fold_results\n",
      "    raise processed_exception\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 550, in _process_fold_results\n",
      "    fold_model, pred_proba, time_start_fit, time_end_fit, predict_time, predict_1_time, predict_n_size, fit_num_cpus, fit_num_gpus = self.ray.get(finished)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\worker.py\", line 2667, in get\n",
      "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\ray\\_private\\worker.py\", line 864, in get_objects\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(TypeError): \u001b[36mray::_ray_fit()\u001b[39m (pid=23080, ip=127.0.0.1)\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1889, in ray._raylet.execute_task\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 201, in _fit\n",
      "    train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "    dataset = self._process_train_data(\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "    self.processor = create_preprocessor(\n",
      "  File \"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\utils\\data_preprocessor.py\", line 40, in create_preprocessor\n",
      "    return ColumnTransformer(\n",
      "TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "Fitting model: XGBoost_r33_BAG_L2 ... Training model for up to 92.17s of the 92.07s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=7.64%)\n",
      "2025-01-27 00:07:46,423\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-27 00:07:46,427\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-27 00:07:46,431\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-27 00:07:46,435\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-27 00:07:46,439\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\t0.9207\t = Validation score   (roc_auc)\n",
      "\t3.08s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: CatBoost_r137_BAG_L2 ... Training model for up to 86.35s of the 86.26s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.26%)\n",
      "\t0.9279\t = Validation score   (roc_auc)\n",
      "\t6.47s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r102_BAG_L2 ... Training model for up to 77.02s of the 76.93s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.05%)\n",
      "\t0.9055\t = Validation score   (roc_auc)\n",
      "\t8.97s\t = Training   runtime\n",
      "\t0.12s\t = Validation runtime\n",
      "Fitting model: CatBoost_r13_BAG_L2 ... Training model for up to 65.38s of the 65.28s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=4.12%)\n",
      "\t0.9278\t = Validation score   (roc_auc)\n",
      "\t53.14s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: LightGBM_r188_BAG_L2 ... Training model for up to 9.20s of the 9.10s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=1.32%)\n",
      "\t0.9344\t = Validation score   (roc_auc)\n",
      "\t1.95s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ... Training model for up to 360.00s of the 4.40s of remaining time.\n",
      "\tEnsemble Weights: {'LightGBM_r188_BAG_L2': 0.692, 'CatBoost_BAG_L2': 0.231, 'NeuralNetFastAI_BAG_L2': 0.077}\n",
      "\t0.9358\t = Validation score   (roc_auc)\n",
      "\t0.05s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 659.3s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 340.2 rows/s (47 batch size)\n",
      "Automatically performing refit_full as a post-fit operation (due to `.fit(..., refit_full=True)`\n",
      "Refitting models via `predictor.refit_full` using all of the data (combined train and validation)...\n",
      "\tModels trained in this way will have the suffix \"_FULL\" and have NaN validation score.\n",
      "\tThis process is not bound by time_limit, but should take less time than the original `predictor.fit` call.\n",
      "\tTo learn more, refer to the `.refit_full` method docstring which explains how \"_FULL\" models differ from normal models.\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBMXT_BAG_L1_FULL ...\n",
      "\t0.38s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBM_BAG_L1_FULL ...\n",
      "\t0.13s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: CatBoost_BAG_L1_FULL ...\n",
      "\t1.05s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: NeuralNetFastAI_BAG_L1_FULL ...\n",
      "\tStopping at the best epoch learned earlier - 11.\n",
      "\t0.45s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: XGBoost_BAG_L1_FULL ...\n",
      "\t0.1s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBMLarge_BAG_L1_FULL ...\n",
      "\t0.24s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: CatBoost_r177_BAG_L1_FULL ...\n",
      "\t0.65s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBM_r131_BAG_L1_FULL ...\n",
      "\t0.25s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: NeuralNetFastAI_r191_BAG_L1_FULL ...\n",
      "\tStopping at the best epoch learned earlier - 8.\n",
      "\t0.36s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: CatBoost_r9_BAG_L1_FULL ...\n",
      "\t12.47s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBM_r96_BAG_L1_FULL ...\n",
      "\t0.34s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: XGBoost_r33_BAG_L1_FULL ...\n",
      "\t0.5s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: CatBoost_r137_BAG_L1_FULL ...\n",
      "\t0.52s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: NeuralNetFastAI_r102_BAG_L1_FULL ...\n",
      "\tStopping at the best epoch learned earlier - 5.\n",
      "\t0.73s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: CatBoost_r13_BAG_L1_FULL ...\n",
      "\t3.86s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBM_r188_BAG_L1_FULL ...\n",
      "\t0.21s\t = Training   runtime\n",
      "Fitting model: WeightedEnsemble_L2_FULL | Skipping fit via cloning parent ...\n",
      "\tEnsemble Weights: {'CatBoost_BAG_L1': 0.5, 'NeuralNetFastAI_r102_BAG_L1': 0.5}\n",
      "\t0.04s\t = Training   runtime\n",
      "Fitting 1 L2 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBMXT_BAG_L2_FULL ...\n",
      "\t0.14s\t = Training   runtime\n",
      "Fitting 1 L2 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBM_BAG_L2_FULL ...\n",
      "\t0.12s\t = Training   runtime\n",
      "Fitting 1 L2 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: CatBoost_BAG_L2_FULL ...\n",
      "\t0.68s\t = Training   runtime\n",
      "Fitting 1 L2 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: NeuralNetFastAI_BAG_L2_FULL ...\n",
      "\tStopping at the best epoch learned earlier - 10.\n",
      "\t0.33s\t = Training   runtime\n",
      "Fitting 1 L2 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: XGBoost_BAG_L2_FULL ...\n",
      "\t0.06s\t = Training   runtime\n",
      "Fitting 1 L2 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBMLarge_BAG_L2_FULL ...\n",
      "\t0.2s\t = Training   runtime\n",
      "Fitting 1 L2 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: CatBoost_r177_BAG_L2_FULL ...\n",
      "\t0.34s\t = Training   runtime\n",
      "Fitting 1 L2 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBM_r131_BAG_L2_FULL ...\n",
      "\t0.2s\t = Training   runtime\n",
      "Fitting 1 L2 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: NeuralNetFastAI_r191_BAG_L2_FULL ...\n",
      "\tStopping at the best epoch learned earlier - 6.\n",
      "\t0.31s\t = Training   runtime\n",
      "Fitting 1 L2 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: CatBoost_r9_BAG_L2_FULL ...\n",
      "\t1.58s\t = Training   runtime\n",
      "Fitting 1 L2 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBM_r96_BAG_L2_FULL ...\n",
      "\t0.19s\t = Training   runtime\n",
      "Fitting 1 L2 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: XGBoost_r33_BAG_L2_FULL ...\n",
      "\t0.2s\t = Training   runtime\n",
      "Fitting 1 L2 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: CatBoost_r137_BAG_L2_FULL ...\n",
      "\t0.39s\t = Training   runtime\n",
      "Fitting 1 L2 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: NeuralNetFastAI_r102_BAG_L2_FULL ...\n",
      "\tStopping at the best epoch learned earlier - 1.\n",
      "\t0.32s\t = Training   runtime\n",
      "Fitting 1 L2 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: CatBoost_r13_BAG_L2_FULL ...\n",
      "\t3.63s\t = Training   runtime\n",
      "Fitting 1 L2 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBM_r188_BAG_L2_FULL ...\n",
      "\t0.16s\t = Training   runtime\n",
      "Fitting model: WeightedEnsemble_L3_FULL | Skipping fit via cloning parent ...\n",
      "\tEnsemble Weights: {'LightGBM_r188_BAG_L2': 0.692, 'CatBoost_BAG_L2': 0.231, 'NeuralNetFastAI_BAG_L2': 0.077}\n",
      "\t0.05s\t = Training   runtime\n",
      "Updated best model to \"WeightedEnsemble_L2_FULL\" (Previously \"WeightedEnsemble_L2\"). AutoGluon will default to using \"WeightedEnsemble_L2_FULL\" for predict() and predict_proba().\n",
      "Refit complete, total runtime = 35.07s ... Best model: \"WeightedEnsemble_L2_FULL\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\autogluon\\tlp\\AutogluonModels\\synthetic\\llm\\v1\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<autogluon.tabular.predictor.predictor.TabularPredictor at 0x20d4cda0c70>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.fit(\n",
    "    train_data = df_train,\n",
    "    presets = ['high_quality'],\n",
    "    time_limit = 00,\n",
    "    auto_stack = True,\n",
    "    excluded_model_types=['KNN','RF','XT', 'LR'],\n",
    "    verbosity = 2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Summary of fit() ***\n",
      "Estimated performance of each model:\n",
      "                               model  score_val eval_metric  pred_time_val    fit_time  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
      "0                WeightedEnsemble_L2   0.936649     roc_auc       0.138155   20.997499                0.000000           0.035488            2      False         17\n",
      "1                WeightedEnsemble_L3   0.935801     roc_auc       0.354326   48.907775                0.001000           0.047008            3      False         34\n",
      "2               LightGBM_r188_BAG_L2   0.934358     roc_auc       0.232352   30.086994                0.017817           1.953573            2      False         33\n",
      "3                  LightGBMXT_BAG_L2   0.933339     roc_auc       0.225541   29.992403                0.011006           1.858983            2      False         18\n",
      "4                LightGBM_r96_BAG_L2   0.930991     roc_auc       0.238528   31.716395                0.023993           3.582975            2      False         28\n",
      "5                    CatBoost_BAG_L2   0.928869     roc_auc       0.263233   40.484546                0.048698          12.351126            2      False         20\n",
      "6               CatBoost_r137_BAG_L2   0.927935     roc_auc       0.274376   34.601844                0.059841           6.468423            2      False         30\n",
      "7                CatBoost_r13_BAG_L2   0.927765     roc_auc       0.275273   81.274566                0.060738          53.141146            2      False         32\n",
      "8               CatBoost_r177_BAG_L2   0.927624     roc_auc       0.225602   36.429641                0.011067           8.296221            2      False         24\n",
      "9                 CatBoost_r9_BAG_L2   0.925502     roc_auc       0.272984   54.434885                0.058449          26.301465            2      False         27\n",
      "10                XGBoost_r33_BAG_L2   0.920692     roc_auc       0.245525   31.214155                0.030990           3.080734            2      False         29\n",
      "11                   LightGBM_BAG_L2   0.918216     roc_auc       0.245557   29.997507                0.031022           1.864086            2      False         19\n",
      "12                    XGBoost_BAG_L2   0.917975     roc_auc       0.236677   30.186174                0.022142           2.052753            2      False         22\n",
      "13              LightGBM_r131_BAG_L2   0.917636     roc_auc       0.220003   30.613745                0.005468           2.480325            2      False         25\n",
      "14                   CatBoost_BAG_L1   0.916645     roc_auc       0.058228   12.367277                0.058228          12.367277            1      False          3\n",
      "15            NeuralNetFastAI_BAG_L2   0.914184     roc_auc       0.286810   34.556068                0.072275           6.422647            2      False         21\n",
      "16       NeuralNetFastAI_r191_BAG_L2   0.914042     roc_auc       0.293851   35.433421                0.079316           7.300000            2      False         26\n",
      "17              CatBoost_r177_BAG_L1   0.909996     roc_auc       0.025390   12.866225                0.025390          12.866225            1      False          7\n",
      "18              CatBoost_r137_BAG_L1   0.908384     roc_auc       0.039102    6.802753                0.039102           6.802753            1      False         13\n",
      "19                CatBoost_r9_BAG_L1   0.908214     roc_auc       0.058563  282.460722                0.058563         282.460722            1      False         10\n",
      "20               CatBoost_r13_BAG_L1   0.906035     roc_auc       0.040562   21.360332                0.040562          21.360332            1      False         15\n",
      "21       NeuralNetFastAI_r102_BAG_L2   0.905498     roc_auc       0.330436   37.100012                0.115901           8.966592            2      False         31\n",
      "22       NeuralNetFastAI_r102_BAG_L1   0.903743     roc_auc       0.079926    8.594735                0.079926           8.594735            1      False         14\n",
      "23              LightGBMLarge_BAG_L2   0.903517     roc_auc       0.233096   30.838174                0.018561           2.704754            2      False         23\n",
      "24       NeuralNetFastAI_r191_BAG_L1   0.901876     roc_auc       0.098693    7.398013                0.098693           7.398013            1      False          9\n",
      "25            NeuralNetFastAI_BAG_L1   0.896896     roc_auc       0.087386    6.964970                0.087386           6.964970            1      False          4\n",
      "26              LightGBM_r131_BAG_L1   0.896443     roc_auc       0.026381    2.437257                0.026381           2.437257            1      False          8\n",
      "27                   LightGBM_BAG_L1   0.893359     roc_auc       0.011824    1.924657                0.011824           1.924657            1      False          2\n",
      "28              LightGBM_r188_BAG_L1   0.892114     roc_auc       0.017051    1.635364                0.017051           1.635364            1      False         16\n",
      "29                XGBoost_r33_BAG_L1   0.892001     roc_auc       0.050000    4.734151                0.050000           4.734151            1      False         12\n",
      "30                    XGBoost_BAG_L1   0.887927     roc_auc       0.015386    2.059904                0.015386           2.059904            1      False          5\n",
      "31                 LightGBMXT_BAG_L1   0.884192     roc_auc       0.021249    1.006346                0.021249           1.006346            1      False          1\n",
      "32               LightGBM_r96_BAG_L1   0.878562     roc_auc       0.053524    3.355938                0.053524           3.355938            1      False         11\n",
      "33              LightGBMLarge_BAG_L1   0.859576     roc_auc       0.035016    2.582947                0.035016           2.582947            1      False          6\n",
      "34           XGBoost_r33_BAG_L2_FULL        NaN     roc_auc            NaN    2.732406                     NaN           0.199574            2       True         63\n",
      "35           XGBoost_r33_BAG_L1_FULL        NaN     roc_auc            NaN    0.500267                     NaN           0.500267            1       True         46\n",
      "36               XGBoost_BAG_L2_FULL        NaN     roc_auc            NaN    2.597584                     NaN           0.064752            2       True         56\n",
      "37               XGBoost_BAG_L1_FULL        NaN     roc_auc            NaN    0.104091                     NaN           0.104091            1       True         39\n",
      "38          WeightedEnsemble_L3_FULL        NaN     roc_auc            NaN    3.751481                     NaN           0.047008            3       True         68\n",
      "39          WeightedEnsemble_L2_FULL        NaN     roc_auc            NaN    1.817718                     NaN           0.035488            2       True         51\n",
      "40  NeuralNetFastAI_r191_BAG_L2_FULL        NaN     roc_auc            NaN    2.839063                     NaN           0.306231            2       True         60\n",
      "41  NeuralNetFastAI_r191_BAG_L1_FULL        NaN     roc_auc            NaN    0.361677                     NaN           0.361677            1       True         43\n",
      "42  NeuralNetFastAI_r102_BAG_L2_FULL        NaN     roc_auc            NaN    2.849591                     NaN           0.316759            2       True         65\n",
      "43  NeuralNetFastAI_r102_BAG_L1_FULL        NaN     roc_auc            NaN    0.731622                     NaN           0.731622            1       True         48\n",
      "44       NeuralNetFastAI_BAG_L2_FULL        NaN     roc_auc            NaN    2.863387                     NaN           0.330555            2       True         55\n",
      "45       NeuralNetFastAI_BAG_L1_FULL        NaN     roc_auc            NaN    0.454179                     NaN           0.454179            1       True         38\n",
      "46          LightGBM_r96_BAG_L2_FULL        NaN     roc_auc            NaN    2.722111                     NaN           0.189279            2       True         62\n",
      "47          LightGBM_r96_BAG_L1_FULL        NaN     roc_auc            NaN    0.337599                     NaN           0.337599            1       True         45\n",
      "48         LightGBM_r188_BAG_L2_FULL        NaN     roc_auc            NaN    2.693116                     NaN           0.160284            2       True         67\n",
      "49         LightGBM_r188_BAG_L1_FULL        NaN     roc_auc            NaN    0.212257                     NaN           0.212257            1       True         50\n",
      "50         LightGBM_r131_BAG_L2_FULL        NaN     roc_auc            NaN    2.736904                     NaN           0.204072            2       True         59\n",
      "51         LightGBM_r131_BAG_L1_FULL        NaN     roc_auc            NaN    0.250335                     NaN           0.250335            1       True         42\n",
      "52              LightGBM_BAG_L2_FULL        NaN     roc_auc            NaN    2.654673                     NaN           0.121841            2       True         53\n",
      "53              LightGBM_BAG_L1_FULL        NaN     roc_auc            NaN    0.129242                     NaN           0.129242            1       True         36\n",
      "54            LightGBMXT_BAG_L2_FULL        NaN     roc_auc            NaN    2.670382                     NaN           0.137550            2       True         52\n",
      "55            LightGBMXT_BAG_L1_FULL        NaN     roc_auc            NaN    0.381888                     NaN           0.381888            1       True         35\n",
      "56         LightGBMLarge_BAG_L2_FULL        NaN     roc_auc            NaN    2.733172                     NaN           0.200340            2       True         57\n",
      "57         LightGBMLarge_BAG_L1_FULL        NaN     roc_auc            NaN    0.242321                     NaN           0.242321            1       True         40\n",
      "58           CatBoost_r9_BAG_L2_FULL        NaN     roc_auc            NaN    4.109240                     NaN           1.576408            2       True         61\n",
      "59           CatBoost_r9_BAG_L1_FULL        NaN     roc_auc            NaN   12.467319                     NaN          12.467319            1       True         44\n",
      "60         CatBoost_r177_BAG_L2_FULL        NaN     roc_auc            NaN    2.874568                     NaN           0.341736            2       True         58\n",
      "61         CatBoost_r177_BAG_L1_FULL        NaN     roc_auc            NaN    0.646950                     NaN           0.646950            1       True         41\n",
      "62          CatBoost_r13_BAG_L2_FULL        NaN     roc_auc            NaN    6.158011                     NaN           3.625180            2       True         66\n",
      "63          CatBoost_r13_BAG_L1_FULL        NaN     roc_auc            NaN    3.857709                     NaN           3.857709            1       True         49\n",
      "64         CatBoost_r137_BAG_L2_FULL        NaN     roc_auc            NaN    2.924256                     NaN           0.391424            2       True         64\n",
      "65         CatBoost_r137_BAG_L1_FULL        NaN     roc_auc            NaN    0.515452                     NaN           0.515452            1       True         47\n",
      "66              CatBoost_BAG_L2_FULL        NaN     roc_auc            NaN    3.213634                     NaN           0.680802            2       True         54\n",
      "67              CatBoost_BAG_L1_FULL        NaN     roc_auc            NaN    1.050608                     NaN           1.050608            1       True         37\n",
      "Number of models trained: 68\n",
      "Types of models trained:\n",
      "{'StackerEnsembleModel_NNFastAiTabular', 'StackerEnsembleModel_CatBoost', 'StackerEnsembleModel_XGBoost', 'StackerEnsembleModel_LGB', 'WeightedEnsembleModel'}\n",
      "Bagging used: True  (with 8 folds)\n",
      "Multi-layer stack-ensembling used: True  (with 3 levels)\n",
      "Feature Metadata (Processed):\n",
      "(raw dtype, special dtypes):\n",
      "('float', [])     : 15 | ['TLP.FigRey.Copia.PD', 'TLP.FigRey.Memoria.PD', 'TLP.Stroop.interferencia.PD', 'TLP.Tavec.04_Rg-Pr.PD', 'TLP.Tavec.05_Rg-Md.PD', ...]\n",
      "('int', [])       : 44 | ['ISC.FPacientes.Edad', 'ISC.resultadosCribaje.Total.PD', 'ISC.resultadosReservaCognitiva.Total.PD', 'ISC.resultadosReservaCognitiva.escolaridad', 'ISC.resultadosReservaCognitiva.idiomas', ...]\n",
      "('int', ['bool']) :  8 | ['ISC.FPacientes.genero', 'ISC.resultadosObservacion.alcohol', 'ISC.resultadosObservacion.ansiedad', 'ISC.resultadosObservacion.depresion', 'ISC.resultadosObservacion.enfermedadesDiabetes', ...]\n",
      "Plot summary of models saved to file: c:\\Users\\jgala\\uned\\tfm\\synthetic-data\\autogluon\\tlp\\AutogluonModels\\synthetic\\llm\\v1SummaryOfModels.html\n",
      "*** End of fit() summary ***\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'model_types': {'LightGBMXT_BAG_L1': 'StackerEnsembleModel_LGB',\n",
       "  'LightGBM_BAG_L1': 'StackerEnsembleModel_LGB',\n",
       "  'CatBoost_BAG_L1': 'StackerEnsembleModel_CatBoost',\n",
       "  'NeuralNetFastAI_BAG_L1': 'StackerEnsembleModel_NNFastAiTabular',\n",
       "  'XGBoost_BAG_L1': 'StackerEnsembleModel_XGBoost',\n",
       "  'LightGBMLarge_BAG_L1': 'StackerEnsembleModel_LGB',\n",
       "  'CatBoost_r177_BAG_L1': 'StackerEnsembleModel_CatBoost',\n",
       "  'LightGBM_r131_BAG_L1': 'StackerEnsembleModel_LGB',\n",
       "  'NeuralNetFastAI_r191_BAG_L1': 'StackerEnsembleModel_NNFastAiTabular',\n",
       "  'CatBoost_r9_BAG_L1': 'StackerEnsembleModel_CatBoost',\n",
       "  'LightGBM_r96_BAG_L1': 'StackerEnsembleModel_LGB',\n",
       "  'XGBoost_r33_BAG_L1': 'StackerEnsembleModel_XGBoost',\n",
       "  'CatBoost_r137_BAG_L1': 'StackerEnsembleModel_CatBoost',\n",
       "  'NeuralNetFastAI_r102_BAG_L1': 'StackerEnsembleModel_NNFastAiTabular',\n",
       "  'CatBoost_r13_BAG_L1': 'StackerEnsembleModel_CatBoost',\n",
       "  'LightGBM_r188_BAG_L1': 'StackerEnsembleModel_LGB',\n",
       "  'WeightedEnsemble_L2': 'WeightedEnsembleModel',\n",
       "  'LightGBMXT_BAG_L2': 'StackerEnsembleModel_LGB',\n",
       "  'LightGBM_BAG_L2': 'StackerEnsembleModel_LGB',\n",
       "  'CatBoost_BAG_L2': 'StackerEnsembleModel_CatBoost',\n",
       "  'NeuralNetFastAI_BAG_L2': 'StackerEnsembleModel_NNFastAiTabular',\n",
       "  'XGBoost_BAG_L2': 'StackerEnsembleModel_XGBoost',\n",
       "  'LightGBMLarge_BAG_L2': 'StackerEnsembleModel_LGB',\n",
       "  'CatBoost_r177_BAG_L2': 'StackerEnsembleModel_CatBoost',\n",
       "  'LightGBM_r131_BAG_L2': 'StackerEnsembleModel_LGB',\n",
       "  'NeuralNetFastAI_r191_BAG_L2': 'StackerEnsembleModel_NNFastAiTabular',\n",
       "  'CatBoost_r9_BAG_L2': 'StackerEnsembleModel_CatBoost',\n",
       "  'LightGBM_r96_BAG_L2': 'StackerEnsembleModel_LGB',\n",
       "  'XGBoost_r33_BAG_L2': 'StackerEnsembleModel_XGBoost',\n",
       "  'CatBoost_r137_BAG_L2': 'StackerEnsembleModel_CatBoost',\n",
       "  'NeuralNetFastAI_r102_BAG_L2': 'StackerEnsembleModel_NNFastAiTabular',\n",
       "  'CatBoost_r13_BAG_L2': 'StackerEnsembleModel_CatBoost',\n",
       "  'LightGBM_r188_BAG_L2': 'StackerEnsembleModel_LGB',\n",
       "  'WeightedEnsemble_L3': 'WeightedEnsembleModel',\n",
       "  'LightGBMXT_BAG_L1_FULL': 'StackerEnsembleModel_LGB',\n",
       "  'LightGBM_BAG_L1_FULL': 'StackerEnsembleModel_LGB',\n",
       "  'CatBoost_BAG_L1_FULL': 'StackerEnsembleModel_CatBoost',\n",
       "  'NeuralNetFastAI_BAG_L1_FULL': 'StackerEnsembleModel_NNFastAiTabular',\n",
       "  'XGBoost_BAG_L1_FULL': 'StackerEnsembleModel_XGBoost',\n",
       "  'LightGBMLarge_BAG_L1_FULL': 'StackerEnsembleModel_LGB',\n",
       "  'CatBoost_r177_BAG_L1_FULL': 'StackerEnsembleModel_CatBoost',\n",
       "  'LightGBM_r131_BAG_L1_FULL': 'StackerEnsembleModel_LGB',\n",
       "  'NeuralNetFastAI_r191_BAG_L1_FULL': 'StackerEnsembleModel_NNFastAiTabular',\n",
       "  'CatBoost_r9_BAG_L1_FULL': 'StackerEnsembleModel_CatBoost',\n",
       "  'LightGBM_r96_BAG_L1_FULL': 'StackerEnsembleModel_LGB',\n",
       "  'XGBoost_r33_BAG_L1_FULL': 'StackerEnsembleModel_XGBoost',\n",
       "  'CatBoost_r137_BAG_L1_FULL': 'StackerEnsembleModel_CatBoost',\n",
       "  'NeuralNetFastAI_r102_BAG_L1_FULL': 'StackerEnsembleModel_NNFastAiTabular',\n",
       "  'CatBoost_r13_BAG_L1_FULL': 'StackerEnsembleModel_CatBoost',\n",
       "  'LightGBM_r188_BAG_L1_FULL': 'StackerEnsembleModel_LGB',\n",
       "  'WeightedEnsemble_L2_FULL': 'WeightedEnsembleModel',\n",
       "  'LightGBMXT_BAG_L2_FULL': 'StackerEnsembleModel_LGB',\n",
       "  'LightGBM_BAG_L2_FULL': 'StackerEnsembleModel_LGB',\n",
       "  'CatBoost_BAG_L2_FULL': 'StackerEnsembleModel_CatBoost',\n",
       "  'NeuralNetFastAI_BAG_L2_FULL': 'StackerEnsembleModel_NNFastAiTabular',\n",
       "  'XGBoost_BAG_L2_FULL': 'StackerEnsembleModel_XGBoost',\n",
       "  'LightGBMLarge_BAG_L2_FULL': 'StackerEnsembleModel_LGB',\n",
       "  'CatBoost_r177_BAG_L2_FULL': 'StackerEnsembleModel_CatBoost',\n",
       "  'LightGBM_r131_BAG_L2_FULL': 'StackerEnsembleModel_LGB',\n",
       "  'NeuralNetFastAI_r191_BAG_L2_FULL': 'StackerEnsembleModel_NNFastAiTabular',\n",
       "  'CatBoost_r9_BAG_L2_FULL': 'StackerEnsembleModel_CatBoost',\n",
       "  'LightGBM_r96_BAG_L2_FULL': 'StackerEnsembleModel_LGB',\n",
       "  'XGBoost_r33_BAG_L2_FULL': 'StackerEnsembleModel_XGBoost',\n",
       "  'CatBoost_r137_BAG_L2_FULL': 'StackerEnsembleModel_CatBoost',\n",
       "  'NeuralNetFastAI_r102_BAG_L2_FULL': 'StackerEnsembleModel_NNFastAiTabular',\n",
       "  'CatBoost_r13_BAG_L2_FULL': 'StackerEnsembleModel_CatBoost',\n",
       "  'LightGBM_r188_BAG_L2_FULL': 'StackerEnsembleModel_LGB',\n",
       "  'WeightedEnsemble_L3_FULL': 'WeightedEnsembleModel'},\n",
       " 'model_performance': {'LightGBMXT_BAG_L1': 0.8841920606626488,\n",
       "  'LightGBM_BAG_L1': 0.8933593639475993,\n",
       "  'CatBoost_BAG_L1': 0.9166454460572108,\n",
       "  'NeuralNetFastAI_BAG_L1': 0.8968961321902498,\n",
       "  'XGBoost_BAG_L1': 0.8879268879268879,\n",
       "  'LightGBMLarge_BAG_L1': 0.8595761536938009,\n",
       "  'CatBoost_r177_BAG_L1': 0.9099963217610276,\n",
       "  'LightGBM_r131_BAG_L1': 0.8964434258551907,\n",
       "  'NeuralNetFastAI_r191_BAG_L1': 0.9018759018759019,\n",
       "  'CatBoost_r9_BAG_L1': 0.9082137905667317,\n",
       "  'LightGBM_r96_BAG_L1': 0.8785615256203491,\n",
       "  'XGBoost_r33_BAG_L1': 0.8920012449424215,\n",
       "  'CatBoost_r137_BAG_L1': 0.9083835554423789,\n",
       "  'NeuralNetFastAI_r102_BAG_L1': 0.9037433155080214,\n",
       "  'CatBoost_r13_BAG_L1': 0.9060351413292591,\n",
       "  'LightGBM_r188_BAG_L1': 0.8921144215261864,\n",
       "  'WeightedEnsemble_L2': 0.9366494072376427,\n",
       "  'LightGBMXT_BAG_L2': 0.9333389921625217,\n",
       "  'LightGBM_BAG_L2': 0.9182157711569476,\n",
       "  'CatBoost_BAG_L2': 0.9288685171038111,\n",
       "  'NeuralNetFastAI_BAG_L2': 0.9141838553603259,\n",
       "  'XGBoost_BAG_L2': 0.9179752709164474,\n",
       "  'LightGBMLarge_BAG_L2': 0.9035169623404918,\n",
       "  'CatBoost_r177_BAG_L2': 0.9276235746823982,\n",
       "  'LightGBM_r131_BAG_L2': 0.9176357411651529,\n",
       "  'NeuralNetFastAI_r191_BAG_L2': 0.91404238463062,\n",
       "  'CatBoost_r9_BAG_L2': 0.9255015137368079,\n",
       "  'LightGBM_r96_BAG_L2': 0.9309905780494016,\n",
       "  'XGBoost_r33_BAG_L2': 0.9206915089268031,\n",
       "  'CatBoost_r137_BAG_L2': 0.9279348102877515,\n",
       "  'NeuralNetFastAI_r102_BAG_L2': 0.9054975525563761,\n",
       "  'CatBoost_r13_BAG_L2': 0.9277650454121043,\n",
       "  'LightGBM_r188_BAG_L2': 0.9343575814164049,\n",
       "  'WeightedEnsemble_L3': 0.9358005828594063,\n",
       "  'LightGBMXT_BAG_L1_FULL': None,\n",
       "  'LightGBM_BAG_L1_FULL': None,\n",
       "  'CatBoost_BAG_L1_FULL': None,\n",
       "  'NeuralNetFastAI_BAG_L1_FULL': None,\n",
       "  'XGBoost_BAG_L1_FULL': None,\n",
       "  'LightGBMLarge_BAG_L1_FULL': None,\n",
       "  'CatBoost_r177_BAG_L1_FULL': None,\n",
       "  'LightGBM_r131_BAG_L1_FULL': None,\n",
       "  'NeuralNetFastAI_r191_BAG_L1_FULL': None,\n",
       "  'CatBoost_r9_BAG_L1_FULL': None,\n",
       "  'LightGBM_r96_BAG_L1_FULL': None,\n",
       "  'XGBoost_r33_BAG_L1_FULL': None,\n",
       "  'CatBoost_r137_BAG_L1_FULL': None,\n",
       "  'NeuralNetFastAI_r102_BAG_L1_FULL': None,\n",
       "  'CatBoost_r13_BAG_L1_FULL': None,\n",
       "  'LightGBM_r188_BAG_L1_FULL': None,\n",
       "  'WeightedEnsemble_L2_FULL': None,\n",
       "  'LightGBMXT_BAG_L2_FULL': None,\n",
       "  'LightGBM_BAG_L2_FULL': None,\n",
       "  'CatBoost_BAG_L2_FULL': None,\n",
       "  'NeuralNetFastAI_BAG_L2_FULL': None,\n",
       "  'XGBoost_BAG_L2_FULL': None,\n",
       "  'LightGBMLarge_BAG_L2_FULL': None,\n",
       "  'CatBoost_r177_BAG_L2_FULL': None,\n",
       "  'LightGBM_r131_BAG_L2_FULL': None,\n",
       "  'NeuralNetFastAI_r191_BAG_L2_FULL': None,\n",
       "  'CatBoost_r9_BAG_L2_FULL': None,\n",
       "  'LightGBM_r96_BAG_L2_FULL': None,\n",
       "  'XGBoost_r33_BAG_L2_FULL': None,\n",
       "  'CatBoost_r137_BAG_L2_FULL': None,\n",
       "  'NeuralNetFastAI_r102_BAG_L2_FULL': None,\n",
       "  'CatBoost_r13_BAG_L2_FULL': None,\n",
       "  'LightGBM_r188_BAG_L2_FULL': None,\n",
       "  'WeightedEnsemble_L3_FULL': None},\n",
       " 'model_best': 'WeightedEnsemble_L2_FULL',\n",
       " 'model_paths': {'LightGBMXT_BAG_L1': ['LightGBMXT_BAG_L1'],\n",
       "  'LightGBM_BAG_L1': ['LightGBM_BAG_L1'],\n",
       "  'CatBoost_BAG_L1': ['CatBoost_BAG_L1'],\n",
       "  'NeuralNetFastAI_BAG_L1': ['NeuralNetFastAI_BAG_L1'],\n",
       "  'XGBoost_BAG_L1': ['XGBoost_BAG_L1'],\n",
       "  'LightGBMLarge_BAG_L1': ['LightGBMLarge_BAG_L1'],\n",
       "  'CatBoost_r177_BAG_L1': ['CatBoost_r177_BAG_L1'],\n",
       "  'LightGBM_r131_BAG_L1': ['LightGBM_r131_BAG_L1'],\n",
       "  'NeuralNetFastAI_r191_BAG_L1': ['NeuralNetFastAI_r191_BAG_L1'],\n",
       "  'CatBoost_r9_BAG_L1': ['CatBoost_r9_BAG_L1'],\n",
       "  'LightGBM_r96_BAG_L1': ['LightGBM_r96_BAG_L1'],\n",
       "  'XGBoost_r33_BAG_L1': ['XGBoost_r33_BAG_L1'],\n",
       "  'CatBoost_r137_BAG_L1': ['CatBoost_r137_BAG_L1'],\n",
       "  'NeuralNetFastAI_r102_BAG_L1': ['NeuralNetFastAI_r102_BAG_L1'],\n",
       "  'CatBoost_r13_BAG_L1': ['CatBoost_r13_BAG_L1'],\n",
       "  'LightGBM_r188_BAG_L1': ['LightGBM_r188_BAG_L1'],\n",
       "  'WeightedEnsemble_L2': ['WeightedEnsemble_L2'],\n",
       "  'LightGBMXT_BAG_L2': ['LightGBMXT_BAG_L2'],\n",
       "  'LightGBM_BAG_L2': ['LightGBM_BAG_L2'],\n",
       "  'CatBoost_BAG_L2': ['CatBoost_BAG_L2'],\n",
       "  'NeuralNetFastAI_BAG_L2': ['NeuralNetFastAI_BAG_L2'],\n",
       "  'XGBoost_BAG_L2': ['XGBoost_BAG_L2'],\n",
       "  'LightGBMLarge_BAG_L2': ['LightGBMLarge_BAG_L2'],\n",
       "  'CatBoost_r177_BAG_L2': ['CatBoost_r177_BAG_L2'],\n",
       "  'LightGBM_r131_BAG_L2': ['LightGBM_r131_BAG_L2'],\n",
       "  'NeuralNetFastAI_r191_BAG_L2': ['NeuralNetFastAI_r191_BAG_L2'],\n",
       "  'CatBoost_r9_BAG_L2': ['CatBoost_r9_BAG_L2'],\n",
       "  'LightGBM_r96_BAG_L2': ['LightGBM_r96_BAG_L2'],\n",
       "  'XGBoost_r33_BAG_L2': ['XGBoost_r33_BAG_L2'],\n",
       "  'CatBoost_r137_BAG_L2': ['CatBoost_r137_BAG_L2'],\n",
       "  'NeuralNetFastAI_r102_BAG_L2': ['NeuralNetFastAI_r102_BAG_L2'],\n",
       "  'CatBoost_r13_BAG_L2': ['CatBoost_r13_BAG_L2'],\n",
       "  'LightGBM_r188_BAG_L2': ['LightGBM_r188_BAG_L2'],\n",
       "  'WeightedEnsemble_L3': ['WeightedEnsemble_L3'],\n",
       "  'LightGBMXT_BAG_L1_FULL': ['LightGBMXT_BAG_L1_FULL'],\n",
       "  'LightGBM_BAG_L1_FULL': ['LightGBM_BAG_L1_FULL'],\n",
       "  'CatBoost_BAG_L1_FULL': ['CatBoost_BAG_L1_FULL'],\n",
       "  'NeuralNetFastAI_BAG_L1_FULL': ['NeuralNetFastAI_BAG_L1_FULL'],\n",
       "  'XGBoost_BAG_L1_FULL': ['XGBoost_BAG_L1_FULL'],\n",
       "  'LightGBMLarge_BAG_L1_FULL': ['LightGBMLarge_BAG_L1_FULL'],\n",
       "  'CatBoost_r177_BAG_L1_FULL': ['CatBoost_r177_BAG_L1_FULL'],\n",
       "  'LightGBM_r131_BAG_L1_FULL': ['LightGBM_r131_BAG_L1_FULL'],\n",
       "  'NeuralNetFastAI_r191_BAG_L1_FULL': ['NeuralNetFastAI_r191_BAG_L1_FULL'],\n",
       "  'CatBoost_r9_BAG_L1_FULL': ['CatBoost_r9_BAG_L1_FULL'],\n",
       "  'LightGBM_r96_BAG_L1_FULL': ['LightGBM_r96_BAG_L1_FULL'],\n",
       "  'XGBoost_r33_BAG_L1_FULL': ['XGBoost_r33_BAG_L1_FULL'],\n",
       "  'CatBoost_r137_BAG_L1_FULL': ['CatBoost_r137_BAG_L1_FULL'],\n",
       "  'NeuralNetFastAI_r102_BAG_L1_FULL': ['NeuralNetFastAI_r102_BAG_L1_FULL'],\n",
       "  'CatBoost_r13_BAG_L1_FULL': ['CatBoost_r13_BAG_L1_FULL'],\n",
       "  'LightGBM_r188_BAG_L1_FULL': ['LightGBM_r188_BAG_L1_FULL'],\n",
       "  'WeightedEnsemble_L2_FULL': ['WeightedEnsemble_L2_FULL'],\n",
       "  'LightGBMXT_BAG_L2_FULL': ['LightGBMXT_BAG_L2_FULL'],\n",
       "  'LightGBM_BAG_L2_FULL': ['LightGBM_BAG_L2_FULL'],\n",
       "  'CatBoost_BAG_L2_FULL': ['CatBoost_BAG_L2_FULL'],\n",
       "  'NeuralNetFastAI_BAG_L2_FULL': ['NeuralNetFastAI_BAG_L2_FULL'],\n",
       "  'XGBoost_BAG_L2_FULL': ['XGBoost_BAG_L2_FULL'],\n",
       "  'LightGBMLarge_BAG_L2_FULL': ['LightGBMLarge_BAG_L2_FULL'],\n",
       "  'CatBoost_r177_BAG_L2_FULL': ['CatBoost_r177_BAG_L2_FULL'],\n",
       "  'LightGBM_r131_BAG_L2_FULL': ['LightGBM_r131_BAG_L2_FULL'],\n",
       "  'NeuralNetFastAI_r191_BAG_L2_FULL': ['NeuralNetFastAI_r191_BAG_L2_FULL'],\n",
       "  'CatBoost_r9_BAG_L2_FULL': ['CatBoost_r9_BAG_L2_FULL'],\n",
       "  'LightGBM_r96_BAG_L2_FULL': ['LightGBM_r96_BAG_L2_FULL'],\n",
       "  'XGBoost_r33_BAG_L2_FULL': ['XGBoost_r33_BAG_L2_FULL'],\n",
       "  'CatBoost_r137_BAG_L2_FULL': ['CatBoost_r137_BAG_L2_FULL'],\n",
       "  'NeuralNetFastAI_r102_BAG_L2_FULL': ['NeuralNetFastAI_r102_BAG_L2_FULL'],\n",
       "  'CatBoost_r13_BAG_L2_FULL': ['CatBoost_r13_BAG_L2_FULL'],\n",
       "  'LightGBM_r188_BAG_L2_FULL': ['LightGBM_r188_BAG_L2_FULL'],\n",
       "  'WeightedEnsemble_L3_FULL': ['WeightedEnsemble_L3_FULL']},\n",
       " 'model_fit_times': {'LightGBMXT_BAG_L1': 1.0063459873199463,\n",
       "  'LightGBM_BAG_L1': 1.924656629562378,\n",
       "  'CatBoost_BAG_L1': 12.367276668548584,\n",
       "  'NeuralNetFastAI_BAG_L1': 6.964970111846924,\n",
       "  'XGBoost_BAG_L1': 2.0599043369293213,\n",
       "  'LightGBMLarge_BAG_L1': 2.582947015762329,\n",
       "  'CatBoost_r177_BAG_L1': 12.866224527359009,\n",
       "  'LightGBM_r131_BAG_L1': 2.4372572898864746,\n",
       "  'NeuralNetFastAI_r191_BAG_L1': 7.398013114929199,\n",
       "  'CatBoost_r9_BAG_L1': 282.46072220802307,\n",
       "  'LightGBM_r96_BAG_L1': 3.3559377193450928,\n",
       "  'XGBoost_r33_BAG_L1': 4.734151363372803,\n",
       "  'CatBoost_r137_BAG_L1': 6.80275297164917,\n",
       "  'NeuralNetFastAI_r102_BAG_L1': 8.594734907150269,\n",
       "  'CatBoost_r13_BAG_L1': 21.360332012176514,\n",
       "  'LightGBM_r188_BAG_L1': 1.635364055633545,\n",
       "  'WeightedEnsemble_L2': 0.03548789024353027,\n",
       "  'LightGBMXT_BAG_L2': 1.858982801437378,\n",
       "  'LightGBM_BAG_L2': 1.864086389541626,\n",
       "  'CatBoost_BAG_L2': 12.351126194000244,\n",
       "  'NeuralNetFastAI_BAG_L2': 6.422647476196289,\n",
       "  'XGBoost_BAG_L2': 2.052753448486328,\n",
       "  'LightGBMLarge_BAG_L2': 2.704753875732422,\n",
       "  'CatBoost_r177_BAG_L2': 8.296221256256104,\n",
       "  'LightGBM_r131_BAG_L2': 2.4803249835968018,\n",
       "  'NeuralNetFastAI_r191_BAG_L2': 7.300000429153442,\n",
       "  'CatBoost_r9_BAG_L2': 26.301465034484863,\n",
       "  'LightGBM_r96_BAG_L2': 3.582974910736084,\n",
       "  'XGBoost_r33_BAG_L2': 3.0807344913482666,\n",
       "  'CatBoost_r137_BAG_L2': 6.468423366546631,\n",
       "  'NeuralNetFastAI_r102_BAG_L2': 8.966591596603394,\n",
       "  'CatBoost_r13_BAG_L2': 53.14114570617676,\n",
       "  'LightGBM_r188_BAG_L2': 1.95357346534729,\n",
       "  'WeightedEnsemble_L3': 0.04700803756713867,\n",
       "  'LightGBMXT_BAG_L1_FULL': 0.38188815116882324,\n",
       "  'LightGBM_BAG_L1_FULL': 0.1292421817779541,\n",
       "  'CatBoost_BAG_L1_FULL': 1.0506083965301514,\n",
       "  'NeuralNetFastAI_BAG_L1_FULL': 0.4541785717010498,\n",
       "  'XGBoost_BAG_L1_FULL': 0.10409116744995117,\n",
       "  'LightGBMLarge_BAG_L1_FULL': 0.24232101440429688,\n",
       "  'CatBoost_r177_BAG_L1_FULL': 0.6469500064849854,\n",
       "  'LightGBM_r131_BAG_L1_FULL': 0.2503347396850586,\n",
       "  'NeuralNetFastAI_r191_BAG_L1_FULL': 0.3616769313812256,\n",
       "  'CatBoost_r9_BAG_L1_FULL': 12.46731948852539,\n",
       "  'LightGBM_r96_BAG_L1_FULL': 0.3375990390777588,\n",
       "  'XGBoost_r33_BAG_L1_FULL': 0.5002667903900146,\n",
       "  'CatBoost_r137_BAG_L1_FULL': 0.5154523849487305,\n",
       "  'NeuralNetFastAI_r102_BAG_L1_FULL': 0.7316219806671143,\n",
       "  'CatBoost_r13_BAG_L1_FULL': 3.8577094078063965,\n",
       "  'LightGBM_r188_BAG_L1_FULL': 0.21225666999816895,\n",
       "  'WeightedEnsemble_L2_FULL': 0.03548789024353027,\n",
       "  'LightGBMXT_BAG_L2_FULL': 0.13754963874816895,\n",
       "  'LightGBM_BAG_L2_FULL': 0.1218409538269043,\n",
       "  'CatBoost_BAG_L2_FULL': 0.6808023452758789,\n",
       "  'NeuralNetFastAI_BAG_L2_FULL': 0.3305552005767822,\n",
       "  'XGBoost_BAG_L2_FULL': 0.06475210189819336,\n",
       "  'LightGBMLarge_BAG_L2_FULL': 0.20034003257751465,\n",
       "  'CatBoost_r177_BAG_L2_FULL': 0.3417356014251709,\n",
       "  'LightGBM_r131_BAG_L2_FULL': 0.2040717601776123,\n",
       "  'NeuralNetFastAI_r191_BAG_L2_FULL': 0.3062310218811035,\n",
       "  'CatBoost_r9_BAG_L2_FULL': 1.5764079093933105,\n",
       "  'LightGBM_r96_BAG_L2_FULL': 0.18927860260009766,\n",
       "  'XGBoost_r33_BAG_L2_FULL': 0.19957375526428223,\n",
       "  'CatBoost_r137_BAG_L2_FULL': 0.39142441749572754,\n",
       "  'NeuralNetFastAI_r102_BAG_L2_FULL': 0.3167586326599121,\n",
       "  'CatBoost_r13_BAG_L2_FULL': 3.6251795291900635,\n",
       "  'LightGBM_r188_BAG_L2_FULL': 0.16028380393981934,\n",
       "  'WeightedEnsemble_L3_FULL': 0.04700803756713867},\n",
       " 'model_pred_times': {'LightGBMXT_BAG_L1': 0.021248817443847656,\n",
       "  'LightGBM_BAG_L1': 0.011824369430541992,\n",
       "  'CatBoost_BAG_L1': 0.058228492736816406,\n",
       "  'NeuralNetFastAI_BAG_L1': 0.0873863697052002,\n",
       "  'XGBoost_BAG_L1': 0.015386104583740234,\n",
       "  'LightGBMLarge_BAG_L1': 0.03501629829406738,\n",
       "  'CatBoost_r177_BAG_L1': 0.025390148162841797,\n",
       "  'LightGBM_r131_BAG_L1': 0.026380538940429688,\n",
       "  'NeuralNetFastAI_r191_BAG_L1': 0.0986928939819336,\n",
       "  'CatBoost_r9_BAG_L1': 0.058563232421875,\n",
       "  'LightGBM_r96_BAG_L1': 0.053524017333984375,\n",
       "  'XGBoost_r33_BAG_L1': 0.04999971389770508,\n",
       "  'CatBoost_r137_BAG_L1': 0.03910183906555176,\n",
       "  'NeuralNetFastAI_r102_BAG_L1': 0.0799262523651123,\n",
       "  'CatBoost_r13_BAG_L1': 0.04056239128112793,\n",
       "  'LightGBM_r188_BAG_L1': 0.017050504684448242,\n",
       "  'WeightedEnsemble_L2': 0.0,\n",
       "  'LightGBMXT_BAG_L2': 0.011006355285644531,\n",
       "  'LightGBM_BAG_L2': 0.031021833419799805,\n",
       "  'CatBoost_BAG_L2': 0.04869818687438965,\n",
       "  'NeuralNetFastAI_BAG_L2': 0.07227540016174316,\n",
       "  'XGBoost_BAG_L2': 0.022141695022583008,\n",
       "  'LightGBMLarge_BAG_L2': 0.01856088638305664,\n",
       "  'CatBoost_r177_BAG_L2': 0.011067390441894531,\n",
       "  'LightGBM_r131_BAG_L2': 0.0054683685302734375,\n",
       "  'NeuralNetFastAI_r191_BAG_L2': 0.0793156623840332,\n",
       "  'CatBoost_r9_BAG_L2': 0.05844879150390625,\n",
       "  'LightGBM_r96_BAG_L2': 0.023992538452148438,\n",
       "  'XGBoost_r33_BAG_L2': 0.030989885330200195,\n",
       "  'CatBoost_r137_BAG_L2': 0.05984067916870117,\n",
       "  'NeuralNetFastAI_r102_BAG_L2': 0.11590099334716797,\n",
       "  'CatBoost_r13_BAG_L2': 0.06073808670043945,\n",
       "  'LightGBM_r188_BAG_L2': 0.017816781997680664,\n",
       "  'WeightedEnsemble_L3': 0.0010004043579101562,\n",
       "  'LightGBMXT_BAG_L1_FULL': None,\n",
       "  'LightGBM_BAG_L1_FULL': None,\n",
       "  'CatBoost_BAG_L1_FULL': None,\n",
       "  'NeuralNetFastAI_BAG_L1_FULL': None,\n",
       "  'XGBoost_BAG_L1_FULL': None,\n",
       "  'LightGBMLarge_BAG_L1_FULL': None,\n",
       "  'CatBoost_r177_BAG_L1_FULL': None,\n",
       "  'LightGBM_r131_BAG_L1_FULL': None,\n",
       "  'NeuralNetFastAI_r191_BAG_L1_FULL': None,\n",
       "  'CatBoost_r9_BAG_L1_FULL': None,\n",
       "  'LightGBM_r96_BAG_L1_FULL': None,\n",
       "  'XGBoost_r33_BAG_L1_FULL': None,\n",
       "  'CatBoost_r137_BAG_L1_FULL': None,\n",
       "  'NeuralNetFastAI_r102_BAG_L1_FULL': None,\n",
       "  'CatBoost_r13_BAG_L1_FULL': None,\n",
       "  'LightGBM_r188_BAG_L1_FULL': None,\n",
       "  'WeightedEnsemble_L2_FULL': None,\n",
       "  'LightGBMXT_BAG_L2_FULL': None,\n",
       "  'LightGBM_BAG_L2_FULL': None,\n",
       "  'CatBoost_BAG_L2_FULL': None,\n",
       "  'NeuralNetFastAI_BAG_L2_FULL': None,\n",
       "  'XGBoost_BAG_L2_FULL': None,\n",
       "  'LightGBMLarge_BAG_L2_FULL': None,\n",
       "  'CatBoost_r177_BAG_L2_FULL': None,\n",
       "  'LightGBM_r131_BAG_L2_FULL': None,\n",
       "  'NeuralNetFastAI_r191_BAG_L2_FULL': None,\n",
       "  'CatBoost_r9_BAG_L2_FULL': None,\n",
       "  'LightGBM_r96_BAG_L2_FULL': None,\n",
       "  'XGBoost_r33_BAG_L2_FULL': None,\n",
       "  'CatBoost_r137_BAG_L2_FULL': None,\n",
       "  'NeuralNetFastAI_r102_BAG_L2_FULL': None,\n",
       "  'CatBoost_r13_BAG_L2_FULL': None,\n",
       "  'LightGBM_r188_BAG_L2_FULL': None,\n",
       "  'WeightedEnsemble_L3_FULL': None},\n",
       " 'num_bag_folds': 8,\n",
       " 'max_stack_level': 3,\n",
       " 'num_classes': 2,\n",
       " 'model_hyperparams': {'LightGBMXT_BAG_L1': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': False},\n",
       "  'LightGBM_BAG_L1': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': False},\n",
       "  'CatBoost_BAG_L1': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': False},\n",
       "  'NeuralNetFastAI_BAG_L1': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': False},\n",
       "  'XGBoost_BAG_L1': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': False},\n",
       "  'LightGBMLarge_BAG_L1': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': False},\n",
       "  'CatBoost_r177_BAG_L1': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': False},\n",
       "  'LightGBM_r131_BAG_L1': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': False},\n",
       "  'NeuralNetFastAI_r191_BAG_L1': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': False},\n",
       "  'CatBoost_r9_BAG_L1': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': False},\n",
       "  'LightGBM_r96_BAG_L1': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': False},\n",
       "  'XGBoost_r33_BAG_L1': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': False},\n",
       "  'CatBoost_r137_BAG_L1': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': False},\n",
       "  'NeuralNetFastAI_r102_BAG_L1': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': False},\n",
       "  'CatBoost_r13_BAG_L1': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': False},\n",
       "  'LightGBM_r188_BAG_L1': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': False},\n",
       "  'WeightedEnsemble_L2': {'use_orig_features': False,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True},\n",
       "  'LightGBMXT_BAG_L2': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': False},\n",
       "  'LightGBM_BAG_L2': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': False},\n",
       "  'CatBoost_BAG_L2': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': False},\n",
       "  'NeuralNetFastAI_BAG_L2': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': False},\n",
       "  'XGBoost_BAG_L2': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': False},\n",
       "  'LightGBMLarge_BAG_L2': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': False},\n",
       "  'CatBoost_r177_BAG_L2': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': False},\n",
       "  'LightGBM_r131_BAG_L2': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': False},\n",
       "  'NeuralNetFastAI_r191_BAG_L2': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': False},\n",
       "  'CatBoost_r9_BAG_L2': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': False},\n",
       "  'LightGBM_r96_BAG_L2': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': False},\n",
       "  'XGBoost_r33_BAG_L2': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': False},\n",
       "  'CatBoost_r137_BAG_L2': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': False},\n",
       "  'NeuralNetFastAI_r102_BAG_L2': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': False},\n",
       "  'CatBoost_r13_BAG_L2': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': False},\n",
       "  'LightGBM_r188_BAG_L2': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': False},\n",
       "  'WeightedEnsemble_L3': {'use_orig_features': False,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True},\n",
       "  'LightGBMXT_BAG_L1_FULL': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True},\n",
       "  'LightGBM_BAG_L1_FULL': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True},\n",
       "  'CatBoost_BAG_L1_FULL': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True},\n",
       "  'NeuralNetFastAI_BAG_L1_FULL': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True},\n",
       "  'XGBoost_BAG_L1_FULL': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True},\n",
       "  'LightGBMLarge_BAG_L1_FULL': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True},\n",
       "  'CatBoost_r177_BAG_L1_FULL': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True},\n",
       "  'LightGBM_r131_BAG_L1_FULL': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True},\n",
       "  'NeuralNetFastAI_r191_BAG_L1_FULL': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True},\n",
       "  'CatBoost_r9_BAG_L1_FULL': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True},\n",
       "  'LightGBM_r96_BAG_L1_FULL': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True},\n",
       "  'XGBoost_r33_BAG_L1_FULL': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True},\n",
       "  'CatBoost_r137_BAG_L1_FULL': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True},\n",
       "  'NeuralNetFastAI_r102_BAG_L1_FULL': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True},\n",
       "  'CatBoost_r13_BAG_L1_FULL': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True},\n",
       "  'LightGBM_r188_BAG_L1_FULL': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True},\n",
       "  'WeightedEnsemble_L2_FULL': {'use_orig_features': False,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True},\n",
       "  'LightGBMXT_BAG_L2_FULL': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True},\n",
       "  'LightGBM_BAG_L2_FULL': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True},\n",
       "  'CatBoost_BAG_L2_FULL': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True},\n",
       "  'NeuralNetFastAI_BAG_L2_FULL': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True},\n",
       "  'XGBoost_BAG_L2_FULL': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True},\n",
       "  'LightGBMLarge_BAG_L2_FULL': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True},\n",
       "  'CatBoost_r177_BAG_L2_FULL': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True},\n",
       "  'LightGBM_r131_BAG_L2_FULL': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True},\n",
       "  'NeuralNetFastAI_r191_BAG_L2_FULL': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True},\n",
       "  'CatBoost_r9_BAG_L2_FULL': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True},\n",
       "  'LightGBM_r96_BAG_L2_FULL': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True},\n",
       "  'XGBoost_r33_BAG_L2_FULL': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True},\n",
       "  'CatBoost_r137_BAG_L2_FULL': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True},\n",
       "  'NeuralNetFastAI_r102_BAG_L2_FULL': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True},\n",
       "  'CatBoost_r13_BAG_L2_FULL': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True},\n",
       "  'LightGBM_r188_BAG_L2_FULL': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True},\n",
       "  'WeightedEnsemble_L3_FULL': {'use_orig_features': False,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True}},\n",
       " 'leaderboard':                         model  score_val eval_metric  pred_time_val  \\\n",
       " 0         WeightedEnsemble_L2   0.936649     roc_auc       0.138155   \n",
       " 1         WeightedEnsemble_L3   0.935801     roc_auc       0.354326   \n",
       " 2        LightGBM_r188_BAG_L2   0.934358     roc_auc       0.232352   \n",
       " 3           LightGBMXT_BAG_L2   0.933339     roc_auc       0.225541   \n",
       " 4         LightGBM_r96_BAG_L2   0.930991     roc_auc       0.238528   \n",
       " ..                        ...        ...         ...            ...   \n",
       " 63   CatBoost_r13_BAG_L1_FULL        NaN     roc_auc            NaN   \n",
       " 64  CatBoost_r137_BAG_L2_FULL        NaN     roc_auc            NaN   \n",
       " 65  CatBoost_r137_BAG_L1_FULL        NaN     roc_auc            NaN   \n",
       " 66       CatBoost_BAG_L2_FULL        NaN     roc_auc            NaN   \n",
       " 67       CatBoost_BAG_L1_FULL        NaN     roc_auc            NaN   \n",
       " \n",
       "      fit_time  pred_time_val_marginal  fit_time_marginal  stack_level  \\\n",
       " 0   20.997499                0.000000           0.035488            2   \n",
       " 1   48.907775                0.001000           0.047008            3   \n",
       " 2   30.086994                0.017817           1.953573            2   \n",
       " 3   29.992403                0.011006           1.858983            2   \n",
       " 4   31.716395                0.023993           3.582975            2   \n",
       " ..        ...                     ...                ...          ...   \n",
       " 63   3.857709                     NaN           3.857709            1   \n",
       " 64   2.924256                     NaN           0.391424            2   \n",
       " 65   0.515452                     NaN           0.515452            1   \n",
       " 66   3.213634                     NaN           0.680802            2   \n",
       " 67   1.050608                     NaN           1.050608            1   \n",
       " \n",
       "     can_infer  fit_order  \n",
       " 0       False         17  \n",
       " 1       False         34  \n",
       " 2       False         33  \n",
       " 3       False         18  \n",
       " 4       False         28  \n",
       " ..        ...        ...  \n",
       " 63       True         49  \n",
       " 64       True         64  \n",
       " 65       True         47  \n",
       " 66       True         54  \n",
       " 67       True         37  \n",
       " \n",
       " [68 rows x 10 columns]}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.fit_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "auxiliary_metrics = ['balanced_accuracy', 'f1', 'f1_macro', 'f1_micro', 'roc_auc', 'average_precision', 'precision', 'recall', 'log_loss', 'pac_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluation: roc_auc on test data: 0.9334239130434783\n",
      "Evaluations on test data:\n",
      "{\n",
      "    \"roc_auc\": 0.9334239130434783,\n",
      "    \"accuracy\": 0.8404255319148937,\n",
      "    \"balanced_accuracy\": 0.8419384057971014,\n",
      "    \"mcc\": 0.6893623328208588,\n",
      "    \"f1\": 0.8314606741573034,\n",
      "    \"precision\": 0.9024390243902439,\n",
      "    \"recall\": 0.7708333333333334\n",
      "}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'roc_auc': 0.9334239130434783,\n",
       " 'accuracy': 0.8404255319148937,\n",
       " 'balanced_accuracy': 0.8419384057971014,\n",
       " 'mcc': 0.6893623328208588,\n",
       " 'f1': 0.8314606741573034,\n",
       " 'precision': 0.9024390243902439,\n",
       " 'recall': 0.7708333333333334}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.evaluate(\n",
    "    df_test,\n",
    "    silent = False,\n",
    "    auxiliary_metrics = auxiliary_metrics\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>score_test</th>\n",
       "      <th>balanced_accuracy</th>\n",
       "      <th>f1</th>\n",
       "      <th>f1_macro</th>\n",
       "      <th>f1_micro</th>\n",
       "      <th>roc_auc</th>\n",
       "      <th>average_precision</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>...</th>\n",
       "      <th>eval_metric</th>\n",
       "      <th>pred_time_test</th>\n",
       "      <th>pred_time_val</th>\n",
       "      <th>fit_time</th>\n",
       "      <th>pred_time_test_marginal</th>\n",
       "      <th>pred_time_val_marginal</th>\n",
       "      <th>fit_time_marginal</th>\n",
       "      <th>stack_level</th>\n",
       "      <th>can_infer</th>\n",
       "      <th>fit_order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CatBoost_BAG_L1_FULL</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>roc_auc</td>\n",
       "      <td>0.008031</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.050608</td>\n",
       "      <td>0.008031</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.050608</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CatBoost_r177_BAG_L1_FULL</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>roc_auc</td>\n",
       "      <td>0.013767</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.646950</td>\n",
       "      <td>0.013767</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.646950</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CatBoost_r137_BAG_L1_FULL</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>roc_auc</td>\n",
       "      <td>0.014653</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.515452</td>\n",
       "      <td>0.014653</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.515452</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CatBoost_r13_BAG_L1_FULL</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>roc_auc</td>\n",
       "      <td>0.017997</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.857709</td>\n",
       "      <td>0.017997</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.857709</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LightGBM_BAG_L1_FULL</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>roc_auc</td>\n",
       "      <td>0.021563</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.129242</td>\n",
       "      <td>0.021563</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.129242</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>XGBoost_r33_BAG_L1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>roc_auc</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>4.734151</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>4.734151</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>XGBoost_BAG_L1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>roc_auc</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.015386</td>\n",
       "      <td>2.059904</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.015386</td>\n",
       "      <td>2.059904</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>LightGBMXT_BAG_L1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>roc_auc</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.021249</td>\n",
       "      <td>1.006346</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.021249</td>\n",
       "      <td>1.006346</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>LightGBM_r96_BAG_L1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>roc_auc</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.053524</td>\n",
       "      <td>3.355938</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.053524</td>\n",
       "      <td>3.355938</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>LightGBMLarge_BAG_L1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>roc_auc</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.035016</td>\n",
       "      <td>2.582947</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.035016</td>\n",
       "      <td>2.582947</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>68 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        model  score_test  balanced_accuracy   f1  f1_macro  \\\n",
       "0        CatBoost_BAG_L1_FULL         1.0                1.0  1.0       1.0   \n",
       "1   CatBoost_r177_BAG_L1_FULL         1.0                1.0  1.0       1.0   \n",
       "2   CatBoost_r137_BAG_L1_FULL         1.0                1.0  1.0       1.0   \n",
       "3    CatBoost_r13_BAG_L1_FULL         1.0                1.0  1.0       1.0   \n",
       "4        LightGBM_BAG_L1_FULL         1.0                1.0  1.0       1.0   \n",
       "..                        ...         ...                ...  ...       ...   \n",
       "63         XGBoost_r33_BAG_L1         NaN                NaN  NaN       NaN   \n",
       "64             XGBoost_BAG_L1         NaN                NaN  NaN       NaN   \n",
       "65          LightGBMXT_BAG_L1         NaN                NaN  NaN       NaN   \n",
       "66        LightGBM_r96_BAG_L1         NaN                NaN  NaN       NaN   \n",
       "67       LightGBMLarge_BAG_L1         NaN                NaN  NaN       NaN   \n",
       "\n",
       "    f1_micro  roc_auc  average_precision  precision  recall  ...  eval_metric  \\\n",
       "0        1.0      1.0                1.0        1.0     1.0  ...      roc_auc   \n",
       "1        1.0      1.0                1.0        1.0     1.0  ...      roc_auc   \n",
       "2        1.0      1.0                1.0        1.0     1.0  ...      roc_auc   \n",
       "3        1.0      1.0                1.0        1.0     1.0  ...      roc_auc   \n",
       "4        1.0      1.0                1.0        1.0     1.0  ...      roc_auc   \n",
       "..       ...      ...                ...        ...     ...  ...          ...   \n",
       "63       NaN      NaN                NaN        NaN     NaN  ...      roc_auc   \n",
       "64       NaN      NaN                NaN        NaN     NaN  ...      roc_auc   \n",
       "65       NaN      NaN                NaN        NaN     NaN  ...      roc_auc   \n",
       "66       NaN      NaN                NaN        NaN     NaN  ...      roc_auc   \n",
       "67       NaN      NaN                NaN        NaN     NaN  ...      roc_auc   \n",
       "\n",
       "    pred_time_test  pred_time_val  fit_time  pred_time_test_marginal  \\\n",
       "0         0.008031            NaN  1.050608                 0.008031   \n",
       "1         0.013767            NaN  0.646950                 0.013767   \n",
       "2         0.014653            NaN  0.515452                 0.014653   \n",
       "3         0.017997            NaN  3.857709                 0.017997   \n",
       "4         0.021563            NaN  0.129242                 0.021563   \n",
       "..             ...            ...       ...                      ...   \n",
       "63             NaN       0.050000  4.734151                      NaN   \n",
       "64             NaN       0.015386  2.059904                      NaN   \n",
       "65             NaN       0.021249  1.006346                      NaN   \n",
       "66             NaN       0.053524  3.355938                      NaN   \n",
       "67             NaN       0.035016  2.582947                      NaN   \n",
       "\n",
       "    pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  \\\n",
       "0                      NaN           1.050608            1       True   \n",
       "1                      NaN           0.646950            1       True   \n",
       "2                      NaN           0.515452            1       True   \n",
       "3                      NaN           3.857709            1       True   \n",
       "4                      NaN           0.129242            1       True   \n",
       "..                     ...                ...          ...        ...   \n",
       "63                0.050000           4.734151            1      False   \n",
       "64                0.015386           2.059904            1      False   \n",
       "65                0.021249           1.006346            1      False   \n",
       "66                0.053524           3.355938            1      False   \n",
       "67                0.035016           2.582947            1      False   \n",
       "\n",
       "    fit_order  \n",
       "0          37  \n",
       "1          41  \n",
       "2          47  \n",
       "3          49  \n",
       "4          36  \n",
       "..        ...  \n",
       "63         12  \n",
       "64          5  \n",
       "65          1  \n",
       "66         11  \n",
       "67          6  \n",
       "\n",
       "[68 rows x 23 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.leaderboard(\n",
    "    df_train,\n",
    "    extra_metrics = auxiliary_metrics,\n",
    "    silent=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing feature importance via permutation shuffling for 67 features using 376 rows with 5 shuffle sets...\n",
      "\t19.52s\t= Expected runtime (3.9s per shuffle set)\n",
      "\t10.42s\t= Actual runtime (Completed 5 of 5 shuffle sets)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>importance</th>\n",
       "      <th>stddev</th>\n",
       "      <th>p_value</th>\n",
       "      <th>n</th>\n",
       "      <th>p99_high</th>\n",
       "      <th>p99_low</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>TLP.Tavec.14_ESem-RL-LP.PD</th>\n",
       "      <td>2.037179e-03</td>\n",
       "      <td>6.793542e-04</td>\n",
       "      <td>0.001287</td>\n",
       "      <td>5</td>\n",
       "      <td>3.435978e-03</td>\n",
       "      <td>6.383789e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TLP.Stroop.color.PD</th>\n",
       "      <td>1.448660e-03</td>\n",
       "      <td>4.991331e-04</td>\n",
       "      <td>0.001453</td>\n",
       "      <td>5</td>\n",
       "      <td>2.476382e-03</td>\n",
       "      <td>4.209383e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TLP.Tavec.30_RCl-LP_frente_RL-LP.PD</th>\n",
       "      <td>1.239284e-03</td>\n",
       "      <td>1.954140e-04</td>\n",
       "      <td>0.000072</td>\n",
       "      <td>5</td>\n",
       "      <td>1.641644e-03</td>\n",
       "      <td>8.369234e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TLP.Tavec.17_ESer-RL-CP.PD</th>\n",
       "      <td>7.299890e-04</td>\n",
       "      <td>6.452058e-05</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>5</td>\n",
       "      <td>8.628377e-04</td>\n",
       "      <td>5.971402e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ISC.FPacientes.Edad</th>\n",
       "      <td>7.130125e-04</td>\n",
       "      <td>2.573057e-04</td>\n",
       "      <td>0.001725</td>\n",
       "      <td>5</td>\n",
       "      <td>1.242808e-03</td>\n",
       "      <td>1.832166e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TLP.Tavec.32_Recon-Ac_frente_RCl-LP.PD</th>\n",
       "      <td>-2.220446e-17</td>\n",
       "      <td>4.965068e-17</td>\n",
       "      <td>0.813050</td>\n",
       "      <td>5</td>\n",
       "      <td>8.002698e-17</td>\n",
       "      <td>-1.244359e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TLP.Tavec.31_Recon-Ac_frente_RL-LP.PD</th>\n",
       "      <td>-1.697649e-05</td>\n",
       "      <td>1.549734e-05</td>\n",
       "      <td>0.964758</td>\n",
       "      <td>5</td>\n",
       "      <td>1.493275e-05</td>\n",
       "      <td>-4.888573e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TLP.Tavec.15_ESer-RI-A.PD</th>\n",
       "      <td>-1.697649e-05</td>\n",
       "      <td>3.796058e-05</td>\n",
       "      <td>0.813050</td>\n",
       "      <td>5</td>\n",
       "      <td>6.118487e-05</td>\n",
       "      <td>-9.513785e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ISC.resultadosObservacion.alcohol</th>\n",
       "      <td>-2.263532e-05</td>\n",
       "      <td>1.265353e-05</td>\n",
       "      <td>0.991935</td>\n",
       "      <td>5</td>\n",
       "      <td>3.418470e-06</td>\n",
       "      <td>-4.868910e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TLP.Tavec.12_ESem-RI-B.PD</th>\n",
       "      <td>-5.658829e-05</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>5</td>\n",
       "      <td>-5.658829e-05</td>\n",
       "      <td>-5.658829e-05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>67 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          importance        stddev   p_value  \\\n",
       "TLP.Tavec.14_ESem-RL-LP.PD              2.037179e-03  6.793542e-04  0.001287   \n",
       "TLP.Stroop.color.PD                     1.448660e-03  4.991331e-04  0.001453   \n",
       "TLP.Tavec.30_RCl-LP_frente_RL-LP.PD     1.239284e-03  1.954140e-04  0.000072   \n",
       "TLP.Tavec.17_ESer-RL-CP.PD              7.299890e-04  6.452058e-05  0.000007   \n",
       "ISC.FPacientes.Edad                     7.130125e-04  2.573057e-04  0.001725   \n",
       "...                                              ...           ...       ...   \n",
       "TLP.Tavec.32_Recon-Ac_frente_RCl-LP.PD -2.220446e-17  4.965068e-17  0.813050   \n",
       "TLP.Tavec.31_Recon-Ac_frente_RL-LP.PD  -1.697649e-05  1.549734e-05  0.964758   \n",
       "TLP.Tavec.15_ESer-RI-A.PD              -1.697649e-05  3.796058e-05  0.813050   \n",
       "ISC.resultadosObservacion.alcohol      -2.263532e-05  1.265353e-05  0.991935   \n",
       "TLP.Tavec.12_ESem-RI-B.PD              -5.658829e-05  0.000000e+00  0.500000   \n",
       "\n",
       "                                        n      p99_high       p99_low  \n",
       "TLP.Tavec.14_ESem-RL-LP.PD              5  3.435978e-03  6.383789e-04  \n",
       "TLP.Stroop.color.PD                     5  2.476382e-03  4.209383e-04  \n",
       "TLP.Tavec.30_RCl-LP_frente_RL-LP.PD     5  1.641644e-03  8.369234e-04  \n",
       "TLP.Tavec.17_ESer-RL-CP.PD              5  8.628377e-04  5.971402e-04  \n",
       "ISC.FPacientes.Edad                     5  1.242808e-03  1.832166e-04  \n",
       "...                                    ..           ...           ...  \n",
       "TLP.Tavec.32_Recon-Ac_frente_RCl-LP.PD  5  8.002698e-17 -1.244359e-16  \n",
       "TLP.Tavec.31_Recon-Ac_frente_RL-LP.PD   5  1.493275e-05 -4.888573e-05  \n",
       "TLP.Tavec.15_ESer-RI-A.PD               5  6.118487e-05 -9.513785e-05  \n",
       "ISC.resultadosObservacion.alcohol       5  3.418470e-06 -4.868910e-05  \n",
       "TLP.Tavec.12_ESem-RI-B.PD               5 -5.658829e-05 -5.658829e-05  \n",
       "\n",
       "[67 rows x 6 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.feature_importance(data=df_train)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
